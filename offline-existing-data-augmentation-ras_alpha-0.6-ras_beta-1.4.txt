OrderedDict([('nn_lr', 0.0001), ('reg_A', 0.001), ('eps_decay_steps', 1), ('update_freq', 1000), ('data_length', 50000), ('fqi_rep', 1)])
Data already exists at: Data/Mountaincar_50000+.npy
offline 15 Mountaincar 50000
Parameters: OrderedDict([('nn_lr', 0.001), ('reg_A', 0.001), ('eps_decay_steps', 1), ('update_freq', 1000), ('data_length', 50000), ('fqi_rep', 1)])
Nnet params: {'loss_features': 'semi_MSTDE', 'beta1': 0.0, 'beta2': 0.99, 'eps_init': 1.0, 'eps_final': 0.01, 'num_actions': 3, 'replay_memory_size': 50000, 'replay_init_size': 5000, 'batch_size': 32, 'fqi_reg_type': 'prev', 'data_aug_type': 'ras', 'data_aug_prob': 0.1, 'random_shift_pad': 4, 'ras_alpha': 0.6, 'ras_beta': 1.4}
load offline data!!!!!
/project/6029407/janjua/Offline-Online-RL-Augmentation/Offline-Online-RL/replay_memory.py:52: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  temp = T.tensor((d.item().get('state')), dtype=T.float32)
/project/6029407/janjua/Offline-Online-RL-Augmentation/Offline-Online-RL/replay_memory.py:54: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.state_memory[:len(temp), :] = T.tensor((d.item().get('state')), dtype=T.float32)
/project/6029407/janjua/Offline-Online-RL-Augmentation/Offline-Online-RL/replay_memory.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.new_state_memory[:len(temp), :] = T.tensor((d.item().get('nstate')), dtype=T.float32)
/project/6029407/janjua/Offline-Online-RL-Augmentation/Offline-Online-RL/replay_memory.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.action_memory[:len(temp)] = T.tensor((d.item().get('action')), dtype=T.int64)
/project/6029407/janjua/Offline-Online-RL-Augmentation/Offline-Online-RL/replay_memory.py:57: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.new_action_memory[:len(temp)] = T.tensor((d.item().get('naction')), dtype=T.int64)
/project/6029407/janjua/Offline-Online-RL-Augmentation/Offline-Online-RL/replay_memory.py:58: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.reward_memory[:len(temp)] = T.tensor((d.item().get('reward')), dtype=T.float32)
/project/6029407/janjua/Offline-Online-RL-Augmentation/Offline-Online-RL/replay_memory.py:59: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.terminal_memory[:len(temp)] = T.tensor((d.item().get('done')), dtype=T.bool)
mem_cntr: 50000 ; mem_size: 50000
/project/6029407/janjua/Offline-Online-RL-Augmentation/Offline-Online-RL/replay_memory.py:249: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  temp = T.tensor((d.item().get('state')), dtype=T.float32)
/project/6029407/janjua/Offline-Online-RL-Augmentation/Offline-Online-RL/replay_memory.py:251: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.state_memory[:len(temp), :] = T.tensor((d.item().get('state')), dtype=T.float32)
/project/6029407/janjua/Offline-Online-RL-Augmentation/Offline-Online-RL/replay_memory.py:252: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.new_state_memory[:len(temp), :] = T.tensor((d.item().get('nstate')), dtype=T.float32)
/project/6029407/janjua/Offline-Online-RL-Augmentation/Offline-Online-RL/replay_memory.py:253: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.action_memory[:len(temp)] = T.tensor((d.item().get('action')), dtype=T.int64)
/project/6029407/janjua/Offline-Online-RL-Augmentation/Offline-Online-RL/replay_memory.py:254: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.new_action_memory[:len(temp)] = T.tensor((d.item().get('naction')), dtype=T.int64)
/project/6029407/janjua/Offline-Online-RL-Augmentation/Offline-Online-RL/replay_memory.py:255: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.reward_memory[:len(temp)] = T.tensor((d.item().get('reward')), dtype=T.float32)
/project/6029407/janjua/Offline-Online-RL-Augmentation/Offline-Online-RL/replay_memory.py:256: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.terminal_memory[:len(temp)] = T.tensor((d.item().get('done')), dtype=T.bool)
/project/6029407/janjua/Offline-Online-RL-Augmentation/Offline-Online-RL/mix_ttn_agent_online_offline.py:155: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  states = T.tensor(state).to(self.q_eval.device)
/project/6029407/janjua/Offline-Online-RL-Augmentation/Offline-Online-RL/mix_ttn_agent_online_offline.py:156: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  rewards = T.tensor(reward).to(self.q_eval.device)
/project/6029407/janjua/Offline-Online-RL-Augmentation/Offline-Online-RL/mix_ttn_agent_online_offline.py:157: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  dones = T.tensor(done).to(self.q_eval.device)
/project/6029407/janjua/Offline-Online-RL-Augmentation/Offline-Online-RL/mix_ttn_agent_online_offline.py:158: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  actions = T.tensor(action).to(self.q_eval.device)
/project/6029407/janjua/Offline-Online-RL-Augmentation/Offline-Online-RL/mix_ttn_agent_online_offline.py:159: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  states_ = T.tensor(new_state).to(self.q_eval.device)
/project/6029407/janjua/Offline-Online-RL-Augmentation/Offline-Online-RL/mix_ttn_agent_online_offline.py:160: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  actions_ = T.tensor(new_action).to(self.q_eval.device)
/project/6029407/janjua/Offline-Online-RL-Augmentation/Offline-Online-RL/mix_ttn_agent_online_offline.py:169: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  states = T.tensor(state).to(self.q_eval.device)
/project/6029407/janjua/Offline-Online-RL-Augmentation/Offline-Online-RL/mix_ttn_agent_online_offline.py:170: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  rewards = T.tensor(reward).to(self.q_eval.device)
/project/6029407/janjua/Offline-Online-RL-Augmentation/Offline-Online-RL/mix_ttn_agent_online_offline.py:171: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  dones = T.tensor(done).to(self.q_eval.device)
/project/6029407/janjua/Offline-Online-RL-Augmentation/Offline-Online-RL/mix_ttn_agent_online_offline.py:172: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  actions = T.tensor(action).to(self.q_eval.device)
/project/6029407/janjua/Offline-Online-RL-Augmentation/Offline-Online-RL/mix_ttn_agent_online_offline.py:173: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  states_ = T.tensor(new_state).to(self.q_eval.device)
/project/6029407/janjua/Offline-Online-RL-Augmentation/Offline-Online-RL/mix_ttn_agent_online_offline.py:174: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  actions_ = T.tensor(new_action).to(self.q_eval.device)
nn.learn_nn_feature_fqi FQI:  998
/project/6029407/janjua/Offline-Online-RL-Augmentation/Offline-Online-RL/mix_ttn_agent_online_offline.py:689: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  states_all = T.tensor(self.memory.state_memory[:mem_index, :]).to(self.q_eval.device)
/project/6029407/janjua/Offline-Online-RL-Augmentation/Offline-Online-RL/mix_ttn_agent_online_offline.py:690: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  actions_all = T.tensor(self.memory.action_memory[:mem_index]).to(self.q_eval.device)
/project/6029407/janjua/Offline-Online-RL-Augmentation/Offline-Online-RL/mix_ttn_agent_online_offline.py:691: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  rewards_all = T.tensor(self.memory.reward_memory[:mem_index]).to(self.q_eval.device)
/project/6029407/janjua/Offline-Online-RL-Augmentation/Offline-Online-RL/mix_ttn_agent_online_offline.py:692: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  states_all_ = T.tensor(self.memory.new_state_memory[:mem_index, :]).to(self.q_eval.device)
/project/6029407/janjua/Offline-Online-RL-Augmentation/Offline-Online-RL/mix_ttn_agent_online_offline.py:693: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  actions_all_ = T.tensor(self.memory.new_action_memory[:mem_index]).to(self.q_eval.device)
/project/6029407/janjua/Offline-Online-RL-Augmentation/Offline-Online-RL/mix_ttn_agent_online_offline.py:694: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  dones_all = T.tensor(self.memory.terminal_memory[:mem_index]).to(self.q_eval.device)
/project/6029407/janjua/Offline-Online-RL-Augmentation/Offline-Online-RL/mix_ttn_agent_online_offline.py:779: UserWarning: torch.lstsq is deprecated in favor of torch.linalg.lstsq and will be removed in a future PyTorch release.
torch.linalg.lstsq has reversed arguments and does not return the QR decomposition in the returned tuple (although it returns other information about the problem).
To get the qr decomposition consider using torch.linalg.qr.
The returned solution in torch.lstsq stored the residuals of the solution in the last m - n columns of the returned value whenever m > n. In torch.linalg.lstsq, the residuals in the field 'residuals' of the returned named tuple.
The unpacking of the solution, as in
X, _ = torch.lstsq(B, A).solution[:A.size(1)]
should be replaced with
X = torch.linalg.lstsq(A, B).solution (Triggered internally at  /tmp/coulombc/pytorch_build_2021-11-09_14-57-01/avx2/python3.7/pytorch/aten/src/ATen/native/BatchLinearAlgebra.cpp:3657.)
  new_weights = T.lstsq(b, A)[0]  # T.mm(A.inverse(), b) #T.lstsq(b, A)[0]  #T.mm(A.inverse(), b) #tf.matrix_solve(A, b)
nn.learn_nn_feature_fqi FQI:  1998
nn.learn_nn_feature_fqi FQI:  2998
nn.learn_nn_feature_fqi FQI:  3998
nn.learn_nn_feature_fqi FQI:  4998
nn.learn_nn_feature_fqi FQI:  5998
nn.learn_nn_feature_fqi FQI:  6998
nn.learn_nn_feature_fqi FQI:  7998
nn.learn_nn_feature_fqi FQI:  8998
nn.learn_nn_feature_fqi FQI:  9998
nn.learn_nn_feature_fqi FQI:  10998
nn.learn_nn_feature_fqi FQI:  11998
nn.learn_nn_feature_fqi FQI:  12998
nn.learn_nn_feature_fqi FQI:  13998
nn.learn_nn_feature_fqi FQI:  14998
nn.learn_nn_feature_fqi FQI:  15998
nn.learn_nn_feature_fqi FQI:  16998
nn.learn_nn_feature_fqi FQI:  17998
nn.learn_nn_feature_fqi FQI:  18998
nn.learn_nn_feature_fqi FQI:  19998
nn.learn_nn_feature_fqi FQI:  20998
nn.learn_nn_feature_fqi FQI:  21998
nn.learn_nn_feature_fqi FQI:  22998
nn.learn_nn_feature_fqi FQI:  23998
nn.learn_nn_feature_fqi FQI:  24998
nn.learn_nn_feature_fqi FQI:  25998
nn.learn_nn_feature_fqi FQI:  26998
nn.learn_nn_feature_fqi FQI:  27998
nn.learn_nn_feature_fqi FQI:  28998
nn.learn_nn_feature_fqi FQI:  29998
nn.learn_nn_feature_fqi FQI:  30998
nn.learn_nn_feature_fqi FQI:  31998
nn.learn_nn_feature_fqi FQI:  32998
nn.learn_nn_feature_fqi FQI:  33998
nn.learn_nn_feature_fqi FQI:  34998
nn.learn_nn_feature_fqi FQI:  35998
nn.learn_nn_feature_fqi FQI:  36998
nn.learn_nn_feature_fqi FQI:  37998
nn.learn_nn_feature_fqi FQI:  38998
nn.learn_nn_feature_fqi FQI:  39998
nn.learn_nn_feature_fqi FQI:  40998
nn.learn_nn_feature_fqi FQI:  41998
nn.learn_nn_feature_fqi FQI:  42998
nn.learn_nn_feature_fqi FQI:  43998
nn.learn_nn_feature_fqi FQI:  44998
nn.learn_nn_feature_fqi FQI:  45998
nn.learn_nn_feature_fqi FQI:  46998
nn.learn_nn_feature_fqi FQI:  47998
nn.learn_nn_feature_fqi FQI:  48998
nn.learn_nn_feature_fqi FQI:  49998
nn.learn_nn_feature_fqi FQI:  50998
nn.learn_nn_feature_fqi FQI:  51998
nn.learn_nn_feature_fqi FQI:  52998
nn.learn_nn_feature_fqi FQI:  53998
nn.learn_nn_feature_fqi FQI:  54998
nn.learn_nn_feature_fqi FQI:  55998
nn.learn_nn_feature_fqi FQI:  56998
nn.learn_nn_feature_fqi FQI:  57998
nn.learn_nn_feature_fqi FQI:  58998
nn.learn_nn_feature_fqi FQI:  59998
nn.learn_nn_feature_fqi FQI:  60998
nn.learn_nn_feature_fqi FQI:  61998
nn.learn_nn_feature_fqi FQI:  62998
nn.learn_nn_feature_fqi FQI:  63998
nn.learn_nn_feature_fqi FQI:  64998
nn.learn_nn_feature_fqi FQI:  65998
nn.learn_nn_feature_fqi FQI:  66998
nn.learn_nn_feature_fqi FQI:  67998
nn.learn_nn_feature_fqi FQI:  68998
nn.learn_nn_feature_fqi FQI:  69998
nn.learn_nn_feature_fqi FQI:  70998
nn.learn_nn_feature_fqi FQI:  71998
nn.learn_nn_feature_fqi FQI:  72998
nn.learn_nn_feature_fqi FQI:  73998
nn.learn_nn_feature_fqi FQI:  74998
nn.learn_nn_feature_fqi FQI:  75998
nn.learn_nn_feature_fqi FQI:  76998
nn.learn_nn_feature_fqi FQI:  77998
nn.learn_nn_feature_fqi FQI:  78998
nn.learn_nn_feature_fqi FQI:  79998
nn.learn_nn_feature_fqi FQI:  80998
nn.learn_nn_feature_fqi FQI:  81998
nn.learn_nn_feature_fqi FQI:  82998
nn.learn_nn_feature_fqi FQI:  83998
nn.learn_nn_feature_fqi FQI:  84998
nn.learn_nn_feature_fqi FQI:  85998
nn.learn_nn_feature_fqi FQI:  86998
nn.learn_nn_feature_fqi FQI:  87998
nn.learn_nn_feature_fqi FQI:  88998
nn.learn_nn_feature_fqi FQI:  89998
nn.learn_nn_feature_fqi FQI:  90998
nn.learn_nn_feature_fqi FQI:  91998
nn.learn_nn_feature_fqi FQI:  92998
nn.learn_nn_feature_fqi FQI:  93998
nn.learn_nn_feature_fqi FQI:  94998
nn.learn_nn_feature_fqi FQI:  95998
nn.learn_nn_feature_fqi FQI:  96998
nn.learn_nn_feature_fqi FQI:  97998
nn.learn_nn_feature_fqi FQI:  98998
nn.learn_nn_feature_fqi FQI:  99998
nn.learn_nn_feature_fqi FQI:  100998
nn.learn_nn_feature_fqi FQI:  101998
nn.learn_nn_feature_fqi FQI:  102998
nn.learn_nn_feature_fqi FQI:  103998
nn.learn_nn_feature_fqi FQI:  104998
nn.learn_nn_feature_fqi FQI:  105998
nn.learn_nn_feature_fqi FQI:  106998
nn.learn_nn_feature_fqi FQI:  107998
nn.learn_nn_feature_fqi FQI:  108998
nn.learn_nn_feature_fqi FQI:  109998
nn.learn_nn_feature_fqi FQI:  110998
nn.learn_nn_feature_fqi FQI:  111998
nn.learn_nn_feature_fqi FQI:  112998
nn.learn_nn_feature_fqi FQI:  113998
nn.learn_nn_feature_fqi FQI:  114998
nn.learn_nn_feature_fqi FQI:  115998
nn.learn_nn_feature_fqi FQI:  116998
nn.learn_nn_feature_fqi FQI:  117998
nn.learn_nn_feature_fqi FQI:  118998
nn.learn_nn_feature_fqi FQI:  119998
nn.learn_nn_feature_fqi FQI:  120998
nn.learn_nn_feature_fqi FQI:  121998
nn.learn_nn_feature_fqi FQI:  122998
nn.learn_nn_feature_fqi FQI:  123998
nn.learn_nn_feature_fqi FQI:  124998
nn.learn_nn_feature_fqi FQI:  125998
nn.learn_nn_feature_fqi FQI:  126998
nn.learn_nn_feature_fqi FQI:  127998
nn.learn_nn_feature_fqi FQI:  128998
nn.learn_nn_feature_fqi FQI:  129998
nn.learn_nn_feature_fqi FQI:  130998
nn.learn_nn_feature_fqi FQI:  131998
nn.learn_nn_feature_fqi FQI:  132998
nn.learn_nn_feature_fqi FQI:  133998
nn.learn_nn_feature_fqi FQI:  134998
nn.learn_nn_feature_fqi FQI:  135998
nn.learn_nn_feature_fqi FQI:  136998
nn.learn_nn_feature_fqi FQI:  137998
nn.learn_nn_feature_fqi FQI:  138998
nn.learn_nn_feature_fqi FQI:  139998
nn.learn_nn_feature_fqi FQI:  140998
nn.learn_nn_feature_fqi FQI:  141998
nn.learn_nn_feature_fqi FQI:  142998
nn.learn_nn_feature_fqi FQI:  143998
nn.learn_nn_feature_fqi FQI:  144998
nn.learn_nn_feature_fqi FQI:  145998
nn.learn_nn_feature_fqi FQI:  146998
nn.learn_nn_feature_fqi FQI:  147998
nn.learn_nn_feature_fqi FQI:  148998
nn.learn_nn_feature_fqi FQI:  149998
nn.learn_nn_feature_fqi FQI:  150998
nn.learn_nn_feature_fqi FQI:  151998
nn.learn_nn_feature_fqi FQI:  152998
nn.learn_nn_feature_fqi FQI:  153998
nn.learn_nn_feature_fqi FQI:  154998
nn.learn_nn_feature_fqi FQI:  155998
/project/6029407/janjua/Offline-Online-RL-Augmentation/Offline-Online-RL/mix_ttn_agent_online_offline.py:213: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /tmp/coulombc/pytorch_build_2021-11-09_14-57-01/avx2/python3.7/pytorch/torch/csrc/utils/tensor_new.cpp:198.)
  state = T.tensor([observation], dtype=T.float).to(self.q_eval.device)
0 1001 -1000.0 -98.99572604650622 number episode from 10: 0 avegar over 10 episode: -98.996 avegare return across last 100 episodes: -98.996 state values: tensor(0.7043) 1000
1 1000 -1000.0 -99.99568287525881 number episode from 10: 1 avegar over 10 episode: -99.496 avegare return across last 100 episodes: -99.496 state values: tensor(0.6887) 1000
2 1000 -1000.0 -99.99568287525881 number episode from 10: 2 avegar over 10 episode: -99.662 avegare return across last 100 episodes: -99.662 state values: tensor(0.6922) 1000
3 1000 -1000.0 -99.99568287525881 number episode from 10: 3 avegar over 10 episode: -99.746 avegare return across last 100 episodes: -99.746 state values: tensor(0.6926) 1000
4 1000 -1000.0 -99.99568287525881 number episode from 10: 4 avegar over 10 episode: -99.796 avegare return across last 100 episodes: -99.796 state values: tensor(0.6922) 1000
5 1000 -1000.0 -99.99568287525881 number episode from 10: 5 avegar over 10 episode: -99.829 avegare return across last 100 episodes: -99.829 state values: tensor(0.7025) 1000
6 1000 -1000.0 -99.99568287525881 number episode from 10: 6 avegar over 10 episode: -99.853 avegare return across last 100 episodes: -99.853 state values: tensor(0.6927) 1000
7 1000 -1000.0 -99.99568287525881 number episode from 10: 7 avegar over 10 episode: -99.871 avegare return across last 100 episodes: -99.871 state values: tensor(0.6957) 1000
8 1000 -1000.0 -99.99568287525881 number episode from 10: 8 avegar over 10 episode: -99.885 avegare return across last 100 episodes: -99.885 state values: tensor(0.7001) 1000
9 1000 -1000.0 -99.99568287525881 number episode from 10: 9 avegar over 10 episode: -99.896 avegare return across last 100 episodes: -99.896 state values: tensor(0.7033) 1000
10 1000 -1000.0 -99.99568287525881 number episode from 10: 10 avegar over 10 episode: -99.905 avegare return across last 100 episodes: -99.905 state values: tensor(0.6893) 1000
11 1000 -1000.0 -99.99568287525881 number episode from 10: 11 avegar over 10 episode: -99.912 avegare return across last 100 episodes: -99.912 state values: tensor(0.6938) 1000
12 1000 -1000.0 -99.99568287525881 number episode from 10: 12 avegar over 10 episode: -99.919 avegare return across last 100 episodes: -99.919 state values: tensor(0.6978) 1000
13 1000 -1000.0 -99.99568287525881 number episode from 10: 13 avegar over 10 episode: -99.924 avegare return across last 100 episodes: -99.924 state values: tensor(0.6895) 1000
14 1000 -1000.0 -99.99568287525881 number episode from 10: 14 avegar over 10 episode: -99.929 avegare return across last 100 episodes: -99.929 state values: tensor(0.6895) 1000
15 1000 -1000.0 -99.99568287525881 number episode from 10: 15 avegar over 10 episode: -99.933 avegare return across last 100 episodes: -99.933 state values: tensor(0.6896) 1000
16 1000 -1000.0 -99.99568287525881 number episode from 10: 16 avegar over 10 episode: -99.937 avegare return across last 100 episodes: -99.937 state values: tensor(0.7019) 1000
17 1000 -1000.0 -99.99568287525881 number episode from 10: 17 avegar over 10 episode: -99.94 avegare return across last 100 episodes: -99.94 state values: tensor(0.6900) 1000
18 1000 -1000.0 -99.99568287525881 number episode from 10: 18 avegar over 10 episode: -99.943 avegare return across last 100 episodes: -99.943 state values: tensor(0.6895) 1000
19 1000 -1000.0 -99.99568287525881 number episode from 10: 19 avegar over 10 episode: -99.946 avegare return across last 100 episodes: -99.946 state values: tensor(0.6901) 1000
20 1000 -1000.0 -99.99568287525881 number episode from 10: 20 avegar over 10 episode: -99.948 avegare return across last 100 episodes: -99.948 state values: tensor(0.7082) 1000
21 1000 -1000.0 -99.99568287525881 number episode from 10: 21 avegar over 10 episode: -99.95 avegare return across last 100 episodes: -99.95 state values: tensor(0.6892) 1000
22 1000 -1000.0 -99.99568287525881 number episode from 10: 22 avegar over 10 episode: -99.952 avegare return across last 100 episodes: -99.952 state values: tensor(0.6894) 1000
23 1000 -1000.0 -99.99568287525881 number episode from 10: 23 avegar over 10 episode: -99.954 avegare return across last 100 episodes: -99.954 state values: tensor(0.6962) 1000
24 1000 -1000.0 -99.99568287525881 number episode from 10: 24 avegar over 10 episode: -99.956 avegare return across last 100 episodes: -99.956 state values: tensor(0.7007) 1000
25 1000 -1000.0 -99.99568287525881 number episode from 10: 25 avegar over 10 episode: -99.957 avegare return across last 100 episodes: -99.957 state values: tensor(0.6891) 1000
26 1000 -1000.0 -99.99568287525881 number episode from 10: 26 avegar over 10 episode: -99.959 avegare return across last 100 episodes: -99.959 state values: tensor(0.6896) 1000
27 1000 -1000.0 -99.99568287525881 number episode from 10: 27 avegar over 10 episode: -99.96 avegare return across last 100 episodes: -99.96 state values: tensor(0.6896) 1000
28 1000 -1000.0 -99.99568287525881 number episode from 10: 28 avegar over 10 episode: -99.961 avegare return across last 100 episodes: -99.961 state values: tensor(0.7004) 1000
29 1000 -1000.0 -99.99568287525881 number episode from 10: 29 avegar over 10 episode: -99.962 avegare return across last 100 episodes: -99.962 state values: tensor(0.6893) 1000
30 1000 -1000.0 -99.99568287525881 number episode from 10: 30 avegar over 10 episode: -99.963 avegare return across last 100 episodes: -99.963 state values: tensor(0.6892) 1000
31 1000 -1000.0 -99.99568287525881 number episode from 10: 31 avegar over 10 episode: -99.964 avegare return across last 100 episodes: -99.964 state values: tensor(0.6962) 1000
32 1000 -1000.0 -99.99568287525881 number episode from 10: 32 avegar over 10 episode: -99.965 avegare return across last 100 episodes: -99.965 state values: tensor(0.6892) 1000
33 1000 -1000.0 -99.99568287525881 number episode from 10: 33 avegar over 10 episode: -99.966 avegare return across last 100 episodes: -99.966 state values: tensor(0.6906) 1000
34 1000 -1000.0 -99.99568287525881 number episode from 10: 34 avegar over 10 episode: -99.967 avegare return across last 100 episodes: -99.967 state values: tensor(0.6979) 1000
35 1000 -1000.0 -99.99568287525881 number episode from 10: 35 avegar over 10 episode: -99.968 avegare return across last 100 episodes: -99.968 state values: tensor(0.6962) 1000
36 1000 -1000.0 -99.99568287525881 number episode from 10: 36 avegar over 10 episode: -99.969 avegare return across last 100 episodes: -99.969 state values: tensor(0.6915) 1000
37 1000 -1000.0 -99.99568287525881 number episode from 10: 37 avegar over 10 episode: -99.969 avegare return across last 100 episodes: -99.969 state values: tensor(0.6911) 1000
38 1000 -1000.0 -99.99568287525881 number episode from 10: 38 avegar over 10 episode: -99.97 avegare return across last 100 episodes: -99.97 state values: tensor(0.7105) 1000
39 1000 -1000.0 -99.99568287525881 number episode from 10: 39 avegar over 10 episode: -99.971 avegare return across last 100 episodes: -99.971 state values: tensor(0.6923) 1000
40 1000 -1000.0 -99.99568287525881 number episode from 10: 40 avegar over 10 episode: -99.971 avegare return across last 100 episodes: -99.971 state values: tensor(0.6971) 1000
41 1000 -1000.0 -99.99568287525881 number episode from 10: 41 avegar over 10 episode: -99.972 avegare return across last 100 episodes: -99.972 state values: tensor(0.6911) 1000
42 1000 -1000.0 -99.99568287525881 number episode from 10: 42 avegar over 10 episode: -99.972 avegare return across last 100 episodes: -99.972 state values: tensor(0.6935) 1000
43 1000 -1000.0 -99.99568287525881 number episode from 10: 43 avegar over 10 episode: -99.973 avegare return across last 100 episodes: -99.973 state values: tensor(0.6968) 1000
44 1000 -1000.0 -99.99568287525881 number episode from 10: 44 avegar over 10 episode: -99.973 avegare return across last 100 episodes: -99.973 state values: tensor(0.6909) 1000
45 1000 -1000.0 -99.99568287525881 number episode from 10: 45 avegar over 10 episode: -99.974 avegare return across last 100 episodes: -99.974 state values: tensor(0.6895) 1000
46 1000 -1000.0 -99.99568287525881 number episode from 10: 46 avegar over 10 episode: -99.974 avegare return across last 100 episodes: -99.974 state values: tensor(0.6916) 1000
47 1000 -1000.0 -99.99568287525881 number episode from 10: 47 avegar over 10 episode: -99.975 avegare return across last 100 episodes: -99.975 state values: tensor(0.7050) 1000
48 1000 -1000.0 -99.99568287525881 number episode from 10: 48 avegar over 10 episode: -99.975 avegare return across last 100 episodes: -99.975 state values: tensor(0.7016) 1000
49 1000 -1000.0 -99.99568287525881 number episode from 10: 49 avegar over 10 episode: -99.976 avegare return across last 100 episodes: -99.976 state values: tensor(0.6891) 1000
50 1000 -1000.0 -99.99568287525881 number episode from 10: 50 avegar over 10 episode: -99.976 avegare return across last 100 episodes: -99.976 state values: tensor(0.6897) 1000
51 1000 -1000.0 -99.99568287525881 number episode from 10: 51 avegar over 10 episode: -99.976 avegare return across last 100 episodes: -99.976 state values: tensor(0.6957) 1000
52 1000 -1000.0 -99.99568287525881 number episode from 10: 52 avegar over 10 episode: -99.977 avegare return across last 100 episodes: -99.977 state values: tensor(0.6896) 1000
53 1000 -1000.0 -99.99568287525881 number episode from 10: 53 avegar over 10 episode: -99.977 avegare return across last 100 episodes: -99.977 state values: tensor(0.6902) 1000
54 1000 -1000.0 -99.99568287525881 number episode from 10: 54 avegar over 10 episode: -99.978 avegare return across last 100 episodes: -99.978 state values: tensor(0.6994) 1000
55 1000 -1000.0 -99.99568287525881 number episode from 10: 55 avegar over 10 episode: -99.978 avegare return across last 100 episodes: -99.978 state values: tensor(0.6907) 1000
56 1000 -1000.0 -99.99568287525881 number episode from 10: 56 avegar over 10 episode: -99.978 avegare return across last 100 episodes: -99.978 state values: tensor(0.6986) 1000
57 1000 -1000.0 -99.99568287525881 number episode from 10: 57 avegar over 10 episode: -99.978 avegare return across last 100 episodes: -99.978 state values: tensor(0.6987) 1000
58 1000 -1000.0 -99.99568287525881 number episode from 10: 58 avegar over 10 episode: -99.979 avegare return across last 100 episodes: -99.979 state values: tensor(0.6906) 1000
59 1000 -1000.0 -99.99568287525881 number episode from 10: 59 avegar over 10 episode: -99.979 avegare return across last 100 episodes: -99.979 state values: tensor(0.6954) 1000
60 1000 -1000.0 -99.99568287525881 number episode from 10: 60 avegar over 10 episode: -99.979 avegare return across last 100 episodes: -99.979 state values: tensor(0.6906) 1000
61 1000 -1000.0 -99.99568287525881 number episode from 10: 61 avegar over 10 episode: -99.98 avegare return across last 100 episodes: -99.98 state values: tensor(0.6893) 1000
62 1000 -1000.0 -99.99568287525881 number episode from 10: 62 avegar over 10 episode: -99.98 avegare return across last 100 episodes: -99.98 state values: tensor(0.6999) 1000
63 1000 -1000.0 -99.99568287525881 number episode from 10: 63 avegar over 10 episode: -99.98 avegare return across last 100 episodes: -99.98 state values: tensor(0.6952) 1000
64 1000 -1000.0 -99.99568287525881 number episode from 10: 64 avegar over 10 episode: -99.98 avegare return across last 100 episodes: -99.98 state values: tensor(0.6891) 1000
65 1000 -1000.0 -99.99568287525881 number episode from 10: 65 avegar over 10 episode: -99.981 avegare return across last 100 episodes: -99.981 state values: tensor(0.6898) 1000
66 1000 -1000.0 -99.99568287525881 number episode from 10: 66 avegar over 10 episode: -99.981 avegare return across last 100 episodes: -99.981 state values: tensor(0.6892) 1000
67 1000 -1000.0 -99.99568287525881 number episode from 10: 67 avegar over 10 episode: -99.981 avegare return across last 100 episodes: -99.981 state values: tensor(0.6938) 1000
68 1000 -1000.0 -99.99568287525881 number episode from 10: 68 avegar over 10 episode: -99.981 avegare return across last 100 episodes: -99.981 state values: tensor(0.6893) 1000
69 1000 -1000.0 -99.99568287525881 number episode from 10: 69 avegar over 10 episode: -99.981 avegare return across last 100 episodes: -99.981 state values: tensor(0.6901) 1000
70 1000 -1000.0 -99.99568287525881 number episode from 10: 70 avegar over 10 episode: -99.982 avegare return across last 100 episodes: -99.982 state values: tensor(0.6932) 1000
71 1000 -1000.0 -99.99568287525881 number episode from 10: 71 avegar over 10 episode: -99.982 avegare return across last 100 episodes: -99.982 state values: tensor(0.6893) 1000
72 1000 -1000.0 -99.99568287525881 number episode from 10: 72 avegar over 10 episode: -99.982 avegare return across last 100 episodes: -99.982 state values: tensor(0.6893) 1000
73 1000 -1000.0 -99.99568287525881 number episode from 10: 73 avegar over 10 episode: -99.982 avegare return across last 100 episodes: -99.982 state values: tensor(0.6996) 1000
74 1000 -1000.0 -99.99568287525881 number episode from 10: 74 avegar over 10 episode: -99.982 avegare return across last 100 episodes: -99.982 state values: tensor(0.6973) 1000
75 1000 -1000.0 -99.99568287525881 number episode from 10: 75 avegar over 10 episode: -99.983 avegare return across last 100 episodes: -99.983 state values: tensor(0.6895) 1000
76 1000 -1000.0 -99.99568287525881 number episode from 10: 76 avegar over 10 episode: -99.983 avegare return across last 100 episodes: -99.983 state values: tensor(0.6892) 1000
77 1000 -1000.0 -99.99568287525881 number episode from 10: 77 avegar over 10 episode: -99.983 avegare return across last 100 episodes: -99.983 state values: tensor(0.6897) 1000
78 1000 -1000.0 -99.99568287525881 number episode from 10: 78 avegar over 10 episode: -99.983 avegare return across last 100 episodes: -99.983 state values: tensor(0.6958) 1000
79 1000 -1000.0 -99.99568287525881 number episode from 10: 79 avegar over 10 episode: -99.983 avegare return across last 100 episodes: -99.983 state values: tensor(0.6889) 1000
80 1000 -1000.0 -99.99568287525881 number episode from 10: 80 avegar over 10 episode: -99.983 avegare return across last 100 episodes: -99.983 state values: tensor(0.7032) 1000
81 1000 -1000.0 -99.99568287525881 number episode from 10: 81 avegar over 10 episode: -99.983 avegare return across last 100 episodes: -99.983 state values: tensor(0.7014) 1000
82 1000 -1000.0 -99.99568287525881 number episode from 10: 82 avegar over 10 episode: -99.984 avegare return across last 100 episodes: -99.984 state values: tensor(0.6983) 1000
83 1000 -1000.0 -99.99568287525881 number episode from 10: 83 avegar over 10 episode: -99.984 avegare return across last 100 episodes: -99.984 state values: tensor(0.7018) 1000
84 1000 -1000.0 -99.99568287525881 number episode from 10: 84 avegar over 10 episode: -99.984 avegare return across last 100 episodes: -99.984 state values: tensor(0.6894) 1000
85 1000 -1000.0 -99.99568287525881 number episode from 10: 85 avegar over 10 episode: -99.984 avegare return across last 100 episodes: -99.984 state values: tensor(0.6894) 1000
86 1000 -1000.0 -99.99568287525881 number episode from 10: 86 avegar over 10 episode: -99.984 avegare return across last 100 episodes: -99.984 state values: tensor(0.6933) 1000
87 1000 -1000.0 -99.99568287525881 number episode from 10: 87 avegar over 10 episode: -99.984 avegare return across last 100 episodes: -99.984 state values: tensor(0.6901) 1000
88 1000 -1000.0 -99.99568287525881 number episode from 10: 88 avegar over 10 episode: -99.984 avegare return across last 100 episodes: -99.984 state values: tensor(0.7047) 1000
89 1000 -1000.0 -99.99568287525881 number episode from 10: 89 avegar over 10 episode: -99.985 avegare return across last 100 episodes: -99.985 state values: tensor(0.6903) 1000
90 1000 -1000.0 -99.99568287525881 number episode from 10: 90 avegar over 10 episode: -99.985 avegare return across last 100 episodes: -99.985 state values: tensor(0.6935) 1000
91 1000 -1000.0 -99.99568287525881 number episode from 10: 91 avegar over 10 episode: -99.985 avegare return across last 100 episodes: -99.985 state values: tensor(0.6893) 1000
92 1000 -1000.0 -99.99568287525881 number episode from 10: 92 avegar over 10 episode: -99.985 avegare return across last 100 episodes: -99.985 state values: tensor(0.6907) 1000
93 1000 -1000.0 -99.99568287525881 number episode from 10: 93 avegar over 10 episode: -99.985 avegare return across last 100 episodes: -99.985 state values: tensor(0.6893) 1000
94 1000 -1000.0 -99.99568287525881 number episode from 10: 94 avegar over 10 episode: -99.985 avegare return across last 100 episodes: -99.985 state values: tensor(0.7004) 1000
95 1000 -1000.0 -99.99568287525881 number episode from 10: 95 avegar over 10 episode: -99.985 avegare return across last 100 episodes: -99.985 state values: tensor(0.6893) 1000
96 1000 -1000.0 -99.99568287525881 number episode from 10: 96 avegar over 10 episode: -99.985 avegare return across last 100 episodes: -99.985 state values: tensor(0.6897) 1000
97 1000 -1000.0 -99.99568287525881 number episode from 10: 97 avegar over 10 episode: -99.985 avegare return across last 100 episodes: -99.985 state values: tensor(0.6907) 1000
98 1000 -1000.0 -99.99568287525881 number episode from 10: 98 avegar over 10 episode: -99.986 avegare return across last 100 episodes: -99.986 state values: tensor(0.6893) 1000
99 1000 -1000.0 -99.99568287525881 number episode from 10: 99 avegar over 10 episode: -99.986 avegare return across last 100 episodes: -99.986 state values: tensor(0.7004) 1000
100 1000 -1000.0 -99.99568287525881 number episode from 10: 100 avegar over 10 episode: -99.986 avegare return across last 100 episodes: -99.996 state values: tensor(0.7005) 1000
101 1000 -1000.0 -99.99568287525881 number episode from 10: 101 avegar over 10 episode: -99.986 avegare return across last 100 episodes: -99.996 state values: tensor(0.6935) 1000
102 1000 -1000.0 -99.99568287525881 number episode from 10: 102 avegar over 10 episode: -99.986 avegare return across last 100 episodes: -99.996 state values: tensor(0.6956) 1000
103 1000 -1000.0 -99.99568287525881 number episode from 10: 103 avegar over 10 episode: -99.986 avegare return across last 100 episodes: -99.996 state values: tensor(0.6924) 1000
104 1000 -1000.0 -99.99568287525881 number episode from 10: 104 avegar over 10 episode: -99.986 avegare return across last 100 episodes: -99.996 state values: tensor(0.6935) 1000
105 1000 -1000.0 -99.99568287525881 number episode from 10: 105 avegar over 10 episode: -99.986 avegare return across last 100 episodes: -99.996 state values: tensor(0.7064) 1000
106 1000 -1000.0 -99.99568287525881 number episode from 10: 106 avegar over 10 episode: -99.986 avegare return across last 100 episodes: -99.996 state values: tensor(0.6999) 1000
107 1000 -1000.0 -99.99568287525881 number episode from 10: 107 avegar over 10 episode: -99.986 avegare return across last 100 episodes: -99.996 state values: tensor(0.6941) 1000
108 1000 -1000.0 -99.99568287525881 number episode from 10: 108 avegar over 10 episode: -99.987 avegare return across last 100 episodes: -99.996 state values: tensor(0.6968) 1000
109 1000 -1000.0 -99.99568287525881 number episode from 10: 109 avegar over 10 episode: -99.987 avegare return across last 100 episodes: -99.996 state values: tensor(0.6916) 1000
110 1000 -1000.0 -99.99568287525881 number episode from 10: 110 avegar over 10 episode: -99.987 avegare return across last 100 episodes: -99.996 state values: tensor(0.6893) 1000
111 1000 -1000.0 -99.99568287525881 number episode from 10: 111 avegar over 10 episode: -99.987 avegare return across last 100 episodes: -99.996 state values: tensor(0.6959) 1000
112 1000 -1000.0 -99.99568287525881 number episode from 10: 112 avegar over 10 episode: -99.987 avegare return across last 100 episodes: -99.996 state values: tensor(0.6985) 1000
113 1000 -1000.0 -99.99568287525881 number episode from 10: 113 avegar over 10 episode: -99.987 avegare return across last 100 episodes: -99.996 state values: tensor(0.6911) 1000
114 1000 -1000.0 -99.99568287525881 number episode from 10: 114 avegar over 10 episode: -99.987 avegare return across last 100 episodes: -99.996 state values: tensor(0.6894) 1000
115 1000 -1000.0 -99.99568287525881 number episode from 10: 115 avegar over 10 episode: -99.987 avegare return across last 100 episodes: -99.996 state values: tensor(0.6895) 1000
116 1000 -1000.0 -99.99568287525881 number episode from 10: 116 avegar over 10 episode: -99.987 avegare return across last 100 episodes: -99.996 state values: tensor(0.6895) 1000
117 1000 -1000.0 -99.99568287525881 number episode from 10: 117 avegar over 10 episode: -99.987 avegare return across last 100 episodes: -99.996 state values: tensor(0.6908) 1000
118 1000 -1000.0 -99.99568287525881 number episode from 10: 118 avegar over 10 episode: -99.987 avegare return across last 100 episodes: -99.996 state values: tensor(0.6908) 1000
119 1000 -1000.0 -99.99568287525881 number episode from 10: 119 avegar over 10 episode: -99.987 avegare return across last 100 episodes: -99.996 state values: tensor(0.6941) 1000
120 1000 -1000.0 -99.99568287525881 number episode from 10: 120 avegar over 10 episode: -99.987 avegare return across last 100 episodes: -99.996 state values: tensor(0.6893) 1000
121 1000 -1000.0 -99.99568287525881 number episode from 10: 121 avegar over 10 episode: -99.987 avegare return across last 100 episodes: -99.996 state values: tensor(0.6925) 1000
122 1000 -1000.0 -99.99568287525881 number episode from 10: 122 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.6936) 1000
123 1000 -1000.0 -99.99568287525881 number episode from 10: 123 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.6889) 1000
124 1000 -1000.0 -99.99568287525881 number episode from 10: 124 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.6923) 1000
125 1000 -1000.0 -99.99568287525881 number episode from 10: 125 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.6936) 1000
126 1000 -1000.0 -99.99568287525881 number episode from 10: 126 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.6943) 1000
127 1000 -1000.0 -99.99568287525881 number episode from 10: 127 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.6950) 1000
128 1000 -1000.0 -99.99568287525881 number episode from 10: 128 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.6967) 1000
129 1000 -1000.0 -99.99568287525881 number episode from 10: 129 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.6897) 1000
130 1000 -1000.0 -99.99568287525881 number episode from 10: 130 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.6895) 1000
131 1000 -1000.0 -99.99568287525881 number episode from 10: 131 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.6894) 1000
132 1000 -1000.0 -99.99568287525881 number episode from 10: 132 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.6978) 1000
133 1000 -1000.0 -99.99568287525881 number episode from 10: 133 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.7010) 1000
134 1000 -1000.0 -99.99568287525881 number episode from 10: 134 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.6919) 1000
135 1000 -1000.0 -99.99568287525881 number episode from 10: 135 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.6894) 1000
136 1000 -1000.0 -99.99568287525881 number episode from 10: 136 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.6891) 1000
137 1000 -1000.0 -99.99568287525881 number episode from 10: 137 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.6986) 1000
138 1000 -1000.0 -99.99568287525881 number episode from 10: 138 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.6965) 1000
139 1000 -1000.0 -99.99568287525881 number episode from 10: 139 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.6951) 1000
140 1000 -1000.0 -99.99568287525881 number episode from 10: 140 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.6916) 1000
141 1000 -1000.0 -99.99568287525881 number episode from 10: 141 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.6894) 1000
142 1000 -1000.0 -99.99568287525881 number episode from 10: 142 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.6893) 1000
143 1000 -1000.0 -99.99568287525881 number episode from 10: 143 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.6901) 1000
144 1000 -1000.0 -99.99568287525881 number episode from 10: 144 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.6894) 1000
145 1000 -1000.0 -99.99568287525881 number episode from 10: 145 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.7017) 1000
146 1000 -1000.0 -99.99568287525881 number episode from 10: 146 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.6896) 1000
147 1000 -1000.0 -99.99568287525881 number episode from 10: 147 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.6892) 1000
148 1000 -1000.0 -99.99568287525881 number episode from 10: 148 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.7007) 1000
149 1000 -1000.0 -99.99568287525881 number episode from 10: 149 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.7025) 1000
150 1000 -1000.0 -99.99568287525881 number episode from 10: 150 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.6916) 1000
151 1000 -1000.0 -99.99568287525881 number episode from 10: 151 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.6972) 1000
152 1000 -1000.0 -99.99568287525881 number episode from 10: 152 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.7028) 1000
153 1000 -1000.0 -99.99568287525881 number episode from 10: 153 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.6895) 1000
154 1000 -1000.0 -99.99568287525881 number episode from 10: 154 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.7098) 1000
155 1000 -1000.0 -99.99568287525881 number episode from 10: 155 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.7086) 1000
156 1000 -1000.0 -99.99568287525881 number episode from 10: 156 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.7059) 1000
157 1000 -1000.0 -99.99568287525881 number episode from 10: 157 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.6894) 1000
158 1000 -1000.0 -99.99568287525881 number episode from 10: 158 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.6898) 1000
159 1000 -1000.0 -99.99568287525881 number episode from 10: 159 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.6892) 1000
160 1000 -1000.0 -99.99568287525881 number episode from 10: 160 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.6895) 1000
161 1000 -1000.0 -99.99568287525881 number episode from 10: 161 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.7004) 1000
162 1000 -1000.0 -99.99568287525881 number episode from 10: 162 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.7025) 1000
163 1000 -1000.0 -99.99568287525881 number episode from 10: 163 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.6941) 1000
164 1000 -1000.0 -99.99568287525881 number episode from 10: 164 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.6894) 1000
165 1000 -1000.0 -99.99568287525881 number episode from 10: 165 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.6926) 1000
166 1000 -1000.0 -99.99568287525881 number episode from 10: 166 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.7006) 1000
167 1000 -1000.0 -99.99568287525881 number episode from 10: 167 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.6896) 1000
168 1000 -1000.0 -99.99568287525881 number episode from 10: 168 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.7014) 1000
169 1000 -1000.0 -99.99568287525881 number episode from 10: 169 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.6989) 1000
170 1000 -1000.0 -99.99568287525881 number episode from 10: 170 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.7101) 1000
171 1000 -1000.0 -99.99568287525881 number episode from 10: 171 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.6908) 1000
172 1000 -1000.0 -99.99568287525881 number episode from 10: 172 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.6896) 1000
173 1000 -1000.0 -99.99568287525881 number episode from 10: 173 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.6999) 1000
174 1000 -1000.0 -99.99568287525881 number episode from 10: 174 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.6946) 1000
175 1000 -1000.0 -99.99568287525881 number episode from 10: 175 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.6902) 1000
176 1000 -1000.0 -99.99568287525881 number episode from 10: 176 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.6945) 1000
177 1000 -1000.0 -99.99568287525881 number episode from 10: 177 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.6923) 1000
178 1000 -1000.0 -99.99568287525881 number episode from 10: 178 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.6916) 1000
179 1000 -1000.0 -99.99568287525881 number episode from 10: 179 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.6935) 1000
180 1000 -1000.0 -99.99568287525881 number episode from 10: 180 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.6917) 1000
181 1000 -1000.0 -99.99568287525881 number episode from 10: 181 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.6942) 1000
182 1000 -1000.0 -99.99568287525881 number episode from 10: 182 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.6918) 1000
183 1000 -1000.0 -99.99568287525881 number episode from 10: 183 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.6959) 1000
184 1000 -1000.0 -99.99568287525881 number episode from 10: 184 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.6954) 1000
185 1000 -1000.0 -99.99568287525881 number episode from 10: 185 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.6897) 1000
186 1000 -1000.0 -99.99568287525881 number episode from 10: 186 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.6911) 1000
187 1000 -1000.0 -99.99568287525881 number episode from 10: 187 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.6897) 1000
188 1000 -1000.0 -99.99568287525881 number episode from 10: 188 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.7002) 1000
189 1000 -1000.0 -99.99568287525881 number episode from 10: 189 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.6893) 1000
190 1000 -1000.0 -99.99568287525881 number episode from 10: 190 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.6893) 1000
191 1000 -1000.0 -99.99568287525881 number episode from 10: 191 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.7001) 1000
192 1000 -1000.0 -99.99568287525881 number episode from 10: 192 avegar over 10 episode: -99.991 avegare return across last 100 episodes: -99.996 state values: tensor(0.6989) 1000
193 1000 -1000.0 -99.99568287525881 number episode from 10: 193 avegar over 10 episode: -99.991 avegare return across last 100 episodes: -99.996 state values: tensor(0.7000) 1000
194 1000 -1000.0 -99.99568287525881 number episode from 10: 194 avegar over 10 episode: -99.991 avegare return across last 100 episodes: -99.996 state values: tensor(0.6937) 1000
195 1000 -1000.0 -99.99568287525881 number episode from 10: 195 avegar over 10 episode: -99.991 avegare return across last 100 episodes: -99.996 state values: tensor(0.6901) 1000
196 1000 -1000.0 -99.99568287525881 number episode from 10: 196 avegar over 10 episode: -99.991 avegare return across last 100 episodes: -99.996 state values: tensor(0.6890) 1000
197 1000 -1000.0 -99.99568287525881 number episode from 10: 197 avegar over 10 episode: -99.991 avegare return across last 100 episodes: -99.996 state values: tensor(0.6976) 1000
198 1000 -1000.0 -99.99568287525881 number episode from 10: 198 avegar over 10 episode: -99.991 avegare return across last 100 episodes: -99.996 state values: tensor(0.6893) 1000
199 1000 -1000.0 -99.99568287525881 number episode from 10: 199 avegar over 10 episode: -99.991 avegare return across last 100 episodes: -99.996 state values: tensor(0.6893) 1000
200 1000 -1000.0 -99.99568287525881 number episode from 10: 200 avegar over 10 episode: -99.991 avegare return across last 100 episodes: -99.996 state values: tensor(0.6922) 1000
load offline data!!!!!
mem_cntr: 50000 ; mem_size: 50000
nn.learn_nn_feature_fqi FQI:  998
nn.learn_nn_feature_fqi FQI:  1998
nn.learn_nn_feature_fqi FQI:  2998
nn.learn_nn_feature_fqi FQI:  3998
nn.learn_nn_feature_fqi FQI:  4998
nn.learn_nn_feature_fqi FQI:  5998
nn.learn_nn_feature_fqi FQI:  6998
nn.learn_nn_feature_fqi FQI:  7998
nn.learn_nn_feature_fqi FQI:  8998
nn.learn_nn_feature_fqi FQI:  9998
nn.learn_nn_feature_fqi FQI:  10998
nn.learn_nn_feature_fqi FQI:  11998
nn.learn_nn_feature_fqi FQI:  12998
nn.learn_nn_feature_fqi FQI:  13998
nn.learn_nn_feature_fqi FQI:  14998
nn.learn_nn_feature_fqi FQI:  15998
nn.learn_nn_feature_fqi FQI:  16998
nn.learn_nn_feature_fqi FQI:  17998
nn.learn_nn_feature_fqi FQI:  18998
nn.learn_nn_feature_fqi FQI:  19998
nn.learn_nn_feature_fqi FQI:  20998
nn.learn_nn_feature_fqi FQI:  21998
nn.learn_nn_feature_fqi FQI:  22998
nn.learn_nn_feature_fqi FQI:  23998
nn.learn_nn_feature_fqi FQI:  24998
nn.learn_nn_feature_fqi FQI:  25998
nn.learn_nn_feature_fqi FQI:  26998
nn.learn_nn_feature_fqi FQI:  27998
nn.learn_nn_feature_fqi FQI:  28998
nn.learn_nn_feature_fqi FQI:  29998
nn.learn_nn_feature_fqi FQI:  30998
nn.learn_nn_feature_fqi FQI:  31998
nn.learn_nn_feature_fqi FQI:  32998
nn.learn_nn_feature_fqi FQI:  33998
nn.learn_nn_feature_fqi FQI:  34998
nn.learn_nn_feature_fqi FQI:  35998
nn.learn_nn_feature_fqi FQI:  36998
nn.learn_nn_feature_fqi FQI:  37998
nn.learn_nn_feature_fqi FQI:  38998
nn.learn_nn_feature_fqi FQI:  39998
nn.learn_nn_feature_fqi FQI:  40998
nn.learn_nn_feature_fqi FQI:  41998
nn.learn_nn_feature_fqi FQI:  42998
nn.learn_nn_feature_fqi FQI:  43998
nn.learn_nn_feature_fqi FQI:  44998
nn.learn_nn_feature_fqi FQI:  45998
nn.learn_nn_feature_fqi FQI:  46998
nn.learn_nn_feature_fqi FQI:  47998
nn.learn_nn_feature_fqi FQI:  48998
nn.learn_nn_feature_fqi FQI:  49998
nn.learn_nn_feature_fqi FQI:  50998
nn.learn_nn_feature_fqi FQI:  51998
nn.learn_nn_feature_fqi FQI:  52998
nn.learn_nn_feature_fqi FQI:  53998
nn.learn_nn_feature_fqi FQI:  54998
nn.learn_nn_feature_fqi FQI:  55998
nn.learn_nn_feature_fqi FQI:  56998
nn.learn_nn_feature_fqi FQI:  57998
nn.learn_nn_feature_fqi FQI:  58998
nn.learn_nn_feature_fqi FQI:  59998
nn.learn_nn_feature_fqi FQI:  60998
nn.learn_nn_feature_fqi FQI:  61998
nn.learn_nn_feature_fqi FQI:  62998
nn.learn_nn_feature_fqi FQI:  63998
nn.learn_nn_feature_fqi FQI:  64998
nn.learn_nn_feature_fqi FQI:  65998
nn.learn_nn_feature_fqi FQI:  66998
nn.learn_nn_feature_fqi FQI:  67998
nn.learn_nn_feature_fqi FQI:  68998
nn.learn_nn_feature_fqi FQI:  69998
nn.learn_nn_feature_fqi FQI:  70998
nn.learn_nn_feature_fqi FQI:  71998
nn.learn_nn_feature_fqi FQI:  72998
nn.learn_nn_feature_fqi FQI:  73998
nn.learn_nn_feature_fqi FQI:  74998
nn.learn_nn_feature_fqi FQI:  75998
nn.learn_nn_feature_fqi FQI:  76998
nn.learn_nn_feature_fqi FQI:  77998
nn.learn_nn_feature_fqi FQI:  78998
nn.learn_nn_feature_fqi FQI:  79998
nn.learn_nn_feature_fqi FQI:  80998
nn.learn_nn_feature_fqi FQI:  81998
nn.learn_nn_feature_fqi FQI:  82998
nn.learn_nn_feature_fqi FQI:  83998
nn.learn_nn_feature_fqi FQI:  84998
nn.learn_nn_feature_fqi FQI:  85998
nn.learn_nn_feature_fqi FQI:  86998
nn.learn_nn_feature_fqi FQI:  87998
nn.learn_nn_feature_fqi FQI:  88998
nn.learn_nn_feature_fqi FQI:  89998
nn.learn_nn_feature_fqi FQI:  90998
nn.learn_nn_feature_fqi FQI:  91998
nn.learn_nn_feature_fqi FQI:  92998
nn.learn_nn_feature_fqi FQI:  93998
nn.learn_nn_feature_fqi FQI:  94998
nn.learn_nn_feature_fqi FQI:  95998
nn.learn_nn_feature_fqi FQI:  96998
nn.learn_nn_feature_fqi FQI:  97998
nn.learn_nn_feature_fqi FQI:  98998
nn.learn_nn_feature_fqi FQI:  99998
nn.learn_nn_feature_fqi FQI:  100998
nn.learn_nn_feature_fqi FQI:  101998
nn.learn_nn_feature_fqi FQI:  102998
nn.learn_nn_feature_fqi FQI:  103998
nn.learn_nn_feature_fqi FQI:  104998
nn.learn_nn_feature_fqi FQI:  105998
nn.learn_nn_feature_fqi FQI:  106998
nn.learn_nn_feature_fqi FQI:  107998
nn.learn_nn_feature_fqi FQI:  108998
nn.learn_nn_feature_fqi FQI:  109998
nn.learn_nn_feature_fqi FQI:  110998
nn.learn_nn_feature_fqi FQI:  111998
nn.learn_nn_feature_fqi FQI:  112998
nn.learn_nn_feature_fqi FQI:  113998
nn.learn_nn_feature_fqi FQI:  114998
nn.learn_nn_feature_fqi FQI:  115998
nn.learn_nn_feature_fqi FQI:  116998
nn.learn_nn_feature_fqi FQI:  117998
nn.learn_nn_feature_fqi FQI:  118998
nn.learn_nn_feature_fqi FQI:  119998
nn.learn_nn_feature_fqi FQI:  120998
nn.learn_nn_feature_fqi FQI:  121998
nn.learn_nn_feature_fqi FQI:  122998
nn.learn_nn_feature_fqi FQI:  123998
nn.learn_nn_feature_fqi FQI:  124998
nn.learn_nn_feature_fqi FQI:  125998
nn.learn_nn_feature_fqi FQI:  126998
nn.learn_nn_feature_fqi FQI:  127998
nn.learn_nn_feature_fqi FQI:  128998
nn.learn_nn_feature_fqi FQI:  129998
nn.learn_nn_feature_fqi FQI:  130998
nn.learn_nn_feature_fqi FQI:  131998
nn.learn_nn_feature_fqi FQI:  132998
nn.learn_nn_feature_fqi FQI:  133998
nn.learn_nn_feature_fqi FQI:  134998
nn.learn_nn_feature_fqi FQI:  135998
nn.learn_nn_feature_fqi FQI:  136998
nn.learn_nn_feature_fqi FQI:  137998
nn.learn_nn_feature_fqi FQI:  138998
nn.learn_nn_feature_fqi FQI:  139998
nn.learn_nn_feature_fqi FQI:  140998
nn.learn_nn_feature_fqi FQI:  141998
nn.learn_nn_feature_fqi FQI:  142998
nn.learn_nn_feature_fqi FQI:  143998
nn.learn_nn_feature_fqi FQI:  144998
nn.learn_nn_feature_fqi FQI:  145998
nn.learn_nn_feature_fqi FQI:  146998
nn.learn_nn_feature_fqi FQI:  147998
nn.learn_nn_feature_fqi FQI:  148998
nn.learn_nn_feature_fqi FQI:  149998
nn.learn_nn_feature_fqi FQI:  150998
nn.learn_nn_feature_fqi FQI:  151998
nn.learn_nn_feature_fqi FQI:  152998
nn.learn_nn_feature_fqi FQI:  153998
nn.learn_nn_feature_fqi FQI:  154998
nn.learn_nn_feature_fqi FQI:  155998
0 1001 -1000.0 -98.99572604650622 number episode from 10: 0 avegar over 10 episode: -98.996 avegare return across last 100 episodes: -98.996 state values: tensor(0.7046) 1000
1 1000 -1000.0 -99.99568287525881 number episode from 10: 1 avegar over 10 episode: -99.496 avegare return across last 100 episodes: -99.496 state values: tensor(0.7040) 1000
2 1000 -1000.0 -99.99568287525881 number episode from 10: 2 avegar over 10 episode: -99.662 avegare return across last 100 episodes: -99.662 state values: tensor(0.7043) 1000
3 1000 -1000.0 -99.99568287525881 number episode from 10: 3 avegar over 10 episode: -99.746 avegare return across last 100 episodes: -99.746 state values: tensor(0.7039) 1000
4 1000 -1000.0 -99.99568287525881 number episode from 10: 4 avegar over 10 episode: -99.796 avegare return across last 100 episodes: -99.796 state values: tensor(0.7041) 1000
5 1000 -1000.0 -99.99568287525881 number episode from 10: 5 avegar over 10 episode: -99.829 avegare return across last 100 episodes: -99.829 state values: tensor(0.7049) 1000
6 1000 -1000.0 -99.99568287525881 number episode from 10: 6 avegar over 10 episode: -99.853 avegare return across last 100 episodes: -99.853 state values: tensor(0.7042) 1000
7 1000 -1000.0 -99.99568287525881 number episode from 10: 7 avegar over 10 episode: -99.871 avegare return across last 100 episodes: -99.871 state values: tensor(0.7039) 1000
8 1000 -1000.0 -99.99568287525881 number episode from 10: 8 avegar over 10 episode: -99.885 avegare return across last 100 episodes: -99.885 state values: tensor(0.7039) 1000
9 1000 -1000.0 -99.99568287525881 number episode from 10: 9 avegar over 10 episode: -99.896 avegare return across last 100 episodes: -99.896 state values: tensor(0.7048) 1000
10 1000 -1000.0 -99.99568287525881 number episode from 10: 10 avegar over 10 episode: -99.905 avegare return across last 100 episodes: -99.905 state values: tensor(0.7040) 1000
11 1000 -1000.0 -99.99568287525881 number episode from 10: 11 avegar over 10 episode: -99.912 avegare return across last 100 episodes: -99.912 state values: tensor(0.7044) 1000
12 1000 -1000.0 -99.99568287525881 number episode from 10: 12 avegar over 10 episode: -99.919 avegare return across last 100 episodes: -99.919 state values: tensor(0.7042) 1000
13 1000 -1000.0 -99.99568287525881 number episode from 10: 13 avegar over 10 episode: -99.924 avegare return across last 100 episodes: -99.924 state values: tensor(0.7039) 1000
14 1000 -1000.0 -99.99568287525881 number episode from 10: 14 avegar over 10 episode: -99.929 avegare return across last 100 episodes: -99.929 state values: tensor(0.7051) 1000
15 1000 -1000.0 -99.99568287525881 number episode from 10: 15 avegar over 10 episode: -99.933 avegare return across last 100 episodes: -99.933 state values: tensor(0.7039) 1000
16 1000 -1000.0 -99.99568287525881 number episode from 10: 16 avegar over 10 episode: -99.937 avegare return across last 100 episodes: -99.937 state values: tensor(0.7045) 1000
17 1000 -1000.0 -99.99568287525881 number episode from 10: 17 avegar over 10 episode: -99.94 avegare return across last 100 episodes: -99.94 state values: tensor(0.7042) 1000
18 1000 -1000.0 -99.99568287525881 number episode from 10: 18 avegar over 10 episode: -99.943 avegare return across last 100 episodes: -99.943 state values: tensor(0.7043) 1000
19 1000 -1000.0 -99.99568287525881 number episode from 10: 19 avegar over 10 episode: -99.946 avegare return across last 100 episodes: -99.946 state values: tensor(0.7048) 1000
20 1000 -1000.0 -99.99568287525881 number episode from 10: 20 avegar over 10 episode: -99.948 avegare return across last 100 episodes: -99.948 state values: tensor(0.7043) 1000
21 1000 -1000.0 -99.99568287525881 number episode from 10: 21 avegar over 10 episode: -99.95 avegare return across last 100 episodes: -99.95 state values: tensor(0.7045) 1000
22 1000 -1000.0 -99.99568287525881 number episode from 10: 22 avegar over 10 episode: -99.952 avegare return across last 100 episodes: -99.952 state values: tensor(0.7048) 1000
23 1000 -1000.0 -99.99568287525881 number episode from 10: 23 avegar over 10 episode: -99.954 avegare return across last 100 episodes: -99.954 state values: tensor(0.7039) 1000
24 1000 -1000.0 -99.99568287525881 number episode from 10: 24 avegar over 10 episode: -99.956 avegare return across last 100 episodes: -99.956 state values: tensor(0.7044) 1000
25 1000 -1000.0 -99.99568287525881 number episode from 10: 25 avegar over 10 episode: -99.957 avegare return across last 100 episodes: -99.957 state values: tensor(0.7040) 1000
26 1000 -1000.0 -99.99568287525881 number episode from 10: 26 avegar over 10 episode: -99.959 avegare return across last 100 episodes: -99.959 state values: tensor(0.7042) 1000
27 1000 -1000.0 -99.99568287525881 number episode from 10: 27 avegar over 10 episode: -99.96 avegare return across last 100 episodes: -99.96 state values: tensor(0.7040) 1000
28 1000 -1000.0 -99.99568287525881 number episode from 10: 28 avegar over 10 episode: -99.961 avegare return across last 100 episodes: -99.961 state values: tensor(0.7046) 1000
29 1000 -1000.0 -99.99568287525881 number episode from 10: 29 avegar over 10 episode: -99.962 avegare return across last 100 episodes: -99.962 state values: tensor(0.7048) 1000
30 1000 -1000.0 -99.99568287525881 number episode from 10: 30 avegar over 10 episode: -99.963 avegare return across last 100 episodes: -99.963 state values: tensor(0.7042) 1000
31 1000 -1000.0 -99.99568287525881 number episode from 10: 31 avegar over 10 episode: -99.964 avegare return across last 100 episodes: -99.964 state values: tensor(0.7041) 1000
32 1000 -1000.0 -99.99568287525881 number episode from 10: 32 avegar over 10 episode: -99.965 avegare return across last 100 episodes: -99.965 state values: tensor(0.7045) 1000
33 1000 -1000.0 -99.99568287525881 number episode from 10: 33 avegar over 10 episode: -99.966 avegare return across last 100 episodes: -99.966 state values: tensor(0.7043) 1000
34 1000 -1000.0 -99.99568287525881 number episode from 10: 34 avegar over 10 episode: -99.967 avegare return across last 100 episodes: -99.967 state values: tensor(0.7038) 1000
35 1000 -1000.0 -99.99568287525881 number episode from 10: 35 avegar over 10 episode: -99.968 avegare return across last 100 episodes: -99.968 state values: tensor(0.7040) 1000
36 1000 -1000.0 -99.99568287525881 number episode from 10: 36 avegar over 10 episode: -99.969 avegare return across last 100 episodes: -99.969 state values: tensor(0.7049) 1000
37 1000 -1000.0 -99.99568287525881 number episode from 10: 37 avegar over 10 episode: -99.969 avegare return across last 100 episodes: -99.969 state values: tensor(0.7043) 1000
38 1000 -1000.0 -99.99568287525881 number episode from 10: 38 avegar over 10 episode: -99.97 avegare return across last 100 episodes: -99.97 state values: tensor(0.7042) 1000
39 1000 -1000.0 -99.99568287525881 number episode from 10: 39 avegar over 10 episode: -99.971 avegare return across last 100 episodes: -99.971 state values: tensor(0.7041) 1000
40 1000 -1000.0 -99.99568287525881 number episode from 10: 40 avegar over 10 episode: -99.971 avegare return across last 100 episodes: -99.971 state values: tensor(0.7048) 1000
41 1000 -1000.0 -99.99568287525881 number episode from 10: 41 avegar over 10 episode: -99.972 avegare return across last 100 episodes: -99.972 state values: tensor(0.7047) 1000
42 1000 -1000.0 -99.99568287525881 number episode from 10: 42 avegar over 10 episode: -99.972 avegare return across last 100 episodes: -99.972 state values: tensor(0.7043) 1000
43 1000 -1000.0 -99.99568287525881 number episode from 10: 43 avegar over 10 episode: -99.973 avegare return across last 100 episodes: -99.973 state values: tensor(0.7046) 1000
44 1000 -1000.0 -99.99568287525881 number episode from 10: 44 avegar over 10 episode: -99.973 avegare return across last 100 episodes: -99.973 state values: tensor(0.7049) 1000
45 1000 -1000.0 -99.99568287525881 number episode from 10: 45 avegar over 10 episode: -99.974 avegare return across last 100 episodes: -99.974 state values: tensor(0.7044) 1000
46 1000 -1000.0 -99.99568287525881 number episode from 10: 46 avegar over 10 episode: -99.974 avegare return across last 100 episodes: -99.974 state values: tensor(0.7051) 1000
47 1000 -1000.0 -99.99568287525881 number episode from 10: 47 avegar over 10 episode: -99.975 avegare return across last 100 episodes: -99.975 state values: tensor(0.7044) 1000
48 1000 -1000.0 -99.99568287525881 number episode from 10: 48 avegar over 10 episode: -99.975 avegare return across last 100 episodes: -99.975 state values: tensor(0.7043) 1000
49 1000 -1000.0 -99.99568287525881 number episode from 10: 49 avegar over 10 episode: -99.976 avegare return across last 100 episodes: -99.976 state values: tensor(0.7044) 1000
50 1000 -1000.0 -99.99568287525881 number episode from 10: 50 avegar over 10 episode: -99.976 avegare return across last 100 episodes: -99.976 state values: tensor(0.7047) 1000
51 1000 -1000.0 -99.99568287525881 number episode from 10: 51 avegar over 10 episode: -99.976 avegare return across last 100 episodes: -99.976 state values: tensor(0.7039) 1000
52 1000 -1000.0 -99.99568287525881 number episode from 10: 52 avegar over 10 episode: -99.977 avegare return across last 100 episodes: -99.977 state values: tensor(0.7047) 1000
53 1000 -1000.0 -99.99568287525881 number episode from 10: 53 avegar over 10 episode: -99.977 avegare return across last 100 episodes: -99.977 state values: tensor(0.7041) 1000
54 1000 -1000.0 -99.99568287525881 number episode from 10: 54 avegar over 10 episode: -99.978 avegare return across last 100 episodes: -99.978 state values: tensor(0.7042) 1000
55 1000 -1000.0 -99.99568287525881 number episode from 10: 55 avegar over 10 episode: -99.978 avegare return across last 100 episodes: -99.978 state values: tensor(0.7039) 1000
56 1000 -1000.0 -99.99568287525881 number episode from 10: 56 avegar over 10 episode: -99.978 avegare return across last 100 episodes: -99.978 state values: tensor(0.7047) 1000
57 1000 -1000.0 -99.99568287525881 number episode from 10: 57 avegar over 10 episode: -99.978 avegare return across last 100 episodes: -99.978 state values: tensor(0.7044) 1000
58 1000 -1000.0 -99.99568287525881 number episode from 10: 58 avegar over 10 episode: -99.979 avegare return across last 100 episodes: -99.979 state values: tensor(0.7040) 1000
59 1000 -1000.0 -99.99568287525881 number episode from 10: 59 avegar over 10 episode: -99.979 avegare return across last 100 episodes: -99.979 state values: tensor(0.7047) 1000
60 1000 -1000.0 -99.99568287525881 number episode from 10: 60 avegar over 10 episode: -99.979 avegare return across last 100 episodes: -99.979 state values: tensor(0.7047) 1000
61 1000 -1000.0 -99.99568287525881 number episode from 10: 61 avegar over 10 episode: -99.98 avegare return across last 100 episodes: -99.98 state values: tensor(0.7042) 1000
62 1000 -1000.0 -99.99568287525881 number episode from 10: 62 avegar over 10 episode: -99.98 avegare return across last 100 episodes: -99.98 state values: tensor(0.7044) 1000
63 1000 -1000.0 -99.99568287525881 number episode from 10: 63 avegar over 10 episode: -99.98 avegare return across last 100 episodes: -99.98 state values: tensor(0.7043) 1000
64 1000 -1000.0 -99.99568287525881 number episode from 10: 64 avegar over 10 episode: -99.98 avegare return across last 100 episodes: -99.98 state values: tensor(0.7046) 1000
65 1000 -1000.0 -99.99568287525881 number episode from 10: 65 avegar over 10 episode: -99.981 avegare return across last 100 episodes: -99.981 state values: tensor(0.7041) 1000
66 1000 -1000.0 -99.99568287525881 number episode from 10: 66 avegar over 10 episode: -99.981 avegare return across last 100 episodes: -99.981 state values: tensor(0.7047) 1000
67 1000 -1000.0 -99.99568287525881 number episode from 10: 67 avegar over 10 episode: -99.981 avegare return across last 100 episodes: -99.981 state values: tensor(0.7048) 1000
68 1000 -1000.0 -99.99568287525881 number episode from 10: 68 avegar over 10 episode: -99.981 avegare return across last 100 episodes: -99.981 state values: tensor(0.7044) 1000
69 1000 -1000.0 -99.99568287525881 number episode from 10: 69 avegar over 10 episode: -99.981 avegare return across last 100 episodes: -99.981 state values: tensor(0.7043) 1000
70 1000 -1000.0 -99.99568287525881 number episode from 10: 70 avegar over 10 episode: -99.982 avegare return across last 100 episodes: -99.982 state values: tensor(0.7048) 1000
71 1000 -1000.0 -99.99568287525881 number episode from 10: 71 avegar over 10 episode: -99.982 avegare return across last 100 episodes: -99.982 state values: tensor(0.7046) 1000
72 1000 -1000.0 -99.99568287525881 number episode from 10: 72 avegar over 10 episode: -99.982 avegare return across last 100 episodes: -99.982 state values: tensor(0.7043) 1000
73 1000 -1000.0 -99.99568287525881 number episode from 10: 73 avegar over 10 episode: -99.982 avegare return across last 100 episodes: -99.982 state values: tensor(0.7046) 1000
74 1000 -1000.0 -99.99568287525881 number episode from 10: 74 avegar over 10 episode: -99.982 avegare return across last 100 episodes: -99.982 state values: tensor(0.7040) 1000
75 1000 -1000.0 -99.99568287525881 number episode from 10: 75 avegar over 10 episode: -99.983 avegare return across last 100 episodes: -99.983 state values: tensor(0.7048) 1000
76 1000 -1000.0 -99.99568287525881 number episode from 10: 76 avegar over 10 episode: -99.983 avegare return across last 100 episodes: -99.983 state values: tensor(0.7048) 1000
77 1000 -1000.0 -99.99568287525881 number episode from 10: 77 avegar over 10 episode: -99.983 avegare return across last 100 episodes: -99.983 state values: tensor(0.7046) 1000
78 1000 -1000.0 -99.99568287525881 number episode from 10: 78 avegar over 10 episode: -99.983 avegare return across last 100 episodes: -99.983 state values: tensor(0.7050) 1000
79 1000 -1000.0 -99.99568287525881 number episode from 10: 79 avegar over 10 episode: -99.983 avegare return across last 100 episodes: -99.983 state values: tensor(0.7044) 1000
80 1000 -1000.0 -99.99568287525881 number episode from 10: 80 avegar over 10 episode: -99.983 avegare return across last 100 episodes: -99.983 state values: tensor(0.7039) 1000
81 1000 -1000.0 -99.99568287525881 number episode from 10: 81 avegar over 10 episode: -99.983 avegare return across last 100 episodes: -99.983 state values: tensor(0.7039) 1000
82 1000 -1000.0 -99.99568287525881 number episode from 10: 82 avegar over 10 episode: -99.984 avegare return across last 100 episodes: -99.984 state values: tensor(0.7038) 1000
83 1000 -1000.0 -99.99568287525881 number episode from 10: 83 avegar over 10 episode: -99.984 avegare return across last 100 episodes: -99.984 state values: tensor(0.7045) 1000
84 1000 -1000.0 -99.99568287525881 number episode from 10: 84 avegar over 10 episode: -99.984 avegare return across last 100 episodes: -99.984 state values: tensor(0.7043) 1000
85 1000 -1000.0 -99.99568287525881 number episode from 10: 85 avegar over 10 episode: -99.984 avegare return across last 100 episodes: -99.984 state values: tensor(0.7049) 1000
86 1000 -1000.0 -99.99568287525881 number episode from 10: 86 avegar over 10 episode: -99.984 avegare return across last 100 episodes: -99.984 state values: tensor(0.7042) 1000
87 1000 -1000.0 -99.99568287525881 number episode from 10: 87 avegar over 10 episode: -99.984 avegare return across last 100 episodes: -99.984 state values: tensor(0.7046) 1000
88 1000 -1000.0 -99.99568287525881 number episode from 10: 88 avegar over 10 episode: -99.984 avegare return across last 100 episodes: -99.984 state values: tensor(0.7047) 1000
89 1000 -1000.0 -99.99568287525881 number episode from 10: 89 avegar over 10 episode: -99.985 avegare return across last 100 episodes: -99.985 state values: tensor(0.7046) 1000
90 1000 -1000.0 -99.99568287525881 number episode from 10: 90 avegar over 10 episode: -99.985 avegare return across last 100 episodes: -99.985 state values: tensor(0.7041) 1000
91 1000 -1000.0 -99.99568287525881 number episode from 10: 91 avegar over 10 episode: -99.985 avegare return across last 100 episodes: -99.985 state values: tensor(0.7045) 1000
92 1000 -1000.0 -99.99568287525881 number episode from 10: 92 avegar over 10 episode: -99.985 avegare return across last 100 episodes: -99.985 state values: tensor(0.7045) 1000
93 1000 -1000.0 -99.99568287525881 number episode from 10: 93 avegar over 10 episode: -99.985 avegare return across last 100 episodes: -99.985 state values: tensor(0.7042) 1000
94 1000 -1000.0 -99.99568287525881 number episode from 10: 94 avegar over 10 episode: -99.985 avegare return across last 100 episodes: -99.985 state values: tensor(0.7049) 1000
95 1000 -1000.0 -99.99568287525881 number episode from 10: 95 avegar over 10 episode: -99.985 avegare return across last 100 episodes: -99.985 state values: tensor(0.7045) 1000
96 1000 -1000.0 -99.99568287525881 number episode from 10: 96 avegar over 10 episode: -99.985 avegare return across last 100 episodes: -99.985 state values: tensor(0.7050) 1000
97 1000 -1000.0 -99.99568287525881 number episode from 10: 97 avegar over 10 episode: -99.985 avegare return across last 100 episodes: -99.985 state values: tensor(0.7046) 1000
98 1000 -1000.0 -99.99568287525881 number episode from 10: 98 avegar over 10 episode: -99.986 avegare return across last 100 episodes: -99.986 state values: tensor(0.7050) 1000
99 1000 -1000.0 -99.99568287525881 number episode from 10: 99 avegar over 10 episode: -99.986 avegare return across last 100 episodes: -99.986 state values: tensor(0.7046) 1000
100 1000 -1000.0 -99.99568287525881 number episode from 10: 100 avegar over 10 episode: -99.986 avegare return across last 100 episodes: -99.996 state values: tensor(0.7052) 1000
101 1000 -1000.0 -99.99568287525881 number episode from 10: 101 avegar over 10 episode: -99.986 avegare return across last 100 episodes: -99.996 state values: tensor(0.7044) 1000
102 1000 -1000.0 -99.99568287525881 number episode from 10: 102 avegar over 10 episode: -99.986 avegare return across last 100 episodes: -99.996 state values: tensor(0.7044) 1000
103 1000 -1000.0 -99.99568287525881 number episode from 10: 103 avegar over 10 episode: -99.986 avegare return across last 100 episodes: -99.996 state values: tensor(0.7046) 1000
104 1000 -1000.0 -99.99568287525881 number episode from 10: 104 avegar over 10 episode: -99.986 avegare return across last 100 episodes: -99.996 state values: tensor(0.7038) 1000
105 1000 -1000.0 -99.99568287525881 number episode from 10: 105 avegar over 10 episode: -99.986 avegare return across last 100 episodes: -99.996 state values: tensor(0.7039) 1000
106 1000 -1000.0 -99.99568287525881 number episode from 10: 106 avegar over 10 episode: -99.986 avegare return across last 100 episodes: -99.996 state values: tensor(0.7039) 1000
107 1000 -1000.0 -99.99568287525881 number episode from 10: 107 avegar over 10 episode: -99.986 avegare return across last 100 episodes: -99.996 state values: tensor(0.7047) 1000
108 1000 -1000.0 -99.99568287525881 number episode from 10: 108 avegar over 10 episode: -99.987 avegare return across last 100 episodes: -99.996 state values: tensor(0.7045) 1000
109 1000 -1000.0 -99.99568287525881 number episode from 10: 109 avegar over 10 episode: -99.987 avegare return across last 100 episodes: -99.996 state values: tensor(0.7042) 1000
110 1000 -1000.0 -99.99568287525881 number episode from 10: 110 avegar over 10 episode: -99.987 avegare return across last 100 episodes: -99.996 state values: tensor(0.7042) 1000
111 1000 -1000.0 -99.99568287525881 number episode from 10: 111 avegar over 10 episode: -99.987 avegare return across last 100 episodes: -99.996 state values: tensor(0.7045) 1000
112 1000 -1000.0 -99.99568287525881 number episode from 10: 112 avegar over 10 episode: -99.987 avegare return across last 100 episodes: -99.996 state values: tensor(0.7040) 1000
113 1000 -1000.0 -99.99568287525881 number episode from 10: 113 avegar over 10 episode: -99.987 avegare return across last 100 episodes: -99.996 state values: tensor(0.7044) 1000
114 1000 -1000.0 -99.99568287525881 number episode from 10: 114 avegar over 10 episode: -99.987 avegare return across last 100 episodes: -99.996 state values: tensor(0.7046) 1000
115 1000 -1000.0 -99.99568287525881 number episode from 10: 115 avegar over 10 episode: -99.987 avegare return across last 100 episodes: -99.996 state values: tensor(0.7040) 1000
116 1000 -1000.0 -99.99568287525881 number episode from 10: 116 avegar over 10 episode: -99.987 avegare return across last 100 episodes: -99.996 state values: tensor(0.7050) 1000
117 1000 -1000.0 -99.99568287525881 number episode from 10: 117 avegar over 10 episode: -99.987 avegare return across last 100 episodes: -99.996 state values: tensor(0.7043) 1000
118 1000 -1000.0 -99.99568287525881 number episode from 10: 118 avegar over 10 episode: -99.987 avegare return across last 100 episodes: -99.996 state values: tensor(0.7046) 1000
119 1000 -1000.0 -99.99568287525881 number episode from 10: 119 avegar over 10 episode: -99.987 avegare return across last 100 episodes: -99.996 state values: tensor(0.7044) 1000
120 1000 -1000.0 -99.99568287525881 number episode from 10: 120 avegar over 10 episode: -99.987 avegare return across last 100 episodes: -99.996 state values: tensor(0.7045) 1000
121 1000 -1000.0 -99.99568287525881 number episode from 10: 121 avegar over 10 episode: -99.987 avegare return across last 100 episodes: -99.996 state values: tensor(0.7042) 1000
122 1000 -1000.0 -99.99568287525881 number episode from 10: 122 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.7041) 1000
123 1000 -1000.0 -99.99568287525881 number episode from 10: 123 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.7039) 1000
124 1000 -1000.0 -99.99568287525881 number episode from 10: 124 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.7046) 1000
125 1000 -1000.0 -99.99568287525881 number episode from 10: 125 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.7040) 1000
126 1000 -1000.0 -99.99568287525881 number episode from 10: 126 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.7041) 1000
127 1000 -1000.0 -99.99568287525881 number episode from 10: 127 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.7039) 1000
128 1000 -1000.0 -99.99568287525881 number episode from 10: 128 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.7044) 1000
129 1000 -1000.0 -99.99568287525881 number episode from 10: 129 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.7040) 1000
130 1000 -1000.0 -99.99568287525881 number episode from 10: 130 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.7041) 1000
131 1000 -1000.0 -99.99568287525881 number episode from 10: 131 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.7041) 1000
132 1000 -1000.0 -99.99568287525881 number episode from 10: 132 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.7039) 1000
133 1000 -1000.0 -99.99568287525881 number episode from 10: 133 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.7047) 1000
134 1000 -1000.0 -99.99568287525881 number episode from 10: 134 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.7046) 1000
135 1000 -1000.0 -99.99568287525881 number episode from 10: 135 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.7039) 1000
136 1000 -1000.0 -99.99568287525881 number episode from 10: 136 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.7041) 1000
137 1000 -1000.0 -99.99568287525881 number episode from 10: 137 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.7040) 1000
138 1000 -1000.0 -99.99568287525881 number episode from 10: 138 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.7048) 1000
139 1000 -1000.0 -99.99568287525881 number episode from 10: 139 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.7039) 1000
140 1000 -1000.0 -99.99568287525881 number episode from 10: 140 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.7042) 1000
141 1000 -1000.0 -99.99568287525881 number episode from 10: 141 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.7043) 1000
142 1000 -1000.0 -99.99568287525881 number episode from 10: 142 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.7044) 1000
143 1000 -1000.0 -99.99568287525881 number episode from 10: 143 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.7045) 1000
144 1000 -1000.0 -99.99568287525881 number episode from 10: 144 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.7041) 1000
145 1000 -1000.0 -99.99568287525881 number episode from 10: 145 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.7040) 1000
146 1000 -1000.0 -99.99568287525881 number episode from 10: 146 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.7039) 1000
147 1000 -1000.0 -99.99568287525881 number episode from 10: 147 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.7038) 1000
148 1000 -1000.0 -99.99568287525881 number episode from 10: 148 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.7040) 1000
149 1000 -1000.0 -99.99568287525881 number episode from 10: 149 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.7043) 1000
150 1000 -1000.0 -99.99568287525881 number episode from 10: 150 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.7041) 1000
151 1000 -1000.0 -99.99568287525881 number episode from 10: 151 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.7043) 1000
152 1000 -1000.0 -99.99568287525881 number episode from 10: 152 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.7042) 1000
153 1000 -1000.0 -99.99568287525881 number episode from 10: 153 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.7044) 1000
154 1000 -1000.0 -99.99568287525881 number episode from 10: 154 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.7047) 1000
155 1000 -1000.0 -99.99568287525881 number episode from 10: 155 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.7041) 1000
156 1000 -1000.0 -99.99568287525881 number episode from 10: 156 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.7046) 1000
157 1000 -1000.0 -99.99568287525881 number episode from 10: 157 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.7047) 1000
158 1000 -1000.0 -99.99568287525881 number episode from 10: 158 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.7044) 1000
159 1000 -1000.0 -99.99568287525881 number episode from 10: 159 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.7048) 1000
160 1000 -1000.0 -99.99568287525881 number episode from 10: 160 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.7045) 1000
161 1000 -1000.0 -99.99568287525881 number episode from 10: 161 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.7046) 1000
162 1000 -1000.0 -99.99568287525881 number episode from 10: 162 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.7045) 1000
163 1000 -1000.0 -99.99568287525881 number episode from 10: 163 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.7041) 1000
164 1000 -1000.0 -99.99568287525881 number episode from 10: 164 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.7043) 1000
165 1000 -1000.0 -99.99568287525881 number episode from 10: 165 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.7048) 1000
166 1000 -1000.0 -99.99568287525881 number episode from 10: 166 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.7042) 1000
167 1000 -1000.0 -99.99568287525881 number episode from 10: 167 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.7050) 1000
168 1000 -1000.0 -99.99568287525881 number episode from 10: 168 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.7048) 1000
169 1000 -1000.0 -99.99568287525881 number episode from 10: 169 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.7047) 1000
170 1000 -1000.0 -99.99568287525881 number episode from 10: 170 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.7043) 1000
171 1000 -1000.0 -99.99568287525881 number episode from 10: 171 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.7043) 1000
172 1000 -1000.0 -99.99568287525881 number episode from 10: 172 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.7039) 1000
173 1000 -1000.0 -99.99568287525881 number episode from 10: 173 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.7045) 1000
174 1000 -1000.0 -99.99568287525881 number episode from 10: 174 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.7042) 1000
175 1000 -1000.0 -99.99568287525881 number episode from 10: 175 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.7047) 1000
176 1000 -1000.0 -99.99568287525881 number episode from 10: 176 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.7040) 1000
177 1000 -1000.0 -99.99568287525881 number episode from 10: 177 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.7043) 1000
178 1000 -1000.0 -99.99568287525881 number episode from 10: 178 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.7039) 1000
179 1000 -1000.0 -99.99568287525881 number episode from 10: 179 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.7041) 1000
180 1000 -1000.0 -99.99568287525881 number episode from 10: 180 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.7047) 1000
181 1000 -1000.0 -99.99568287525881 number episode from 10: 181 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.7042) 1000
182 1000 -1000.0 -99.99568287525881 number episode from 10: 182 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.7049) 1000
183 1000 -1000.0 -99.99568287525881 number episode from 10: 183 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.7043) 1000
184 1000 -1000.0 -99.99568287525881 number episode from 10: 184 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.7046) 1000
185 1000 -1000.0 -99.99568287525881 number episode from 10: 185 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.7041) 1000
186 1000 -1000.0 -99.99568287525881 number episode from 10: 186 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.7047) 1000
187 1000 -1000.0 -99.99568287525881 number episode from 10: 187 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.7047) 1000
188 1000 -1000.0 -99.99568287525881 number episode from 10: 188 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.7042) 1000
189 1000 -1000.0 -99.99568287525881 number episode from 10: 189 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.7045) 1000
190 1000 -1000.0 -99.99568287525881 number episode from 10: 190 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.7041) 1000
191 1000 -1000.0 -99.99568287525881 number episode from 10: 191 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.7043) 1000
192 1000 -1000.0 -99.99568287525881 number episode from 10: 192 avegar over 10 episode: -99.991 avegare return across last 100 episodes: -99.996 state values: tensor(0.7049) 1000
193 1000 -1000.0 -99.99568287525881 number episode from 10: 193 avegar over 10 episode: -99.991 avegare return across last 100 episodes: -99.996 state values: tensor(0.7044) 1000
194 1000 -1000.0 -99.99568287525881 number episode from 10: 194 avegar over 10 episode: -99.991 avegare return across last 100 episodes: -99.996 state values: tensor(0.7038) 1000
195 1000 -1000.0 -99.99568287525881 number episode from 10: 195 avegar over 10 episode: -99.991 avegare return across last 100 episodes: -99.996 state values: tensor(0.7042) 1000
196 1000 -1000.0 -99.99568287525881 number episode from 10: 196 avegar over 10 episode: -99.991 avegare return across last 100 episodes: -99.996 state values: tensor(0.7045) 1000
197 1000 -1000.0 -99.99568287525881 number episode from 10: 197 avegar over 10 episode: -99.991 avegare return across last 100 episodes: -99.996 state values: tensor(0.7042) 1000
198 1000 -1000.0 -99.99568287525881 number episode from 10: 198 avegar over 10 episode: -99.991 avegare return across last 100 episodes: -99.996 state values: tensor(0.7047) 1000
199 1000 -1000.0 -99.99568287525881 number episode from 10: 199 avegar over 10 episode: -99.991 avegare return across last 100 episodes: -99.996 state values: tensor(0.7041) 1000
200 1000 -1000.0 -99.99568287525881 number episode from 10: 200 avegar over 10 episode: -99.991 avegare return across last 100 episodes: -99.996 state values: tensor(0.7044) 1000
load offline data!!!!!
mem_cntr: 50000 ; mem_size: 50000
nn.learn_nn_feature_fqi FQI:  998
nn.learn_nn_feature_fqi FQI:  1998
nn.learn_nn_feature_fqi FQI:  2998
nn.learn_nn_feature_fqi FQI:  3998
nn.learn_nn_feature_fqi FQI:  4998
nn.learn_nn_feature_fqi FQI:  5998
nn.learn_nn_feature_fqi FQI:  6998
nn.learn_nn_feature_fqi FQI:  7998
nn.learn_nn_feature_fqi FQI:  8998
nn.learn_nn_feature_fqi FQI:  9998
nn.learn_nn_feature_fqi FQI:  10998
nn.learn_nn_feature_fqi FQI:  11998
nn.learn_nn_feature_fqi FQI:  12998
nn.learn_nn_feature_fqi FQI:  13998
nn.learn_nn_feature_fqi FQI:  14998
nn.learn_nn_feature_fqi FQI:  15998
nn.learn_nn_feature_fqi FQI:  16998
nn.learn_nn_feature_fqi FQI:  17998
nn.learn_nn_feature_fqi FQI:  18998
nn.learn_nn_feature_fqi FQI:  19998
nn.learn_nn_feature_fqi FQI:  20998
nn.learn_nn_feature_fqi FQI:  21998
nn.learn_nn_feature_fqi FQI:  22998
nn.learn_nn_feature_fqi FQI:  23998
nn.learn_nn_feature_fqi FQI:  24998
nn.learn_nn_feature_fqi FQI:  25998
nn.learn_nn_feature_fqi FQI:  26998
nn.learn_nn_feature_fqi FQI:  27998
nn.learn_nn_feature_fqi FQI:  28998
nn.learn_nn_feature_fqi FQI:  29998
nn.learn_nn_feature_fqi FQI:  30998
nn.learn_nn_feature_fqi FQI:  31998
nn.learn_nn_feature_fqi FQI:  32998
nn.learn_nn_feature_fqi FQI:  33998
nn.learn_nn_feature_fqi FQI:  34998
nn.learn_nn_feature_fqi FQI:  35998
nn.learn_nn_feature_fqi FQI:  36998
nn.learn_nn_feature_fqi FQI:  37998
nn.learn_nn_feature_fqi FQI:  38998
nn.learn_nn_feature_fqi FQI:  39998
nn.learn_nn_feature_fqi FQI:  40998
nn.learn_nn_feature_fqi FQI:  41998
nn.learn_nn_feature_fqi FQI:  42998
nn.learn_nn_feature_fqi FQI:  43998
nn.learn_nn_feature_fqi FQI:  44998
nn.learn_nn_feature_fqi FQI:  45998
nn.learn_nn_feature_fqi FQI:  46998
nn.learn_nn_feature_fqi FQI:  47998
nn.learn_nn_feature_fqi FQI:  48998
nn.learn_nn_feature_fqi FQI:  49998
nn.learn_nn_feature_fqi FQI:  50998
nn.learn_nn_feature_fqi FQI:  51998
nn.learn_nn_feature_fqi FQI:  52998
nn.learn_nn_feature_fqi FQI:  53998
nn.learn_nn_feature_fqi FQI:  54998
nn.learn_nn_feature_fqi FQI:  55998
nn.learn_nn_feature_fqi FQI:  56998
nn.learn_nn_feature_fqi FQI:  57998
nn.learn_nn_feature_fqi FQI:  58998
nn.learn_nn_feature_fqi FQI:  59998
nn.learn_nn_feature_fqi FQI:  60998
nn.learn_nn_feature_fqi FQI:  61998
nn.learn_nn_feature_fqi FQI:  62998
nn.learn_nn_feature_fqi FQI:  63998
nn.learn_nn_feature_fqi FQI:  64998
nn.learn_nn_feature_fqi FQI:  65998
nn.learn_nn_feature_fqi FQI:  66998
nn.learn_nn_feature_fqi FQI:  67998
nn.learn_nn_feature_fqi FQI:  68998
nn.learn_nn_feature_fqi FQI:  69998
nn.learn_nn_feature_fqi FQI:  70998
nn.learn_nn_feature_fqi FQI:  71998
nn.learn_nn_feature_fqi FQI:  72998
nn.learn_nn_feature_fqi FQI:  73998
nn.learn_nn_feature_fqi FQI:  74998
nn.learn_nn_feature_fqi FQI:  75998
nn.learn_nn_feature_fqi FQI:  76998
nn.learn_nn_feature_fqi FQI:  77998
nn.learn_nn_feature_fqi FQI:  78998
nn.learn_nn_feature_fqi FQI:  79998
nn.learn_nn_feature_fqi FQI:  80998
nn.learn_nn_feature_fqi FQI:  81998
nn.learn_nn_feature_fqi FQI:  82998
nn.learn_nn_feature_fqi FQI:  83998
nn.learn_nn_feature_fqi FQI:  84998
nn.learn_nn_feature_fqi FQI:  85998
nn.learn_nn_feature_fqi FQI:  86998
nn.learn_nn_feature_fqi FQI:  87998
nn.learn_nn_feature_fqi FQI:  88998
nn.learn_nn_feature_fqi FQI:  89998
nn.learn_nn_feature_fqi FQI:  90998
nn.learn_nn_feature_fqi FQI:  91998
nn.learn_nn_feature_fqi FQI:  92998
nn.learn_nn_feature_fqi FQI:  93998
nn.learn_nn_feature_fqi FQI:  94998
nn.learn_nn_feature_fqi FQI:  95998
nn.learn_nn_feature_fqi FQI:  96998
nn.learn_nn_feature_fqi FQI:  97998
nn.learn_nn_feature_fqi FQI:  98998
nn.learn_nn_feature_fqi FQI:  99998
nn.learn_nn_feature_fqi FQI:  100998
nn.learn_nn_feature_fqi FQI:  101998
nn.learn_nn_feature_fqi FQI:  102998
nn.learn_nn_feature_fqi FQI:  103998
nn.learn_nn_feature_fqi FQI:  104998
nn.learn_nn_feature_fqi FQI:  105998
nn.learn_nn_feature_fqi FQI:  106998
nn.learn_nn_feature_fqi FQI:  107998
nn.learn_nn_feature_fqi FQI:  108998
nn.learn_nn_feature_fqi FQI:  109998
nn.learn_nn_feature_fqi FQI:  110998
nn.learn_nn_feature_fqi FQI:  111998
nn.learn_nn_feature_fqi FQI:  112998
nn.learn_nn_feature_fqi FQI:  113998
nn.learn_nn_feature_fqi FQI:  114998
nn.learn_nn_feature_fqi FQI:  115998
nn.learn_nn_feature_fqi FQI:  116998
nn.learn_nn_feature_fqi FQI:  117998
nn.learn_nn_feature_fqi FQI:  118998
nn.learn_nn_feature_fqi FQI:  119998
nn.learn_nn_feature_fqi FQI:  120998
nn.learn_nn_feature_fqi FQI:  121998
nn.learn_nn_feature_fqi FQI:  122998
nn.learn_nn_feature_fqi FQI:  123998
nn.learn_nn_feature_fqi FQI:  124998
nn.learn_nn_feature_fqi FQI:  125998
nn.learn_nn_feature_fqi FQI:  126998
nn.learn_nn_feature_fqi FQI:  127998
nn.learn_nn_feature_fqi FQI:  128998
nn.learn_nn_feature_fqi FQI:  129998
nn.learn_nn_feature_fqi FQI:  130998
nn.learn_nn_feature_fqi FQI:  131998
nn.learn_nn_feature_fqi FQI:  132998
nn.learn_nn_feature_fqi FQI:  133998
nn.learn_nn_feature_fqi FQI:  134998
nn.learn_nn_feature_fqi FQI:  135998
nn.learn_nn_feature_fqi FQI:  136998
nn.learn_nn_feature_fqi FQI:  137998
nn.learn_nn_feature_fqi FQI:  138998
nn.learn_nn_feature_fqi FQI:  139998
nn.learn_nn_feature_fqi FQI:  140998
nn.learn_nn_feature_fqi FQI:  141998
nn.learn_nn_feature_fqi FQI:  142998
nn.learn_nn_feature_fqi FQI:  143998
nn.learn_nn_feature_fqi FQI:  144998
nn.learn_nn_feature_fqi FQI:  145998
nn.learn_nn_feature_fqi FQI:  146998
nn.learn_nn_feature_fqi FQI:  147998
nn.learn_nn_feature_fqi FQI:  148998
nn.learn_nn_feature_fqi FQI:  149998
nn.learn_nn_feature_fqi FQI:  150998
nn.learn_nn_feature_fqi FQI:  151998
nn.learn_nn_feature_fqi FQI:  152998
nn.learn_nn_feature_fqi FQI:  153998
nn.learn_nn_feature_fqi FQI:  154998
nn.learn_nn_feature_fqi FQI:  155998
0 1001 -1000.0 -98.99572604650622 number episode from 10: 0 avegar over 10 episode: -98.996 avegare return across last 100 episodes: -98.996 state values: tensor(0.8139) 1000
1 1000 -1000.0 -99.99568287525881 number episode from 10: 1 avegar over 10 episode: -99.496 avegare return across last 100 episodes: -99.496 state values: tensor(0.8112) 1000
2 1000 -1000.0 -99.99568287525881 number episode from 10: 2 avegar over 10 episode: -99.662 avegare return across last 100 episodes: -99.662 state values: tensor(0.8482) 1000
3 1000 -1000.0 -99.99568287525881 number episode from 10: 3 avegar over 10 episode: -99.746 avegare return across last 100 episodes: -99.746 state values: tensor(0.8136) 1000
4 1000 -1000.0 -99.99568287525881 number episode from 10: 4 avegar over 10 episode: -99.796 avegare return across last 100 episodes: -99.796 state values: tensor(0.8119) 1000
5 1000 -1000.0 -99.99568287525881 number episode from 10: 5 avegar over 10 episode: -99.829 avegare return across last 100 episodes: -99.829 state values: tensor(0.8143) 1000
6 1000 -1000.0 -99.99568287525881 number episode from 10: 6 avegar over 10 episode: -99.853 avegare return across last 100 episodes: -99.853 state values: tensor(0.8506) 1000
7 1000 -1000.0 -99.99568287525881 number episode from 10: 7 avegar over 10 episode: -99.871 avegare return across last 100 episodes: -99.871 state values: tensor(0.8140) 1000
8 1000 -1000.0 -99.99568287525881 number episode from 10: 8 avegar over 10 episode: -99.885 avegare return across last 100 episodes: -99.885 state values: tensor(0.8145) 1000
9 1000 -1000.0 -99.99568287525881 number episode from 10: 9 avegar over 10 episode: -99.896 avegare return across last 100 episodes: -99.896 state values: tensor(0.8114) 1000
10 1000 -1000.0 -99.99568287525881 number episode from 10: 10 avegar over 10 episode: -99.905 avegare return across last 100 episodes: -99.905 state values: tensor(0.8479) 1000
11 1000 -1000.0 -99.99568287525881 number episode from 10: 11 avegar over 10 episode: -99.912 avegare return across last 100 episodes: -99.912 state values: tensor(0.8129) 1000
12 1000 -1000.0 -99.99568287525881 number episode from 10: 12 avegar over 10 episode: -99.919 avegare return across last 100 episodes: -99.919 state values: tensor(0.8123) 1000
13 1000 -1000.0 -99.99568287525881 number episode from 10: 13 avegar over 10 episode: -99.924 avegare return across last 100 episodes: -99.924 state values: tensor(0.8120) 1000
14 1000 -1000.0 -99.99568287525881 number episode from 10: 14 avegar over 10 episode: -99.929 avegare return across last 100 episodes: -99.929 state values: tensor(0.8134) 1000
15 1000 -1000.0 -99.99568287525881 number episode from 10: 15 avegar over 10 episode: -99.933 avegare return across last 100 episodes: -99.933 state values: tensor(0.8140) 1000
16 1000 -1000.0 -99.99568287525881 number episode from 10: 16 avegar over 10 episode: -99.937 avegare return across last 100 episodes: -99.937 state values: tensor(0.8117) 1000
17 1000 -1000.0 -99.99568287525881 number episode from 10: 17 avegar over 10 episode: -99.94 avegare return across last 100 episodes: -99.94 state values: tensor(0.8123) 1000
18 1000 -1000.0 -99.99568287525881 number episode from 10: 18 avegar over 10 episode: -99.943 avegare return across last 100 episodes: -99.943 state values: tensor(0.8138) 1000
19 1000 -1000.0 -99.99568287525881 number episode from 10: 19 avegar over 10 episode: -99.946 avegare return across last 100 episodes: -99.946 state values: tensor(0.8135) 1000
20 1000 -1000.0 -99.99568287525881 number episode from 10: 20 avegar over 10 episode: -99.948 avegare return across last 100 episodes: -99.948 state values: tensor(0.8139) 1000
21 1000 -1000.0 -99.99568287525881 number episode from 10: 21 avegar over 10 episode: -99.95 avegare return across last 100 episodes: -99.95 state values: tensor(0.8126) 1000
22 1000 -1000.0 -99.99568287525881 number episode from 10: 22 avegar over 10 episode: -99.952 avegare return across last 100 episodes: -99.952 state values: tensor(0.8118) 1000
23 1000 -1000.0 -99.99568287525881 number episode from 10: 23 avegar over 10 episode: -99.954 avegare return across last 100 episodes: -99.954 state values: tensor(0.8130) 1000
24 1000 -1000.0 -99.99568287525881 number episode from 10: 24 avegar over 10 episode: -99.956 avegare return across last 100 episodes: -99.956 state values: tensor(0.8123) 1000
25 1000 -1000.0 -99.99568287525881 number episode from 10: 25 avegar over 10 episode: -99.957 avegare return across last 100 episodes: -99.957 state values: tensor(0.8112) 1000
26 1000 -1000.0 -99.99568287525881 number episode from 10: 26 avegar over 10 episode: -99.959 avegare return across last 100 episodes: -99.959 state values: tensor(0.8492) 1000
27 1000 -1000.0 -99.99568287525881 number episode from 10: 27 avegar over 10 episode: -99.96 avegare return across last 100 episodes: -99.96 state values: tensor(0.8111) 1000
28 1000 -1000.0 -99.99568287525881 number episode from 10: 28 avegar over 10 episode: -99.961 avegare return across last 100 episodes: -99.961 state values: tensor(0.8134) 1000
29 1000 -1000.0 -99.99568287525881 number episode from 10: 29 avegar over 10 episode: -99.962 avegare return across last 100 episodes: -99.962 state values: tensor(0.8115) 1000
30 1000 -1000.0 -99.99568287525881 number episode from 10: 30 avegar over 10 episode: -99.963 avegare return across last 100 episodes: -99.963 state values: tensor(0.8116) 1000
31 1000 -1000.0 -99.99568287525881 number episode from 10: 31 avegar over 10 episode: -99.964 avegare return across last 100 episodes: -99.964 state values: tensor(0.8114) 1000
32 1000 -1000.0 -99.99568287525881 number episode from 10: 32 avegar over 10 episode: -99.965 avegare return across last 100 episodes: -99.965 state values: tensor(0.8495) 1000
33 1000 -1000.0 -99.99568287525881 number episode from 10: 33 avegar over 10 episode: -99.966 avegare return across last 100 episodes: -99.966 state values: tensor(0.8131) 1000
34 1000 -1000.0 -99.99568287525881 number episode from 10: 34 avegar over 10 episode: -99.967 avegare return across last 100 episodes: -99.967 state values: tensor(0.8497) 1000
35 1000 -1000.0 -99.99568287525881 number episode from 10: 35 avegar over 10 episode: -99.968 avegare return across last 100 episodes: -99.968 state values: tensor(0.8117) 1000
36 1000 -1000.0 -99.99568287525881 number episode from 10: 36 avegar over 10 episode: -99.969 avegare return across last 100 episodes: -99.969 state values: tensor(0.8115) 1000
37 1000 -1000.0 -99.99568287525881 number episode from 10: 37 avegar over 10 episode: -99.969 avegare return across last 100 episodes: -99.969 state values: tensor(0.8125) 1000
38 1000 -1000.0 -99.99568287525881 number episode from 10: 38 avegar over 10 episode: -99.97 avegare return across last 100 episodes: -99.97 state values: tensor(0.8114) 1000
39 1000 -1000.0 -99.99568287525881 number episode from 10: 39 avegar over 10 episode: -99.971 avegare return across last 100 episodes: -99.971 state values: tensor(0.8125) 1000
40 1000 -1000.0 -99.99568287525881 number episode from 10: 40 avegar over 10 episode: -99.971 avegare return across last 100 episodes: -99.971 state values: tensor(0.8125) 1000
41 1000 -1000.0 -99.99568287525881 number episode from 10: 41 avegar over 10 episode: -99.972 avegare return across last 100 episodes: -99.972 state values: tensor(0.8124) 1000
42 1000 -1000.0 -99.99568287525881 number episode from 10: 42 avegar over 10 episode: -99.972 avegare return across last 100 episodes: -99.972 state values: tensor(0.8128) 1000
43 1000 -1000.0 -99.99568287525881 number episode from 10: 43 avegar over 10 episode: -99.973 avegare return across last 100 episodes: -99.973 state values: tensor(0.8115) 1000
44 1000 -1000.0 -99.99568287525881 number episode from 10: 44 avegar over 10 episode: -99.973 avegare return across last 100 episodes: -99.973 state values: tensor(0.8119) 1000
45 1000 -1000.0 -99.99568287525881 number episode from 10: 45 avegar over 10 episode: -99.974 avegare return across last 100 episodes: -99.974 state values: tensor(0.8114) 1000
46 1000 -1000.0 -99.99568287525881 number episode from 10: 46 avegar over 10 episode: -99.974 avegare return across last 100 episodes: -99.974 state values: tensor(0.8140) 1000
47 1000 -1000.0 -99.99568287525881 number episode from 10: 47 avegar over 10 episode: -99.975 avegare return across last 100 episodes: -99.975 state values: tensor(0.8130) 1000
48 1000 -1000.0 -99.99568287525881 number episode from 10: 48 avegar over 10 episode: -99.975 avegare return across last 100 episodes: -99.975 state values: tensor(0.8138) 1000
49 1000 -1000.0 -99.99568287525881 number episode from 10: 49 avegar over 10 episode: -99.976 avegare return across last 100 episodes: -99.976 state values: tensor(0.8116) 1000
50 1000 -1000.0 -99.99568287525881 number episode from 10: 50 avegar over 10 episode: -99.976 avegare return across last 100 episodes: -99.976 state values: tensor(0.8118) 1000
51 1000 -1000.0 -99.99568287525881 number episode from 10: 51 avegar over 10 episode: -99.976 avegare return across last 100 episodes: -99.976 state values: tensor(0.8111) 1000
52 1000 -1000.0 -99.99568287525881 number episode from 10: 52 avegar over 10 episode: -99.977 avegare return across last 100 episodes: -99.977 state values: tensor(0.8113) 1000
53 1000 -1000.0 -99.99568287525881 number episode from 10: 53 avegar over 10 episode: -99.977 avegare return across last 100 episodes: -99.977 state values: tensor(0.8496) 1000
54 1000 -1000.0 -99.99568287525881 number episode from 10: 54 avegar over 10 episode: -99.978 avegare return across last 100 episodes: -99.978 state values: tensor(0.8124) 1000
55 1000 -1000.0 -99.99568287525881 number episode from 10: 55 avegar over 10 episode: -99.978 avegare return across last 100 episodes: -99.978 state values: tensor(0.8137) 1000
56 1000 -1000.0 -99.99568287525881 number episode from 10: 56 avegar over 10 episode: -99.978 avegare return across last 100 episodes: -99.978 state values: tensor(0.8134) 1000
57 1000 -1000.0 -99.99568287525881 number episode from 10: 57 avegar over 10 episode: -99.978 avegare return across last 100 episodes: -99.978 state values: tensor(0.8225) 1000
58 1000 -1000.0 -99.99568287525881 number episode from 10: 58 avegar over 10 episode: -99.979 avegare return across last 100 episodes: -99.979 state values: tensor(0.8111) 1000
59 1000 -1000.0 -99.99568287525881 number episode from 10: 59 avegar over 10 episode: -99.979 avegare return across last 100 episodes: -99.979 state values: tensor(0.8134) 1000
60 1000 -1000.0 -99.99568287525881 number episode from 10: 60 avegar over 10 episode: -99.979 avegare return across last 100 episodes: -99.979 state values: tensor(0.8489) 1000
61 1000 -1000.0 -99.99568287525881 number episode from 10: 61 avegar over 10 episode: -99.98 avegare return across last 100 episodes: -99.98 state values: tensor(0.8501) 1000
62 1000 -1000.0 -99.99568287525881 number episode from 10: 62 avegar over 10 episode: -99.98 avegare return across last 100 episodes: -99.98 state values: tensor(0.8120) 1000
63 1000 -1000.0 -99.99568287525881 number episode from 10: 63 avegar over 10 episode: -99.98 avegare return across last 100 episodes: -99.98 state values: tensor(0.8170) 1000
64 1000 -1000.0 -99.99568287525881 number episode from 10: 64 avegar over 10 episode: -99.98 avegare return across last 100 episodes: -99.98 state values: tensor(0.8113) 1000
65 1000 -1000.0 -99.99568287525881 number episode from 10: 65 avegar over 10 episode: -99.981 avegare return across last 100 episodes: -99.981 state values: tensor(0.8144) 1000
66 1000 -1000.0 -99.99568287525881 number episode from 10: 66 avegar over 10 episode: -99.981 avegare return across last 100 episodes: -99.981 state values: tensor(0.8138) 1000
67 1000 -1000.0 -99.99568287525881 number episode from 10: 67 avegar over 10 episode: -99.981 avegare return across last 100 episodes: -99.981 state values: tensor(0.8140) 1000
68 1000 -1000.0 -99.99568287525881 number episode from 10: 68 avegar over 10 episode: -99.981 avegare return across last 100 episodes: -99.981 state values: tensor(0.8111) 1000
69 1000 -1000.0 -99.99568287525881 number episode from 10: 69 avegar over 10 episode: -99.981 avegare return across last 100 episodes: -99.981 state values: tensor(0.8141) 1000
70 1000 -1000.0 -99.99568287525881 number episode from 10: 70 avegar over 10 episode: -99.982 avegare return across last 100 episodes: -99.982 state values: tensor(0.8494) 1000
71 1000 -1000.0 -99.99568287525881 number episode from 10: 71 avegar over 10 episode: -99.982 avegare return across last 100 episodes: -99.982 state values: tensor(0.8114) 1000
72 1000 -1000.0 -99.99568287525881 number episode from 10: 72 avegar over 10 episode: -99.982 avegare return across last 100 episodes: -99.982 state values: tensor(0.8133) 1000
73 1000 -1000.0 -99.99568287525881 number episode from 10: 73 avegar over 10 episode: -99.982 avegare return across last 100 episodes: -99.982 state values: tensor(0.8135) 1000
74 1000 -1000.0 -99.99568287525881 number episode from 10: 74 avegar over 10 episode: -99.982 avegare return across last 100 episodes: -99.982 state values: tensor(0.8130) 1000
75 1000 -1000.0 -99.99568287525881 number episode from 10: 75 avegar over 10 episode: -99.983 avegare return across last 100 episodes: -99.983 state values: tensor(0.8110) 1000
76 1000 -1000.0 -99.99568287525881 number episode from 10: 76 avegar over 10 episode: -99.983 avegare return across last 100 episodes: -99.983 state values: tensor(0.8129) 1000
77 1000 -1000.0 -99.99568287525881 number episode from 10: 77 avegar over 10 episode: -99.983 avegare return across last 100 episodes: -99.983 state values: tensor(0.8126) 1000
78 1000 -1000.0 -99.99568287525881 number episode from 10: 78 avegar over 10 episode: -99.983 avegare return across last 100 episodes: -99.983 state values: tensor(0.8114) 1000
79 1000 -1000.0 -99.99568287525881 number episode from 10: 79 avegar over 10 episode: -99.983 avegare return across last 100 episodes: -99.983 state values: tensor(0.8140) 1000
80 1000 -1000.0 -99.99568287525881 number episode from 10: 80 avegar over 10 episode: -99.983 avegare return across last 100 episodes: -99.983 state values: tensor(0.8430) 1000
81 1000 -1000.0 -99.99568287525881 number episode from 10: 81 avegar over 10 episode: -99.983 avegare return across last 100 episodes: -99.983 state values: tensor(0.8138) 1000
82 1000 -1000.0 -99.99568287525881 number episode from 10: 82 avegar over 10 episode: -99.984 avegare return across last 100 episodes: -99.984 state values: tensor(0.8494) 1000
83 1000 -1000.0 -99.99568287525881 number episode from 10: 83 avegar over 10 episode: -99.984 avegare return across last 100 episodes: -99.984 state values: tensor(0.8514) 1000
84 1000 -1000.0 -99.99568287525881 number episode from 10: 84 avegar over 10 episode: -99.984 avegare return across last 100 episodes: -99.984 state values: tensor(0.8139) 1000
85 1000 -1000.0 -99.99568287525881 number episode from 10: 85 avegar over 10 episode: -99.984 avegare return across last 100 episodes: -99.984 state values: tensor(0.8122) 1000
86 1000 -1000.0 -99.99568287525881 number episode from 10: 86 avegar over 10 episode: -99.984 avegare return across last 100 episodes: -99.984 state values: tensor(0.8117) 1000
87 1000 -1000.0 -99.99568287525881 number episode from 10: 87 avegar over 10 episode: -99.984 avegare return across last 100 episodes: -99.984 state values: tensor(0.8115) 1000
88 1000 -1000.0 -99.99568287525881 number episode from 10: 88 avegar over 10 episode: -99.984 avegare return across last 100 episodes: -99.984 state values: tensor(0.8506) 1000
89 1000 -1000.0 -99.99568287525881 number episode from 10: 89 avegar over 10 episode: -99.985 avegare return across last 100 episodes: -99.985 state values: tensor(0.8128) 1000
90 1000 -1000.0 -99.99568287525881 number episode from 10: 90 avegar over 10 episode: -99.985 avegare return across last 100 episodes: -99.985 state values: tensor(0.8119) 1000
91 1000 -1000.0 -99.99568287525881 number episode from 10: 91 avegar over 10 episode: -99.985 avegare return across last 100 episodes: -99.985 state values: tensor(0.8135) 1000
92 1000 -1000.0 -99.99568287525881 number episode from 10: 92 avegar over 10 episode: -99.985 avegare return across last 100 episodes: -99.985 state values: tensor(0.8500) 1000
93 1000 -1000.0 -99.99568287525881 number episode from 10: 93 avegar over 10 episode: -99.985 avegare return across last 100 episodes: -99.985 state values: tensor(0.8137) 1000
94 1000 -1000.0 -99.99568287525881 number episode from 10: 94 avegar over 10 episode: -99.985 avegare return across last 100 episodes: -99.985 state values: tensor(0.8116) 1000
95 1000 -1000.0 -99.99568287525881 number episode from 10: 95 avegar over 10 episode: -99.985 avegare return across last 100 episodes: -99.985 state values: tensor(0.8130) 1000
96 1000 -1000.0 -99.99568287525881 number episode from 10: 96 avegar over 10 episode: -99.985 avegare return across last 100 episodes: -99.985 state values: tensor(0.8495) 1000
97 1000 -1000.0 -99.99568287525881 number episode from 10: 97 avegar over 10 episode: -99.985 avegare return across last 100 episodes: -99.985 state values: tensor(0.8494) 1000
98 1000 -1000.0 -99.99568287525881 number episode from 10: 98 avegar over 10 episode: -99.986 avegare return across last 100 episodes: -99.986 state values: tensor(0.8116) 1000
99 1000 -1000.0 -99.99568287525881 number episode from 10: 99 avegar over 10 episode: -99.986 avegare return across last 100 episodes: -99.986 state values: tensor(0.8124) 1000
100 1000 -1000.0 -99.99568287525881 number episode from 10: 100 avegar over 10 episode: -99.986 avegare return across last 100 episodes: -99.996 state values: tensor(0.8127) 1000
101 1000 -1000.0 -99.99568287525881 number episode from 10: 101 avegar over 10 episode: -99.986 avegare return across last 100 episodes: -99.996 state values: tensor(0.8368) 1000
102 1000 -1000.0 -99.99568287525881 number episode from 10: 102 avegar over 10 episode: -99.986 avegare return across last 100 episodes: -99.996 state values: tensor(0.8121) 1000
103 1000 -1000.0 -99.99568287525881 number episode from 10: 103 avegar over 10 episode: -99.986 avegare return across last 100 episodes: -99.996 state values: tensor(0.8502) 1000
104 1000 -1000.0 -99.99568287525881 number episode from 10: 104 avegar over 10 episode: -99.986 avegare return across last 100 episodes: -99.996 state values: tensor(0.8131) 1000
105 1000 -1000.0 -99.99568287525881 number episode from 10: 105 avegar over 10 episode: -99.986 avegare return across last 100 episodes: -99.996 state values: tensor(0.8114) 1000
106 1000 -1000.0 -99.99568287525881 number episode from 10: 106 avegar over 10 episode: -99.986 avegare return across last 100 episodes: -99.996 state values: tensor(0.8181) 1000
107 1000 -1000.0 -99.99568287525881 number episode from 10: 107 avegar over 10 episode: -99.986 avegare return across last 100 episodes: -99.996 state values: tensor(0.8130) 1000
108 1000 -1000.0 -99.99568287525881 number episode from 10: 108 avegar over 10 episode: -99.987 avegare return across last 100 episodes: -99.996 state values: tensor(0.8499) 1000
109 1000 -1000.0 -99.99568287525881 number episode from 10: 109 avegar over 10 episode: -99.987 avegare return across last 100 episodes: -99.996 state values: tensor(0.8496) 1000
110 1000 -1000.0 -99.99568287525881 number episode from 10: 110 avegar over 10 episode: -99.987 avegare return across last 100 episodes: -99.996 state values: tensor(0.8142) 1000
111 1000 -1000.0 -99.99568287525881 number episode from 10: 111 avegar over 10 episode: -99.987 avegare return across last 100 episodes: -99.996 state values: tensor(0.8189) 1000
112 1000 -1000.0 -99.99568287525881 number episode from 10: 112 avegar over 10 episode: -99.987 avegare return across last 100 episodes: -99.996 state values: tensor(0.8501) 1000
113 1000 -1000.0 -99.99568287525881 number episode from 10: 113 avegar over 10 episode: -99.987 avegare return across last 100 episodes: -99.996 state values: tensor(0.8489) 1000
114 1000 -1000.0 -99.99568287525881 number episode from 10: 114 avegar over 10 episode: -99.987 avegare return across last 100 episodes: -99.996 state values: tensor(0.8510) 1000
115 1000 -1000.0 -99.99568287525881 number episode from 10: 115 avegar over 10 episode: -99.987 avegare return across last 100 episodes: -99.996 state values: tensor(0.8115) 1000
116 1000 -1000.0 -99.99568287525881 number episode from 10: 116 avegar over 10 episode: -99.987 avegare return across last 100 episodes: -99.996 state values: tensor(0.8125) 1000
117 1000 -1000.0 -99.99568287525881 number episode from 10: 117 avegar over 10 episode: -99.987 avegare return across last 100 episodes: -99.996 state values: tensor(0.8119) 1000
118 1000 -1000.0 -99.99568287525881 number episode from 10: 118 avegar over 10 episode: -99.987 avegare return across last 100 episodes: -99.996 state values: tensor(0.8116) 1000
119 1000 -1000.0 -99.99568287525881 number episode from 10: 119 avegar over 10 episode: -99.987 avegare return across last 100 episodes: -99.996 state values: tensor(0.8115) 1000
120 1000 -1000.0 -99.99568287525881 number episode from 10: 120 avegar over 10 episode: -99.987 avegare return across last 100 episodes: -99.996 state values: tensor(0.8129) 1000
121 1000 -1000.0 -99.99568287525881 number episode from 10: 121 avegar over 10 episode: -99.987 avegare return across last 100 episodes: -99.996 state values: tensor(0.8487) 1000
122 1000 -1000.0 -99.99568287525881 number episode from 10: 122 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.8490) 1000
123 1000 -1000.0 -99.99568287525881 number episode from 10: 123 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.8116) 1000
124 1000 -1000.0 -99.99568287525881 number episode from 10: 124 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.8294) 1000
125 1000 -1000.0 -99.99568287525881 number episode from 10: 125 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.8127) 1000
126 1000 -1000.0 -99.99568287525881 number episode from 10: 126 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.8117) 1000
127 1000 -1000.0 -99.99568287525881 number episode from 10: 127 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.8497) 1000
128 1000 -1000.0 -99.99568287525881 number episode from 10: 128 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.8126) 1000
129 1000 -1000.0 -99.99568287525881 number episode from 10: 129 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.8143) 1000
130 1000 -1000.0 -99.99568287525881 number episode from 10: 130 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.8116) 1000
131 1000 -1000.0 -99.99568287525881 number episode from 10: 131 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.8128) 1000
132 1000 -1000.0 -99.99568287525881 number episode from 10: 132 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.8123) 1000
133 1000 -1000.0 -99.99568287525881 number episode from 10: 133 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.8111) 1000
134 1000 -1000.0 -99.99568287525881 number episode from 10: 134 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.8117) 1000
135 1000 -1000.0 -99.99568287525881 number episode from 10: 135 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.8246) 1000
136 1000 -1000.0 -99.99568287525881 number episode from 10: 136 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.8135) 1000
137 1000 -1000.0 -99.99568287525881 number episode from 10: 137 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.8112) 1000
138 1000 -1000.0 -99.99568287525881 number episode from 10: 138 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.8135) 1000
139 1000 -1000.0 -99.99568287525881 number episode from 10: 139 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.8118) 1000
140 1000 -1000.0 -99.99568287525881 number episode from 10: 140 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.8471) 1000
141 1000 -1000.0 -99.99568287525881 number episode from 10: 141 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.8110) 1000
142 1000 -1000.0 -99.99568287525881 number episode from 10: 142 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.8119) 1000
143 1000 -1000.0 -99.99568287525881 number episode from 10: 143 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.8115) 1000
144 1000 -1000.0 -99.99568287525881 number episode from 10: 144 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.8115) 1000
145 1000 -1000.0 -99.99568287525881 number episode from 10: 145 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.8489) 1000
146 1000 -1000.0 -99.99568287525881 number episode from 10: 146 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.8120) 1000
147 1000 -1000.0 -99.99568287525881 number episode from 10: 147 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.8499) 1000
148 1000 -1000.0 -99.99568287525881 number episode from 10: 148 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.8140) 1000
149 1000 -1000.0 -99.99568287525881 number episode from 10: 149 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.8114) 1000
150 1000 -1000.0 -99.99568287525881 number episode from 10: 150 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.8113) 1000
151 1000 -1000.0 -99.99568287525881 number episode from 10: 151 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.8134) 1000
152 1000 -1000.0 -99.99568287525881 number episode from 10: 152 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.8503) 1000
153 1000 -1000.0 -99.99568287525881 number episode from 10: 153 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.8120) 1000
154 1000 -1000.0 -99.99568287525881 number episode from 10: 154 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.8138) 1000
155 1000 -1000.0 -99.99568287525881 number episode from 10: 155 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.8119) 1000
156 1000 -1000.0 -99.99568287525881 number episode from 10: 156 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.8185) 1000
157 1000 -1000.0 -99.99568287525881 number episode from 10: 157 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.8112) 1000
158 1000 -1000.0 -99.99568287525881 number episode from 10: 158 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.8128) 1000
159 1000 -1000.0 -99.99568287525881 number episode from 10: 159 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.8122) 1000
160 1000 -1000.0 -99.99568287525881 number episode from 10: 160 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.8117) 1000
161 1000 -1000.0 -99.99568287525881 number episode from 10: 161 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.8129) 1000
162 1000 -1000.0 -99.99568287525881 number episode from 10: 162 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.8504) 1000
163 1000 -1000.0 -99.99568287525881 number episode from 10: 163 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.8126) 1000
164 1000 -1000.0 -99.99568287525881 number episode from 10: 164 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.8144) 1000
165 1000 -1000.0 -99.99568287525881 number episode from 10: 165 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.8480) 1000
166 1000 -1000.0 -99.99568287525881 number episode from 10: 166 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.8136) 1000
167 1000 -1000.0 -99.99568287525881 number episode from 10: 167 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.8141) 1000
168 1000 -1000.0 -99.99568287525881 number episode from 10: 168 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.8115) 1000
169 1000 -1000.0 -99.99568287525881 number episode from 10: 169 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.8490) 1000
170 1000 -1000.0 -99.99568287525881 number episode from 10: 170 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.8136) 1000
171 1000 -1000.0 -99.99568287525881 number episode from 10: 171 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.8132) 1000
172 1000 -1000.0 -99.99568287525881 number episode from 10: 172 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.8120) 1000
173 1000 -1000.0 -99.99568287525881 number episode from 10: 173 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.8110) 1000
174 1000 -1000.0 -99.99568287525881 number episode from 10: 174 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.8111) 1000
175 1000 -1000.0 -99.99568287525881 number episode from 10: 175 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.8123) 1000
176 1000 -1000.0 -99.99568287525881 number episode from 10: 176 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.8134) 1000
177 1000 -1000.0 -99.99568287525881 number episode from 10: 177 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.8129) 1000
178 1000 -1000.0 -99.99568287525881 number episode from 10: 178 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.8115) 1000
179 1000 -1000.0 -99.99568287525881 number episode from 10: 179 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.8111) 1000
180 1000 -1000.0 -99.99568287525881 number episode from 10: 180 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.8136) 1000
181 1000 -1000.0 -99.99568287525881 number episode from 10: 181 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.8347) 1000
182 1000 -1000.0 -99.99568287525881 number episode from 10: 182 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.8513) 1000
183 1000 -1000.0 -99.99568287525881 number episode from 10: 183 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.8145) 1000
184 1000 -1000.0 -99.99568287525881 number episode from 10: 184 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.8123) 1000
185 1000 -1000.0 -99.99568287525881 number episode from 10: 185 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.8116) 1000
186 1000 -1000.0 -99.99568287525881 number episode from 10: 186 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.8114) 1000
187 1000 -1000.0 -99.99568287525881 number episode from 10: 187 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.8112) 1000
188 1000 -1000.0 -99.99568287525881 number episode from 10: 188 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.8139) 1000
189 1000 -1000.0 -99.99568287525881 number episode from 10: 189 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.8125) 1000
190 1000 -1000.0 -99.99568287525881 number episode from 10: 190 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.8111) 1000
191 1000 -1000.0 -99.99568287525881 number episode from 10: 191 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.8349) 1000
192 1000 -1000.0 -99.99568287525881 number episode from 10: 192 avegar over 10 episode: -99.991 avegare return across last 100 episodes: -99.996 state values: tensor(0.8141) 1000
193 1000 -1000.0 -99.99568287525881 number episode from 10: 193 avegar over 10 episode: -99.991 avegare return across last 100 episodes: -99.996 state values: tensor(0.8140) 1000
194 1000 -1000.0 -99.99568287525881 number episode from 10: 194 avegar over 10 episode: -99.991 avegare return across last 100 episodes: -99.996 state values: tensor(0.8112) 1000
195 1000 -1000.0 -99.99568287525881 number episode from 10: 195 avegar over 10 episode: -99.991 avegare return across last 100 episodes: -99.996 state values: tensor(0.8125) 1000
196 1000 -1000.0 -99.99568287525881 number episode from 10: 196 avegar over 10 episode: -99.991 avegare return across last 100 episodes: -99.996 state values: tensor(0.8120) 1000
197 1000 -1000.0 -99.99568287525881 number episode from 10: 197 avegar over 10 episode: -99.991 avegare return across last 100 episodes: -99.996 state values: tensor(0.8125) 1000
198 1000 -1000.0 -99.99568287525881 number episode from 10: 198 avegar over 10 episode: -99.991 avegare return across last 100 episodes: -99.996 state values: tensor(0.8115) 1000
199 1000 -1000.0 -99.99568287525881 number episode from 10: 199 avegar over 10 episode: -99.991 avegare return across last 100 episodes: -99.996 state values: tensor(0.8478) 1000
200 1000 -1000.0 -99.99568287525881 number episode from 10: 200 avegar over 10 episode: -99.991 avegare return across last 100 episodes: -99.996 state values: tensor(0.8133) 1000
load offline data!!!!!
mem_cntr: 50000 ; mem_size: 50000
nn.learn_nn_feature_fqi FQI:  998
nn.learn_nn_feature_fqi FQI:  1998
nn.learn_nn_feature_fqi FQI:  2998
nn.learn_nn_feature_fqi FQI:  3998
nn.learn_nn_feature_fqi FQI:  4998
nn.learn_nn_feature_fqi FQI:  5998
nn.learn_nn_feature_fqi FQI:  6998
nn.learn_nn_feature_fqi FQI:  7998
nn.learn_nn_feature_fqi FQI:  8998
nn.learn_nn_feature_fqi FQI:  9998
nn.learn_nn_feature_fqi FQI:  10998
nn.learn_nn_feature_fqi FQI:  11998
nn.learn_nn_feature_fqi FQI:  12998
nn.learn_nn_feature_fqi FQI:  13998
nn.learn_nn_feature_fqi FQI:  14998
nn.learn_nn_feature_fqi FQI:  15998
nn.learn_nn_feature_fqi FQI:  16998
nn.learn_nn_feature_fqi FQI:  17998
nn.learn_nn_feature_fqi FQI:  18998
nn.learn_nn_feature_fqi FQI:  19998
nn.learn_nn_feature_fqi FQI:  20998
nn.learn_nn_feature_fqi FQI:  21998
nn.learn_nn_feature_fqi FQI:  22998
nn.learn_nn_feature_fqi FQI:  23998
nn.learn_nn_feature_fqi FQI:  24998
nn.learn_nn_feature_fqi FQI:  25998
nn.learn_nn_feature_fqi FQI:  26998
nn.learn_nn_feature_fqi FQI:  27998
nn.learn_nn_feature_fqi FQI:  28998
nn.learn_nn_feature_fqi FQI:  29998
nn.learn_nn_feature_fqi FQI:  30998
nn.learn_nn_feature_fqi FQI:  31998
nn.learn_nn_feature_fqi FQI:  32998
nn.learn_nn_feature_fqi FQI:  33998
nn.learn_nn_feature_fqi FQI:  34998
nn.learn_nn_feature_fqi FQI:  35998
nn.learn_nn_feature_fqi FQI:  36998
nn.learn_nn_feature_fqi FQI:  37998
nn.learn_nn_feature_fqi FQI:  38998
nn.learn_nn_feature_fqi FQI:  39998
nn.learn_nn_feature_fqi FQI:  40998
nn.learn_nn_feature_fqi FQI:  41998
nn.learn_nn_feature_fqi FQI:  42998
nn.learn_nn_feature_fqi FQI:  43998
nn.learn_nn_feature_fqi FQI:  44998
nn.learn_nn_feature_fqi FQI:  45998
nn.learn_nn_feature_fqi FQI:  46998
nn.learn_nn_feature_fqi FQI:  47998
nn.learn_nn_feature_fqi FQI:  48998
nn.learn_nn_feature_fqi FQI:  49998
nn.learn_nn_feature_fqi FQI:  50998
nn.learn_nn_feature_fqi FQI:  51998
nn.learn_nn_feature_fqi FQI:  52998
nn.learn_nn_feature_fqi FQI:  53998
nn.learn_nn_feature_fqi FQI:  54998
nn.learn_nn_feature_fqi FQI:  55998
nn.learn_nn_feature_fqi FQI:  56998
nn.learn_nn_feature_fqi FQI:  57998
nn.learn_nn_feature_fqi FQI:  58998
nn.learn_nn_feature_fqi FQI:  59998
nn.learn_nn_feature_fqi FQI:  60998
nn.learn_nn_feature_fqi FQI:  61998
nn.learn_nn_feature_fqi FQI:  62998
nn.learn_nn_feature_fqi FQI:  63998
nn.learn_nn_feature_fqi FQI:  64998
nn.learn_nn_feature_fqi FQI:  65998
nn.learn_nn_feature_fqi FQI:  66998
nn.learn_nn_feature_fqi FQI:  67998
nn.learn_nn_feature_fqi FQI:  68998
nn.learn_nn_feature_fqi FQI:  69998
nn.learn_nn_feature_fqi FQI:  70998
nn.learn_nn_feature_fqi FQI:  71998
nn.learn_nn_feature_fqi FQI:  72998
nn.learn_nn_feature_fqi FQI:  73998
nn.learn_nn_feature_fqi FQI:  74998
nn.learn_nn_feature_fqi FQI:  75998
nn.learn_nn_feature_fqi FQI:  76998
nn.learn_nn_feature_fqi FQI:  77998
nn.learn_nn_feature_fqi FQI:  78998
nn.learn_nn_feature_fqi FQI:  79998
nn.learn_nn_feature_fqi FQI:  80998
nn.learn_nn_feature_fqi FQI:  81998
nn.learn_nn_feature_fqi FQI:  82998
nn.learn_nn_feature_fqi FQI:  83998
nn.learn_nn_feature_fqi FQI:  84998
nn.learn_nn_feature_fqi FQI:  85998
nn.learn_nn_feature_fqi FQI:  86998
nn.learn_nn_feature_fqi FQI:  87998
nn.learn_nn_feature_fqi FQI:  88998
nn.learn_nn_feature_fqi FQI:  89998
nn.learn_nn_feature_fqi FQI:  90998
nn.learn_nn_feature_fqi FQI:  91998
nn.learn_nn_feature_fqi FQI:  92998
nn.learn_nn_feature_fqi FQI:  93998
nn.learn_nn_feature_fqi FQI:  94998
nn.learn_nn_feature_fqi FQI:  95998
nn.learn_nn_feature_fqi FQI:  96998
nn.learn_nn_feature_fqi FQI:  97998
nn.learn_nn_feature_fqi FQI:  98998
nn.learn_nn_feature_fqi FQI:  99998
nn.learn_nn_feature_fqi FQI:  100998
nn.learn_nn_feature_fqi FQI:  101998
nn.learn_nn_feature_fqi FQI:  102998
nn.learn_nn_feature_fqi FQI:  103998
nn.learn_nn_feature_fqi FQI:  104998
nn.learn_nn_feature_fqi FQI:  105998
nn.learn_nn_feature_fqi FQI:  106998
nn.learn_nn_feature_fqi FQI:  107998
nn.learn_nn_feature_fqi FQI:  108998
nn.learn_nn_feature_fqi FQI:  109998
nn.learn_nn_feature_fqi FQI:  110998
nn.learn_nn_feature_fqi FQI:  111998
nn.learn_nn_feature_fqi FQI:  112998
nn.learn_nn_feature_fqi FQI:  113998
nn.learn_nn_feature_fqi FQI:  114998
nn.learn_nn_feature_fqi FQI:  115998
nn.learn_nn_feature_fqi FQI:  116998
nn.learn_nn_feature_fqi FQI:  117998
nn.learn_nn_feature_fqi FQI:  118998
nn.learn_nn_feature_fqi FQI:  119998
nn.learn_nn_feature_fqi FQI:  120998
nn.learn_nn_feature_fqi FQI:  121998
nn.learn_nn_feature_fqi FQI:  122998
nn.learn_nn_feature_fqi FQI:  123998
nn.learn_nn_feature_fqi FQI:  124998
nn.learn_nn_feature_fqi FQI:  125998
nn.learn_nn_feature_fqi FQI:  126998
nn.learn_nn_feature_fqi FQI:  127998
nn.learn_nn_feature_fqi FQI:  128998
nn.learn_nn_feature_fqi FQI:  129998
nn.learn_nn_feature_fqi FQI:  130998
nn.learn_nn_feature_fqi FQI:  131998
nn.learn_nn_feature_fqi FQI:  132998
nn.learn_nn_feature_fqi FQI:  133998
nn.learn_nn_feature_fqi FQI:  134998
nn.learn_nn_feature_fqi FQI:  135998
nn.learn_nn_feature_fqi FQI:  136998
nn.learn_nn_feature_fqi FQI:  137998
nn.learn_nn_feature_fqi FQI:  138998
nn.learn_nn_feature_fqi FQI:  139998
nn.learn_nn_feature_fqi FQI:  140998
nn.learn_nn_feature_fqi FQI:  141998
nn.learn_nn_feature_fqi FQI:  142998
nn.learn_nn_feature_fqi FQI:  143998
nn.learn_nn_feature_fqi FQI:  144998
nn.learn_nn_feature_fqi FQI:  145998
nn.learn_nn_feature_fqi FQI:  146998
nn.learn_nn_feature_fqi FQI:  147998
nn.learn_nn_feature_fqi FQI:  148998
nn.learn_nn_feature_fqi FQI:  149998
nn.learn_nn_feature_fqi FQI:  150998
nn.learn_nn_feature_fqi FQI:  151998
nn.learn_nn_feature_fqi FQI:  152998
nn.learn_nn_feature_fqi FQI:  153998
nn.learn_nn_feature_fqi FQI:  154998
nn.learn_nn_feature_fqi FQI:  155998
0 1001 -1000.0 -98.99572604650622 number episode from 10: 0 avegar over 10 episode: -98.996 avegare return across last 100 episodes: -98.996 state values: tensor(0.7071) 1000
1 1000 -1000.0 -99.99568287525881 number episode from 10: 1 avegar over 10 episode: -99.496 avegare return across last 100 episodes: -99.496 state values: tensor(0.7047) 1000
2 1000 -1000.0 -99.99568287525881 number episode from 10: 2 avegar over 10 episode: -99.662 avegare return across last 100 episodes: -99.662 state values: tensor(0.7062) 1000
3 1000 -1000.0 -99.99568287525881 number episode from 10: 3 avegar over 10 episode: -99.746 avegare return across last 100 episodes: -99.746 state values: tensor(0.7034) 1000
4 1000 -1000.0 -99.99568287525881 number episode from 10: 4 avegar over 10 episode: -99.796 avegare return across last 100 episodes: -99.796 state values: tensor(0.7044) 1000
5 1000 -1000.0 -99.99568287525881 number episode from 10: 5 avegar over 10 episode: -99.829 avegare return across last 100 episodes: -99.829 state values: tensor(0.7051) 1000
6 1000 -1000.0 -99.99568287525881 number episode from 10: 6 avegar over 10 episode: -99.853 avegare return across last 100 episodes: -99.853 state values: tensor(0.7047) 1000
7 1000 -1000.0 -99.99568287525881 number episode from 10: 7 avegar over 10 episode: -99.871 avegare return across last 100 episodes: -99.871 state values: tensor(0.7057) 1000
8 1000 -1000.0 -99.99568287525881 number episode from 10: 8 avegar over 10 episode: -99.885 avegare return across last 100 episodes: -99.885 state values: tensor(0.7092) 1000
9 1000 -1000.0 -99.99568287525881 number episode from 10: 9 avegar over 10 episode: -99.896 avegare return across last 100 episodes: -99.896 state values: tensor(0.7106) 1000
10 1000 -1000.0 -99.99568287525881 number episode from 10: 10 avegar over 10 episode: -99.905 avegare return across last 100 episodes: -99.905 state values: tensor(0.7047) 1000
11 1000 -1000.0 -99.99568287525881 number episode from 10: 11 avegar over 10 episode: -99.912 avegare return across last 100 episodes: -99.912 state values: tensor(0.7045) 1000
12 1000 -1000.0 -99.99568287525881 number episode from 10: 12 avegar over 10 episode: -99.919 avegare return across last 100 episodes: -99.919 state values: tensor(0.7072) 1000
13 1000 -1000.0 -99.99568287525881 number episode from 10: 13 avegar over 10 episode: -99.924 avegare return across last 100 episodes: -99.924 state values: tensor(0.7043) 1000
14 1000 -1000.0 -99.99568287525881 number episode from 10: 14 avegar over 10 episode: -99.929 avegare return across last 100 episodes: -99.929 state values: tensor(0.7045) 1000
15 1000 -1000.0 -99.99568287525881 number episode from 10: 15 avegar over 10 episode: -99.933 avegare return across last 100 episodes: -99.933 state values: tensor(0.7032) 1000
16 1000 -1000.0 -99.99568287525881 number episode from 10: 16 avegar over 10 episode: -99.937 avegare return across last 100 episodes: -99.937 state values: tensor(0.7048) 1000
17 1000 -1000.0 -99.99568287525881 number episode from 10: 17 avegar over 10 episode: -99.94 avegare return across last 100 episodes: -99.94 state values: tensor(0.7034) 1000
18 1000 -1000.0 -99.99568287525881 number episode from 10: 18 avegar over 10 episode: -99.943 avegare return across last 100 episodes: -99.943 state values: tensor(0.7062) 1000
19 1000 -1000.0 -99.99568287525881 number episode from 10: 19 avegar over 10 episode: -99.946 avegare return across last 100 episodes: -99.946 state values: tensor(0.7043) 1000
20 1000 -1000.0 -99.99568287525881 number episode from 10: 20 avegar over 10 episode: -99.948 avegare return across last 100 episodes: -99.948 state values: tensor(0.7071) 1000
21 1000 -1000.0 -99.99568287525881 number episode from 10: 21 avegar over 10 episode: -99.95 avegare return across last 100 episodes: -99.95 state values: tensor(0.7100) 1000
22 1000 -1000.0 -99.99568287525881 number episode from 10: 22 avegar over 10 episode: -99.952 avegare return across last 100 episodes: -99.952 state values: tensor(0.7058) 1000
23 1000 -1000.0 -99.99568287525881 number episode from 10: 23 avegar over 10 episode: -99.954 avegare return across last 100 episodes: -99.954 state values: tensor(0.7042) 1000
24 1000 -1000.0 -99.99568287525881 number episode from 10: 24 avegar over 10 episode: -99.956 avegare return across last 100 episodes: -99.956 state values: tensor(0.7048) 1000
25 1000 -1000.0 -99.99568287525881 number episode from 10: 25 avegar over 10 episode: -99.957 avegare return across last 100 episodes: -99.957 state values: tensor(0.7067) 1000
26 1000 -1000.0 -99.99568287525881 number episode from 10: 26 avegar over 10 episode: -99.959 avegare return across last 100 episodes: -99.959 state values: tensor(0.7044) 1000
27 1000 -1000.0 -99.99568287525881 number episode from 10: 27 avegar over 10 episode: -99.96 avegare return across last 100 episodes: -99.96 state values: tensor(0.7113) 1000
28 1000 -1000.0 -99.99568287525881 number episode from 10: 28 avegar over 10 episode: -99.961 avegare return across last 100 episodes: -99.961 state values: tensor(0.7058) 1000
29 1000 -1000.0 -99.99568287525881 number episode from 10: 29 avegar over 10 episode: -99.962 avegare return across last 100 episodes: -99.962 state values: tensor(0.7067) 1000
30 1000 -1000.0 -99.99568287525881 number episode from 10: 30 avegar over 10 episode: -99.963 avegare return across last 100 episodes: -99.963 state values: tensor(0.7088) 1000
31 1000 -1000.0 -99.99568287525881 number episode from 10: 31 avegar over 10 episode: -99.964 avegare return across last 100 episodes: -99.964 state values: tensor(0.7077) 1000
32 1000 -1000.0 -99.99568287525881 number episode from 10: 32 avegar over 10 episode: -99.965 avegare return across last 100 episodes: -99.965 state values: tensor(0.7047) 1000
33 1000 -1000.0 -99.99568287525881 number episode from 10: 33 avegar over 10 episode: -99.966 avegare return across last 100 episodes: -99.966 state values: tensor(0.7097) 1000
34 1000 -1000.0 -99.99568287525881 number episode from 10: 34 avegar over 10 episode: -99.967 avegare return across last 100 episodes: -99.967 state values: tensor(0.7035) 1000
35 1000 -1000.0 -99.99568287525881 number episode from 10: 35 avegar over 10 episode: -99.968 avegare return across last 100 episodes: -99.968 state values: tensor(0.7107) 1000
36 1000 -1000.0 -99.99568287525881 number episode from 10: 36 avegar over 10 episode: -99.969 avegare return across last 100 episodes: -99.969 state values: tensor(0.7032) 1000
37 1000 -1000.0 -99.99568287525881 number episode from 10: 37 avegar over 10 episode: -99.969 avegare return across last 100 episodes: -99.969 state values: tensor(0.7046) 1000
38 1000 -1000.0 -99.99568287525881 number episode from 10: 38 avegar over 10 episode: -99.97 avegare return across last 100 episodes: -99.97 state values: tensor(0.7067) 1000
39 1000 -1000.0 -99.99568287525881 number episode from 10: 39 avegar over 10 episode: -99.971 avegare return across last 100 episodes: -99.971 state values: tensor(0.7039) 1000
40 1000 -1000.0 -99.99568287525881 number episode from 10: 40 avegar over 10 episode: -99.971 avegare return across last 100 episodes: -99.971 state values: tensor(0.7104) 1000
41 1000 -1000.0 -99.99568287525881 number episode from 10: 41 avegar over 10 episode: -99.972 avegare return across last 100 episodes: -99.972 state values: tensor(0.7083) 1000
42 1000 -1000.0 -99.99568287525881 number episode from 10: 42 avegar over 10 episode: -99.972 avegare return across last 100 episodes: -99.972 state values: tensor(0.7090) 1000
43 1000 -1000.0 -99.99568287525881 number episode from 10: 43 avegar over 10 episode: -99.973 avegare return across last 100 episodes: -99.973 state values: tensor(0.7057) 1000
44 1000 -1000.0 -99.99568287525881 number episode from 10: 44 avegar over 10 episode: -99.973 avegare return across last 100 episodes: -99.973 state values: tensor(0.7094) 1000
45 1000 -1000.0 -99.99568287525881 number episode from 10: 45 avegar over 10 episode: -99.974 avegare return across last 100 episodes: -99.974 state values: tensor(0.7061) 1000
46 1000 -1000.0 -99.99568287525881 number episode from 10: 46 avegar over 10 episode: -99.974 avegare return across last 100 episodes: -99.974 state values: tensor(0.7042) 1000
47 1000 -1000.0 -99.99568287525881 number episode from 10: 47 avegar over 10 episode: -99.975 avegare return across last 100 episodes: -99.975 state values: tensor(0.7033) 1000
48 1000 -1000.0 -99.99568287525881 number episode from 10: 48 avegar over 10 episode: -99.975 avegare return across last 100 episodes: -99.975 state values: tensor(0.7034) 1000
49 1000 -1000.0 -99.99568287525881 number episode from 10: 49 avegar over 10 episode: -99.976 avegare return across last 100 episodes: -99.976 state values: tensor(0.7068) 1000
50 1000 -1000.0 -99.99568287525881 number episode from 10: 50 avegar over 10 episode: -99.976 avegare return across last 100 episodes: -99.976 state values: tensor(0.7040) 1000
51 1000 -1000.0 -99.99568287525881 number episode from 10: 51 avegar over 10 episode: -99.976 avegare return across last 100 episodes: -99.976 state values: tensor(0.7038) 1000
52 1000 -1000.0 -99.99568287525881 number episode from 10: 52 avegar over 10 episode: -99.977 avegare return across last 100 episodes: -99.977 state values: tensor(0.7049) 1000
53 1000 -1000.0 -99.99568287525881 number episode from 10: 53 avegar over 10 episode: -99.977 avegare return across last 100 episodes: -99.977 state values: tensor(0.7069) 1000
54 1000 -1000.0 -99.99568287525881 number episode from 10: 54 avegar over 10 episode: -99.978 avegare return across last 100 episodes: -99.978 state values: tensor(0.7085) 1000
55 1000 -1000.0 -99.99568287525881 number episode from 10: 55 avegar over 10 episode: -99.978 avegare return across last 100 episodes: -99.978 state values: tensor(0.7099) 1000
56 1000 -1000.0 -99.99568287525881 number episode from 10: 56 avegar over 10 episode: -99.978 avegare return across last 100 episodes: -99.978 state values: tensor(0.7057) 1000
57 1000 -1000.0 -99.99568287525881 number episode from 10: 57 avegar over 10 episode: -99.978 avegare return across last 100 episodes: -99.978 state values: tensor(0.7044) 1000
58 1000 -1000.0 -99.99568287525881 number episode from 10: 58 avegar over 10 episode: -99.979 avegare return across last 100 episodes: -99.979 state values: tensor(0.7060) 1000
59 1000 -1000.0 -99.99568287525881 number episode from 10: 59 avegar over 10 episode: -99.979 avegare return across last 100 episodes: -99.979 state values: tensor(0.7106) 1000
60 1000 -1000.0 -99.99568287525881 number episode from 10: 60 avegar over 10 episode: -99.979 avegare return across last 100 episodes: -99.979 state values: tensor(0.7045) 1000
61 1000 -1000.0 -99.99568287525881 number episode from 10: 61 avegar over 10 episode: -99.98 avegare return across last 100 episodes: -99.98 state values: tensor(0.7040) 1000
62 1000 -1000.0 -99.99568287525881 number episode from 10: 62 avegar over 10 episode: -99.98 avegare return across last 100 episodes: -99.98 state values: tensor(0.7065) 1000
63 1000 -1000.0 -99.99568287525881 number episode from 10: 63 avegar over 10 episode: -99.98 avegare return across last 100 episodes: -99.98 state values: tensor(0.7056) 1000
64 1000 -1000.0 -99.99568287525881 number episode from 10: 64 avegar over 10 episode: -99.98 avegare return across last 100 episodes: -99.98 state values: tensor(0.7032) 1000
65 1000 -1000.0 -99.99568287525881 number episode from 10: 65 avegar over 10 episode: -99.981 avegare return across last 100 episodes: -99.981 state values: tensor(0.7043) 1000
66 1000 -1000.0 -99.99568287525881 number episode from 10: 66 avegar over 10 episode: -99.981 avegare return across last 100 episodes: -99.981 state values: tensor(0.7061) 1000
67 1000 -1000.0 -99.99568287525881 number episode from 10: 67 avegar over 10 episode: -99.981 avegare return across last 100 episodes: -99.981 state values: tensor(0.7032) 1000
68 1000 -1000.0 -99.99568287525881 number episode from 10: 68 avegar over 10 episode: -99.981 avegare return across last 100 episodes: -99.981 state values: tensor(0.7040) 1000
69 1000 -1000.0 -99.99568287525881 number episode from 10: 69 avegar over 10 episode: -99.981 avegare return across last 100 episodes: -99.981 state values: tensor(0.7037) 1000
70 1000 -1000.0 -99.99568287525881 number episode from 10: 70 avegar over 10 episode: -99.982 avegare return across last 100 episodes: -99.982 state values: tensor(0.7074) 1000
71 1000 -1000.0 -99.99568287525881 number episode from 10: 71 avegar over 10 episode: -99.982 avegare return across last 100 episodes: -99.982 state values: tensor(0.7034) 1000
72 1000 -1000.0 -99.99568287525881 number episode from 10: 72 avegar over 10 episode: -99.982 avegare return across last 100 episodes: -99.982 state values: tensor(0.7069) 1000
73 1000 -1000.0 -99.99568287525881 number episode from 10: 73 avegar over 10 episode: -99.982 avegare return across last 100 episodes: -99.982 state values: tensor(0.7043) 1000
74 1000 -1000.0 -99.99568287525881 number episode from 10: 74 avegar over 10 episode: -99.982 avegare return across last 100 episodes: -99.982 state values: tensor(0.7032) 1000
75 1000 -1000.0 -99.99568287525881 number episode from 10: 75 avegar over 10 episode: -99.983 avegare return across last 100 episodes: -99.983 state values: tensor(0.7106) 1000
76 1000 -1000.0 -99.99568287525881 number episode from 10: 76 avegar over 10 episode: -99.983 avegare return across last 100 episodes: -99.983 state values: tensor(0.7042) 1000
77 1000 -1000.0 -99.99568287525881 number episode from 10: 77 avegar over 10 episode: -99.983 avegare return across last 100 episodes: -99.983 state values: tensor(0.7036) 1000
78 1000 -1000.0 -99.99568287525881 number episode from 10: 78 avegar over 10 episode: -99.983 avegare return across last 100 episodes: -99.983 state values: tensor(0.7088) 1000
79 1000 -1000.0 -99.99568287525881 number episode from 10: 79 avegar over 10 episode: -99.983 avegare return across last 100 episodes: -99.983 state values: tensor(0.7044) 1000
80 1000 -1000.0 -99.99568287525881 number episode from 10: 80 avegar over 10 episode: -99.983 avegare return across last 100 episodes: -99.983 state values: tensor(0.7076) 1000
81 1000 -1000.0 -99.99568287525881 number episode from 10: 81 avegar over 10 episode: -99.983 avegare return across last 100 episodes: -99.983 state values: tensor(0.7046) 1000
82 1000 -1000.0 -99.99568287525881 number episode from 10: 82 avegar over 10 episode: -99.984 avegare return across last 100 episodes: -99.984 state values: tensor(0.7056) 1000
83 1000 -1000.0 -99.99568287525881 number episode from 10: 83 avegar over 10 episode: -99.984 avegare return across last 100 episodes: -99.984 state values: tensor(0.7037) 1000
84 1000 -1000.0 -99.99568287525881 number episode from 10: 84 avegar over 10 episode: -99.984 avegare return across last 100 episodes: -99.984 state values: tensor(0.7038) 1000
85 1000 -1000.0 -99.99568287525881 number episode from 10: 85 avegar over 10 episode: -99.984 avegare return across last 100 episodes: -99.984 state values: tensor(0.7038) 1000
86 1000 -1000.0 -99.99568287525881 number episode from 10: 86 avegar over 10 episode: -99.984 avegare return across last 100 episodes: -99.984 state values: tensor(0.7034) 1000
87 1000 -1000.0 -99.99568287525881 number episode from 10: 87 avegar over 10 episode: -99.984 avegare return across last 100 episodes: -99.984 state values: tensor(0.7043) 1000
88 1000 -1000.0 -99.99568287525881 number episode from 10: 88 avegar over 10 episode: -99.984 avegare return across last 100 episodes: -99.984 state values: tensor(0.7102) 1000
89 1000 -1000.0 -99.99568287525881 number episode from 10: 89 avegar over 10 episode: -99.985 avegare return across last 100 episodes: -99.985 state values: tensor(0.7064) 1000
90 1000 -1000.0 -99.99568287525881 number episode from 10: 90 avegar over 10 episode: -99.985 avegare return across last 100 episodes: -99.985 state values: tensor(0.7095) 1000
91 1000 -1000.0 -99.99568287525881 number episode from 10: 91 avegar over 10 episode: -99.985 avegare return across last 100 episodes: -99.985 state values: tensor(0.7074) 1000
92 1000 -1000.0 -99.99568287525881 number episode from 10: 92 avegar over 10 episode: -99.985 avegare return across last 100 episodes: -99.985 state values: tensor(0.7064) 1000
93 1000 -1000.0 -99.99568287525881 number episode from 10: 93 avegar over 10 episode: -99.985 avegare return across last 100 episodes: -99.985 state values: tensor(0.7107) 1000
94 1000 -1000.0 -99.99568287525881 number episode from 10: 94 avegar over 10 episode: -99.985 avegare return across last 100 episodes: -99.985 state values: tensor(0.7057) 1000
95 1000 -1000.0 -99.99568287525881 number episode from 10: 95 avegar over 10 episode: -99.985 avegare return across last 100 episodes: -99.985 state values: tensor(0.7052) 1000
96 1000 -1000.0 -99.99568287525881 number episode from 10: 96 avegar over 10 episode: -99.985 avegare return across last 100 episodes: -99.985 state values: tensor(0.7069) 1000
97 1000 -1000.0 -99.99568287525881 number episode from 10: 97 avegar over 10 episode: -99.985 avegare return across last 100 episodes: -99.985 state values: tensor(0.7063) 1000
98 1000 -1000.0 -99.99568287525881 number episode from 10: 98 avegar over 10 episode: -99.986 avegare return across last 100 episodes: -99.986 state values: tensor(0.7032) 1000
99 1000 -1000.0 -99.99568287525881 number episode from 10: 99 avegar over 10 episode: -99.986 avegare return across last 100 episodes: -99.986 state values: tensor(0.7099) 1000
100 1000 -1000.0 -99.99568287525881 number episode from 10: 100 avegar over 10 episode: -99.986 avegare return across last 100 episodes: -99.996 state values: tensor(0.7033) 1000
101 1000 -1000.0 -99.99568287525881 number episode from 10: 101 avegar over 10 episode: -99.986 avegare return across last 100 episodes: -99.996 state values: tensor(0.7049) 1000
102 1000 -1000.0 -99.99568287525881 number episode from 10: 102 avegar over 10 episode: -99.986 avegare return across last 100 episodes: -99.996 state values: tensor(0.7051) 1000
103 1000 -1000.0 -99.99568287525881 number episode from 10: 103 avegar over 10 episode: -99.986 avegare return across last 100 episodes: -99.996 state values: tensor(0.7032) 1000
104 1000 -1000.0 -99.99568287525881 number episode from 10: 104 avegar over 10 episode: -99.986 avegare return across last 100 episodes: -99.996 state values: tensor(0.7098) 1000
105 1000 -1000.0 -99.99568287525881 number episode from 10: 105 avegar over 10 episode: -99.986 avegare return across last 100 episodes: -99.996 state values: tensor(0.7070) 1000
106 1000 -1000.0 -99.99568287525881 number episode from 10: 106 avegar over 10 episode: -99.986 avegare return across last 100 episodes: -99.996 state values: tensor(0.7034) 1000
107 1000 -1000.0 -99.99568287525881 number episode from 10: 107 avegar over 10 episode: -99.986 avegare return across last 100 episodes: -99.996 state values: tensor(0.7036) 1000
108 1000 -1000.0 -99.99568287525881 number episode from 10: 108 avegar over 10 episode: -99.987 avegare return across last 100 episodes: -99.996 state values: tensor(0.7034) 1000
109 1000 -1000.0 -99.99568287525881 number episode from 10: 109 avegar over 10 episode: -99.987 avegare return across last 100 episodes: -99.996 state values: tensor(0.7108) 1000
110 1000 -1000.0 -99.99568287525881 number episode from 10: 110 avegar over 10 episode: -99.987 avegare return across last 100 episodes: -99.996 state values: tensor(0.7033) 1000
111 1000 -1000.0 -99.99568287525881 number episode from 10: 111 avegar over 10 episode: -99.987 avegare return across last 100 episodes: -99.996 state values: tensor(0.7037) 1000
112 1000 -1000.0 -99.99568287525881 number episode from 10: 112 avegar over 10 episode: -99.987 avegare return across last 100 episodes: -99.996 state values: tensor(0.7112) 1000
113 1000 -1000.0 -99.99568287525881 number episode from 10: 113 avegar over 10 episode: -99.987 avegare return across last 100 episodes: -99.996 state values: tensor(0.7038) 1000
114 1000 -1000.0 -99.99568287525881 number episode from 10: 114 avegar over 10 episode: -99.987 avegare return across last 100 episodes: -99.996 state values: tensor(0.7042) 1000
115 1000 -1000.0 -99.99568287525881 number episode from 10: 115 avegar over 10 episode: -99.987 avegare return across last 100 episodes: -99.996 state values: tensor(0.7041) 1000
116 1000 -1000.0 -99.99568287525881 number episode from 10: 116 avegar over 10 episode: -99.987 avegare return across last 100 episodes: -99.996 state values: tensor(0.7051) 1000
117 1000 -1000.0 -99.99568287525881 number episode from 10: 117 avegar over 10 episode: -99.987 avegare return across last 100 episodes: -99.996 state values: tensor(0.7034) 1000
118 1000 -1000.0 -99.99568287525881 number episode from 10: 118 avegar over 10 episode: -99.987 avegare return across last 100 episodes: -99.996 state values: tensor(0.7058) 1000
119 1000 -1000.0 -99.99568287525881 number episode from 10: 119 avegar over 10 episode: -99.987 avegare return across last 100 episodes: -99.996 state values: tensor(0.7040) 1000
120 1000 -1000.0 -99.99568287525881 number episode from 10: 120 avegar over 10 episode: -99.987 avegare return across last 100 episodes: -99.996 state values: tensor(0.7067) 1000
121 1000 -1000.0 -99.99568287525881 number episode from 10: 121 avegar over 10 episode: -99.987 avegare return across last 100 episodes: -99.996 state values: tensor(0.7066) 1000
122 1000 -1000.0 -99.99568287525881 number episode from 10: 122 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.7047) 1000
123 1000 -1000.0 -99.99568287525881 number episode from 10: 123 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.7038) 1000
124 1000 -1000.0 -99.99568287525881 number episode from 10: 124 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.7062) 1000
125 1000 -1000.0 -99.99568287525881 number episode from 10: 125 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.7036) 1000
126 1000 -1000.0 -99.99568287525881 number episode from 10: 126 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.7039) 1000
127 1000 -1000.0 -99.99568287525881 number episode from 10: 127 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.7032) 1000
128 1000 -1000.0 -99.99568287525881 number episode from 10: 128 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.7045) 1000
129 1000 -1000.0 -99.99568287525881 number episode from 10: 129 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.7064) 1000
130 1000 -1000.0 -99.99568287525881 number episode from 10: 130 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.7032) 1000
131 1000 -1000.0 -99.99568287525881 number episode from 10: 131 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.7114) 1000
132 1000 -1000.0 -99.99568287525881 number episode from 10: 132 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.7082) 1000
133 1000 -1000.0 -99.99568287525881 number episode from 10: 133 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.7056) 1000
134 1000 -1000.0 -99.99568287525881 number episode from 10: 134 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.7034) 1000
135 1000 -1000.0 -99.99568287525881 number episode from 10: 135 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.7076) 1000
136 1000 -1000.0 -99.99568287525881 number episode from 10: 136 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.7043) 1000
137 1000 -1000.0 -99.99568287525881 number episode from 10: 137 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.7034) 1000
138 1000 -1000.0 -99.99568287525881 number episode from 10: 138 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.7080) 1000
139 1000 -1000.0 -99.99568287525881 number episode from 10: 139 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.7055) 1000
140 1000 -1000.0 -99.99568287525881 number episode from 10: 140 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.7088) 1000
141 1000 -1000.0 -99.99568287525881 number episode from 10: 141 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.7057) 1000
142 1000 -1000.0 -99.99568287525881 number episode from 10: 142 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.7066) 1000
143 1000 -1000.0 -99.99568287525881 number episode from 10: 143 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.7034) 1000
144 1000 -1000.0 -99.99568287525881 number episode from 10: 144 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.7111) 1000
145 1000 -1000.0 -99.99568287525881 number episode from 10: 145 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.7085) 1000
146 1000 -1000.0 -99.99568287525881 number episode from 10: 146 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.7035) 1000
147 1000 -1000.0 -99.99568287525881 number episode from 10: 147 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.7070) 1000
148 1000 -1000.0 -99.99568287525881 number episode from 10: 148 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.7087) 1000
149 1000 -1000.0 -99.99568287525881 number episode from 10: 149 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.7052) 1000
150 1000 -1000.0 -99.99568287525881 number episode from 10: 150 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.7067) 1000
151 1000 -1000.0 -99.99568287525881 number episode from 10: 151 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.7109) 1000
152 1000 -1000.0 -99.99568287525881 number episode from 10: 152 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.7038) 1000
153 1000 -1000.0 -99.99568287525881 number episode from 10: 153 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.7058) 1000
154 1000 -1000.0 -99.99568287525881 number episode from 10: 154 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.7066) 1000
155 1000 -1000.0 -99.99568287525881 number episode from 10: 155 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.7056) 1000
156 1000 -1000.0 -99.99568287525881 number episode from 10: 156 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.7034) 1000
157 1000 -1000.0 -99.99568287525881 number episode from 10: 157 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.7045) 1000
158 1000 -1000.0 -99.99568287525881 number episode from 10: 158 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.7042) 1000
159 1000 -1000.0 -99.99568287525881 number episode from 10: 159 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.7044) 1000
160 1000 -1000.0 -99.99568287525881 number episode from 10: 160 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.7038) 1000
161 1000 -1000.0 -99.99568287525881 number episode from 10: 161 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.7054) 1000
162 1000 -1000.0 -99.99568287525881 number episode from 10: 162 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.7090) 1000
163 1000 -1000.0 -99.99568287525881 number episode from 10: 163 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.7034) 1000
164 1000 -1000.0 -99.99568287525881 number episode from 10: 164 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.7041) 1000
165 1000 -1000.0 -99.99568287525881 number episode from 10: 165 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.7094) 1000
166 1000 -1000.0 -99.99568287525881 number episode from 10: 166 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.7033) 1000
167 1000 -1000.0 -99.99568287525881 number episode from 10: 167 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.7037) 1000
168 1000 -1000.0 -99.99568287525881 number episode from 10: 168 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.7065) 1000
169 1000 -1000.0 -99.99568287525881 number episode from 10: 169 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.7057) 1000
170 1000 -1000.0 -99.99568287525881 number episode from 10: 170 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.7106) 1000
171 1000 -1000.0 -99.99568287525881 number episode from 10: 171 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.7042) 1000
172 1000 -1000.0 -99.99568287525881 number episode from 10: 172 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.7061) 1000
173 1000 -1000.0 -99.99568287525881 number episode from 10: 173 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.7032) 1000
174 1000 -1000.0 -99.99568287525881 number episode from 10: 174 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.7032) 1000
175 1000 -1000.0 -99.99568287525881 number episode from 10: 175 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.7106) 1000
176 1000 -1000.0 -99.99568287525881 number episode from 10: 176 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.7075) 1000
177 1000 -1000.0 -99.99568287525881 number episode from 10: 177 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.7047) 1000
178 1000 -1000.0 -99.99568287525881 number episode from 10: 178 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.7033) 1000
179 1000 -1000.0 -99.99568287525881 number episode from 10: 179 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.7033) 1000
180 1000 -1000.0 -99.99568287525881 number episode from 10: 180 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.7035) 1000
181 1000 -1000.0 -99.99568287525881 number episode from 10: 181 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.7064) 1000
182 1000 -1000.0 -99.99568287525881 number episode from 10: 182 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.7105) 1000
183 1000 -1000.0 -99.99568287525881 number episode from 10: 183 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.7037) 1000
184 1000 -1000.0 -99.99568287525881 number episode from 10: 184 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.7032) 1000
185 1000 -1000.0 -99.99568287525881 number episode from 10: 185 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.7084) 1000
186 1000 -1000.0 -99.99568287525881 number episode from 10: 186 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.7033) 1000
187 1000 -1000.0 -99.99568287525881 number episode from 10: 187 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.7034) 1000
188 1000 -1000.0 -99.99568287525881 number episode from 10: 188 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.7033) 1000
189 1000 -1000.0 -99.99568287525881 number episode from 10: 189 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.7034) 1000
190 1000 -1000.0 -99.99568287525881 number episode from 10: 190 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.7092) 1000
191 1000 -1000.0 -99.99568287525881 number episode from 10: 191 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.7039) 1000
192 1000 -1000.0 -99.99568287525881 number episode from 10: 192 avegar over 10 episode: -99.991 avegare return across last 100 episodes: -99.996 state values: tensor(0.7050) 1000
193 1000 -1000.0 -99.99568287525881 number episode from 10: 193 avegar over 10 episode: -99.991 avegare return across last 100 episodes: -99.996 state values: tensor(0.7037) 1000
194 1000 -1000.0 -99.99568287525881 number episode from 10: 194 avegar over 10 episode: -99.991 avegare return across last 100 episodes: -99.996 state values: tensor(0.7059) 1000
195 1000 -1000.0 -99.99568287525881 number episode from 10: 195 avegar over 10 episode: -99.991 avegare return across last 100 episodes: -99.996 state values: tensor(0.7045) 1000
196 1000 -1000.0 -99.99568287525881 number episode from 10: 196 avegar over 10 episode: -99.991 avegare return across last 100 episodes: -99.996 state values: tensor(0.7036) 1000
197 1000 -1000.0 -99.99568287525881 number episode from 10: 197 avegar over 10 episode: -99.991 avegare return across last 100 episodes: -99.996 state values: tensor(0.7036) 1000
198 1000 -1000.0 -99.99568287525881 number episode from 10: 198 avegar over 10 episode: -99.991 avegare return across last 100 episodes: -99.996 state values: tensor(0.7052) 1000
199 1000 -1000.0 -99.99568287525881 number episode from 10: 199 avegar over 10 episode: -99.991 avegare return across last 100 episodes: -99.996 state values: tensor(0.7039) 1000
200 1000 -1000.0 -99.99568287525881 number episode from 10: 200 avegar over 10 episode: -99.991 avegare return across last 100 episodes: -99.996 state values: tensor(0.7105) 1000
load offline data!!!!!
mem_cntr: 50000 ; mem_size: 50000
nn.learn_nn_feature_fqi FQI:  998
nn.learn_nn_feature_fqi FQI:  1998
nn.learn_nn_feature_fqi FQI:  2998
nn.learn_nn_feature_fqi FQI:  3998
nn.learn_nn_feature_fqi FQI:  4998
nn.learn_nn_feature_fqi FQI:  5998
nn.learn_nn_feature_fqi FQI:  6998
nn.learn_nn_feature_fqi FQI:  7998
nn.learn_nn_feature_fqi FQI:  8998
nn.learn_nn_feature_fqi FQI:  9998
nn.learn_nn_feature_fqi FQI:  10998
nn.learn_nn_feature_fqi FQI:  11998
nn.learn_nn_feature_fqi FQI:  12998
nn.learn_nn_feature_fqi FQI:  13998
nn.learn_nn_feature_fqi FQI:  14998
nn.learn_nn_feature_fqi FQI:  15998
nn.learn_nn_feature_fqi FQI:  16998
nn.learn_nn_feature_fqi FQI:  17998
nn.learn_nn_feature_fqi FQI:  18998
nn.learn_nn_feature_fqi FQI:  19998
nn.learn_nn_feature_fqi FQI:  20998
nn.learn_nn_feature_fqi FQI:  21998
nn.learn_nn_feature_fqi FQI:  22998
nn.learn_nn_feature_fqi FQI:  23998
nn.learn_nn_feature_fqi FQI:  24998
nn.learn_nn_feature_fqi FQI:  25998
nn.learn_nn_feature_fqi FQI:  26998
nn.learn_nn_feature_fqi FQI:  27998
nn.learn_nn_feature_fqi FQI:  28998
nn.learn_nn_feature_fqi FQI:  29998
nn.learn_nn_feature_fqi FQI:  30998
nn.learn_nn_feature_fqi FQI:  31998
nn.learn_nn_feature_fqi FQI:  32998
nn.learn_nn_feature_fqi FQI:  33998
nn.learn_nn_feature_fqi FQI:  34998
nn.learn_nn_feature_fqi FQI:  35998
nn.learn_nn_feature_fqi FQI:  36998
nn.learn_nn_feature_fqi FQI:  37998
nn.learn_nn_feature_fqi FQI:  38998
nn.learn_nn_feature_fqi FQI:  39998
nn.learn_nn_feature_fqi FQI:  40998
nn.learn_nn_feature_fqi FQI:  41998
nn.learn_nn_feature_fqi FQI:  42998
nn.learn_nn_feature_fqi FQI:  43998
nn.learn_nn_feature_fqi FQI:  44998
nn.learn_nn_feature_fqi FQI:  45998
nn.learn_nn_feature_fqi FQI:  46998
nn.learn_nn_feature_fqi FQI:  47998
nn.learn_nn_feature_fqi FQI:  48998
nn.learn_nn_feature_fqi FQI:  49998
nn.learn_nn_feature_fqi FQI:  50998
nn.learn_nn_feature_fqi FQI:  51998
nn.learn_nn_feature_fqi FQI:  52998
nn.learn_nn_feature_fqi FQI:  53998
nn.learn_nn_feature_fqi FQI:  54998
nn.learn_nn_feature_fqi FQI:  55998
nn.learn_nn_feature_fqi FQI:  56998
nn.learn_nn_feature_fqi FQI:  57998
nn.learn_nn_feature_fqi FQI:  58998
nn.learn_nn_feature_fqi FQI:  59998
nn.learn_nn_feature_fqi FQI:  60998
nn.learn_nn_feature_fqi FQI:  61998
nn.learn_nn_feature_fqi FQI:  62998
nn.learn_nn_feature_fqi FQI:  63998
nn.learn_nn_feature_fqi FQI:  64998
nn.learn_nn_feature_fqi FQI:  65998
nn.learn_nn_feature_fqi FQI:  66998
nn.learn_nn_feature_fqi FQI:  67998
nn.learn_nn_feature_fqi FQI:  68998
nn.learn_nn_feature_fqi FQI:  69998
nn.learn_nn_feature_fqi FQI:  70998
nn.learn_nn_feature_fqi FQI:  71998
nn.learn_nn_feature_fqi FQI:  72998
nn.learn_nn_feature_fqi FQI:  73998
nn.learn_nn_feature_fqi FQI:  74998
nn.learn_nn_feature_fqi FQI:  75998
nn.learn_nn_feature_fqi FQI:  76998
nn.learn_nn_feature_fqi FQI:  77998
nn.learn_nn_feature_fqi FQI:  78998
nn.learn_nn_feature_fqi FQI:  79998
nn.learn_nn_feature_fqi FQI:  80998
nn.learn_nn_feature_fqi FQI:  81998
nn.learn_nn_feature_fqi FQI:  82998
nn.learn_nn_feature_fqi FQI:  83998
nn.learn_nn_feature_fqi FQI:  84998
nn.learn_nn_feature_fqi FQI:  85998
nn.learn_nn_feature_fqi FQI:  86998
nn.learn_nn_feature_fqi FQI:  87998
nn.learn_nn_feature_fqi FQI:  88998
nn.learn_nn_feature_fqi FQI:  89998
nn.learn_nn_feature_fqi FQI:  90998
nn.learn_nn_feature_fqi FQI:  91998
nn.learn_nn_feature_fqi FQI:  92998
nn.learn_nn_feature_fqi FQI:  93998
nn.learn_nn_feature_fqi FQI:  94998
nn.learn_nn_feature_fqi FQI:  95998
nn.learn_nn_feature_fqi FQI:  96998
nn.learn_nn_feature_fqi FQI:  97998
nn.learn_nn_feature_fqi FQI:  98998
nn.learn_nn_feature_fqi FQI:  99998
nn.learn_nn_feature_fqi FQI:  100998
nn.learn_nn_feature_fqi FQI:  101998
nn.learn_nn_feature_fqi FQI:  102998
nn.learn_nn_feature_fqi FQI:  103998
nn.learn_nn_feature_fqi FQI:  104998
nn.learn_nn_feature_fqi FQI:  105998
nn.learn_nn_feature_fqi FQI:  106998
nn.learn_nn_feature_fqi FQI:  107998
nn.learn_nn_feature_fqi FQI:  108998
nn.learn_nn_feature_fqi FQI:  109998
nn.learn_nn_feature_fqi FQI:  110998
nn.learn_nn_feature_fqi FQI:  111998
nn.learn_nn_feature_fqi FQI:  112998
nn.learn_nn_feature_fqi FQI:  113998
nn.learn_nn_feature_fqi FQI:  114998
nn.learn_nn_feature_fqi FQI:  115998
nn.learn_nn_feature_fqi FQI:  116998
nn.learn_nn_feature_fqi FQI:  117998
nn.learn_nn_feature_fqi FQI:  118998
nn.learn_nn_feature_fqi FQI:  119998
nn.learn_nn_feature_fqi FQI:  120998
nn.learn_nn_feature_fqi FQI:  121998
nn.learn_nn_feature_fqi FQI:  122998
nn.learn_nn_feature_fqi FQI:  123998
nn.learn_nn_feature_fqi FQI:  124998
nn.learn_nn_feature_fqi FQI:  125998
nn.learn_nn_feature_fqi FQI:  126998
nn.learn_nn_feature_fqi FQI:  127998
nn.learn_nn_feature_fqi FQI:  128998
nn.learn_nn_feature_fqi FQI:  129998
nn.learn_nn_feature_fqi FQI:  130998
nn.learn_nn_feature_fqi FQI:  131998
nn.learn_nn_feature_fqi FQI:  132998
nn.learn_nn_feature_fqi FQI:  133998
nn.learn_nn_feature_fqi FQI:  134998
nn.learn_nn_feature_fqi FQI:  135998
nn.learn_nn_feature_fqi FQI:  136998
nn.learn_nn_feature_fqi FQI:  137998
nn.learn_nn_feature_fqi FQI:  138998
nn.learn_nn_feature_fqi FQI:  139998
nn.learn_nn_feature_fqi FQI:  140998
nn.learn_nn_feature_fqi FQI:  141998
nn.learn_nn_feature_fqi FQI:  142998
nn.learn_nn_feature_fqi FQI:  143998
nn.learn_nn_feature_fqi FQI:  144998
nn.learn_nn_feature_fqi FQI:  145998
nn.learn_nn_feature_fqi FQI:  146998
nn.learn_nn_feature_fqi FQI:  147998
nn.learn_nn_feature_fqi FQI:  148998
nn.learn_nn_feature_fqi FQI:  149998
nn.learn_nn_feature_fqi FQI:  150998
nn.learn_nn_feature_fqi FQI:  151998
nn.learn_nn_feature_fqi FQI:  152998
nn.learn_nn_feature_fqi FQI:  153998
nn.learn_nn_feature_fqi FQI:  154998
nn.learn_nn_feature_fqi FQI:  155998
0 1001 -1000.0 -98.99572604650622 number episode from 10: 0 avegar over 10 episode: -98.996 avegare return across last 100 episodes: -98.996 state values: tensor(0.8624) 1000
1 1000 -1000.0 -99.99568287525881 number episode from 10: 1 avegar over 10 episode: -99.496 avegare return across last 100 episodes: -99.496 state values: tensor(0.8621) 1000
2 1000 -1000.0 -99.99568287525881 number episode from 10: 2 avegar over 10 episode: -99.662 avegare return across last 100 episodes: -99.662 state values: tensor(0.8622) 1000
3 1000 -1000.0 -99.99568287525881 number episode from 10: 3 avegar over 10 episode: -99.746 avegare return across last 100 episodes: -99.746 state values: tensor(0.8623) 1000
4 1000 -1000.0 -99.99568287525881 number episode from 10: 4 avegar over 10 episode: -99.796 avegare return across last 100 episodes: -99.796 state values: tensor(0.8620) 1000
5 1000 -1000.0 -99.99568287525881 number episode from 10: 5 avegar over 10 episode: -99.829 avegare return across last 100 episodes: -99.829 state values: tensor(0.8623) 1000
6 1000 -1000.0 -99.99568287525881 number episode from 10: 6 avegar over 10 episode: -99.853 avegare return across last 100 episodes: -99.853 state values: tensor(0.8622) 1000
7 1000 -1000.0 -99.99568287525881 number episode from 10: 7 avegar over 10 episode: -99.871 avegare return across last 100 episodes: -99.871 state values: tensor(0.8621) 1000
8 1000 -1000.0 -99.99568287525881 number episode from 10: 8 avegar over 10 episode: -99.885 avegare return across last 100 episodes: -99.885 state values: tensor(0.8621) 1000
9 1000 -1000.0 -99.99568287525881 number episode from 10: 9 avegar over 10 episode: -99.896 avegare return across last 100 episodes: -99.896 state values: tensor(0.8620) 1000
10 1000 -1000.0 -99.99568287525881 number episode from 10: 10 avegar over 10 episode: -99.905 avegare return across last 100 episodes: -99.905 state values: tensor(0.8624) 1000
11 1000 -1000.0 -99.99568287525881 number episode from 10: 11 avegar over 10 episode: -99.912 avegare return across last 100 episodes: -99.912 state values: tensor(0.8622) 1000
12 1000 -1000.0 -99.99568287525881 number episode from 10: 12 avegar over 10 episode: -99.919 avegare return across last 100 episodes: -99.919 state values: tensor(0.8619) 1000
13 1000 -1000.0 -99.99568287525881 number episode from 10: 13 avegar over 10 episode: -99.924 avegare return across last 100 episodes: -99.924 state values: tensor(0.8624) 1000
14 1000 -1000.0 -99.99568287525881 number episode from 10: 14 avegar over 10 episode: -99.929 avegare return across last 100 episodes: -99.929 state values: tensor(0.8622) 1000
15 1000 -1000.0 -99.99568287525881 number episode from 10: 15 avegar over 10 episode: -99.933 avegare return across last 100 episodes: -99.933 state values: tensor(0.8620) 1000
16 1000 -1000.0 -99.99568287525881 number episode from 10: 16 avegar over 10 episode: -99.937 avegare return across last 100 episodes: -99.937 state values: tensor(0.8623) 1000
17 1000 -1000.0 -99.99568287525881 number episode from 10: 17 avegar over 10 episode: -99.94 avegare return across last 100 episodes: -99.94 state values: tensor(0.8623) 1000
18 1000 -1000.0 -99.99568287525881 number episode from 10: 18 avegar over 10 episode: -99.943 avegare return across last 100 episodes: -99.943 state values: tensor(0.8623) 1000
19 1000 -1000.0 -99.99568287525881 number episode from 10: 19 avegar over 10 episode: -99.946 avegare return across last 100 episodes: -99.946 state values: tensor(0.8622) 1000
20 1000 -1000.0 -99.99568287525881 number episode from 10: 20 avegar over 10 episode: -99.948 avegare return across last 100 episodes: -99.948 state values: tensor(0.8622) 1000
21 1000 -1000.0 -99.99568287525881 number episode from 10: 21 avegar over 10 episode: -99.95 avegare return across last 100 episodes: -99.95 state values: tensor(0.8623) 1000
22 1000 -1000.0 -99.99568287525881 number episode from 10: 22 avegar over 10 episode: -99.952 avegare return across last 100 episodes: -99.952 state values: tensor(0.8623) 1000
23 1000 -1000.0 -99.99568287525881 number episode from 10: 23 avegar over 10 episode: -99.954 avegare return across last 100 episodes: -99.954 state values: tensor(0.8622) 1000
24 1000 -1000.0 -99.99568287525881 number episode from 10: 24 avegar over 10 episode: -99.956 avegare return across last 100 episodes: -99.956 state values: tensor(0.8624) 1000
25 1000 -1000.0 -99.99568287525881 number episode from 10: 25 avegar over 10 episode: -99.957 avegare return across last 100 episodes: -99.957 state values: tensor(0.8621) 1000
26 1000 -1000.0 -99.99568287525881 number episode from 10: 26 avegar over 10 episode: -99.959 avegare return across last 100 episodes: -99.959 state values: tensor(0.8620) 1000
27 1000 -1000.0 -99.99568287525881 number episode from 10: 27 avegar over 10 episode: -99.96 avegare return across last 100 episodes: -99.96 state values: tensor(0.8622) 1000
28 1000 -1000.0 -99.99568287525881 number episode from 10: 28 avegar over 10 episode: -99.961 avegare return across last 100 episodes: -99.961 state values: tensor(0.8620) 1000
29 1000 -1000.0 -99.99568287525881 number episode from 10: 29 avegar over 10 episode: -99.962 avegare return across last 100 episodes: -99.962 state values: tensor(0.8624) 1000
30 1000 -1000.0 -99.99568287525881 number episode from 10: 30 avegar over 10 episode: -99.963 avegare return across last 100 episodes: -99.963 state values: tensor(0.8622) 1000
31 1000 -1000.0 -99.99568287525881 number episode from 10: 31 avegar over 10 episode: -99.964 avegare return across last 100 episodes: -99.964 state values: tensor(0.8622) 1000
32 1000 -1000.0 -99.99568287525881 number episode from 10: 32 avegar over 10 episode: -99.965 avegare return across last 100 episodes: -99.965 state values: tensor(0.8623) 1000
33 1000 -1000.0 -99.99568287525881 number episode from 10: 33 avegar over 10 episode: -99.966 avegare return across last 100 episodes: -99.966 state values: tensor(0.8621) 1000
34 1000 -1000.0 -99.99568287525881 number episode from 10: 34 avegar over 10 episode: -99.967 avegare return across last 100 episodes: -99.967 state values: tensor(0.8620) 1000
35 1000 -1000.0 -99.99568287525881 number episode from 10: 35 avegar over 10 episode: -99.968 avegare return across last 100 episodes: -99.968 state values: tensor(0.8622) 1000
36 1000 -1000.0 -99.99568287525881 number episode from 10: 36 avegar over 10 episode: -99.969 avegare return across last 100 episodes: -99.969 state values: tensor(0.8622) 1000
37 1000 -1000.0 -99.99568287525881 number episode from 10: 37 avegar over 10 episode: -99.969 avegare return across last 100 episodes: -99.969 state values: tensor(0.8620) 1000
38 1000 -1000.0 -99.99568287525881 number episode from 10: 38 avegar over 10 episode: -99.97 avegare return across last 100 episodes: -99.97 state values: tensor(0.8621) 1000
39 1000 -1000.0 -99.99568287525881 number episode from 10: 39 avegar over 10 episode: -99.971 avegare return across last 100 episodes: -99.971 state values: tensor(0.8622) 1000
40 1000 -1000.0 -99.99568287525881 number episode from 10: 40 avegar over 10 episode: -99.971 avegare return across last 100 episodes: -99.971 state values: tensor(0.8622) 1000
41 1000 -1000.0 -99.99568287525881 number episode from 10: 41 avegar over 10 episode: -99.972 avegare return across last 100 episodes: -99.972 state values: tensor(0.8618) 1000
42 1000 -1000.0 -99.99568287525881 number episode from 10: 42 avegar over 10 episode: -99.972 avegare return across last 100 episodes: -99.972 state values: tensor(0.8623) 1000
43 1000 -1000.0 -99.99568287525881 number episode from 10: 43 avegar over 10 episode: -99.973 avegare return across last 100 episodes: -99.973 state values: tensor(0.8622) 1000
44 1000 -1000.0 -99.99568287525881 number episode from 10: 44 avegar over 10 episode: -99.973 avegare return across last 100 episodes: -99.973 state values: tensor(0.8622) 1000
45 1000 -1000.0 -99.99568287525881 number episode from 10: 45 avegar over 10 episode: -99.974 avegare return across last 100 episodes: -99.974 state values: tensor(0.8622) 1000
46 1000 -1000.0 -99.99568287525881 number episode from 10: 46 avegar over 10 episode: -99.974 avegare return across last 100 episodes: -99.974 state values: tensor(0.8622) 1000
47 1000 -1000.0 -99.99568287525881 number episode from 10: 47 avegar over 10 episode: -99.975 avegare return across last 100 episodes: -99.975 state values: tensor(0.8622) 1000
48 1000 -1000.0 -99.99568287525881 number episode from 10: 48 avegar over 10 episode: -99.975 avegare return across last 100 episodes: -99.975 state values: tensor(0.8624) 1000
49 1000 -1000.0 -99.99568287525881 number episode from 10: 49 avegar over 10 episode: -99.976 avegare return across last 100 episodes: -99.976 state values: tensor(0.8624) 1000
50 1000 -1000.0 -99.99568287525881 number episode from 10: 50 avegar over 10 episode: -99.976 avegare return across last 100 episodes: -99.976 state values: tensor(0.8622) 1000
51 1000 -1000.0 -99.99568287525881 number episode from 10: 51 avegar over 10 episode: -99.976 avegare return across last 100 episodes: -99.976 state values: tensor(0.8622) 1000
52 1000 -1000.0 -99.99568287525881 number episode from 10: 52 avegar over 10 episode: -99.977 avegare return across last 100 episodes: -99.977 state values: tensor(0.8618) 1000
53 1000 -1000.0 -99.99568287525881 number episode from 10: 53 avegar over 10 episode: -99.977 avegare return across last 100 episodes: -99.977 state values: tensor(0.8623) 1000
54 1000 -1000.0 -99.99568287525881 number episode from 10: 54 avegar over 10 episode: -99.978 avegare return across last 100 episodes: -99.978 state values: tensor(0.8623) 1000
55 1000 -1000.0 -99.99568287525881 number episode from 10: 55 avegar over 10 episode: -99.978 avegare return across last 100 episodes: -99.978 state values: tensor(0.8622) 1000
56 1000 -1000.0 -99.99568287525881 number episode from 10: 56 avegar over 10 episode: -99.978 avegare return across last 100 episodes: -99.978 state values: tensor(0.8623) 1000
57 1000 -1000.0 -99.99568287525881 number episode from 10: 57 avegar over 10 episode: -99.978 avegare return across last 100 episodes: -99.978 state values: tensor(0.8620) 1000
58 1000 -1000.0 -99.99568287525881 number episode from 10: 58 avegar over 10 episode: -99.979 avegare return across last 100 episodes: -99.979 state values: tensor(0.8621) 1000
59 1000 -1000.0 -99.99568287525881 number episode from 10: 59 avegar over 10 episode: -99.979 avegare return across last 100 episodes: -99.979 state values: tensor(0.8624) 1000
60 1000 -1000.0 -99.99568287525881 number episode from 10: 60 avegar over 10 episode: -99.979 avegare return across last 100 episodes: -99.979 state values: tensor(0.8623) 1000
61 1000 -1000.0 -99.99568287525881 number episode from 10: 61 avegar over 10 episode: -99.98 avegare return across last 100 episodes: -99.98 state values: tensor(0.8622) 1000
62 1000 -1000.0 -99.99568287525881 number episode from 10: 62 avegar over 10 episode: -99.98 avegare return across last 100 episodes: -99.98 state values: tensor(0.8622) 1000
63 1000 -1000.0 -99.99568287525881 number episode from 10: 63 avegar over 10 episode: -99.98 avegare return across last 100 episodes: -99.98 state values: tensor(0.8623) 1000
64 1000 -1000.0 -99.99568287525881 number episode from 10: 64 avegar over 10 episode: -99.98 avegare return across last 100 episodes: -99.98 state values: tensor(0.8618) 1000
65 1000 -1000.0 -99.99568287525881 number episode from 10: 65 avegar over 10 episode: -99.981 avegare return across last 100 episodes: -99.981 state values: tensor(0.8621) 1000
66 1000 -1000.0 -99.99568287525881 number episode from 10: 66 avegar over 10 episode: -99.981 avegare return across last 100 episodes: -99.981 state values: tensor(0.8621) 1000
67 1000 -1000.0 -99.99568287525881 number episode from 10: 67 avegar over 10 episode: -99.981 avegare return across last 100 episodes: -99.981 state values: tensor(0.8624) 1000
68 1000 -1000.0 -99.99568287525881 number episode from 10: 68 avegar over 10 episode: -99.981 avegare return across last 100 episodes: -99.981 state values: tensor(0.8624) 1000
69 1000 -1000.0 -99.99568287525881 number episode from 10: 69 avegar over 10 episode: -99.981 avegare return across last 100 episodes: -99.981 state values: tensor(0.8622) 1000
70 1000 -1000.0 -99.99568287525881 number episode from 10: 70 avegar over 10 episode: -99.982 avegare return across last 100 episodes: -99.982 state values: tensor(0.8623) 1000
71 1000 -1000.0 -99.99568287525881 number episode from 10: 71 avegar over 10 episode: -99.982 avegare return across last 100 episodes: -99.982 state values: tensor(0.8619) 1000
72 1000 -1000.0 -99.99568287525881 number episode from 10: 72 avegar over 10 episode: -99.982 avegare return across last 100 episodes: -99.982 state values: tensor(0.8622) 1000
73 1000 -1000.0 -99.99568287525881 number episode from 10: 73 avegar over 10 episode: -99.982 avegare return across last 100 episodes: -99.982 state values: tensor(0.8621) 1000
74 1000 -1000.0 -99.99568287525881 number episode from 10: 74 avegar over 10 episode: -99.982 avegare return across last 100 episodes: -99.982 state values: tensor(0.8621) 1000
75 1000 -1000.0 -99.99568287525881 number episode from 10: 75 avegar over 10 episode: -99.983 avegare return across last 100 episodes: -99.983 state values: tensor(0.8621) 1000
76 1000 -1000.0 -99.99568287525881 number episode from 10: 76 avegar over 10 episode: -99.983 avegare return across last 100 episodes: -99.983 state values: tensor(0.8620) 1000
77 1000 -1000.0 -99.99568287525881 number episode from 10: 77 avegar over 10 episode: -99.983 avegare return across last 100 episodes: -99.983 state values: tensor(0.8621) 1000
78 1000 -1000.0 -99.99568287525881 number episode from 10: 78 avegar over 10 episode: -99.983 avegare return across last 100 episodes: -99.983 state values: tensor(0.8621) 1000
79 1000 -1000.0 -99.99568287525881 number episode from 10: 79 avegar over 10 episode: -99.983 avegare return across last 100 episodes: -99.983 state values: tensor(0.8622) 1000
80 1000 -1000.0 -99.99568287525881 number episode from 10: 80 avegar over 10 episode: -99.983 avegare return across last 100 episodes: -99.983 state values: tensor(0.8622) 1000
81 1000 -1000.0 -99.99568287525881 number episode from 10: 81 avegar over 10 episode: -99.983 avegare return across last 100 episodes: -99.983 state values: tensor(0.8621) 1000
82 1000 -1000.0 -99.99568287525881 number episode from 10: 82 avegar over 10 episode: -99.984 avegare return across last 100 episodes: -99.984 state values: tensor(0.8621) 1000
83 1000 -1000.0 -99.99568287525881 number episode from 10: 83 avegar over 10 episode: -99.984 avegare return across last 100 episodes: -99.984 state values: tensor(0.8622) 1000
84 1000 -1000.0 -99.99568287525881 number episode from 10: 84 avegar over 10 episode: -99.984 avegare return across last 100 episodes: -99.984 state values: tensor(0.8624) 1000
85 1000 -1000.0 -99.99568287525881 number episode from 10: 85 avegar over 10 episode: -99.984 avegare return across last 100 episodes: -99.984 state values: tensor(0.8623) 1000
86 1000 -1000.0 -99.99568287525881 number episode from 10: 86 avegar over 10 episode: -99.984 avegare return across last 100 episodes: -99.984 state values: tensor(0.8623) 1000
87 1000 -1000.0 -99.99568287525881 number episode from 10: 87 avegar over 10 episode: -99.984 avegare return across last 100 episodes: -99.984 state values: tensor(0.8622) 1000
88 1000 -1000.0 -99.99568287525881 number episode from 10: 88 avegar over 10 episode: -99.984 avegare return across last 100 episodes: -99.984 state values: tensor(0.8623) 1000
89 1000 -1000.0 -99.99568287525881 number episode from 10: 89 avegar over 10 episode: -99.985 avegare return across last 100 episodes: -99.985 state values: tensor(0.8621) 1000
90 1000 -1000.0 -99.99568287525881 number episode from 10: 90 avegar over 10 episode: -99.985 avegare return across last 100 episodes: -99.985 state values: tensor(0.8622) 1000
91 1000 -1000.0 -99.99568287525881 number episode from 10: 91 avegar over 10 episode: -99.985 avegare return across last 100 episodes: -99.985 state values: tensor(0.8623) 1000
92 1000 -1000.0 -99.99568287525881 number episode from 10: 92 avegar over 10 episode: -99.985 avegare return across last 100 episodes: -99.985 state values: tensor(0.8620) 1000
93 1000 -1000.0 -99.99568287525881 number episode from 10: 93 avegar over 10 episode: -99.985 avegare return across last 100 episodes: -99.985 state values: tensor(0.8623) 1000
94 1000 -1000.0 -99.99568287525881 number episode from 10: 94 avegar over 10 episode: -99.985 avegare return across last 100 episodes: -99.985 state values: tensor(0.8620) 1000
95 1000 -1000.0 -99.99568287525881 number episode from 10: 95 avegar over 10 episode: -99.985 avegare return across last 100 episodes: -99.985 state values: tensor(0.8624) 1000
96 1000 -1000.0 -99.99568287525881 number episode from 10: 96 avegar over 10 episode: -99.985 avegare return across last 100 episodes: -99.985 state values: tensor(0.8623) 1000
97 1000 -1000.0 -99.99568287525881 number episode from 10: 97 avegar over 10 episode: -99.985 avegare return across last 100 episodes: -99.985 state values: tensor(0.8622) 1000
98 1000 -1000.0 -99.99568287525881 number episode from 10: 98 avegar over 10 episode: -99.986 avegare return across last 100 episodes: -99.986 state values: tensor(0.8620) 1000
99 1000 -1000.0 -99.99568287525881 number episode from 10: 99 avegar over 10 episode: -99.986 avegare return across last 100 episodes: -99.986 state values: tensor(0.8621) 1000
100 1000 -1000.0 -99.99568287525881 number episode from 10: 100 avegar over 10 episode: -99.986 avegare return across last 100 episodes: -99.996 state values: tensor(0.8618) 1000
101 1000 -1000.0 -99.99568287525881 number episode from 10: 101 avegar over 10 episode: -99.986 avegare return across last 100 episodes: -99.996 state values: tensor(0.8622) 1000
102 1000 -1000.0 -99.99568287525881 number episode from 10: 102 avegar over 10 episode: -99.986 avegare return across last 100 episodes: -99.996 state values: tensor(0.8623) 1000
103 1000 -1000.0 -99.99568287525881 number episode from 10: 103 avegar over 10 episode: -99.986 avegare return across last 100 episodes: -99.996 state values: tensor(0.8624) 1000
104 1000 -1000.0 -99.99568287525881 number episode from 10: 104 avegar over 10 episode: -99.986 avegare return across last 100 episodes: -99.996 state values: tensor(0.8623) 1000
105 1000 -1000.0 -99.99568287525881 number episode from 10: 105 avegar over 10 episode: -99.986 avegare return across last 100 episodes: -99.996 state values: tensor(0.8622) 1000
106 1000 -1000.0 -99.99568287525881 number episode from 10: 106 avegar over 10 episode: -99.986 avegare return across last 100 episodes: -99.996 state values: tensor(0.8622) 1000
107 1000 -1000.0 -99.99568287525881 number episode from 10: 107 avegar over 10 episode: -99.986 avegare return across last 100 episodes: -99.996 state values: tensor(0.8621) 1000
108 1000 -1000.0 -99.99568287525881 number episode from 10: 108 avegar over 10 episode: -99.987 avegare return across last 100 episodes: -99.996 state values: tensor(0.8623) 1000
109 1000 -1000.0 -99.99568287525881 number episode from 10: 109 avegar over 10 episode: -99.987 avegare return across last 100 episodes: -99.996 state values: tensor(0.8622) 1000
110 1000 -1000.0 -99.99568287525881 number episode from 10: 110 avegar over 10 episode: -99.987 avegare return across last 100 episodes: -99.996 state values: tensor(0.8621) 1000
111 1000 -1000.0 -99.99568287525881 number episode from 10: 111 avegar over 10 episode: -99.987 avegare return across last 100 episodes: -99.996 state values: tensor(0.8624) 1000
112 1000 -1000.0 -99.99568287525881 number episode from 10: 112 avegar over 10 episode: -99.987 avegare return across last 100 episodes: -99.996 state values: tensor(0.8621) 1000
113 1000 -1000.0 -99.99568287525881 number episode from 10: 113 avegar over 10 episode: -99.987 avegare return across last 100 episodes: -99.996 state values: tensor(0.8623) 1000
114 1000 -1000.0 -99.99568287525881 number episode from 10: 114 avegar over 10 episode: -99.987 avegare return across last 100 episodes: -99.996 state values: tensor(0.8621) 1000
115 1000 -1000.0 -99.99568287525881 number episode from 10: 115 avegar over 10 episode: -99.987 avegare return across last 100 episodes: -99.996 state values: tensor(0.8621) 1000
116 1000 -1000.0 -99.99568287525881 number episode from 10: 116 avegar over 10 episode: -99.987 avegare return across last 100 episodes: -99.996 state values: tensor(0.8623) 1000
117 1000 -1000.0 -99.99568287525881 number episode from 10: 117 avegar over 10 episode: -99.987 avegare return across last 100 episodes: -99.996 state values: tensor(0.8623) 1000
118 1000 -1000.0 -99.99568287525881 number episode from 10: 118 avegar over 10 episode: -99.987 avegare return across last 100 episodes: -99.996 state values: tensor(0.8619) 1000
119 1000 -1000.0 -99.99568287525881 number episode from 10: 119 avegar over 10 episode: -99.987 avegare return across last 100 episodes: -99.996 state values: tensor(0.8623) 1000
120 1000 -1000.0 -99.99568287525881 number episode from 10: 120 avegar over 10 episode: -99.987 avegare return across last 100 episodes: -99.996 state values: tensor(0.8622) 1000
121 1000 -1000.0 -99.99568287525881 number episode from 10: 121 avegar over 10 episode: -99.987 avegare return across last 100 episodes: -99.996 state values: tensor(0.8623) 1000
122 1000 -1000.0 -99.99568287525881 number episode from 10: 122 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.8620) 1000
123 1000 -1000.0 -99.99568287525881 number episode from 10: 123 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.8624) 1000
124 1000 -1000.0 -99.99568287525881 number episode from 10: 124 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.8624) 1000
125 1000 -1000.0 -99.99568287525881 number episode from 10: 125 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.8620) 1000
126 1000 -1000.0 -99.99568287525881 number episode from 10: 126 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.8621) 1000
127 1000 -1000.0 -99.99568287525881 number episode from 10: 127 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.8623) 1000
128 1000 -1000.0 -99.99568287525881 number episode from 10: 128 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.8621) 1000
129 1000 -1000.0 -99.99568287525881 number episode from 10: 129 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.8624) 1000
130 1000 -1000.0 -99.99568287525881 number episode from 10: 130 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.8621) 1000
131 1000 -1000.0 -99.99568287525881 number episode from 10: 131 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.8623) 1000
132 1000 -1000.0 -99.99568287525881 number episode from 10: 132 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.8622) 1000
133 1000 -1000.0 -99.99568287525881 number episode from 10: 133 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.8620) 1000
134 1000 -1000.0 -99.99568287525881 number episode from 10: 134 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.8624) 1000
135 1000 -1000.0 -99.99568287525881 number episode from 10: 135 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.8623) 1000
136 1000 -1000.0 -99.99568287525881 number episode from 10: 136 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.8624) 1000
137 1000 -1000.0 -99.99568287525881 number episode from 10: 137 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.8623) 1000
138 1000 -1000.0 -99.99568287525881 number episode from 10: 138 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.8622) 1000
139 1000 -1000.0 -99.99568287525881 number episode from 10: 139 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.8622) 1000
140 1000 -1000.0 -99.99568287525881 number episode from 10: 140 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.8621) 1000
141 1000 -1000.0 -99.99568287525881 number episode from 10: 141 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.8622) 1000
142 1000 -1000.0 -99.99568287525881 number episode from 10: 142 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.8622) 1000
143 1000 -1000.0 -99.99568287525881 number episode from 10: 143 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.8620) 1000
144 1000 -1000.0 -99.99568287525881 number episode from 10: 144 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.8622) 1000
145 1000 -1000.0 -99.99568287525881 number episode from 10: 145 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.8623) 1000
146 1000 -1000.0 -99.99568287525881 number episode from 10: 146 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.8621) 1000
147 1000 -1000.0 -99.99568287525881 number episode from 10: 147 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.8622) 1000
148 1000 -1000.0 -99.99568287525881 number episode from 10: 148 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.8624) 1000
149 1000 -1000.0 -99.99568287525881 number episode from 10: 149 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.8623) 1000
150 1000 -1000.0 -99.99568287525881 number episode from 10: 150 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.8623) 1000
151 1000 -1000.0 -99.99568287525881 number episode from 10: 151 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.8621) 1000
152 1000 -1000.0 -99.99568287525881 number episode from 10: 152 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.8624) 1000
153 1000 -1000.0 -99.99568287525881 number episode from 10: 153 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.8621) 1000
154 1000 -1000.0 -99.99568287525881 number episode from 10: 154 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.8619) 1000
155 1000 -1000.0 -99.99568287525881 number episode from 10: 155 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.8623) 1000
156 1000 -1000.0 -99.99568287525881 number episode from 10: 156 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.8622) 1000
157 1000 -1000.0 -99.99568287525881 number episode from 10: 157 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.8622) 1000
158 1000 -1000.0 -99.99568287525881 number episode from 10: 158 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.8620) 1000
159 1000 -1000.0 -99.99568287525881 number episode from 10: 159 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.8622) 1000
160 1000 -1000.0 -99.99568287525881 number episode from 10: 160 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.8620) 1000
161 1000 -1000.0 -99.99568287525881 number episode from 10: 161 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.8624) 1000
162 1000 -1000.0 -99.99568287525881 number episode from 10: 162 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.8623) 1000
163 1000 -1000.0 -99.99568287525881 number episode from 10: 163 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.8622) 1000
164 1000 -1000.0 -99.99568287525881 number episode from 10: 164 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.8621) 1000
165 1000 -1000.0 -99.99568287525881 number episode from 10: 165 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.8623) 1000
166 1000 -1000.0 -99.99568287525881 number episode from 10: 166 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.8622) 1000
167 1000 -1000.0 -99.99568287525881 number episode from 10: 167 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.8623) 1000
168 1000 -1000.0 -99.99568287525881 number episode from 10: 168 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.8623) 1000
169 1000 -1000.0 -99.99568287525881 number episode from 10: 169 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.8623) 1000
170 1000 -1000.0 -99.99568287525881 number episode from 10: 170 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.8623) 1000
171 1000 -1000.0 -99.99568287525881 number episode from 10: 171 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.8624) 1000
172 1000 -1000.0 -99.99568287525881 number episode from 10: 172 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.8622) 1000
173 1000 -1000.0 -99.99568287525881 number episode from 10: 173 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.8622) 1000
174 1000 -1000.0 -99.99568287525881 number episode from 10: 174 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.8619) 1000
175 1000 -1000.0 -99.99568287525881 number episode from 10: 175 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.8623) 1000
176 1000 -1000.0 -99.99568287525881 number episode from 10: 176 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.8622) 1000
177 1000 -1000.0 -99.99568287525881 number episode from 10: 177 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.8623) 1000
178 1000 -1000.0 -99.99568287525881 number episode from 10: 178 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.8621) 1000
179 1000 -1000.0 -99.99568287525881 number episode from 10: 179 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.8621) 1000
180 1000 -1000.0 -99.99568287525881 number episode from 10: 180 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.8622) 1000
181 1000 -1000.0 -99.99568287525881 number episode from 10: 181 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.8622) 1000
182 1000 -1000.0 -99.99568287525881 number episode from 10: 182 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.8623) 1000
183 1000 -1000.0 -99.99568287525881 number episode from 10: 183 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.8623) 1000
184 1000 -1000.0 -99.99568287525881 number episode from 10: 184 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.8623) 1000
185 1000 -1000.0 -99.99568287525881 number episode from 10: 185 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.8621) 1000
186 1000 -1000.0 -99.99568287525881 number episode from 10: 186 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.8621) 1000
187 1000 -1000.0 -99.99568287525881 number episode from 10: 187 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.8623) 1000
188 1000 -1000.0 -99.99568287525881 number episode from 10: 188 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.8623) 1000
189 1000 -1000.0 -99.99568287525881 number episode from 10: 189 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.8624) 1000
190 1000 -1000.0 -99.99568287525881 number episode from 10: 190 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.8621) 1000
191 1000 -1000.0 -99.99568287525881 number episode from 10: 191 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.8623) 1000
192 1000 -1000.0 -99.99568287525881 number episode from 10: 192 avegar over 10 episode: -99.991 avegare return across last 100 episodes: -99.996 state values: tensor(0.8622) 1000
193 1000 -1000.0 -99.99568287525881 number episode from 10: 193 avegar over 10 episode: -99.991 avegare return across last 100 episodes: -99.996 state values: tensor(0.8620) 1000
194 1000 -1000.0 -99.99568287525881 number episode from 10: 194 avegar over 10 episode: -99.991 avegare return across last 100 episodes: -99.996 state values: tensor(0.8622) 1000
195 1000 -1000.0 -99.99568287525881 number episode from 10: 195 avegar over 10 episode: -99.991 avegare return across last 100 episodes: -99.996 state values: tensor(0.8622) 1000
196 1000 -1000.0 -99.99568287525881 number episode from 10: 196 avegar over 10 episode: -99.991 avegare return across last 100 episodes: -99.996 state values: tensor(0.8623) 1000
197 1000 -1000.0 -99.99568287525881 number episode from 10: 197 avegar over 10 episode: -99.991 avegare return across last 100 episodes: -99.996 state values: tensor(0.8623) 1000
198 1000 -1000.0 -99.99568287525881 number episode from 10: 198 avegar over 10 episode: -99.991 avegare return across last 100 episodes: -99.996 state values: tensor(0.8621) 1000
199 1000 -1000.0 -99.99568287525881 number episode from 10: 199 avegar over 10 episode: -99.991 avegare return across last 100 episodes: -99.996 state values: tensor(0.8620) 1000
200 1000 -1000.0 -99.99568287525881 number episode from 10: 200 avegar over 10 episode: -99.991 avegare return across last 100 episodes: -99.996 state values: tensor(0.8620) 1000
load offline data!!!!!
mem_cntr: 50000 ; mem_size: 50000
nn.learn_nn_feature_fqi FQI:  998
nn.learn_nn_feature_fqi FQI:  1998
nn.learn_nn_feature_fqi FQI:  2998
nn.learn_nn_feature_fqi FQI:  3998
nn.learn_nn_feature_fqi FQI:  4998
nn.learn_nn_feature_fqi FQI:  5998
nn.learn_nn_feature_fqi FQI:  6998
nn.learn_nn_feature_fqi FQI:  7998
nn.learn_nn_feature_fqi FQI:  8998
nn.learn_nn_feature_fqi FQI:  9998
nn.learn_nn_feature_fqi FQI:  10998
nn.learn_nn_feature_fqi FQI:  11998
nn.learn_nn_feature_fqi FQI:  12998
nn.learn_nn_feature_fqi FQI:  13998
nn.learn_nn_feature_fqi FQI:  14998
nn.learn_nn_feature_fqi FQI:  15998
nn.learn_nn_feature_fqi FQI:  16998
nn.learn_nn_feature_fqi FQI:  17998
nn.learn_nn_feature_fqi FQI:  18998
nn.learn_nn_feature_fqi FQI:  19998
nn.learn_nn_feature_fqi FQI:  20998
nn.learn_nn_feature_fqi FQI:  21998
nn.learn_nn_feature_fqi FQI:  22998
nn.learn_nn_feature_fqi FQI:  23998
nn.learn_nn_feature_fqi FQI:  24998
nn.learn_nn_feature_fqi FQI:  25998
nn.learn_nn_feature_fqi FQI:  26998
nn.learn_nn_feature_fqi FQI:  27998
nn.learn_nn_feature_fqi FQI:  28998
nn.learn_nn_feature_fqi FQI:  29998
nn.learn_nn_feature_fqi FQI:  30998
nn.learn_nn_feature_fqi FQI:  31998
nn.learn_nn_feature_fqi FQI:  32998
nn.learn_nn_feature_fqi FQI:  33998
nn.learn_nn_feature_fqi FQI:  34998
nn.learn_nn_feature_fqi FQI:  35998
nn.learn_nn_feature_fqi FQI:  36998
nn.learn_nn_feature_fqi FQI:  37998
nn.learn_nn_feature_fqi FQI:  38998
nn.learn_nn_feature_fqi FQI:  39998
nn.learn_nn_feature_fqi FQI:  40998
nn.learn_nn_feature_fqi FQI:  41998
nn.learn_nn_feature_fqi FQI:  42998
nn.learn_nn_feature_fqi FQI:  43998
nn.learn_nn_feature_fqi FQI:  44998
nn.learn_nn_feature_fqi FQI:  45998
nn.learn_nn_feature_fqi FQI:  46998
nn.learn_nn_feature_fqi FQI:  47998
nn.learn_nn_feature_fqi FQI:  48998
nn.learn_nn_feature_fqi FQI:  49998
nn.learn_nn_feature_fqi FQI:  50998
nn.learn_nn_feature_fqi FQI:  51998
nn.learn_nn_feature_fqi FQI:  52998
nn.learn_nn_feature_fqi FQI:  53998
nn.learn_nn_feature_fqi FQI:  54998
nn.learn_nn_feature_fqi FQI:  55998
nn.learn_nn_feature_fqi FQI:  56998
nn.learn_nn_feature_fqi FQI:  57998
nn.learn_nn_feature_fqi FQI:  58998
nn.learn_nn_feature_fqi FQI:  59998
nn.learn_nn_feature_fqi FQI:  60998
nn.learn_nn_feature_fqi FQI:  61998
nn.learn_nn_feature_fqi FQI:  62998
nn.learn_nn_feature_fqi FQI:  63998
nn.learn_nn_feature_fqi FQI:  64998
nn.learn_nn_feature_fqi FQI:  65998
nn.learn_nn_feature_fqi FQI:  66998
nn.learn_nn_feature_fqi FQI:  67998
nn.learn_nn_feature_fqi FQI:  68998
nn.learn_nn_feature_fqi FQI:  69998
nn.learn_nn_feature_fqi FQI:  70998
nn.learn_nn_feature_fqi FQI:  71998
nn.learn_nn_feature_fqi FQI:  72998
nn.learn_nn_feature_fqi FQI:  73998
nn.learn_nn_feature_fqi FQI:  74998
nn.learn_nn_feature_fqi FQI:  75998
nn.learn_nn_feature_fqi FQI:  76998
nn.learn_nn_feature_fqi FQI:  77998
nn.learn_nn_feature_fqi FQI:  78998
nn.learn_nn_feature_fqi FQI:  79998
nn.learn_nn_feature_fqi FQI:  80998
nn.learn_nn_feature_fqi FQI:  81998
nn.learn_nn_feature_fqi FQI:  82998
nn.learn_nn_feature_fqi FQI:  83998
nn.learn_nn_feature_fqi FQI:  84998
nn.learn_nn_feature_fqi FQI:  85998
nn.learn_nn_feature_fqi FQI:  86998
nn.learn_nn_feature_fqi FQI:  87998
nn.learn_nn_feature_fqi FQI:  88998
nn.learn_nn_feature_fqi FQI:  89998
nn.learn_nn_feature_fqi FQI:  90998
nn.learn_nn_feature_fqi FQI:  91998
nn.learn_nn_feature_fqi FQI:  92998
nn.learn_nn_feature_fqi FQI:  93998
nn.learn_nn_feature_fqi FQI:  94998
nn.learn_nn_feature_fqi FQI:  95998
nn.learn_nn_feature_fqi FQI:  96998
nn.learn_nn_feature_fqi FQI:  97998
nn.learn_nn_feature_fqi FQI:  98998
nn.learn_nn_feature_fqi FQI:  99998
nn.learn_nn_feature_fqi FQI:  100998
nn.learn_nn_feature_fqi FQI:  101998
nn.learn_nn_feature_fqi FQI:  102998
nn.learn_nn_feature_fqi FQI:  103998
nn.learn_nn_feature_fqi FQI:  104998
nn.learn_nn_feature_fqi FQI:  105998
nn.learn_nn_feature_fqi FQI:  106998
nn.learn_nn_feature_fqi FQI:  107998
nn.learn_nn_feature_fqi FQI:  108998
nn.learn_nn_feature_fqi FQI:  109998
nn.learn_nn_feature_fqi FQI:  110998
nn.learn_nn_feature_fqi FQI:  111998
nn.learn_nn_feature_fqi FQI:  112998
nn.learn_nn_feature_fqi FQI:  113998
nn.learn_nn_feature_fqi FQI:  114998
nn.learn_nn_feature_fqi FQI:  115998
nn.learn_nn_feature_fqi FQI:  116998
nn.learn_nn_feature_fqi FQI:  117998
nn.learn_nn_feature_fqi FQI:  118998
nn.learn_nn_feature_fqi FQI:  119998
nn.learn_nn_feature_fqi FQI:  120998
nn.learn_nn_feature_fqi FQI:  121998
nn.learn_nn_feature_fqi FQI:  122998
nn.learn_nn_feature_fqi FQI:  123998
nn.learn_nn_feature_fqi FQI:  124998
nn.learn_nn_feature_fqi FQI:  125998
nn.learn_nn_feature_fqi FQI:  126998
nn.learn_nn_feature_fqi FQI:  127998
nn.learn_nn_feature_fqi FQI:  128998
nn.learn_nn_feature_fqi FQI:  129998
nn.learn_nn_feature_fqi FQI:  130998
nn.learn_nn_feature_fqi FQI:  131998
nn.learn_nn_feature_fqi FQI:  132998
nn.learn_nn_feature_fqi FQI:  133998
nn.learn_nn_feature_fqi FQI:  134998
nn.learn_nn_feature_fqi FQI:  135998
nn.learn_nn_feature_fqi FQI:  136998
nn.learn_nn_feature_fqi FQI:  137998
nn.learn_nn_feature_fqi FQI:  138998
nn.learn_nn_feature_fqi FQI:  139998
nn.learn_nn_feature_fqi FQI:  140998
nn.learn_nn_feature_fqi FQI:  141998
nn.learn_nn_feature_fqi FQI:  142998
nn.learn_nn_feature_fqi FQI:  143998
nn.learn_nn_feature_fqi FQI:  144998
nn.learn_nn_feature_fqi FQI:  145998
nn.learn_nn_feature_fqi FQI:  146998
nn.learn_nn_feature_fqi FQI:  147998
nn.learn_nn_feature_fqi FQI:  148998
nn.learn_nn_feature_fqi FQI:  149998
nn.learn_nn_feature_fqi FQI:  150998
nn.learn_nn_feature_fqi FQI:  151998
nn.learn_nn_feature_fqi FQI:  152998
nn.learn_nn_feature_fqi FQI:  153998
nn.learn_nn_feature_fqi FQI:  154998
nn.learn_nn_feature_fqi FQI:  155998
0 1001 -1000.0 -98.99572604650622 number episode from 10: 0 avegar over 10 episode: -98.996 avegare return across last 100 episodes: -98.996 state values: tensor(0.8284) 1000
1 1000 -1000.0 -99.99568287525881 number episode from 10: 1 avegar over 10 episode: -99.496 avegare return across last 100 episodes: -99.496 state values: tensor(0.8227) 1000
2 1000 -1000.0 -99.99568287525881 number episode from 10: 2 avegar over 10 episode: -99.662 avegare return across last 100 episodes: -99.662 state values: tensor(0.8189) 1000
3 1000 -1000.0 -99.99568287525881 number episode from 10: 3 avegar over 10 episode: -99.746 avegare return across last 100 episodes: -99.746 state values: tensor(0.8293) 1000
4 1000 -1000.0 -99.99568287525881 number episode from 10: 4 avegar over 10 episode: -99.796 avegare return across last 100 episodes: -99.796 state values: tensor(0.8218) 1000
5 1000 -1000.0 -99.99568287525881 number episode from 10: 5 avegar over 10 episode: -99.829 avegare return across last 100 episodes: -99.829 state values: tensor(0.8219) 1000
6 1000 -1000.0 -99.99568287525881 number episode from 10: 6 avegar over 10 episode: -99.853 avegare return across last 100 episodes: -99.853 state values: tensor(0.8290) 1000
7 1000 -1000.0 -99.99568287525881 number episode from 10: 7 avegar over 10 episode: -99.871 avegare return across last 100 episodes: -99.871 state values: tensor(0.8215) 1000
8 1000 -1000.0 -99.99568287525881 number episode from 10: 8 avegar over 10 episode: -99.885 avegare return across last 100 episodes: -99.885 state values: tensor(0.8246) 1000
9 1000 -1000.0 -99.99568287525881 number episode from 10: 9 avegar over 10 episode: -99.896 avegare return across last 100 episodes: -99.896 state values: tensor(0.8250) 1000
10 1000 -1000.0 -99.99568287525881 number episode from 10: 10 avegar over 10 episode: -99.905 avegare return across last 100 episodes: -99.905 state values: tensor(0.8249) 1000
11 1000 -1000.0 -99.99568287525881 number episode from 10: 11 avegar over 10 episode: -99.912 avegare return across last 100 episodes: -99.912 state values: tensor(0.8263) 1000
12 1000 -1000.0 -99.99568287525881 number episode from 10: 12 avegar over 10 episode: -99.919 avegare return across last 100 episodes: -99.919 state values: tensor(0.8287) 1000
13 1000 -1000.0 -99.99568287525881 number episode from 10: 13 avegar over 10 episode: -99.924 avegare return across last 100 episodes: -99.924 state values: tensor(0.8272) 1000
14 1000 -1000.0 -99.99568287525881 number episode from 10: 14 avegar over 10 episode: -99.929 avegare return across last 100 episodes: -99.929 state values: tensor(0.8206) 1000
15 1000 -1000.0 -99.99568287525881 number episode from 10: 15 avegar over 10 episode: -99.933 avegare return across last 100 episodes: -99.933 state values: tensor(0.8285) 1000
16 1000 -1000.0 -99.99568287525881 number episode from 10: 16 avegar over 10 episode: -99.937 avegare return across last 100 episodes: -99.937 state values: tensor(0.8285) 1000
17 1000 -1000.0 -99.99568287525881 number episode from 10: 17 avegar over 10 episode: -99.94 avegare return across last 100 episodes: -99.94 state values: tensor(0.8227) 1000
18 1000 -1000.0 -99.99568287525881 number episode from 10: 18 avegar over 10 episode: -99.943 avegare return across last 100 episodes: -99.943 state values: tensor(0.8293) 1000
19 1000 -1000.0 -99.99568287525881 number episode from 10: 19 avegar over 10 episode: -99.946 avegare return across last 100 episodes: -99.946 state values: tensor(0.8160) 1000
20 1000 -1000.0 -99.99568287525881 number episode from 10: 20 avegar over 10 episode: -99.948 avegare return across last 100 episodes: -99.948 state values: tensor(0.8295) 1000
21 1000 -1000.0 -99.99568287525881 number episode from 10: 21 avegar over 10 episode: -99.95 avegare return across last 100 episodes: -99.95 state values: tensor(0.8293) 1000
22 1000 -1000.0 -99.99568287525881 number episode from 10: 22 avegar over 10 episode: -99.952 avegare return across last 100 episodes: -99.952 state values: tensor(0.8262) 1000
23 1000 -1000.0 -99.99568287525881 number episode from 10: 23 avegar over 10 episode: -99.954 avegare return across last 100 episodes: -99.954 state values: tensor(0.8237) 1000
24 1000 -1000.0 -99.99568287525881 number episode from 10: 24 avegar over 10 episode: -99.956 avegare return across last 100 episodes: -99.956 state values: tensor(0.8263) 1000
25 1000 -1000.0 -99.99568287525881 number episode from 10: 25 avegar over 10 episode: -99.957 avegare return across last 100 episodes: -99.957 state values: tensor(0.8228) 1000
26 1000 -1000.0 -99.99568287525881 number episode from 10: 26 avegar over 10 episode: -99.959 avegare return across last 100 episodes: -99.959 state values: tensor(0.8216) 1000
27 1000 -1000.0 -99.99568287525881 number episode from 10: 27 avegar over 10 episode: -99.96 avegare return across last 100 episodes: -99.96 state values: tensor(0.8191) 1000
28 1000 -1000.0 -99.99568287525881 number episode from 10: 28 avegar over 10 episode: -99.961 avegare return across last 100 episodes: -99.961 state values: tensor(0.8278) 1000
29 1000 -1000.0 -99.99568287525881 number episode from 10: 29 avegar over 10 episode: -99.962 avegare return across last 100 episodes: -99.962 state values: tensor(0.8278) 1000
30 1000 -1000.0 -99.99568287525881 number episode from 10: 30 avegar over 10 episode: -99.963 avegare return across last 100 episodes: -99.963 state values: tensor(0.8199) 1000
31 1000 -1000.0 -99.99568287525881 number episode from 10: 31 avegar over 10 episode: -99.964 avegare return across last 100 episodes: -99.964 state values: tensor(0.8207) 1000
32 1000 -1000.0 -99.99568287525881 number episode from 10: 32 avegar over 10 episode: -99.965 avegare return across last 100 episodes: -99.965 state values: tensor(0.8284) 1000
33 1000 -1000.0 -99.99568287525881 number episode from 10: 33 avegar over 10 episode: -99.966 avegare return across last 100 episodes: -99.966 state values: tensor(0.8162) 1000
34 1000 -1000.0 -99.99568287525881 number episode from 10: 34 avegar over 10 episode: -99.967 avegare return across last 100 episodes: -99.967 state values: tensor(0.8261) 1000
35 1000 -1000.0 -99.99568287525881 number episode from 10: 35 avegar over 10 episode: -99.968 avegare return across last 100 episodes: -99.968 state values: tensor(0.8203) 1000
36 1000 -1000.0 -99.99568287525881 number episode from 10: 36 avegar over 10 episode: -99.969 avegare return across last 100 episodes: -99.969 state values: tensor(0.8202) 1000
37 1000 -1000.0 -99.99568287525881 number episode from 10: 37 avegar over 10 episode: -99.969 avegare return across last 100 episodes: -99.969 state values: tensor(0.8185) 1000
38 1000 -1000.0 -99.99568287525881 number episode from 10: 38 avegar over 10 episode: -99.97 avegare return across last 100 episodes: -99.97 state values: tensor(0.8223) 1000
39 1000 -1000.0 -99.99568287525881 number episode from 10: 39 avegar over 10 episode: -99.971 avegare return across last 100 episodes: -99.971 state values: tensor(0.8186) 1000
40 1000 -1000.0 -99.99568287525881 number episode from 10: 40 avegar over 10 episode: -99.971 avegare return across last 100 episodes: -99.971 state values: tensor(0.8248) 1000
41 1000 -1000.0 -99.99568287525881 number episode from 10: 41 avegar over 10 episode: -99.972 avegare return across last 100 episodes: -99.972 state values: tensor(0.8228) 1000
42 1000 -1000.0 -99.99568287525881 number episode from 10: 42 avegar over 10 episode: -99.972 avegare return across last 100 episodes: -99.972 state values: tensor(0.8289) 1000
43 1000 -1000.0 -99.99568287525881 number episode from 10: 43 avegar over 10 episode: -99.973 avegare return across last 100 episodes: -99.973 state values: tensor(0.8289) 1000
44 1000 -1000.0 -99.99568287525881 number episode from 10: 44 avegar over 10 episode: -99.973 avegare return across last 100 episodes: -99.973 state values: tensor(0.8255) 1000
45 1000 -1000.0 -99.99568287525881 number episode from 10: 45 avegar over 10 episode: -99.974 avegare return across last 100 episodes: -99.974 state values: tensor(0.8205) 1000
46 1000 -1000.0 -99.99568287525881 number episode from 10: 46 avegar over 10 episode: -99.974 avegare return across last 100 episodes: -99.974 state values: tensor(0.8197) 1000
47 1000 -1000.0 -99.99568287525881 number episode from 10: 47 avegar over 10 episode: -99.975 avegare return across last 100 episodes: -99.975 state values: tensor(0.8282) 1000
48 1000 -1000.0 -99.99568287525881 number episode from 10: 48 avegar over 10 episode: -99.975 avegare return across last 100 episodes: -99.975 state values: tensor(0.8235) 1000
49 1000 -1000.0 -99.99568287525881 number episode from 10: 49 avegar over 10 episode: -99.976 avegare return across last 100 episodes: -99.976 state values: tensor(0.8251) 1000
50 1000 -1000.0 -99.99568287525881 number episode from 10: 50 avegar over 10 episode: -99.976 avegare return across last 100 episodes: -99.976 state values: tensor(0.8223) 1000
51 1000 -1000.0 -99.99568287525881 number episode from 10: 51 avegar over 10 episode: -99.976 avegare return across last 100 episodes: -99.976 state values: tensor(0.8283) 1000
52 1000 -1000.0 -99.99568287525881 number episode from 10: 52 avegar over 10 episode: -99.977 avegare return across last 100 episodes: -99.977 state values: tensor(0.8293) 1000
53 1000 -1000.0 -99.99568287525881 number episode from 10: 53 avegar over 10 episode: -99.977 avegare return across last 100 episodes: -99.977 state values: tensor(0.8290) 1000
54 1000 -1000.0 -99.99568287525881 number episode from 10: 54 avegar over 10 episode: -99.978 avegare return across last 100 episodes: -99.978 state values: tensor(0.8282) 1000
55 1000 -1000.0 -99.99568287525881 number episode from 10: 55 avegar over 10 episode: -99.978 avegare return across last 100 episodes: -99.978 state values: tensor(0.8158) 1000
56 1000 -1000.0 -99.99568287525881 number episode from 10: 56 avegar over 10 episode: -99.978 avegare return across last 100 episodes: -99.978 state values: tensor(0.8291) 1000
57 1000 -1000.0 -99.99568287525881 number episode from 10: 57 avegar over 10 episode: -99.978 avegare return across last 100 episodes: -99.978 state values: tensor(0.8208) 1000
58 1000 -1000.0 -99.99568287525881 number episode from 10: 58 avegar over 10 episode: -99.979 avegare return across last 100 episodes: -99.979 state values: tensor(0.8264) 1000
59 1000 -1000.0 -99.99568287525881 number episode from 10: 59 avegar over 10 episode: -99.979 avegare return across last 100 episodes: -99.979 state values: tensor(0.8289) 1000
60 1000 -1000.0 -99.99568287525881 number episode from 10: 60 avegar over 10 episode: -99.979 avegare return across last 100 episodes: -99.979 state values: tensor(0.8191) 1000
61 1000 -1000.0 -99.99568287525881 number episode from 10: 61 avegar over 10 episode: -99.98 avegare return across last 100 episodes: -99.98 state values: tensor(0.8243) 1000
62 1000 -1000.0 -99.99568287525881 number episode from 10: 62 avegar over 10 episode: -99.98 avegare return across last 100 episodes: -99.98 state values: tensor(0.8234) 1000
63 1000 -1000.0 -99.99568287525881 number episode from 10: 63 avegar over 10 episode: -99.98 avegare return across last 100 episodes: -99.98 state values: tensor(0.8293) 1000
64 1000 -1000.0 -99.99568287525881 number episode from 10: 64 avegar over 10 episode: -99.98 avegare return across last 100 episodes: -99.98 state values: tensor(0.8273) 1000
65 1000 -1000.0 -99.99568287525881 number episode from 10: 65 avegar over 10 episode: -99.981 avegare return across last 100 episodes: -99.981 state values: tensor(0.8266) 1000
66 1000 -1000.0 -99.99568287525881 number episode from 10: 66 avegar over 10 episode: -99.981 avegare return across last 100 episodes: -99.981 state values: tensor(0.8286) 1000
67 1000 -1000.0 -99.99568287525881 number episode from 10: 67 avegar over 10 episode: -99.981 avegare return across last 100 episodes: -99.981 state values: tensor(0.8270) 1000
68 1000 -1000.0 -99.99568287525881 number episode from 10: 68 avegar over 10 episode: -99.981 avegare return across last 100 episodes: -99.981 state values: tensor(0.8285) 1000
69 1000 -1000.0 -99.99568287525881 number episode from 10: 69 avegar over 10 episode: -99.981 avegare return across last 100 episodes: -99.981 state values: tensor(0.8207) 1000
70 1000 -1000.0 -99.99568287525881 number episode from 10: 70 avegar over 10 episode: -99.982 avegare return across last 100 episodes: -99.982 state values: tensor(0.8288) 1000
71 1000 -1000.0 -99.99568287525881 number episode from 10: 71 avegar over 10 episode: -99.982 avegare return across last 100 episodes: -99.982 state values: tensor(0.8198) 1000
72 1000 -1000.0 -99.99568287525881 number episode from 10: 72 avegar over 10 episode: -99.982 avegare return across last 100 episodes: -99.982 state values: tensor(0.8192) 1000
73 1000 -1000.0 -99.99568287525881 number episode from 10: 73 avegar over 10 episode: -99.982 avegare return across last 100 episodes: -99.982 state values: tensor(0.8206) 1000
74 1000 -1000.0 -99.99568287525881 number episode from 10: 74 avegar over 10 episode: -99.982 avegare return across last 100 episodes: -99.982 state values: tensor(0.8286) 1000
75 1000 -1000.0 -99.99568287525881 number episode from 10: 75 avegar over 10 episode: -99.983 avegare return across last 100 episodes: -99.983 state values: tensor(0.8283) 1000
76 1000 -1000.0 -99.99568287525881 number episode from 10: 76 avegar over 10 episode: -99.983 avegare return across last 100 episodes: -99.983 state values: tensor(0.8280) 1000
77 1000 -1000.0 -99.99568287525881 number episode from 10: 77 avegar over 10 episode: -99.983 avegare return across last 100 episodes: -99.983 state values: tensor(0.8283) 1000
78 1000 -1000.0 -99.99568287525881 number episode from 10: 78 avegar over 10 episode: -99.983 avegare return across last 100 episodes: -99.983 state values: tensor(0.8232) 1000
79 1000 -1000.0 -99.99568287525881 number episode from 10: 79 avegar over 10 episode: -99.983 avegare return across last 100 episodes: -99.983 state values: tensor(0.8252) 1000
80 1000 -1000.0 -99.99568287525881 number episode from 10: 80 avegar over 10 episode: -99.983 avegare return across last 100 episodes: -99.983 state values: tensor(0.8195) 1000
81 1000 -1000.0 -99.99568287525881 number episode from 10: 81 avegar over 10 episode: -99.983 avegare return across last 100 episodes: -99.983 state values: tensor(0.8282) 1000
82 1000 -1000.0 -99.99568287525881 number episode from 10: 82 avegar over 10 episode: -99.984 avegare return across last 100 episodes: -99.984 state values: tensor(0.8205) 1000
83 1000 -1000.0 -99.99568287525881 number episode from 10: 83 avegar over 10 episode: -99.984 avegare return across last 100 episodes: -99.984 state values: tensor(0.8265) 1000
84 1000 -1000.0 -99.99568287525881 number episode from 10: 84 avegar over 10 episode: -99.984 avegare return across last 100 episodes: -99.984 state values: tensor(0.8226) 1000
85 1000 -1000.0 -99.99568287525881 number episode from 10: 85 avegar over 10 episode: -99.984 avegare return across last 100 episodes: -99.984 state values: tensor(0.8289) 1000
86 1000 -1000.0 -99.99568287525881 number episode from 10: 86 avegar over 10 episode: -99.984 avegare return across last 100 episodes: -99.984 state values: tensor(0.8287) 1000
87 1000 -1000.0 -99.99568287525881 number episode from 10: 87 avegar over 10 episode: -99.984 avegare return across last 100 episodes: -99.984 state values: tensor(0.8293) 1000
88 1000 -1000.0 -99.99568287525881 number episode from 10: 88 avegar over 10 episode: -99.984 avegare return across last 100 episodes: -99.984 state values: tensor(0.8216) 1000
89 1000 -1000.0 -99.99568287525881 number episode from 10: 89 avegar over 10 episode: -99.985 avegare return across last 100 episodes: -99.985 state values: tensor(0.8216) 1000
90 1000 -1000.0 -99.99568287525881 number episode from 10: 90 avegar over 10 episode: -99.985 avegare return across last 100 episodes: -99.985 state values: tensor(0.8198) 1000
91 1000 -1000.0 -99.99568287525881 number episode from 10: 91 avegar over 10 episode: -99.985 avegare return across last 100 episodes: -99.985 state values: tensor(0.8232) 1000
92 1000 -1000.0 -99.99568287525881 number episode from 10: 92 avegar over 10 episode: -99.985 avegare return across last 100 episodes: -99.985 state values: tensor(0.8227) 1000
93 1000 -1000.0 -99.99568287525881 number episode from 10: 93 avegar over 10 episode: -99.985 avegare return across last 100 episodes: -99.985 state values: tensor(0.8298) 1000
94 1000 -1000.0 -99.99568287525881 number episode from 10: 94 avegar over 10 episode: -99.985 avegare return across last 100 episodes: -99.985 state values: tensor(0.8245) 1000
95 1000 -1000.0 -99.99568287525881 number episode from 10: 95 avegar over 10 episode: -99.985 avegare return across last 100 episodes: -99.985 state values: tensor(0.8173) 1000
96 1000 -1000.0 -99.99568287525881 number episode from 10: 96 avegar over 10 episode: -99.985 avegare return across last 100 episodes: -99.985 state values: tensor(0.8219) 1000
97 1000 -1000.0 -99.99568287525881 number episode from 10: 97 avegar over 10 episode: -99.985 avegare return across last 100 episodes: -99.985 state values: tensor(0.8238) 1000
98 1000 -1000.0 -99.99568287525881 number episode from 10: 98 avegar over 10 episode: -99.986 avegare return across last 100 episodes: -99.986 state values: tensor(0.8225) 1000
99 1000 -1000.0 -99.99568287525881 number episode from 10: 99 avegar over 10 episode: -99.986 avegare return across last 100 episodes: -99.986 state values: tensor(0.8232) 1000
100 1000 -1000.0 -99.99568287525881 number episode from 10: 100 avegar over 10 episode: -99.986 avegare return across last 100 episodes: -99.996 state values: tensor(0.8232) 1000
101 1000 -1000.0 -99.99568287525881 number episode from 10: 101 avegar over 10 episode: -99.986 avegare return across last 100 episodes: -99.996 state values: tensor(0.8270) 1000
102 1000 -1000.0 -99.99568287525881 number episode from 10: 102 avegar over 10 episode: -99.986 avegare return across last 100 episodes: -99.996 state values: tensor(0.8285) 1000
103 1000 -1000.0 -99.99568287525881 number episode from 10: 103 avegar over 10 episode: -99.986 avegare return across last 100 episodes: -99.996 state values: tensor(0.8295) 1000
104 1000 -1000.0 -99.99568287525881 number episode from 10: 104 avegar over 10 episode: -99.986 avegare return across last 100 episodes: -99.996 state values: tensor(0.8242) 1000
105 1000 -1000.0 -99.99568287525881 number episode from 10: 105 avegar over 10 episode: -99.986 avegare return across last 100 episodes: -99.996 state values: tensor(0.8291) 1000
106 1000 -1000.0 -99.99568287525881 number episode from 10: 106 avegar over 10 episode: -99.986 avegare return across last 100 episodes: -99.996 state values: tensor(0.8201) 1000
107 1000 -1000.0 -99.99568287525881 number episode from 10: 107 avegar over 10 episode: -99.986 avegare return across last 100 episodes: -99.996 state values: tensor(0.8294) 1000
108 1000 -1000.0 -99.99568287525881 number episode from 10: 108 avegar over 10 episode: -99.987 avegare return across last 100 episodes: -99.996 state values: tensor(0.8214) 1000
109 1000 -1000.0 -99.99568287525881 number episode from 10: 109 avegar over 10 episode: -99.987 avegare return across last 100 episodes: -99.996 state values: tensor(0.8222) 1000
110 1000 -1000.0 -99.99568287525881 number episode from 10: 110 avegar over 10 episode: -99.987 avegare return across last 100 episodes: -99.996 state values: tensor(0.8215) 1000
111 1000 -1000.0 -99.99568287525881 number episode from 10: 111 avegar over 10 episode: -99.987 avegare return across last 100 episodes: -99.996 state values: tensor(0.8287) 1000
112 1000 -1000.0 -99.99568287525881 number episode from 10: 112 avegar over 10 episode: -99.987 avegare return across last 100 episodes: -99.996 state values: tensor(0.8165) 1000
113 1000 -1000.0 -99.99568287525881 number episode from 10: 113 avegar over 10 episode: -99.987 avegare return across last 100 episodes: -99.996 state values: tensor(0.8220) 1000
114 1000 -1000.0 -99.99568287525881 number episode from 10: 114 avegar over 10 episode: -99.987 avegare return across last 100 episodes: -99.996 state values: tensor(0.8283) 1000
115 1000 -1000.0 -99.99568287525881 number episode from 10: 115 avegar over 10 episode: -99.987 avegare return across last 100 episodes: -99.996 state values: tensor(0.8283) 1000
116 1000 -1000.0 -99.99568287525881 number episode from 10: 116 avegar over 10 episode: -99.987 avegare return across last 100 episodes: -99.996 state values: tensor(0.8234) 1000
117 1000 -1000.0 -99.99568287525881 number episode from 10: 117 avegar over 10 episode: -99.987 avegare return across last 100 episodes: -99.996 state values: tensor(0.8293) 1000
118 1000 -1000.0 -99.99568287525881 number episode from 10: 118 avegar over 10 episode: -99.987 avegare return across last 100 episodes: -99.996 state values: tensor(0.8286) 1000
119 1000 -1000.0 -99.99568287525881 number episode from 10: 119 avegar over 10 episode: -99.987 avegare return across last 100 episodes: -99.996 state values: tensor(0.8241) 1000
120 1000 -1000.0 -99.99568287525881 number episode from 10: 120 avegar over 10 episode: -99.987 avegare return across last 100 episodes: -99.996 state values: tensor(0.8283) 1000
121 1000 -1000.0 -99.99568287525881 number episode from 10: 121 avegar over 10 episode: -99.987 avegare return across last 100 episodes: -99.996 state values: tensor(0.8173) 1000
122 1000 -1000.0 -99.99568287525881 number episode from 10: 122 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.8232) 1000
123 1000 -1000.0 -99.99568287525881 number episode from 10: 123 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.8236) 1000
124 1000 -1000.0 -99.99568287525881 number episode from 10: 124 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.8239) 1000
125 1000 -1000.0 -99.99568287525881 number episode from 10: 125 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.8274) 1000
126 1000 -1000.0 -99.99568287525881 number episode from 10: 126 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.8188) 1000
127 1000 -1000.0 -99.99568287525881 number episode from 10: 127 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.8235) 1000
128 1000 -1000.0 -99.99568287525881 number episode from 10: 128 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.8287) 1000
129 1000 -1000.0 -99.99568287525881 number episode from 10: 129 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.8260) 1000
130 1000 -1000.0 -99.99568287525881 number episode from 10: 130 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.8297) 1000
131 1000 -1000.0 -99.99568287525881 number episode from 10: 131 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.8216) 1000
132 1000 -1000.0 -99.99568287525881 number episode from 10: 132 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.8160) 1000
133 1000 -1000.0 -99.99568287525881 number episode from 10: 133 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.8235) 1000
134 1000 -1000.0 -99.99568287525881 number episode from 10: 134 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.8243) 1000
135 1000 -1000.0 -99.99568287525881 number episode from 10: 135 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.8250) 1000
136 1000 -1000.0 -99.99568287525881 number episode from 10: 136 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.8209) 1000
137 1000 -1000.0 -99.99568287525881 number episode from 10: 137 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.8281) 1000
138 1000 -1000.0 -99.99568287525881 number episode from 10: 138 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.8209) 1000
139 1000 -1000.0 -99.99568287525881 number episode from 10: 139 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.8277) 1000
140 1000 -1000.0 -99.99568287525881 number episode from 10: 140 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.8288) 1000
141 1000 -1000.0 -99.99568287525881 number episode from 10: 141 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.8292) 1000
142 1000 -1000.0 -99.99568287525881 number episode from 10: 142 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.8292) 1000
143 1000 -1000.0 -99.99568287525881 number episode from 10: 143 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.8255) 1000
144 1000 -1000.0 -99.99568287525881 number episode from 10: 144 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.8286) 1000
145 1000 -1000.0 -99.99568287525881 number episode from 10: 145 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.8232) 1000
146 1000 -1000.0 -99.99568287525881 number episode from 10: 146 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.8276) 1000
147 1000 -1000.0 -99.99568287525881 number episode from 10: 147 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.8205) 1000
148 1000 -1000.0 -99.99568287525881 number episode from 10: 148 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.8277) 1000
149 1000 -1000.0 -99.99568287525881 number episode from 10: 149 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.8242) 1000
150 1000 -1000.0 -99.99568287525881 number episode from 10: 150 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.8263) 1000
151 1000 -1000.0 -99.99568287525881 number episode from 10: 151 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.8250) 1000
152 1000 -1000.0 -99.99568287525881 number episode from 10: 152 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.8272) 1000
153 1000 -1000.0 -99.99568287525881 number episode from 10: 153 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.8283) 1000
154 1000 -1000.0 -99.99568287525881 number episode from 10: 154 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.8233) 1000
155 1000 -1000.0 -99.99568287525881 number episode from 10: 155 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.8212) 1000
156 1000 -1000.0 -99.99568287525881 number episode from 10: 156 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.8191) 1000
157 1000 -1000.0 -99.99568287525881 number episode from 10: 157 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.8287) 1000
158 1000 -1000.0 -99.99568287525881 number episode from 10: 158 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.8215) 1000
159 1000 -1000.0 -99.99568287525881 number episode from 10: 159 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.8282) 1000
160 1000 -1000.0 -99.99568287525881 number episode from 10: 160 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.8212) 1000
161 1000 -1000.0 -99.99568287525881 number episode from 10: 161 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.8282) 1000
162 1000 -1000.0 -99.99568287525881 number episode from 10: 162 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.8292) 1000
163 1000 -1000.0 -99.99568287525881 number episode from 10: 163 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.8238) 1000
164 1000 -1000.0 -99.99568287525881 number episode from 10: 164 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.8285) 1000
165 1000 -1000.0 -99.99568287525881 number episode from 10: 165 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.8305) 1000
166 1000 -1000.0 -99.99568287525881 number episode from 10: 166 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.8288) 1000
167 1000 -1000.0 -99.99568287525881 number episode from 10: 167 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.8292) 1000
168 1000 -1000.0 -99.99568287525881 number episode from 10: 168 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.8294) 1000
169 1000 -1000.0 -99.99568287525881 number episode from 10: 169 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.8289) 1000
170 1000 -1000.0 -99.99568287525881 number episode from 10: 170 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.8206) 1000
171 1000 -1000.0 -99.99568287525881 number episode from 10: 171 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.8279) 1000
172 1000 -1000.0 -99.99568287525881 number episode from 10: 172 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.8284) 1000
173 1000 -1000.0 -99.99568287525881 number episode from 10: 173 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.8278) 1000
174 1000 -1000.0 -99.99568287525881 number episode from 10: 174 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.8249) 1000
175 1000 -1000.0 -99.99568287525881 number episode from 10: 175 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.8176) 1000
176 1000 -1000.0 -99.99568287525881 number episode from 10: 176 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.8215) 1000
177 1000 -1000.0 -99.99568287525881 number episode from 10: 177 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.8223) 1000
178 1000 -1000.0 -99.99568287525881 number episode from 10: 178 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.8295) 1000
179 1000 -1000.0 -99.99568287525881 number episode from 10: 179 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.8277) 1000
180 1000 -1000.0 -99.99568287525881 number episode from 10: 180 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.8209) 1000
181 1000 -1000.0 -99.99568287525881 number episode from 10: 181 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.8190) 1000
182 1000 -1000.0 -99.99568287525881 number episode from 10: 182 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.8229) 1000
183 1000 -1000.0 -99.99568287525881 number episode from 10: 183 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.8202) 1000
184 1000 -1000.0 -99.99568287525881 number episode from 10: 184 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.8242) 1000
185 1000 -1000.0 -99.99568287525881 number episode from 10: 185 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.8205) 1000
186 1000 -1000.0 -99.99568287525881 number episode from 10: 186 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.8239) 1000
187 1000 -1000.0 -99.99568287525881 number episode from 10: 187 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.8275) 1000
188 1000 -1000.0 -99.99568287525881 number episode from 10: 188 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.8244) 1000
189 1000 -1000.0 -99.99568287525881 number episode from 10: 189 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.8282) 1000
190 1000 -1000.0 -99.99568287525881 number episode from 10: 190 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.8257) 1000
191 1000 -1000.0 -99.99568287525881 number episode from 10: 191 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.8242) 1000
192 1000 -1000.0 -99.99568287525881 number episode from 10: 192 avegar over 10 episode: -99.991 avegare return across last 100 episodes: -99.996 state values: tensor(0.8207) 1000
193 1000 -1000.0 -99.99568287525881 number episode from 10: 193 avegar over 10 episode: -99.991 avegare return across last 100 episodes: -99.996 state values: tensor(0.8290) 1000
194 1000 -1000.0 -99.99568287525881 number episode from 10: 194 avegar over 10 episode: -99.991 avegare return across last 100 episodes: -99.996 state values: tensor(0.8245) 1000
195 1000 -1000.0 -99.99568287525881 number episode from 10: 195 avegar over 10 episode: -99.991 avegare return across last 100 episodes: -99.996 state values: tensor(0.8288) 1000
196 1000 -1000.0 -99.99568287525881 number episode from 10: 196 avegar over 10 episode: -99.991 avegare return across last 100 episodes: -99.996 state values: tensor(0.8252) 1000
197 1000 -1000.0 -99.99568287525881 number episode from 10: 197 avegar over 10 episode: -99.991 avegare return across last 100 episodes: -99.996 state values: tensor(0.8290) 1000
198 1000 -1000.0 -99.99568287525881 number episode from 10: 198 avegar over 10 episode: -99.991 avegare return across last 100 episodes: -99.996 state values: tensor(0.8292) 1000
199 1000 -1000.0 -99.99568287525881 number episode from 10: 199 avegar over 10 episode: -99.991 avegare return across last 100 episodes: -99.996 state values: tensor(0.8246) 1000
200 1000 -1000.0 -99.99568287525881 number episode from 10: 200 avegar over 10 episode: -99.991 avegare return across last 100 episodes: -99.996 state values: tensor(0.8286) 1000
load offline data!!!!!
mem_cntr: 50000 ; mem_size: 50000
nn.learn_nn_feature_fqi FQI:  998
nn.learn_nn_feature_fqi FQI:  1998
nn.learn_nn_feature_fqi FQI:  2998
nn.learn_nn_feature_fqi FQI:  3998
nn.learn_nn_feature_fqi FQI:  4998
nn.learn_nn_feature_fqi FQI:  5998
nn.learn_nn_feature_fqi FQI:  6998
nn.learn_nn_feature_fqi FQI:  7998
nn.learn_nn_feature_fqi FQI:  8998
nn.learn_nn_feature_fqi FQI:  9998
nn.learn_nn_feature_fqi FQI:  10998
nn.learn_nn_feature_fqi FQI:  11998
nn.learn_nn_feature_fqi FQI:  12998
nn.learn_nn_feature_fqi FQI:  13998
nn.learn_nn_feature_fqi FQI:  14998
nn.learn_nn_feature_fqi FQI:  15998
nn.learn_nn_feature_fqi FQI:  16998
nn.learn_nn_feature_fqi FQI:  17998
nn.learn_nn_feature_fqi FQI:  18998
nn.learn_nn_feature_fqi FQI:  19998
nn.learn_nn_feature_fqi FQI:  20998
nn.learn_nn_feature_fqi FQI:  21998
nn.learn_nn_feature_fqi FQI:  22998
nn.learn_nn_feature_fqi FQI:  23998
nn.learn_nn_feature_fqi FQI:  24998
nn.learn_nn_feature_fqi FQI:  25998
nn.learn_nn_feature_fqi FQI:  26998
nn.learn_nn_feature_fqi FQI:  27998
nn.learn_nn_feature_fqi FQI:  28998
nn.learn_nn_feature_fqi FQI:  29998
nn.learn_nn_feature_fqi FQI:  30998
nn.learn_nn_feature_fqi FQI:  31998
nn.learn_nn_feature_fqi FQI:  32998
nn.learn_nn_feature_fqi FQI:  33998
nn.learn_nn_feature_fqi FQI:  34998
nn.learn_nn_feature_fqi FQI:  35998
nn.learn_nn_feature_fqi FQI:  36998
nn.learn_nn_feature_fqi FQI:  37998
nn.learn_nn_feature_fqi FQI:  38998
nn.learn_nn_feature_fqi FQI:  39998
nn.learn_nn_feature_fqi FQI:  40998
nn.learn_nn_feature_fqi FQI:  41998
nn.learn_nn_feature_fqi FQI:  42998
nn.learn_nn_feature_fqi FQI:  43998
nn.learn_nn_feature_fqi FQI:  44998
nn.learn_nn_feature_fqi FQI:  45998
nn.learn_nn_feature_fqi FQI:  46998
nn.learn_nn_feature_fqi FQI:  47998
nn.learn_nn_feature_fqi FQI:  48998
nn.learn_nn_feature_fqi FQI:  49998
nn.learn_nn_feature_fqi FQI:  50998
nn.learn_nn_feature_fqi FQI:  51998
nn.learn_nn_feature_fqi FQI:  52998
nn.learn_nn_feature_fqi FQI:  53998
nn.learn_nn_feature_fqi FQI:  54998
nn.learn_nn_feature_fqi FQI:  55998
nn.learn_nn_feature_fqi FQI:  56998
nn.learn_nn_feature_fqi FQI:  57998
nn.learn_nn_feature_fqi FQI:  58998
nn.learn_nn_feature_fqi FQI:  59998
nn.learn_nn_feature_fqi FQI:  60998
nn.learn_nn_feature_fqi FQI:  61998
nn.learn_nn_feature_fqi FQI:  62998
nn.learn_nn_feature_fqi FQI:  63998
nn.learn_nn_feature_fqi FQI:  64998
nn.learn_nn_feature_fqi FQI:  65998
nn.learn_nn_feature_fqi FQI:  66998
nn.learn_nn_feature_fqi FQI:  67998
nn.learn_nn_feature_fqi FQI:  68998
nn.learn_nn_feature_fqi FQI:  69998
nn.learn_nn_feature_fqi FQI:  70998
nn.learn_nn_feature_fqi FQI:  71998
nn.learn_nn_feature_fqi FQI:  72998
nn.learn_nn_feature_fqi FQI:  73998
nn.learn_nn_feature_fqi FQI:  74998
nn.learn_nn_feature_fqi FQI:  75998
nn.learn_nn_feature_fqi FQI:  76998
nn.learn_nn_feature_fqi FQI:  77998
nn.learn_nn_feature_fqi FQI:  78998
nn.learn_nn_feature_fqi FQI:  79998
nn.learn_nn_feature_fqi FQI:  80998
nn.learn_nn_feature_fqi FQI:  81998
nn.learn_nn_feature_fqi FQI:  82998
nn.learn_nn_feature_fqi FQI:  83998
nn.learn_nn_feature_fqi FQI:  84998
nn.learn_nn_feature_fqi FQI:  85998
nn.learn_nn_feature_fqi FQI:  86998
nn.learn_nn_feature_fqi FQI:  87998
nn.learn_nn_feature_fqi FQI:  88998
nn.learn_nn_feature_fqi FQI:  89998
nn.learn_nn_feature_fqi FQI:  90998
nn.learn_nn_feature_fqi FQI:  91998
nn.learn_nn_feature_fqi FQI:  92998
nn.learn_nn_feature_fqi FQI:  93998
nn.learn_nn_feature_fqi FQI:  94998
nn.learn_nn_feature_fqi FQI:  95998
nn.learn_nn_feature_fqi FQI:  96998
nn.learn_nn_feature_fqi FQI:  97998
nn.learn_nn_feature_fqi FQI:  98998
nn.learn_nn_feature_fqi FQI:  99998
nn.learn_nn_feature_fqi FQI:  100998
nn.learn_nn_feature_fqi FQI:  101998
nn.learn_nn_feature_fqi FQI:  102998
nn.learn_nn_feature_fqi FQI:  103998
nn.learn_nn_feature_fqi FQI:  104998
nn.learn_nn_feature_fqi FQI:  105998
nn.learn_nn_feature_fqi FQI:  106998
nn.learn_nn_feature_fqi FQI:  107998
nn.learn_nn_feature_fqi FQI:  108998
nn.learn_nn_feature_fqi FQI:  109998
nn.learn_nn_feature_fqi FQI:  110998
nn.learn_nn_feature_fqi FQI:  111998
nn.learn_nn_feature_fqi FQI:  112998
nn.learn_nn_feature_fqi FQI:  113998
nn.learn_nn_feature_fqi FQI:  114998
nn.learn_nn_feature_fqi FQI:  115998
nn.learn_nn_feature_fqi FQI:  116998
nn.learn_nn_feature_fqi FQI:  117998
nn.learn_nn_feature_fqi FQI:  118998
nn.learn_nn_feature_fqi FQI:  119998
nn.learn_nn_feature_fqi FQI:  120998
nn.learn_nn_feature_fqi FQI:  121998
nn.learn_nn_feature_fqi FQI:  122998
nn.learn_nn_feature_fqi FQI:  123998
nn.learn_nn_feature_fqi FQI:  124998
nn.learn_nn_feature_fqi FQI:  125998
nn.learn_nn_feature_fqi FQI:  126998
nn.learn_nn_feature_fqi FQI:  127998
nn.learn_nn_feature_fqi FQI:  128998
nn.learn_nn_feature_fqi FQI:  129998
nn.learn_nn_feature_fqi FQI:  130998
nn.learn_nn_feature_fqi FQI:  131998
nn.learn_nn_feature_fqi FQI:  132998
nn.learn_nn_feature_fqi FQI:  133998
nn.learn_nn_feature_fqi FQI:  134998
nn.learn_nn_feature_fqi FQI:  135998
nn.learn_nn_feature_fqi FQI:  136998
nn.learn_nn_feature_fqi FQI:  137998
nn.learn_nn_feature_fqi FQI:  138998
nn.learn_nn_feature_fqi FQI:  139998
nn.learn_nn_feature_fqi FQI:  140998
nn.learn_nn_feature_fqi FQI:  141998
nn.learn_nn_feature_fqi FQI:  142998
nn.learn_nn_feature_fqi FQI:  143998
nn.learn_nn_feature_fqi FQI:  144998
nn.learn_nn_feature_fqi FQI:  145998
nn.learn_nn_feature_fqi FQI:  146998
nn.learn_nn_feature_fqi FQI:  147998
nn.learn_nn_feature_fqi FQI:  148998
nn.learn_nn_feature_fqi FQI:  149998
nn.learn_nn_feature_fqi FQI:  150998
nn.learn_nn_feature_fqi FQI:  151998
nn.learn_nn_feature_fqi FQI:  152998
nn.learn_nn_feature_fqi FQI:  153998
nn.learn_nn_feature_fqi FQI:  154998
nn.learn_nn_feature_fqi FQI:  155998
0 521 -520.0 -98.46796967728812 number episode from 10: 0 avegar over 10 episode: -98.468 avegare return across last 100 episodes: -98.468 state values: tensor(0.8932) 520
1 620 -620.0 -99.80329262156505 number episode from 10: 1 avegar over 10 episode: -99.136 avegare return across last 100 episodes: -99.136 state values: tensor(0.8903) 620
2 1000 -1000.0 -99.99568287525881 number episode from 10: 2 avegar over 10 episode: -99.422 avegare return across last 100 episodes: -99.422 state values: tensor(0.8200) 1000
3 514 -514.0 -99.42919203690323 number episode from 10: 3 avegar over 10 episode: -99.424 avegare return across last 100 episodes: -99.424 state values: tensor(0.8858) 514
4 533 -533.0 -99.52841637065397 number episode from 10: 4 avegar over 10 episode: -99.445 avegare return across last 100 episodes: -99.445 state values: tensor(0.8892) 533
5 536 -536.0 -99.54242287602918 number episode from 10: 5 avegar over 10 episode: -99.461 avegare return across last 100 episodes: -99.461 state values: tensor(0.8922) 536
6 520 -520.0 -99.46259563362437 number episode from 10: 6 avegar over 10 episode: -99.461 avegare return across last 100 episodes: -99.461 state values: tensor(0.8884) 520
7 519 -519.0 -99.45716730669129 number episode from 10: 7 avegar over 10 episode: -99.461 avegare return across last 100 episodes: -99.461 state values: tensor(0.8839) 519
8 623 -623.0 -99.80913502741193 number episode from 10: 8 avegar over 10 episode: -99.5 avegare return across last 100 episodes: -99.5 state values: tensor(0.8907) 623
9 537 -537.0 -99.5469986472689 number episode from 10: 9 avegar over 10 episode: -99.504 avegare return across last 100 episodes: -99.504 state values: tensor(0.8927) 537
10 523 -523.0 -99.47855708071009 number episode from 10: 10 avegar over 10 episode: -99.502 avegare return across last 100 episodes: -99.502 state values: tensor(0.8964) 523
11 911 -911.0 -99.98944003987278 number episode from 10: 11 avegar over 10 episode: -99.543 avegare return across last 100 episodes: -99.543 state values: tensor(0.8551) 911
12 433 -433.0 -98.71163398374672 number episode from 10: 12 avegar over 10 episode: -99.479 avegare return across last 100 episodes: -99.479 state values: tensor(0.8894) 433
13 544 -544.0 -99.57777313656436 number episode from 10: 13 avegar over 10 episode: -99.486 avegare return across last 100 episodes: -99.486 state values: tensor(0.9028) 544
14 1000 -1000.0 -99.99568287525881 number episode from 10: 14 avegar over 10 episode: -99.52 avegare return across last 100 episodes: -99.52 state values: tensor(0.8196) 1000
15 902 -902.0 -99.98844032758407 number episode from 10: 15 avegar over 10 episode: -99.549 avegare return across last 100 episodes: -99.549 state values: tensor(0.8560) 902
16 436 -436.0 -98.74989974279546 number episode from 10: 16 avegar over 10 episode: -99.502 avegare return across last 100 episodes: -99.502 state values: tensor(0.8919) 436
17 514 -514.0 -99.42919203690323 number episode from 10: 17 avegar over 10 episode: -99.498 avegare return across last 100 episodes: -99.498 state values: tensor(0.8833) 514
18 437 -437.0 -98.76240074536751 number episode from 10: 18 avegar over 10 episode: -99.459 avegare return across last 100 episodes: -99.459 state values: tensor(0.8922) 437
19 534 -534.0 -99.53313220694743 number episode from 10: 19 avegar over 10 episode: -99.463 avegare return across last 100 episodes: -99.463 state values: tensor(0.8901) 534
20 1000 -1000.0 -99.99568287525881 number episode from 10: 20 avegar over 10 episode: -99.488 avegare return across last 100 episodes: -99.488 state values: tensor(0.8288) 1000
21 524 -524.0 -99.483771509903 number episode from 10: 21 avegar over 10 episode: -99.488 avegare return across last 100 episodes: -99.488 state values: tensor(0.8874) 524
22 542 -542.0 -99.56920022096149 number episode from 10: 22 avegar over 10 episode: -99.492 avegare return across last 100 episodes: -99.492 state values: tensor(0.9027) 542
23 430 -430.0 -98.67219690399219 number episode from 10: 23 avegar over 10 episode: -99.457 avegare return across last 100 episodes: -99.457 state values: tensor(0.8904) 430
24 1000 -1000.0 -99.99568287525881 number episode from 10: 24 avegar over 10 episode: -99.479 avegare return across last 100 episodes: -99.479 state values: tensor(0.8194) 1000
25 514 -514.0 -99.42919203690323 number episode from 10: 25 avegar over 10 episode: -99.477 avegare return across last 100 episodes: -99.477 state values: tensor(0.8866) 514
26 431 -431.0 -98.68547493495227 number episode from 10: 26 avegar over 10 episode: -99.448 avegare return across last 100 episodes: -99.448 state values: tensor(0.8897) 431
27 629 -629.0 -99.82030441709234 number episode from 10: 27 avegar over 10 episode: -99.461 avegare return across last 100 episodes: -99.461 state values: tensor(0.8957) 629
28 433 -433.0 -98.71163398374672 number episode from 10: 28 avegar over 10 episode: -99.435 avegare return across last 100 episodes: -99.435 state values: tensor(0.8901) 433
29 520 -520.0 -99.46259563362437 number episode from 10: 29 avegar over 10 episode: -99.436 avegare return across last 100 episodes: -99.436 state values: tensor(0.8898) 520
30 432 -432.0 -98.69862018560275 number episode from 10: 30 avegar over 10 episode: -99.412 avegare return across last 100 episodes: -99.412 state values: tensor(0.8897) 432
31 1000 -1000.0 -99.99568287525881 number episode from 10: 31 avegar over 10 episode: -99.431 avegare return across last 100 episodes: -99.431 state values: tensor(0.8442) 1000
32 1000 -1000.0 -99.99568287525881 number episode from 10: 32 avegar over 10 episode: -99.448 avegare return across last 100 episodes: -99.448 state values: tensor(0.8444) 1000
33 544 -544.0 -99.57777313656436 number episode from 10: 33 avegar over 10 episode: -99.452 avegare return across last 100 episodes: -99.452 state values: tensor(0.9029) 544
34 523 -523.0 -99.47855708071009 number episode from 10: 34 avegar over 10 episode: -99.452 avegare return across last 100 episodes: -99.452 state values: tensor(0.8898) 523
35 520 -520.0 -99.46259563362437 number episode from 10: 35 avegar over 10 episode: -99.453 avegare return across last 100 episodes: -99.453 state values: tensor(0.8899) 520
36 1000 -1000.0 -99.99568287525881 number episode from 10: 36 avegar over 10 episode: -99.467 avegare return across last 100 episodes: -99.467 state values: tensor(0.8199) 1000
37 530 -530.0 -99.51398112401843 number episode from 10: 37 avegar over 10 episode: -99.469 avegare return across last 100 episodes: -99.469 state values: tensor(0.8903) 530
38 1000 -1000.0 -99.99568287525881 number episode from 10: 38 avegar over 10 episode: -99.482 avegare return across last 100 episodes: -99.482 state values: tensor(0.8204) 1000
39 1000 -1000.0 -99.99568287525881 number episode from 10: 39 avegar over 10 episode: -99.495 avegare return across last 100 episodes: -99.495 state values: tensor(0.8205) 1000
40 518 -518.0 -99.45168414817302 number episode from 10: 40 avegar over 10 episode: -99.494 avegare return across last 100 episodes: -99.494 state values: tensor(0.8935) 518
41 514 -514.0 -99.42919203690323 number episode from 10: 41 avegar over 10 episode: -99.492 avegare return across last 100 episodes: -99.492 state values: tensor(0.8869) 514
42 536 -536.0 -99.54242287602918 number episode from 10: 42 avegar over 10 episode: -99.493 avegare return across last 100 episodes: -99.493 state values: tensor(0.8911) 536
43 517 -517.0 -99.44614560421516 number episode from 10: 43 avegar over 10 episode: -99.492 avegare return across last 100 episodes: -99.492 state values: tensor(0.8874) 517
44 544 -544.0 -99.57777313656436 number episode from 10: 44 avegar over 10 episode: -99.494 avegare return across last 100 episodes: -99.494 state values: tensor(0.9018) 544
45 1000 -1000.0 -99.99568287525881 number episode from 10: 45 avegar over 10 episode: -99.505 avegare return across last 100 episodes: -99.505 state values: tensor(0.8198) 1000
46 619 -619.0 -99.80130567834854 number episode from 10: 46 avegar over 10 episode: -99.511 avegare return across last 100 episodes: -99.511 state values: tensor(0.8958) 619
47 535 -535.0 -99.53780088487795 number episode from 10: 47 avegar over 10 episode: -99.512 avegare return across last 100 episodes: -99.512 state values: tensor(0.9050) 535
48 517 -517.0 -99.44614560421516 number episode from 10: 48 avegar over 10 episode: -99.511 avegare return across last 100 episodes: -99.511 state values: tensor(0.8872) 517
49 529 -529.0 -99.50907184244286 number episode from 10: 49 avegar over 10 episode: -99.511 avegare return across last 100 episodes: -99.511 state values: tensor(0.8889) 529
50 509 -509.0 -99.3997750416455 number episode from 10: 50 avegar over 10 episode: -99.508 avegare return across last 100 episodes: -99.508 state values: tensor(0.8844) 509
51 610 -610.0 -99.78249527067084 number episode from 10: 51 avegar over 10 episode: -99.514 avegare return across last 100 episodes: -99.514 state values: tensor(0.8872) 610
52 544 -544.0 -99.57777313656436 number episode from 10: 52 avegar over 10 episode: -99.515 avegare return across last 100 episodes: -99.515 state values: tensor(0.9016) 544
53 522 -522.0 -99.47328998051525 number episode from 10: 53 avegar over 10 episode: -99.514 avegare return across last 100 episodes: -99.514 state values: tensor(0.8921) 522
54 516 -516.0 -99.44055111536885 number episode from 10: 54 avegar over 10 episode: -99.513 avegare return across last 100 episodes: -99.513 state values: tensor(0.8860) 516
55 524 -524.0 -99.483771509903 number episode from 10: 55 avegar over 10 episode: -99.512 avegare return across last 100 episodes: -99.512 state values: tensor(0.8962) 524
56 518 -518.0 -99.45168414817302 number episode from 10: 56 avegar over 10 episode: -99.511 avegare return across last 100 episodes: -99.511 state values: tensor(0.8889) 518
57 534 -534.0 -99.53313220694743 number episode from 10: 57 avegar over 10 episode: -99.512 avegare return across last 100 episodes: -99.512 state values: tensor(0.8930) 534
58 520 -520.0 -99.46259563362437 number episode from 10: 58 avegar over 10 episode: -99.511 avegare return across last 100 episodes: -99.511 state values: tensor(0.8898) 520
59 518 -518.0 -99.45168414817302 number episode from 10: 59 avegar over 10 episode: -99.51 avegare return across last 100 episodes: -99.51 state values: tensor(0.8919) 518
60 434 -434.0 -98.72451764390925 number episode from 10: 60 avegar over 10 episode: -99.497 avegare return across last 100 episodes: -99.497 state values: tensor(0.8911) 434
61 520 -520.0 -99.46259563362437 number episode from 10: 61 avegar over 10 episode: -99.496 avegare return across last 100 episodes: -99.496 state values: tensor(0.8905) 520
62 523 -523.0 -99.47855708071009 number episode from 10: 62 avegar over 10 episode: -99.496 avegare return across last 100 episodes: -99.496 state values: tensor(0.8956) 523
63 547 -547.0 -99.59031369663526 number episode from 10: 63 avegar over 10 episode: -99.498 avegare return across last 100 episodes: -99.498 state values: tensor(0.9026) 547
64 548 -548.0 -99.59441055966892 number episode from 10: 64 avegar over 10 episode: -99.499 avegare return across last 100 episodes: -99.499 state values: tensor(0.9009) 548
65 433 -433.0 -98.71163398374672 number episode from 10: 65 avegar over 10 episode: -99.487 avegare return across last 100 episodes: -99.487 state values: tensor(0.8925) 433
66 541 -541.0 -99.56484870804191 number episode from 10: 66 avegar over 10 episode: -99.488 avegare return across last 100 episodes: -99.488 state values: tensor(0.8986) 541
67 519 -519.0 -99.45716730669129 number episode from 10: 67 avegar over 10 episode: -99.488 avegare return across last 100 episodes: -99.488 state values: tensor(0.8891) 519
68 444 -444.0 -98.84647662016155 number episode from 10: 68 avegar over 10 episode: -99.479 avegare return across last 100 episodes: -99.479 state values: tensor(0.9058) 444
69 516 -516.0 -99.44055111536885 number episode from 10: 69 avegar over 10 episode: -99.478 avegare return across last 100 episodes: -99.478 state values: tensor(0.8869) 516
70 425 -425.0 -98.60376762496365 number episode from 10: 70 avegar over 10 episode: -99.466 avegare return across last 100 episodes: -99.466 state values: tensor(0.8909) 425
71 1000 -1000.0 -99.99568287525881 number episode from 10: 71 avegar over 10 episode: -99.473 avegare return across last 100 episodes: -99.473 state values: tensor(0.8195) 1000
72 418 -418.0 -98.50200162663309 number episode from 10: 72 avegar over 10 episode: -99.46 avegare return across last 100 episodes: -99.46 state values: tensor(0.8959) 418
73 419 -419.0 -98.51698161036676 number episode from 10: 73 avegar over 10 episode: -99.447 avegare return across last 100 episodes: -99.447 state values: tensor(0.8917) 419
74 535 -535.0 -99.53780088487795 number episode from 10: 74 avegar over 10 episode: -99.448 avegare return across last 100 episodes: -99.448 state values: tensor(0.8972) 535
75 547 -547.0 -99.59031369663526 number episode from 10: 75 avegar over 10 episode: -99.45 avegare return across last 100 episodes: -99.45 state values: tensor(0.9047) 547
76 518 -518.0 -99.45168414817302 number episode from 10: 76 avegar over 10 episode: -99.45 avegare return across last 100 episodes: -99.45 state values: tensor(0.8923) 518
77 903 -903.0 -99.98855592430823 number episode from 10: 77 avegar over 10 episode: -99.457 avegare return across last 100 episodes: -99.457 state values: tensor(0.8566) 903
78 519 -519.0 -99.45716730669129 number episode from 10: 78 avegar over 10 episode: -99.457 avegare return across last 100 episodes: -99.457 state values: tensor(0.8881) 519
79 513 -513.0 -99.42342629990226 number episode from 10: 79 avegar over 10 episode: -99.457 avegare return across last 100 episodes: -99.457 state values: tensor(0.8837) 513
80 432 -432.0 -98.69862018560275 number episode from 10: 80 avegar over 10 episode: -99.447 avegare return across last 100 episodes: -99.447 state values: tensor(0.8908) 432
81 515 -515.0 -99.4349001165342 number episode from 10: 81 avegar over 10 episode: -99.447 avegare return across last 100 episodes: -99.447 state values: tensor(0.8866) 515
82 514 -514.0 -99.42919203690323 number episode from 10: 82 avegar over 10 episode: -99.447 avegare return across last 100 episodes: -99.447 state values: tensor(0.8850) 514
83 517 -517.0 -99.44614560421516 number episode from 10: 83 avegar over 10 episode: -99.447 avegare return across last 100 episodes: -99.447 state values: tensor(0.8873) 517
84 438 -438.0 -98.77477673791384 number episode from 10: 84 avegar over 10 episode: -99.439 avegare return across last 100 episodes: -99.439 state values: tensor(0.8885) 438
85 532 -532.0 -99.52365289965047 number episode from 10: 85 avegar over 10 episode: -99.44 avegare return across last 100 episodes: -99.44 state values: tensor(0.9001) 532
86 1000 -1000.0 -99.99568287525881 number episode from 10: 86 avegar over 10 episode: -99.446 avegare return across last 100 episodes: -99.446 state values: tensor(0.8200) 1000
87 439 -439.0 -98.7870289705347 number episode from 10: 87 avegar over 10 episode: -99.439 avegare return across last 100 episodes: -99.439 state values: tensor(0.8902) 439
88 514 -514.0 -99.42919203690323 number episode from 10: 88 avegar over 10 episode: -99.439 avegare return across last 100 episodes: -99.439 state values: tensor(0.8876) 514
89 526 -526.0 -99.49404445685593 number episode from 10: 89 avegar over 10 episode: -99.439 avegare return across last 100 episodes: -99.439 state values: tensor(0.8957) 526
90 527 -527.0 -99.49910401228738 number episode from 10: 90 avegar over 10 episode: -99.44 avegare return across last 100 episodes: -99.44 state values: tensor(0.8906) 527
91 625 -625.0 -99.81293324036642 number episode from 10: 91 avegar over 10 episode: -99.444 avegare return across last 100 episodes: -99.444 state values: tensor(0.8977) 625
92 515 -515.0 -99.4349001165342 number episode from 10: 92 avegar over 10 episode: -99.444 avegare return across last 100 episodes: -99.444 state values: tensor(0.8883) 515
93 529 -529.0 -99.50907184244286 number episode from 10: 93 avegar over 10 episode: -99.445 avegare return across last 100 episodes: -99.445 state values: tensor(0.8895) 529
94 437 -437.0 -98.76240074536751 number episode from 10: 94 avegar over 10 episode: -99.437 avegare return across last 100 episodes: -99.437 state values: tensor(0.8964) 437
95 421 -421.0 -98.54649367632047 number episode from 10: 95 avegar over 10 episode: -99.428 avegare return across last 100 episodes: -99.428 state values: tensor(0.8911) 421
96 515 -515.0 -99.4349001165342 number episode from 10: 96 avegar over 10 episode: -99.428 avegare return across last 100 episodes: -99.428 state values: tensor(0.8849) 515
97 533 -533.0 -99.52841637065397 number episode from 10: 97 avegar over 10 episode: -99.429 avegare return across last 100 episodes: -99.429 state values: tensor(0.9012) 533
98 445 -445.0 -98.85801185395994 number episode from 10: 98 avegar over 10 episode: -99.424 avegare return across last 100 episodes: -99.424 state values: tensor(0.8912) 445
99 521 -521.0 -99.46796967728812 number episode from 10: 99 avegar over 10 episode: -99.424 avegare return across last 100 episodes: -99.424 state values: tensor(0.8892) 521
100 1000 -1000.0 -99.99568287525881 number episode from 10: 100 avegar over 10 episode: -99.43 avegare return across last 100 episodes: -99.439 state values: tensor(0.8202) 1000
101 531 -531.0 -99.51884131277825 number episode from 10: 101 avegar over 10 episode: -99.43 avegare return across last 100 episodes: -99.436 state values: tensor(0.8894) 531
102 426 -426.0 -98.61772994871401 number episode from 10: 102 avegar over 10 episode: -99.423 avegare return across last 100 episodes: -99.423 state values: tensor(0.8897) 426
103 533 -533.0 -99.52841637065397 number episode from 10: 103 avegar over 10 episode: -99.424 avegare return across last 100 episodes: -99.424 state values: tensor(0.8912) 533
104 518 -518.0 -99.45168414817302 number episode from 10: 104 avegar over 10 episode: -99.424 avegare return across last 100 episodes: -99.423 state values: tensor(0.8901) 518
105 518 -518.0 -99.45168414817302 number episode from 10: 105 avegar over 10 episode: -99.424 avegare return across last 100 episodes: -99.422 state values: tensor(0.8855) 518
106 630 -630.0 -99.82210137292142 number episode from 10: 106 avegar over 10 episode: -99.428 avegare return across last 100 episodes: -99.426 state values: tensor(0.8967) 630
107 523 -523.0 -99.47855708071009 number episode from 10: 107 avegar over 10 episode: -99.428 avegare return across last 100 episodes: -99.426 state values: tensor(0.8903) 523
108 535 -535.0 -99.53780088487795 number episode from 10: 108 avegar over 10 episode: -99.429 avegare return across last 100 episodes: -99.423 state values: tensor(0.8914) 535
109 513 -513.0 -99.42342629990226 number episode from 10: 109 avegar over 10 episode: -99.429 avegare return across last 100 episodes: -99.422 state values: tensor(0.8845) 513
110 1000 -1000.0 -99.99568287525881 number episode from 10: 110 avegar over 10 episode: -99.434 avegare return across last 100 episodes: -99.427 state values: tensor(0.8441) 1000
111 556 -556.0 -99.62574449581848 number episode from 10: 111 avegar over 10 episode: -99.436 avegare return across last 100 episodes: -99.423 state values: tensor(0.9045) 556
112 530 -530.0 -99.51398112401843 number episode from 10: 112 avegar over 10 episode: -99.437 avegare return across last 100 episodes: -99.431 state values: tensor(0.9014) 530
113 518 -518.0 -99.45168414817302 number episode from 10: 113 avegar over 10 episode: -99.437 avegare return across last 100 episodes: -99.43 state values: tensor(0.8890) 518
114 519 -519.0 -99.45716730669129 number episode from 10: 114 avegar over 10 episode: -99.437 avegare return across last 100 episodes: -99.425 state values: tensor(0.8894) 519
115 436 -436.0 -98.74989974279546 number episode from 10: 115 avegar over 10 episode: -99.431 avegare return across last 100 episodes: -99.412 state values: tensor(0.8900) 436
116 541 -541.0 -99.56484870804191 number episode from 10: 116 avegar over 10 episode: -99.432 avegare return across last 100 episodes: -99.42 state values: tensor(0.8940) 541
117 431 -431.0 -98.68547493495227 number episode from 10: 117 avegar over 10 episode: -99.426 avegare return across last 100 episodes: -99.413 state values: tensor(0.8902) 431
118 529 -529.0 -99.50907184244286 number episode from 10: 118 avegar over 10 episode: -99.427 avegare return across last 100 episodes: -99.42 state values: tensor(0.8916) 529
119 528 -528.0 -99.5041129721645 number episode from 10: 119 avegar over 10 episode: -99.427 avegare return across last 100 episodes: -99.42 state values: tensor(0.8925) 528
120 1000 -1000.0 -99.99568287525881 number episode from 10: 120 avegar over 10 episode: -99.432 avegare return across last 100 episodes: -99.42 state values: tensor(0.8200) 1000
121 1000 -1000.0 -99.99568287525881 number episode from 10: 121 avegar over 10 episode: -99.437 avegare return across last 100 episodes: -99.425 state values: tensor(0.8202) 1000
122 627 -627.0 -99.81665586888313 number episode from 10: 122 avegar over 10 episode: -99.44 avegare return across last 100 episodes: -99.428 state values: tensor(0.8958) 627
123 425 -425.0 -98.60376762496365 number episode from 10: 123 avegar over 10 episode: -99.433 avegare return across last 100 episodes: -99.427 state values: tensor(0.8933) 425
124 1000 -1000.0 -99.99568287525881 number episode from 10: 124 avegar over 10 episode: -99.437 avegare return across last 100 episodes: -99.427 state values: tensor(0.8200) 1000
125 543 -543.0 -99.57350821875188 number episode from 10: 125 avegar over 10 episode: -99.439 avegare return across last 100 episodes: -99.429 state values: tensor(0.9029) 543
126 1000 -1000.0 -99.99568287525881 number episode from 10: 126 avegar over 10 episode: -99.443 avegare return across last 100 episodes: -99.442 state values: tensor(0.8199) 1000
127 625 -625.0 -99.81293324036642 number episode from 10: 127 avegar over 10 episode: -99.446 avegare return across last 100 episodes: -99.442 state values: tensor(0.8928) 625
128 434 -434.0 -98.72451764390925 number episode from 10: 128 avegar over 10 episode: -99.44 avegare return across last 100 episodes: -99.442 state values: tensor(0.8913) 434
129 532 -532.0 -99.52365289965047 number episode from 10: 129 avegar over 10 episode: -99.441 avegare return across last 100 episodes: -99.442 state values: tensor(0.8894) 532
130 530 -530.0 -99.51398112401843 number episode from 10: 130 avegar over 10 episode: -99.441 avegare return across last 100 episodes: -99.45 state values: tensor(0.9006) 530
131 513 -513.0 -99.42342629990226 number episode from 10: 131 avegar over 10 episode: -99.441 avegare return across last 100 episodes: -99.445 state values: tensor(0.8879) 513
132 547 -547.0 -99.59031369663526 number episode from 10: 132 avegar over 10 episode: -99.442 avegare return across last 100 episodes: -99.441 state values: tensor(0.9027) 547
133 532 -532.0 -99.52365289965047 number episode from 10: 133 avegar over 10 episode: -99.443 avegare return across last 100 episodes: -99.44 state values: tensor(0.8916) 532
134 518 -518.0 -99.45168414817302 number episode from 10: 134 avegar over 10 episode: -99.443 avegare return across last 100 episodes: -99.44 state values: tensor(0.8894) 518
135 431 -431.0 -98.68547493495227 number episode from 10: 135 avegar over 10 episode: -99.438 avegare return across last 100 episodes: -99.432 state values: tensor(0.8909) 431
136 517 -517.0 -99.44614560421516 number episode from 10: 136 avegar over 10 episode: -99.438 avegare return across last 100 episodes: -99.427 state values: tensor(0.8894) 517
137 643 -643.0 -99.8438902147759 number episode from 10: 137 avegar over 10 episode: -99.441 avegare return across last 100 episodes: -99.43 state values: tensor(0.8996) 643
138 533 -533.0 -99.52841637065397 number episode from 10: 138 avegar over 10 episode: -99.441 avegare return across last 100 episodes: -99.425 state values: tensor(0.9031) 533
139 622 -622.0 -99.80720709839589 number episode from 10: 139 avegar over 10 episode: -99.444 avegare return across last 100 episodes: -99.423 state values: tensor(0.8883) 622
140 513 -513.0 -99.42342629990226 number episode from 10: 140 avegar over 10 episode: -99.444 avegare return across last 100 episodes: -99.423 state values: tensor(0.8845) 513
141 551 -551.0 -99.60645697163618 number episode from 10: 141 avegar over 10 episode: -99.445 avegare return across last 100 episodes: -99.425 state values: tensor(0.9033) 551
142 519 -519.0 -99.45716730669129 number episode from 10: 142 avegar over 10 episode: -99.445 avegare return across last 100 episodes: -99.424 state values: tensor(0.8889) 519
143 518 -518.0 -99.45168414817302 number episode from 10: 143 avegar over 10 episode: -99.445 avegare return across last 100 episodes: -99.424 state values: tensor(0.8861) 518
144 522 -522.0 -99.47328998051525 number episode from 10: 144 avegar over 10 episode: -99.445 avegare return across last 100 episodes: -99.423 state values: tensor(0.8867) 522
145 434 -434.0 -98.72451764390925 number episode from 10: 145 avegar over 10 episode: -99.44 avegare return across last 100 episodes: -99.41 state values: tensor(0.8916) 434
146 519 -519.0 -99.45716730669129 number episode from 10: 146 avegar over 10 episode: -99.44 avegare return across last 100 episodes: -99.407 state values: tensor(0.8838) 519
147 522 -522.0 -99.47328998051525 number episode from 10: 147 avegar over 10 episode: -99.441 avegare return across last 100 episodes: -99.406 state values: tensor(0.8923) 522
148 434 -434.0 -98.72451764390925 number episode from 10: 148 avegar over 10 episode: -99.436 avegare return across last 100 episodes: -99.399 state values: tensor(0.8894) 434
149 523 -523.0 -99.47855708071009 number episode from 10: 149 avegar over 10 episode: -99.436 avegare return across last 100 episodes: -99.399 state values: tensor(0.8845) 523
150 1000 -1000.0 -99.99568287525881 number episode from 10: 150 avegar over 10 episode: -99.44 avegare return across last 100 episodes: -99.405 state values: tensor(0.8208) 1000
151 671 -671.0 -99.88218093417017 number episode from 10: 151 avegar over 10 episode: -99.443 avegare return across last 100 episodes: -99.406 state values: tensor(0.8700) 671
152 517 -517.0 -99.44614560421516 number episode from 10: 152 avegar over 10 episode: -99.443 avegare return across last 100 episodes: -99.404 state values: tensor(0.8865) 517
153 542 -542.0 -99.56920022096149 number episode from 10: 153 avegar over 10 episode: -99.443 avegare return across last 100 episodes: -99.405 state values: tensor(0.9015) 542
154 993 -993.0 -99.9953682166697 number episode from 10: 154 avegar over 10 episode: -99.447 avegare return across last 100 episodes: -99.411 state values: tensor(0.8601) 993
155 435 -435.0 -98.73727246747016 number episode from 10: 155 avegar over 10 episode: -99.442 avegare return across last 100 episodes: -99.403 state values: tensor(0.8924) 435
156 535 -535.0 -99.53780088487795 number episode from 10: 156 avegar over 10 episode: -99.443 avegare return across last 100 episodes: -99.404 state values: tensor(0.8917) 535
157 758 -758.0 -99.95085520758803 number episode from 10: 157 avegar over 10 episode: -99.446 avegare return across last 100 episodes: -99.408 state values: tensor(0.8646) 758
158 433 -433.0 -98.71163398374672 number episode from 10: 158 avegar over 10 episode: -99.442 avegare return across last 100 episodes: -99.401 state values: tensor(0.8909) 433
159 434 -434.0 -98.72451764390925 number episode from 10: 159 avegar over 10 episode: -99.437 avegare return across last 100 episodes: -99.394 state values: tensor(0.8894) 434
160 1000 -1000.0 -99.99568287525881 number episode from 10: 160 avegar over 10 episode: -99.441 avegare return across last 100 episodes: -99.406 state values: tensor(0.8335) 1000
161 523 -523.0 -99.47855708071009 number episode from 10: 161 avegar over 10 episode: -99.441 avegare return across last 100 episodes: -99.406 state values: tensor(0.8923) 523
162 529 -529.0 -99.50907184244286 number episode from 10: 162 avegar over 10 episode: -99.441 avegare return across last 100 episodes: -99.407 state values: tensor(0.9021) 529
163 622 -622.0 -99.80720709839589 number episode from 10: 163 avegar over 10 episode: -99.444 avegare return across last 100 episodes: -99.409 state values: tensor(0.8906) 622
164 517 -517.0 -99.44614560421516 number episode from 10: 164 avegar over 10 episode: -99.444 avegare return across last 100 episodes: -99.407 state values: tensor(0.8897) 517
165 627 -627.0 -99.81665586888313 number episode from 10: 165 avegar over 10 episode: -99.446 avegare return across last 100 episodes: -99.419 state values: tensor(0.8952) 627
166 517 -517.0 -99.44614560421516 number episode from 10: 166 avegar over 10 episode: -99.446 avegare return across last 100 episodes: -99.417 state values: tensor(0.8882) 517
167 434 -434.0 -98.72451764390925 number episode from 10: 167 avegar over 10 episode: -99.442 avegare return across last 100 episodes: -99.41 state values: tensor(0.8911) 434
168 436 -436.0 -98.74989974279546 number episode from 10: 168 avegar over 10 episode: -99.437 avegare return across last 100 episodes: -99.409 state values: tensor(0.8912) 436
169 526 -526.0 -99.49404445685593 number episode from 10: 169 avegar over 10 episode: -99.438 avegare return across last 100 episodes: -99.41 state values: tensor(0.8925) 526
170 518 -518.0 -99.45168414817302 number episode from 10: 170 avegar over 10 episode: -99.438 avegare return across last 100 episodes: -99.418 state values: tensor(0.8882) 518
171 530 -530.0 -99.51398112401843 number episode from 10: 171 avegar over 10 episode: -99.438 avegare return across last 100 episodes: -99.413 state values: tensor(0.8892) 530
172 646 -646.0 -99.84852683150685 number episode from 10: 172 avegar over 10 episode: -99.441 avegare return across last 100 episodes: -99.427 state values: tensor(0.8986) 646
173 536 -536.0 -99.54242287602918 number episode from 10: 173 avegar over 10 episode: -99.441 avegare return across last 100 episodes: -99.437 state values: tensor(0.8939) 536
174 433 -433.0 -98.71163398374672 number episode from 10: 174 avegar over 10 episode: -99.437 avegare return across last 100 episodes: -99.429 state values: tensor(0.8909) 433
175 515 -515.0 -99.4349001165342 number episode from 10: 175 avegar over 10 episode: -99.437 avegare return across last 100 episodes: -99.427 state values: tensor(0.8858) 515
176 1000 -1000.0 -99.99568287525881 number episode from 10: 176 avegar over 10 episode: -99.44 avegare return across last 100 episodes: -99.433 state values: tensor(0.8356) 1000
177 533 -533.0 -99.52841637065397 number episode from 10: 177 avegar over 10 episode: -99.441 avegare return across last 100 episodes: -99.428 state values: tensor(0.8949) 533
178 733 -733.0 -99.9368173786718 number episode from 10: 178 avegar over 10 episode: -99.443 avegare return across last 100 episodes: -99.433 state values: tensor(0.8621) 733
179 531 -531.0 -99.51884131277825 number episode from 10: 179 avegar over 10 episode: -99.444 avegare return across last 100 episodes: -99.434 state values: tensor(0.8901) 531
180 1000 -1000.0 -99.99568287525881 number episode from 10: 180 avegar over 10 episode: -99.447 avegare return across last 100 episodes: -99.447 state values: tensor(0.8206) 1000
181 590 -590.0 -99.73407154367938 number episode from 10: 181 avegar over 10 episode: -99.449 avegare return across last 100 episodes: -99.45 state values: tensor(0.8742) 590
182 514 -514.0 -99.42919203690323 number episode from 10: 182 avegar over 10 episode: -99.448 avegare return across last 100 episodes: -99.45 state values: tensor(0.8846) 514
183 433 -433.0 -98.71163398374672 number episode from 10: 183 avegar over 10 episode: -99.444 avegare return across last 100 episodes: -99.442 state values: tensor(0.8914) 433
184 547 -547.0 -99.59031369663526 number episode from 10: 184 avegar over 10 episode: -99.445 avegare return across last 100 episodes: -99.451 state values: tensor(0.9052) 547
185 532 -532.0 -99.52365289965047 number episode from 10: 185 avegar over 10 episode: -99.446 avegare return across last 100 episodes: -99.451 state values: tensor(0.9003) 532
186 1000 -1000.0 -99.99568287525881 number episode from 10: 186 avegar over 10 episode: -99.449 avegare return across last 100 episodes: -99.451 state values: tensor(0.8201) 1000
187 1000 -1000.0 -99.99568287525881 number episode from 10: 187 avegar over 10 episode: -99.451 avegare return across last 100 episodes: -99.463 state values: tensor(0.8199) 1000
188 515 -515.0 -99.4349001165342 number episode from 10: 188 avegar over 10 episode: -99.451 avegare return across last 100 episodes: -99.463 state values: tensor(0.8881) 515
189 437 -437.0 -98.76240074536751 number episode from 10: 189 avegar over 10 episode: -99.448 avegare return across last 100 episodes: -99.455 state values: tensor(0.8903) 437
190 535 -535.0 -99.53780088487795 number episode from 10: 190 avegar over 10 episode: -99.448 avegare return across last 100 episodes: -99.456 state values: tensor(0.9007) 535
191 432 -432.0 -98.69862018560275 number episode from 10: 191 avegar over 10 episode: -99.444 avegare return across last 100 episodes: -99.445 state values: tensor(0.8906) 432
192 618 -618.0 -99.79929866499853 number episode from 10: 192 avegar over 10 episode: -99.446 avegare return across last 100 episodes: -99.448 state values: tensor(0.8865) 618
193 437 -437.0 -98.76240074536751 number episode from 10: 193 avegar over 10 episode: -99.443 avegare return across last 100 episodes: -99.441 state values: tensor(0.8921) 437
194 435 -435.0 -98.73727246747016 number episode from 10: 194 avegar over 10 episode: -99.439 avegare return across last 100 episodes: -99.441 state values: tensor(0.8912) 435
195 619 -619.0 -99.80130567834854 number episode from 10: 195 avegar over 10 episode: -99.441 avegare return across last 100 episodes: -99.453 state values: tensor(0.8805) 619
196 532 -532.0 -99.52365289965047 number episode from 10: 196 avegar over 10 episode: -99.441 avegare return across last 100 episodes: -99.454 state values: tensor(0.8910) 532
197 518 -518.0 -99.45168414817302 number episode from 10: 197 avegar over 10 episode: -99.441 avegare return across last 100 episodes: -99.453 state values: tensor(0.8845) 518
198 1000 -1000.0 -99.99568287525881 number episode from 10: 198 avegar over 10 episode: -99.444 avegare return across last 100 episodes: -99.465 state values: tensor(0.8553) 1000
199 521 -521.0 -99.46796967728812 number episode from 10: 199 avegar over 10 episode: -99.444 avegare return across last 100 episodes: -99.465 state values: tensor(0.8883) 521
200 518 -518.0 -99.45168414817302 number episode from 10: 200 avegar over 10 episode: -99.444 avegare return across last 100 episodes: -99.459 state values: tensor(0.8819) 518
load offline data!!!!!
mem_cntr: 50000 ; mem_size: 50000
nn.learn_nn_feature_fqi FQI:  998
nn.learn_nn_feature_fqi FQI:  1998
nn.learn_nn_feature_fqi FQI:  2998
nn.learn_nn_feature_fqi FQI:  3998
nn.learn_nn_feature_fqi FQI:  4998
nn.learn_nn_feature_fqi FQI:  5998
nn.learn_nn_feature_fqi FQI:  6998
nn.learn_nn_feature_fqi FQI:  7998
nn.learn_nn_feature_fqi FQI:  8998
nn.learn_nn_feature_fqi FQI:  9998
nn.learn_nn_feature_fqi FQI:  10998
nn.learn_nn_feature_fqi FQI:  11998
nn.learn_nn_feature_fqi FQI:  12998
nn.learn_nn_feature_fqi FQI:  13998
nn.learn_nn_feature_fqi FQI:  14998
nn.learn_nn_feature_fqi FQI:  15998
nn.learn_nn_feature_fqi FQI:  16998
nn.learn_nn_feature_fqi FQI:  17998
nn.learn_nn_feature_fqi FQI:  18998
nn.learn_nn_feature_fqi FQI:  19998
nn.learn_nn_feature_fqi FQI:  20998
nn.learn_nn_feature_fqi FQI:  21998
nn.learn_nn_feature_fqi FQI:  22998
nn.learn_nn_feature_fqi FQI:  23998
nn.learn_nn_feature_fqi FQI:  24998
nn.learn_nn_feature_fqi FQI:  25998
nn.learn_nn_feature_fqi FQI:  26998
nn.learn_nn_feature_fqi FQI:  27998
nn.learn_nn_feature_fqi FQI:  28998
nn.learn_nn_feature_fqi FQI:  29998
nn.learn_nn_feature_fqi FQI:  30998
nn.learn_nn_feature_fqi FQI:  31998
nn.learn_nn_feature_fqi FQI:  32998
nn.learn_nn_feature_fqi FQI:  33998
nn.learn_nn_feature_fqi FQI:  34998
nn.learn_nn_feature_fqi FQI:  35998
nn.learn_nn_feature_fqi FQI:  36998
nn.learn_nn_feature_fqi FQI:  37998
nn.learn_nn_feature_fqi FQI:  38998
nn.learn_nn_feature_fqi FQI:  39998
nn.learn_nn_feature_fqi FQI:  40998
nn.learn_nn_feature_fqi FQI:  41998
nn.learn_nn_feature_fqi FQI:  42998
nn.learn_nn_feature_fqi FQI:  43998
nn.learn_nn_feature_fqi FQI:  44998
nn.learn_nn_feature_fqi FQI:  45998
nn.learn_nn_feature_fqi FQI:  46998
nn.learn_nn_feature_fqi FQI:  47998
nn.learn_nn_feature_fqi FQI:  48998
nn.learn_nn_feature_fqi FQI:  49998
nn.learn_nn_feature_fqi FQI:  50998
nn.learn_nn_feature_fqi FQI:  51998
nn.learn_nn_feature_fqi FQI:  52998
nn.learn_nn_feature_fqi FQI:  53998
nn.learn_nn_feature_fqi FQI:  54998
nn.learn_nn_feature_fqi FQI:  55998
nn.learn_nn_feature_fqi FQI:  56998
nn.learn_nn_feature_fqi FQI:  57998
nn.learn_nn_feature_fqi FQI:  58998
nn.learn_nn_feature_fqi FQI:  59998
nn.learn_nn_feature_fqi FQI:  60998
nn.learn_nn_feature_fqi FQI:  61998
nn.learn_nn_feature_fqi FQI:  62998
nn.learn_nn_feature_fqi FQI:  63998
nn.learn_nn_feature_fqi FQI:  64998
nn.learn_nn_feature_fqi FQI:  65998
nn.learn_nn_feature_fqi FQI:  66998
nn.learn_nn_feature_fqi FQI:  67998
nn.learn_nn_feature_fqi FQI:  68998
nn.learn_nn_feature_fqi FQI:  69998
nn.learn_nn_feature_fqi FQI:  70998
nn.learn_nn_feature_fqi FQI:  71998
nn.learn_nn_feature_fqi FQI:  72998
nn.learn_nn_feature_fqi FQI:  73998
nn.learn_nn_feature_fqi FQI:  74998
nn.learn_nn_feature_fqi FQI:  75998
nn.learn_nn_feature_fqi FQI:  76998
nn.learn_nn_feature_fqi FQI:  77998
nn.learn_nn_feature_fqi FQI:  78998
nn.learn_nn_feature_fqi FQI:  79998
nn.learn_nn_feature_fqi FQI:  80998
nn.learn_nn_feature_fqi FQI:  81998
nn.learn_nn_feature_fqi FQI:  82998
nn.learn_nn_feature_fqi FQI:  83998
nn.learn_nn_feature_fqi FQI:  84998
nn.learn_nn_feature_fqi FQI:  85998
nn.learn_nn_feature_fqi FQI:  86998
nn.learn_nn_feature_fqi FQI:  87998
nn.learn_nn_feature_fqi FQI:  88998
nn.learn_nn_feature_fqi FQI:  89998
nn.learn_nn_feature_fqi FQI:  90998
nn.learn_nn_feature_fqi FQI:  91998
nn.learn_nn_feature_fqi FQI:  92998
nn.learn_nn_feature_fqi FQI:  93998
nn.learn_nn_feature_fqi FQI:  94998
nn.learn_nn_feature_fqi FQI:  95998
nn.learn_nn_feature_fqi FQI:  96998
nn.learn_nn_feature_fqi FQI:  97998
nn.learn_nn_feature_fqi FQI:  98998
nn.learn_nn_feature_fqi FQI:  99998
nn.learn_nn_feature_fqi FQI:  100998
nn.learn_nn_feature_fqi FQI:  101998
nn.learn_nn_feature_fqi FQI:  102998
nn.learn_nn_feature_fqi FQI:  103998
nn.learn_nn_feature_fqi FQI:  104998
nn.learn_nn_feature_fqi FQI:  105998
nn.learn_nn_feature_fqi FQI:  106998
nn.learn_nn_feature_fqi FQI:  107998
nn.learn_nn_feature_fqi FQI:  108998
nn.learn_nn_feature_fqi FQI:  109998
nn.learn_nn_feature_fqi FQI:  110998
nn.learn_nn_feature_fqi FQI:  111998
nn.learn_nn_feature_fqi FQI:  112998
nn.learn_nn_feature_fqi FQI:  113998
nn.learn_nn_feature_fqi FQI:  114998
nn.learn_nn_feature_fqi FQI:  115998
nn.learn_nn_feature_fqi FQI:  116998
nn.learn_nn_feature_fqi FQI:  117998
nn.learn_nn_feature_fqi FQI:  118998
nn.learn_nn_feature_fqi FQI:  119998
nn.learn_nn_feature_fqi FQI:  120998
nn.learn_nn_feature_fqi FQI:  121998
nn.learn_nn_feature_fqi FQI:  122998
nn.learn_nn_feature_fqi FQI:  123998
nn.learn_nn_feature_fqi FQI:  124998
nn.learn_nn_feature_fqi FQI:  125998
nn.learn_nn_feature_fqi FQI:  126998
nn.learn_nn_feature_fqi FQI:  127998
nn.learn_nn_feature_fqi FQI:  128998
nn.learn_nn_feature_fqi FQI:  129998
nn.learn_nn_feature_fqi FQI:  130998
nn.learn_nn_feature_fqi FQI:  131998
nn.learn_nn_feature_fqi FQI:  132998
nn.learn_nn_feature_fqi FQI:  133998
nn.learn_nn_feature_fqi FQI:  134998
nn.learn_nn_feature_fqi FQI:  135998
nn.learn_nn_feature_fqi FQI:  136998
nn.learn_nn_feature_fqi FQI:  137998
nn.learn_nn_feature_fqi FQI:  138998
nn.learn_nn_feature_fqi FQI:  139998
nn.learn_nn_feature_fqi FQI:  140998
nn.learn_nn_feature_fqi FQI:  141998
nn.learn_nn_feature_fqi FQI:  142998
nn.learn_nn_feature_fqi FQI:  143998
nn.learn_nn_feature_fqi FQI:  144998
nn.learn_nn_feature_fqi FQI:  145998
nn.learn_nn_feature_fqi FQI:  146998
nn.learn_nn_feature_fqi FQI:  147998
nn.learn_nn_feature_fqi FQI:  148998
nn.learn_nn_feature_fqi FQI:  149998
nn.learn_nn_feature_fqi FQI:  150998
nn.learn_nn_feature_fqi FQI:  151998
nn.learn_nn_feature_fqi FQI:  152998
nn.learn_nn_feature_fqi FQI:  153998
nn.learn_nn_feature_fqi FQI:  154998
nn.learn_nn_feature_fqi FQI:  155998
0 1001 -1000.0 -98.99572604650622 number episode from 10: 0 avegar over 10 episode: -98.996 avegare return across last 100 episodes: -98.996 state values: tensor(0.9447) 1000
1 1000 -1000.0 -99.99568287525881 number episode from 10: 1 avegar over 10 episode: -99.496 avegare return across last 100 episodes: -99.496 state values: tensor(0.9415) 1000
2 1000 -1000.0 -99.99568287525881 number episode from 10: 2 avegar over 10 episode: -99.662 avegare return across last 100 episodes: -99.662 state values: tensor(0.9454) 1000
3 1000 -1000.0 -99.99568287525881 number episode from 10: 3 avegar over 10 episode: -99.746 avegare return across last 100 episodes: -99.746 state values: tensor(0.9470) 1000
4 1000 -1000.0 -99.99568287525881 number episode from 10: 4 avegar over 10 episode: -99.796 avegare return across last 100 episodes: -99.796 state values: tensor(0.9423) 1000
5 1000 -1000.0 -99.99568287525881 number episode from 10: 5 avegar over 10 episode: -99.829 avegare return across last 100 episodes: -99.829 state values: tensor(0.9000) 1000
6 1000 -1000.0 -99.99568287525881 number episode from 10: 6 avegar over 10 episode: -99.853 avegare return across last 100 episodes: -99.853 state values: tensor(0.9437) 1000
7 1000 -1000.0 -99.99568287525881 number episode from 10: 7 avegar over 10 episode: -99.871 avegare return across last 100 episodes: -99.871 state values: tensor(0.9433) 1000
8 1000 -1000.0 -99.99568287525881 number episode from 10: 8 avegar over 10 episode: -99.885 avegare return across last 100 episodes: -99.885 state values: tensor(0.9232) 1000
9 1000 -1000.0 -99.99568287525881 number episode from 10: 9 avegar over 10 episode: -99.896 avegare return across last 100 episodes: -99.896 state values: tensor(0.8962) 1000
10 1000 -1000.0 -99.99568287525881 number episode from 10: 10 avegar over 10 episode: -99.905 avegare return across last 100 episodes: -99.905 state values: tensor(0.9454) 1000
11 1000 -1000.0 -99.99568287525881 number episode from 10: 11 avegar over 10 episode: -99.912 avegare return across last 100 episodes: -99.912 state values: tensor(0.8969) 1000
12 1000 -1000.0 -99.99568287525881 number episode from 10: 12 avegar over 10 episode: -99.919 avegare return across last 100 episodes: -99.919 state values: tensor(0.8991) 1000
13 1000 -1000.0 -99.99568287525881 number episode from 10: 13 avegar over 10 episode: -99.924 avegare return across last 100 episodes: -99.924 state values: tensor(0.9476) 1000
14 1000 -1000.0 -99.99568287525881 number episode from 10: 14 avegar over 10 episode: -99.929 avegare return across last 100 episodes: -99.929 state values: tensor(0.9009) 1000
15 1000 -1000.0 -99.99568287525881 number episode from 10: 15 avegar over 10 episode: -99.933 avegare return across last 100 episodes: -99.933 state values: tensor(0.9424) 1000
16 1000 -1000.0 -99.99568287525881 number episode from 10: 16 avegar over 10 episode: -99.937 avegare return across last 100 episodes: -99.937 state values: tensor(0.9008) 1000
17 1000 -1000.0 -99.99568287525881 number episode from 10: 17 avegar over 10 episode: -99.94 avegare return across last 100 episodes: -99.94 state values: tensor(0.9421) 1000
18 1000 -1000.0 -99.99568287525881 number episode from 10: 18 avegar over 10 episode: -99.943 avegare return across last 100 episodes: -99.943 state values: tensor(0.9444) 1000
19 1000 -1000.0 -99.99568287525881 number episode from 10: 19 avegar over 10 episode: -99.946 avegare return across last 100 episodes: -99.946 state values: tensor(0.9467) 1000
20 1000 -1000.0 -99.99568287525881 number episode from 10: 20 avegar over 10 episode: -99.948 avegare return across last 100 episodes: -99.948 state values: tensor(0.9474) 1000
21 1000 -1000.0 -99.99568287525881 number episode from 10: 21 avegar over 10 episode: -99.95 avegare return across last 100 episodes: -99.95 state values: tensor(0.8946) 1000
22 1000 -1000.0 -99.99568287525881 number episode from 10: 22 avegar over 10 episode: -99.952 avegare return across last 100 episodes: -99.952 state values: tensor(0.9442) 1000
23 1000 -1000.0 -99.99568287525881 number episode from 10: 23 avegar over 10 episode: -99.954 avegare return across last 100 episodes: -99.954 state values: tensor(0.9469) 1000
24 1000 -1000.0 -99.99568287525881 number episode from 10: 24 avegar over 10 episode: -99.956 avegare return across last 100 episodes: -99.956 state values: tensor(0.9455) 1000
25 1000 -1000.0 -99.99568287525881 number episode from 10: 25 avegar over 10 episode: -99.957 avegare return across last 100 episodes: -99.957 state values: tensor(0.8962) 1000
26 1000 -1000.0 -99.99568287525881 number episode from 10: 26 avegar over 10 episode: -99.959 avegare return across last 100 episodes: -99.959 state values: tensor(0.9416) 1000
27 1000 -1000.0 -99.99568287525881 number episode from 10: 27 avegar over 10 episode: -99.96 avegare return across last 100 episodes: -99.96 state values: tensor(0.8954) 1000
28 1000 -1000.0 -99.99568287525881 number episode from 10: 28 avegar over 10 episode: -99.961 avegare return across last 100 episodes: -99.961 state values: tensor(0.9012) 1000
29 1000 -1000.0 -99.99568287525881 number episode from 10: 29 avegar over 10 episode: -99.962 avegare return across last 100 episodes: -99.962 state values: tensor(0.9010) 1000
30 1000 -1000.0 -99.99568287525881 number episode from 10: 30 avegar over 10 episode: -99.963 avegare return across last 100 episodes: -99.963 state values: tensor(0.9251) 1000
31 1000 -1000.0 -99.99568287525881 number episode from 10: 31 avegar over 10 episode: -99.964 avegare return across last 100 episodes: -99.964 state values: tensor(0.9442) 1000
32 1000 -1000.0 -99.99568287525881 number episode from 10: 32 avegar over 10 episode: -99.965 avegare return across last 100 episodes: -99.965 state values: tensor(0.8964) 1000
33 1000 -1000.0 -99.99568287525881 number episode from 10: 33 avegar over 10 episode: -99.966 avegare return across last 100 episodes: -99.966 state values: tensor(0.9475) 1000
34 1000 -1000.0 -99.99568287525881 number episode from 10: 34 avegar over 10 episode: -99.967 avegare return across last 100 episodes: -99.967 state values: tensor(0.9028) 1000
35 1000 -1000.0 -99.99568287525881 number episode from 10: 35 avegar over 10 episode: -99.968 avegare return across last 100 episodes: -99.968 state values: tensor(0.9444) 1000
36 1000 -1000.0 -99.99568287525881 number episode from 10: 36 avegar over 10 episode: -99.969 avegare return across last 100 episodes: -99.969 state values: tensor(0.9352) 1000
37 1000 -1000.0 -99.99568287525881 number episode from 10: 37 avegar over 10 episode: -99.969 avegare return across last 100 episodes: -99.969 state values: tensor(0.8968) 1000
38 1000 -1000.0 -99.99568287525881 number episode from 10: 38 avegar over 10 episode: -99.97 avegare return across last 100 episodes: -99.97 state values: tensor(0.9461) 1000
39 1000 -1000.0 -99.99568287525881 number episode from 10: 39 avegar over 10 episode: -99.971 avegare return across last 100 episodes: -99.971 state values: tensor(0.9436) 1000
40 1000 -1000.0 -99.99568287525881 number episode from 10: 40 avegar over 10 episode: -99.971 avegare return across last 100 episodes: -99.971 state values: tensor(0.9459) 1000
41 1000 -1000.0 -99.99568287525881 number episode from 10: 41 avegar over 10 episode: -99.972 avegare return across last 100 episodes: -99.972 state values: tensor(0.9475) 1000
42 1000 -1000.0 -99.99568287525881 number episode from 10: 42 avegar over 10 episode: -99.972 avegare return across last 100 episodes: -99.972 state values: tensor(0.9370) 1000
43 1000 -1000.0 -99.99568287525881 number episode from 10: 43 avegar over 10 episode: -99.973 avegare return across last 100 episodes: -99.973 state values: tensor(0.8983) 1000
44 1000 -1000.0 -99.99568287525881 number episode from 10: 44 avegar over 10 episode: -99.973 avegare return across last 100 episodes: -99.973 state values: tensor(0.8999) 1000
45 1000 -1000.0 -99.99568287525881 number episode from 10: 45 avegar over 10 episode: -99.974 avegare return across last 100 episodes: -99.974 state values: tensor(0.8947) 1000
46 1000 -1000.0 -99.99568287525881 number episode from 10: 46 avegar over 10 episode: -99.974 avegare return across last 100 episodes: -99.974 state values: tensor(0.8954) 1000
47 1000 -1000.0 -99.99568287525881 number episode from 10: 47 avegar over 10 episode: -99.975 avegare return across last 100 episodes: -99.975 state values: tensor(0.8950) 1000
48 1000 -1000.0 -99.99568287525881 number episode from 10: 48 avegar over 10 episode: -99.975 avegare return across last 100 episodes: -99.975 state values: tensor(0.9470) 1000
49 1000 -1000.0 -99.99568287525881 number episode from 10: 49 avegar over 10 episode: -99.976 avegare return across last 100 episodes: -99.976 state values: tensor(0.8979) 1000
50 1000 -1000.0 -99.99568287525881 number episode from 10: 50 avegar over 10 episode: -99.976 avegare return across last 100 episodes: -99.976 state values: tensor(0.8953) 1000
51 1000 -1000.0 -99.99568287525881 number episode from 10: 51 avegar over 10 episode: -99.976 avegare return across last 100 episodes: -99.976 state values: tensor(0.8983) 1000
52 1000 -1000.0 -99.99568287525881 number episode from 10: 52 avegar over 10 episode: -99.977 avegare return across last 100 episodes: -99.977 state values: tensor(0.8966) 1000
53 1000 -1000.0 -99.99568287525881 number episode from 10: 53 avegar over 10 episode: -99.977 avegare return across last 100 episodes: -99.977 state values: tensor(0.9043) 1000
54 1000 -1000.0 -99.99568287525881 number episode from 10: 54 avegar over 10 episode: -99.978 avegare return across last 100 episodes: -99.978 state values: tensor(0.9443) 1000
55 1000 -1000.0 -99.99568287525881 number episode from 10: 55 avegar over 10 episode: -99.978 avegare return across last 100 episodes: -99.978 state values: tensor(0.8992) 1000
56 1000 -1000.0 -99.99568287525881 number episode from 10: 56 avegar over 10 episode: -99.978 avegare return across last 100 episodes: -99.978 state values: tensor(0.8949) 1000
57 1000 -1000.0 -99.99568287525881 number episode from 10: 57 avegar over 10 episode: -99.978 avegare return across last 100 episodes: -99.978 state values: tensor(0.9109) 1000
58 1000 -1000.0 -99.99568287525881 number episode from 10: 58 avegar over 10 episode: -99.979 avegare return across last 100 episodes: -99.979 state values: tensor(0.8992) 1000
59 1000 -1000.0 -99.99568287525881 number episode from 10: 59 avegar over 10 episode: -99.979 avegare return across last 100 episodes: -99.979 state values: tensor(0.8978) 1000
60 1000 -1000.0 -99.99568287525881 number episode from 10: 60 avegar over 10 episode: -99.979 avegare return across last 100 episodes: -99.979 state values: tensor(0.8959) 1000
61 1000 -1000.0 -99.99568287525881 number episode from 10: 61 avegar over 10 episode: -99.98 avegare return across last 100 episodes: -99.98 state values: tensor(0.9474) 1000
62 1000 -1000.0 -99.99568287525881 number episode from 10: 62 avegar over 10 episode: -99.98 avegare return across last 100 episodes: -99.98 state values: tensor(0.9424) 1000
63 1000 -1000.0 -99.99568287525881 number episode from 10: 63 avegar over 10 episode: -99.98 avegare return across last 100 episodes: -99.98 state values: tensor(0.9439) 1000
64 1000 -1000.0 -99.99568287525881 number episode from 10: 64 avegar over 10 episode: -99.98 avegare return across last 100 episodes: -99.98 state values: tensor(0.8970) 1000
65 1000 -1000.0 -99.99568287525881 number episode from 10: 65 avegar over 10 episode: -99.981 avegare return across last 100 episodes: -99.981 state values: tensor(0.9003) 1000
66 1000 -1000.0 -99.99568287525881 number episode from 10: 66 avegar over 10 episode: -99.981 avegare return across last 100 episodes: -99.981 state values: tensor(0.8954) 1000
67 1000 -1000.0 -99.99568287525881 number episode from 10: 67 avegar over 10 episode: -99.981 avegare return across last 100 episodes: -99.981 state values: tensor(0.9433) 1000
68 1000 -1000.0 -99.99568287525881 number episode from 10: 68 avegar over 10 episode: -99.981 avegare return across last 100 episodes: -99.981 state values: tensor(0.8956) 1000
69 1000 -1000.0 -99.99568287525881 number episode from 10: 69 avegar over 10 episode: -99.981 avegare return across last 100 episodes: -99.981 state values: tensor(0.8960) 1000
70 1000 -1000.0 -99.99568287525881 number episode from 10: 70 avegar over 10 episode: -99.982 avegare return across last 100 episodes: -99.982 state values: tensor(0.9042) 1000
71 1000 -1000.0 -99.99568287525881 number episode from 10: 71 avegar over 10 episode: -99.982 avegare return across last 100 episodes: -99.982 state values: tensor(0.8964) 1000
72 1000 -1000.0 -99.99568287525881 number episode from 10: 72 avegar over 10 episode: -99.982 avegare return across last 100 episodes: -99.982 state values: tensor(0.8966) 1000
73 1000 -1000.0 -99.99568287525881 number episode from 10: 73 avegar over 10 episode: -99.982 avegare return across last 100 episodes: -99.982 state values: tensor(0.8981) 1000
74 1000 -1000.0 -99.99568287525881 number episode from 10: 74 avegar over 10 episode: -99.982 avegare return across last 100 episodes: -99.982 state values: tensor(0.9223) 1000
75 1000 -1000.0 -99.99568287525881 number episode from 10: 75 avegar over 10 episode: -99.983 avegare return across last 100 episodes: -99.983 state values: tensor(0.9386) 1000
76 1000 -1000.0 -99.99568287525881 number episode from 10: 76 avegar over 10 episode: -99.983 avegare return across last 100 episodes: -99.983 state values: tensor(0.9398) 1000
77 1000 -1000.0 -99.99568287525881 number episode from 10: 77 avegar over 10 episode: -99.983 avegare return across last 100 episodes: -99.983 state values: tensor(0.9480) 1000
78 1000 -1000.0 -99.99568287525881 number episode from 10: 78 avegar over 10 episode: -99.983 avegare return across last 100 episodes: -99.983 state values: tensor(0.9455) 1000
79 1000 -1000.0 -99.99568287525881 number episode from 10: 79 avegar over 10 episode: -99.983 avegare return across last 100 episodes: -99.983 state values: tensor(0.9479) 1000
80 1000 -1000.0 -99.99568287525881 number episode from 10: 80 avegar over 10 episode: -99.983 avegare return across last 100 episodes: -99.983 state values: tensor(0.9439) 1000
81 1000 -1000.0 -99.99568287525881 number episode from 10: 81 avegar over 10 episode: -99.983 avegare return across last 100 episodes: -99.983 state values: tensor(0.8951) 1000
82 1000 -1000.0 -99.99568287525881 number episode from 10: 82 avegar over 10 episode: -99.984 avegare return across last 100 episodes: -99.984 state values: tensor(0.9440) 1000
83 1000 -1000.0 -99.99568287525881 number episode from 10: 83 avegar over 10 episode: -99.984 avegare return across last 100 episodes: -99.984 state values: tensor(0.9434) 1000
84 1000 -1000.0 -99.99568287525881 number episode from 10: 84 avegar over 10 episode: -99.984 avegare return across last 100 episodes: -99.984 state values: tensor(0.9438) 1000
85 1000 -1000.0 -99.99568287525881 number episode from 10: 85 avegar over 10 episode: -99.984 avegare return across last 100 episodes: -99.984 state values: tensor(0.9475) 1000
86 1000 -1000.0 -99.99568287525881 number episode from 10: 86 avegar over 10 episode: -99.984 avegare return across last 100 episodes: -99.984 state values: tensor(0.8987) 1000
87 1000 -1000.0 -99.99568287525881 number episode from 10: 87 avegar over 10 episode: -99.984 avegare return across last 100 episodes: -99.984 state values: tensor(0.8947) 1000
88 1000 -1000.0 -99.99568287525881 number episode from 10: 88 avegar over 10 episode: -99.984 avegare return across last 100 episodes: -99.984 state values: tensor(0.9205) 1000
89 1000 -1000.0 -99.99568287525881 number episode from 10: 89 avegar over 10 episode: -99.985 avegare return across last 100 episodes: -99.985 state values: tensor(0.8975) 1000
90 1000 -1000.0 -99.99568287525881 number episode from 10: 90 avegar over 10 episode: -99.985 avegare return across last 100 episodes: -99.985 state values: tensor(0.8987) 1000
91 1000 -1000.0 -99.99568287525881 number episode from 10: 91 avegar over 10 episode: -99.985 avegare return across last 100 episodes: -99.985 state values: tensor(0.9443) 1000
92 1000 -1000.0 -99.99568287525881 number episode from 10: 92 avegar over 10 episode: -99.985 avegare return across last 100 episodes: -99.985 state values: tensor(0.9243) 1000
93 1000 -1000.0 -99.99568287525881 number episode from 10: 93 avegar over 10 episode: -99.985 avegare return across last 100 episodes: -99.985 state values: tensor(0.8952) 1000
94 1000 -1000.0 -99.99568287525881 number episode from 10: 94 avegar over 10 episode: -99.985 avegare return across last 100 episodes: -99.985 state values: tensor(0.9430) 1000
95 1000 -1000.0 -99.99568287525881 number episode from 10: 95 avegar over 10 episode: -99.985 avegare return across last 100 episodes: -99.985 state values: tensor(0.9269) 1000
96 1000 -1000.0 -99.99568287525881 number episode from 10: 96 avegar over 10 episode: -99.985 avegare return across last 100 episodes: -99.985 state values: tensor(0.9002) 1000
97 1000 -1000.0 -99.99568287525881 number episode from 10: 97 avegar over 10 episode: -99.985 avegare return across last 100 episodes: -99.985 state values: tensor(0.9031) 1000
98 1000 -1000.0 -99.99568287525881 number episode from 10: 98 avegar over 10 episode: -99.986 avegare return across last 100 episodes: -99.986 state values: tensor(0.8978) 1000
99 1000 -1000.0 -99.99568287525881 number episode from 10: 99 avegar over 10 episode: -99.986 avegare return across last 100 episodes: -99.986 state values: tensor(0.9470) 1000
100 1000 -1000.0 -99.99568287525881 number episode from 10: 100 avegar over 10 episode: -99.986 avegare return across last 100 episodes: -99.996 state values: tensor(0.9010) 1000
101 1000 -1000.0 -99.99568287525881 number episode from 10: 101 avegar over 10 episode: -99.986 avegare return across last 100 episodes: -99.996 state values: tensor(0.8987) 1000
102 1000 -1000.0 -99.99568287525881 number episode from 10: 102 avegar over 10 episode: -99.986 avegare return across last 100 episodes: -99.996 state values: tensor(0.8964) 1000
103 1000 -1000.0 -99.99568287525881 number episode from 10: 103 avegar over 10 episode: -99.986 avegare return across last 100 episodes: -99.996 state values: tensor(0.8962) 1000
104 1000 -1000.0 -99.99568287525881 number episode from 10: 104 avegar over 10 episode: -99.986 avegare return across last 100 episodes: -99.996 state values: tensor(0.9447) 1000
105 1000 -1000.0 -99.99568287525881 number episode from 10: 105 avegar over 10 episode: -99.986 avegare return across last 100 episodes: -99.996 state values: tensor(0.8974) 1000
106 1000 -1000.0 -99.99568287525881 number episode from 10: 106 avegar over 10 episode: -99.986 avegare return across last 100 episodes: -99.996 state values: tensor(0.8998) 1000
107 1000 -1000.0 -99.99568287525881 number episode from 10: 107 avegar over 10 episode: -99.986 avegare return across last 100 episodes: -99.996 state values: tensor(0.9423) 1000
108 1000 -1000.0 -99.99568287525881 number episode from 10: 108 avegar over 10 episode: -99.987 avegare return across last 100 episodes: -99.996 state values: tensor(0.9072) 1000
109 1000 -1000.0 -99.99568287525881 number episode from 10: 109 avegar over 10 episode: -99.987 avegare return across last 100 episodes: -99.996 state values: tensor(0.9472) 1000
110 1000 -1000.0 -99.99568287525881 number episode from 10: 110 avegar over 10 episode: -99.987 avegare return across last 100 episodes: -99.996 state values: tensor(0.9013) 1000
111 1000 -1000.0 -99.99568287525881 number episode from 10: 111 avegar over 10 episode: -99.987 avegare return across last 100 episodes: -99.996 state values: tensor(0.9459) 1000
112 1000 -1000.0 -99.99568287525881 number episode from 10: 112 avegar over 10 episode: -99.987 avegare return across last 100 episodes: -99.996 state values: tensor(0.9443) 1000
113 1000 -1000.0 -99.99568287525881 number episode from 10: 113 avegar over 10 episode: -99.987 avegare return across last 100 episodes: -99.996 state values: tensor(0.9147) 1000
114 1000 -1000.0 -99.99568287525881 number episode from 10: 114 avegar over 10 episode: -99.987 avegare return across last 100 episodes: -99.996 state values: tensor(0.9052) 1000
115 1000 -1000.0 -99.99568287525881 number episode from 10: 115 avegar over 10 episode: -99.987 avegare return across last 100 episodes: -99.996 state values: tensor(0.8947) 1000
116 1000 -1000.0 -99.99568287525881 number episode from 10: 116 avegar over 10 episode: -99.987 avegare return across last 100 episodes: -99.996 state values: tensor(0.9040) 1000
117 1000 -1000.0 -99.99568287525881 number episode from 10: 117 avegar over 10 episode: -99.987 avegare return across last 100 episodes: -99.996 state values: tensor(0.9458) 1000
118 1000 -1000.0 -99.99568287525881 number episode from 10: 118 avegar over 10 episode: -99.987 avegare return across last 100 episodes: -99.996 state values: tensor(0.9144) 1000
119 1000 -1000.0 -99.99568287525881 number episode from 10: 119 avegar over 10 episode: -99.987 avegare return across last 100 episodes: -99.996 state values: tensor(0.8961) 1000
120 1000 -1000.0 -99.99568287525881 number episode from 10: 120 avegar over 10 episode: -99.987 avegare return across last 100 episodes: -99.996 state values: tensor(0.8956) 1000
121 1000 -1000.0 -99.99568287525881 number episode from 10: 121 avegar over 10 episode: -99.987 avegare return across last 100 episodes: -99.996 state values: tensor(0.9467) 1000
122 1000 -1000.0 -99.99568287525881 number episode from 10: 122 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.9456) 1000
123 1000 -1000.0 -99.99568287525881 number episode from 10: 123 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.9469) 1000
124 1000 -1000.0 -99.99568287525881 number episode from 10: 124 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.9014) 1000
125 1000 -1000.0 -99.99568287525881 number episode from 10: 125 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.8965) 1000
126 1000 -1000.0 -99.99568287525881 number episode from 10: 126 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.9389) 1000
127 1000 -1000.0 -99.99568287525881 number episode from 10: 127 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.9348) 1000
128 1000 -1000.0 -99.99568287525881 number episode from 10: 128 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.9427) 1000
129 1000 -1000.0 -99.99568287525881 number episode from 10: 129 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.9467) 1000
130 1000 -1000.0 -99.99568287525881 number episode from 10: 130 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.9439) 1000
131 1000 -1000.0 -99.99568287525881 number episode from 10: 131 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.9377) 1000
132 1000 -1000.0 -99.99568287525881 number episode from 10: 132 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.9472) 1000
133 1000 -1000.0 -99.99568287525881 number episode from 10: 133 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.9024) 1000
134 1000 -1000.0 -99.99568287525881 number episode from 10: 134 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.9323) 1000
135 1000 -1000.0 -99.99568287525881 number episode from 10: 135 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.9455) 1000
136 1000 -1000.0 -99.99568287525881 number episode from 10: 136 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.8968) 1000
137 1000 -1000.0 -99.99568287525881 number episode from 10: 137 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.9448) 1000
138 1000 -1000.0 -99.99568287525881 number episode from 10: 138 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.9434) 1000
139 1000 -1000.0 -99.99568287525881 number episode from 10: 139 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.9438) 1000
140 1000 -1000.0 -99.99568287525881 number episode from 10: 140 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.9008) 1000
141 1000 -1000.0 -99.99568287525881 number episode from 10: 141 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.9471) 1000
142 1000 -1000.0 -99.99568287525881 number episode from 10: 142 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.9457) 1000
143 1000 -1000.0 -99.99568287525881 number episode from 10: 143 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.9441) 1000
144 1000 -1000.0 -99.99568287525881 number episode from 10: 144 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.9031) 1000
145 1000 -1000.0 -99.99568287525881 number episode from 10: 145 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.9441) 1000
146 1000 -1000.0 -99.99568287525881 number episode from 10: 146 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.8951) 1000
147 1000 -1000.0 -99.99568287525881 number episode from 10: 147 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.9470) 1000
148 1000 -1000.0 -99.99568287525881 number episode from 10: 148 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.8947) 1000
149 1000 -1000.0 -99.99568287525881 number episode from 10: 149 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.9424) 1000
150 1000 -1000.0 -99.99568287525881 number episode from 10: 150 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.9454) 1000
151 1000 -1000.0 -99.99568287525881 number episode from 10: 151 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.9470) 1000
152 1000 -1000.0 -99.99568287525881 number episode from 10: 152 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.9459) 1000
153 1000 -1000.0 -99.99568287525881 number episode from 10: 153 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.9459) 1000
154 1000 -1000.0 -99.99568287525881 number episode from 10: 154 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.9439) 1000
155 1000 -1000.0 -99.99568287525881 number episode from 10: 155 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.9473) 1000
156 1000 -1000.0 -99.99568287525881 number episode from 10: 156 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.9461) 1000
157 1000 -1000.0 -99.99568287525881 number episode from 10: 157 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.9466) 1000
158 1000 -1000.0 -99.99568287525881 number episode from 10: 158 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.9431) 1000
159 1000 -1000.0 -99.99568287525881 number episode from 10: 159 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.9446) 1000
160 1000 -1000.0 -99.99568287525881 number episode from 10: 160 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.9020) 1000
161 1000 -1000.0 -99.99568287525881 number episode from 10: 161 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.9012) 1000
162 1000 -1000.0 -99.99568287525881 number episode from 10: 162 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.9006) 1000
163 1000 -1000.0 -99.99568287525881 number episode from 10: 163 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.8963) 1000
164 1000 -1000.0 -99.99568287525881 number episode from 10: 164 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.9439) 1000
165 1000 -1000.0 -99.99568287525881 number episode from 10: 165 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.8980) 1000
166 1000 -1000.0 -99.99568287525881 number episode from 10: 166 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.9086) 1000
167 1000 -1000.0 -99.99568287525881 number episode from 10: 167 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.9472) 1000
168 1000 -1000.0 -99.99568287525881 number episode from 10: 168 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.9003) 1000
169 1000 -1000.0 -99.99568287525881 number episode from 10: 169 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.8955) 1000
170 1000 -1000.0 -99.99568287525881 number episode from 10: 170 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.9018) 1000
171 1000 -1000.0 -99.99568287525881 number episode from 10: 171 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.9088) 1000
172 1000 -1000.0 -99.99568287525881 number episode from 10: 172 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.9051) 1000
173 1000 -1000.0 -99.99568287525881 number episode from 10: 173 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.9442) 1000
174 1000 -1000.0 -99.99568287525881 number episode from 10: 174 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.9413) 1000
175 1000 -1000.0 -99.99568287525881 number episode from 10: 175 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.9418) 1000
176 1000 -1000.0 -99.99568287525881 number episode from 10: 176 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.9443) 1000
177 1000 -1000.0 -99.99568287525881 number episode from 10: 177 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.9030) 1000
178 1000 -1000.0 -99.99568287525881 number episode from 10: 178 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.9478) 1000
179 1000 -1000.0 -99.99568287525881 number episode from 10: 179 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.8965) 1000
180 1000 -1000.0 -99.99568287525881 number episode from 10: 180 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.8984) 1000
181 1000 -1000.0 -99.99568287525881 number episode from 10: 181 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.9456) 1000
182 1000 -1000.0 -99.99568287525881 number episode from 10: 182 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.9468) 1000
183 1000 -1000.0 -99.99568287525881 number episode from 10: 183 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.8948) 1000
184 1000 -1000.0 -99.99568287525881 number episode from 10: 184 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.9447) 1000
185 1000 -1000.0 -99.99568287525881 number episode from 10: 185 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.9475) 1000
186 1000 -1000.0 -99.99568287525881 number episode from 10: 186 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.8956) 1000
187 1000 -1000.0 -99.99568287525881 number episode from 10: 187 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.9472) 1000
188 1000 -1000.0 -99.99568287525881 number episode from 10: 188 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.9457) 1000
189 1000 -1000.0 -99.99568287525881 number episode from 10: 189 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.9304) 1000
190 1000 -1000.0 -99.99568287525881 number episode from 10: 190 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.8962) 1000
191 1000 -1000.0 -99.99568287525881 number episode from 10: 191 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.8980) 1000
192 1000 -1000.0 -99.99568287525881 number episode from 10: 192 avegar over 10 episode: -99.991 avegare return across last 100 episodes: -99.996 state values: tensor(0.8978) 1000
193 1000 -1000.0 -99.99568287525881 number episode from 10: 193 avegar over 10 episode: -99.991 avegare return across last 100 episodes: -99.996 state values: tensor(0.8947) 1000
194 1000 -1000.0 -99.99568287525881 number episode from 10: 194 avegar over 10 episode: -99.991 avegare return across last 100 episodes: -99.996 state values: tensor(0.9463) 1000
195 1000 -1000.0 -99.99568287525881 number episode from 10: 195 avegar over 10 episode: -99.991 avegare return across last 100 episodes: -99.996 state values: tensor(0.9351) 1000
196 1000 -1000.0 -99.99568287525881 number episode from 10: 196 avegar over 10 episode: -99.991 avegare return across last 100 episodes: -99.996 state values: tensor(0.9394) 1000
197 1000 -1000.0 -99.99568287525881 number episode from 10: 197 avegar over 10 episode: -99.991 avegare return across last 100 episodes: -99.996 state values: tensor(0.9455) 1000
198 1000 -1000.0 -99.99568287525881 number episode from 10: 198 avegar over 10 episode: -99.991 avegare return across last 100 episodes: -99.996 state values: tensor(0.9470) 1000
199 1000 -1000.0 -99.99568287525881 number episode from 10: 199 avegar over 10 episode: -99.991 avegare return across last 100 episodes: -99.996 state values: tensor(0.9448) 1000
200 1000 -1000.0 -99.99568287525881 number episode from 10: 200 avegar over 10 episode: -99.991 avegare return across last 100 episodes: -99.996 state values: tensor(0.9457) 1000
load offline data!!!!!
mem_cntr: 50000 ; mem_size: 50000
nn.learn_nn_feature_fqi FQI:  998
nn.learn_nn_feature_fqi FQI:  1998
nn.learn_nn_feature_fqi FQI:  2998
nn.learn_nn_feature_fqi FQI:  3998
nn.learn_nn_feature_fqi FQI:  4998
nn.learn_nn_feature_fqi FQI:  5998
nn.learn_nn_feature_fqi FQI:  6998
nn.learn_nn_feature_fqi FQI:  7998
nn.learn_nn_feature_fqi FQI:  8998
nn.learn_nn_feature_fqi FQI:  9998
nn.learn_nn_feature_fqi FQI:  10998
nn.learn_nn_feature_fqi FQI:  11998
nn.learn_nn_feature_fqi FQI:  12998
nn.learn_nn_feature_fqi FQI:  13998
nn.learn_nn_feature_fqi FQI:  14998
nn.learn_nn_feature_fqi FQI:  15998
nn.learn_nn_feature_fqi FQI:  16998
nn.learn_nn_feature_fqi FQI:  17998
nn.learn_nn_feature_fqi FQI:  18998
nn.learn_nn_feature_fqi FQI:  19998
nn.learn_nn_feature_fqi FQI:  20998
nn.learn_nn_feature_fqi FQI:  21998
nn.learn_nn_feature_fqi FQI:  22998
nn.learn_nn_feature_fqi FQI:  23998
nn.learn_nn_feature_fqi FQI:  24998
nn.learn_nn_feature_fqi FQI:  25998
nn.learn_nn_feature_fqi FQI:  26998
nn.learn_nn_feature_fqi FQI:  27998
nn.learn_nn_feature_fqi FQI:  28998
nn.learn_nn_feature_fqi FQI:  29998
nn.learn_nn_feature_fqi FQI:  30998
nn.learn_nn_feature_fqi FQI:  31998
nn.learn_nn_feature_fqi FQI:  32998
nn.learn_nn_feature_fqi FQI:  33998
nn.learn_nn_feature_fqi FQI:  34998
nn.learn_nn_feature_fqi FQI:  35998
nn.learn_nn_feature_fqi FQI:  36998
nn.learn_nn_feature_fqi FQI:  37998
nn.learn_nn_feature_fqi FQI:  38998
nn.learn_nn_feature_fqi FQI:  39998
nn.learn_nn_feature_fqi FQI:  40998
nn.learn_nn_feature_fqi FQI:  41998
nn.learn_nn_feature_fqi FQI:  42998
nn.learn_nn_feature_fqi FQI:  43998
nn.learn_nn_feature_fqi FQI:  44998
nn.learn_nn_feature_fqi FQI:  45998
nn.learn_nn_feature_fqi FQI:  46998
nn.learn_nn_feature_fqi FQI:  47998
nn.learn_nn_feature_fqi FQI:  48998
nn.learn_nn_feature_fqi FQI:  49998
nn.learn_nn_feature_fqi FQI:  50998
nn.learn_nn_feature_fqi FQI:  51998
nn.learn_nn_feature_fqi FQI:  52998
nn.learn_nn_feature_fqi FQI:  53998
nn.learn_nn_feature_fqi FQI:  54998
nn.learn_nn_feature_fqi FQI:  55998
nn.learn_nn_feature_fqi FQI:  56998
nn.learn_nn_feature_fqi FQI:  57998
nn.learn_nn_feature_fqi FQI:  58998
nn.learn_nn_feature_fqi FQI:  59998
nn.learn_nn_feature_fqi FQI:  60998
nn.learn_nn_feature_fqi FQI:  61998
nn.learn_nn_feature_fqi FQI:  62998
nn.learn_nn_feature_fqi FQI:  63998
nn.learn_nn_feature_fqi FQI:  64998
nn.learn_nn_feature_fqi FQI:  65998
nn.learn_nn_feature_fqi FQI:  66998
nn.learn_nn_feature_fqi FQI:  67998
nn.learn_nn_feature_fqi FQI:  68998
nn.learn_nn_feature_fqi FQI:  69998
nn.learn_nn_feature_fqi FQI:  70998
nn.learn_nn_feature_fqi FQI:  71998
nn.learn_nn_feature_fqi FQI:  72998
nn.learn_nn_feature_fqi FQI:  73998
nn.learn_nn_feature_fqi FQI:  74998
nn.learn_nn_feature_fqi FQI:  75998
nn.learn_nn_feature_fqi FQI:  76998
nn.learn_nn_feature_fqi FQI:  77998
nn.learn_nn_feature_fqi FQI:  78998
nn.learn_nn_feature_fqi FQI:  79998
nn.learn_nn_feature_fqi FQI:  80998
nn.learn_nn_feature_fqi FQI:  81998
nn.learn_nn_feature_fqi FQI:  82998
nn.learn_nn_feature_fqi FQI:  83998
nn.learn_nn_feature_fqi FQI:  84998
nn.learn_nn_feature_fqi FQI:  85998
nn.learn_nn_feature_fqi FQI:  86998
nn.learn_nn_feature_fqi FQI:  87998
nn.learn_nn_feature_fqi FQI:  88998
nn.learn_nn_feature_fqi FQI:  89998
nn.learn_nn_feature_fqi FQI:  90998
nn.learn_nn_feature_fqi FQI:  91998
nn.learn_nn_feature_fqi FQI:  92998
nn.learn_nn_feature_fqi FQI:  93998
nn.learn_nn_feature_fqi FQI:  94998
nn.learn_nn_feature_fqi FQI:  95998
nn.learn_nn_feature_fqi FQI:  96998
nn.learn_nn_feature_fqi FQI:  97998
nn.learn_nn_feature_fqi FQI:  98998
nn.learn_nn_feature_fqi FQI:  99998
nn.learn_nn_feature_fqi FQI:  100998
nn.learn_nn_feature_fqi FQI:  101998
nn.learn_nn_feature_fqi FQI:  102998
nn.learn_nn_feature_fqi FQI:  103998
nn.learn_nn_feature_fqi FQI:  104998
nn.learn_nn_feature_fqi FQI:  105998
nn.learn_nn_feature_fqi FQI:  106998
nn.learn_nn_feature_fqi FQI:  107998
nn.learn_nn_feature_fqi FQI:  108998
nn.learn_nn_feature_fqi FQI:  109998
nn.learn_nn_feature_fqi FQI:  110998
nn.learn_nn_feature_fqi FQI:  111998
nn.learn_nn_feature_fqi FQI:  112998
nn.learn_nn_feature_fqi FQI:  113998
nn.learn_nn_feature_fqi FQI:  114998
nn.learn_nn_feature_fqi FQI:  115998
nn.learn_nn_feature_fqi FQI:  116998
nn.learn_nn_feature_fqi FQI:  117998
nn.learn_nn_feature_fqi FQI:  118998
nn.learn_nn_feature_fqi FQI:  119998
nn.learn_nn_feature_fqi FQI:  120998
nn.learn_nn_feature_fqi FQI:  121998
nn.learn_nn_feature_fqi FQI:  122998
nn.learn_nn_feature_fqi FQI:  123998
nn.learn_nn_feature_fqi FQI:  124998
nn.learn_nn_feature_fqi FQI:  125998
nn.learn_nn_feature_fqi FQI:  126998
nn.learn_nn_feature_fqi FQI:  127998
nn.learn_nn_feature_fqi FQI:  128998
nn.learn_nn_feature_fqi FQI:  129998
nn.learn_nn_feature_fqi FQI:  130998
nn.learn_nn_feature_fqi FQI:  131998
nn.learn_nn_feature_fqi FQI:  132998
nn.learn_nn_feature_fqi FQI:  133998
nn.learn_nn_feature_fqi FQI:  134998
nn.learn_nn_feature_fqi FQI:  135998
nn.learn_nn_feature_fqi FQI:  136998
nn.learn_nn_feature_fqi FQI:  137998
nn.learn_nn_feature_fqi FQI:  138998
nn.learn_nn_feature_fqi FQI:  139998
nn.learn_nn_feature_fqi FQI:  140998
nn.learn_nn_feature_fqi FQI:  141998
nn.learn_nn_feature_fqi FQI:  142998
nn.learn_nn_feature_fqi FQI:  143998
nn.learn_nn_feature_fqi FQI:  144998
nn.learn_nn_feature_fqi FQI:  145998
nn.learn_nn_feature_fqi FQI:  146998
nn.learn_nn_feature_fqi FQI:  147998
nn.learn_nn_feature_fqi FQI:  148998
nn.learn_nn_feature_fqi FQI:  149998
nn.learn_nn_feature_fqi FQI:  150998
nn.learn_nn_feature_fqi FQI:  151998
nn.learn_nn_feature_fqi FQI:  152998
nn.learn_nn_feature_fqi FQI:  153998
nn.learn_nn_feature_fqi FQI:  154998
nn.learn_nn_feature_fqi FQI:  155998
0 1001 -1000.0 -98.99572604650622 number episode from 10: 0 avegar over 10 episode: -98.996 avegare return across last 100 episodes: -98.996 state values: tensor(0.8939) 1000
1 1000 -1000.0 -99.99568287525881 number episode from 10: 1 avegar over 10 episode: -99.496 avegare return across last 100 episodes: -99.496 state values: tensor(0.8938) 1000
2 1000 -1000.0 -99.99568287525881 number episode from 10: 2 avegar over 10 episode: -99.662 avegare return across last 100 episodes: -99.662 state values: tensor(0.8939) 1000
3 1000 -1000.0 -99.99568287525881 number episode from 10: 3 avegar over 10 episode: -99.746 avegare return across last 100 episodes: -99.746 state values: tensor(0.8940) 1000
4 1000 -1000.0 -99.99568287525881 number episode from 10: 4 avegar over 10 episode: -99.796 avegare return across last 100 episodes: -99.796 state values: tensor(0.8938) 1000
5 1000 -1000.0 -99.99568287525881 number episode from 10: 5 avegar over 10 episode: -99.829 avegare return across last 100 episodes: -99.829 state values: tensor(0.8939) 1000
6 1000 -1000.0 -99.99568287525881 number episode from 10: 6 avegar over 10 episode: -99.853 avegare return across last 100 episodes: -99.853 state values: tensor(0.8941) 1000
7 1000 -1000.0 -99.99568287525881 number episode from 10: 7 avegar over 10 episode: -99.871 avegare return across last 100 episodes: -99.871 state values: tensor(0.8939) 1000
8 1000 -1000.0 -99.99568287525881 number episode from 10: 8 avegar over 10 episode: -99.885 avegare return across last 100 episodes: -99.885 state values: tensor(0.8940) 1000
9 1000 -1000.0 -99.99568287525881 number episode from 10: 9 avegar over 10 episode: -99.896 avegare return across last 100 episodes: -99.896 state values: tensor(0.8939) 1000
10 1000 -1000.0 -99.99568287525881 number episode from 10: 10 avegar over 10 episode: -99.905 avegare return across last 100 episodes: -99.905 state values: tensor(0.8939) 1000
11 1000 -1000.0 -99.99568287525881 number episode from 10: 11 avegar over 10 episode: -99.912 avegare return across last 100 episodes: -99.912 state values: tensor(0.8909) 1000
12 1000 -1000.0 -99.99568287525881 number episode from 10: 12 avegar over 10 episode: -99.919 avegare return across last 100 episodes: -99.919 state values: tensor(0.8943) 1000
13 1000 -1000.0 -99.99568287525881 number episode from 10: 13 avegar over 10 episode: -99.924 avegare return across last 100 episodes: -99.924 state values: tensor(0.8940) 1000
14 1000 -1000.0 -99.99568287525881 number episode from 10: 14 avegar over 10 episode: -99.929 avegare return across last 100 episodes: -99.929 state values: tensor(0.8929) 1000
15 1000 -1000.0 -99.99568287525881 number episode from 10: 15 avegar over 10 episode: -99.933 avegare return across last 100 episodes: -99.933 state values: tensor(0.8940) 1000
16 1000 -1000.0 -99.99568287525881 number episode from 10: 16 avegar over 10 episode: -99.937 avegare return across last 100 episodes: -99.937 state values: tensor(0.8939) 1000
17 1000 -1000.0 -99.99568287525881 number episode from 10: 17 avegar over 10 episode: -99.94 avegare return across last 100 episodes: -99.94 state values: tensor(0.8939) 1000
18 1000 -1000.0 -99.99568287525881 number episode from 10: 18 avegar over 10 episode: -99.943 avegare return across last 100 episodes: -99.943 state values: tensor(0.8940) 1000
19 1000 -1000.0 -99.99568287525881 number episode from 10: 19 avegar over 10 episode: -99.946 avegare return across last 100 episodes: -99.946 state values: tensor(0.8940) 1000
20 1000 -1000.0 -99.99568287525881 number episode from 10: 20 avegar over 10 episode: -99.948 avegare return across last 100 episodes: -99.948 state values: tensor(0.8940) 1000
21 1000 -1000.0 -99.99568287525881 number episode from 10: 21 avegar over 10 episode: -99.95 avegare return across last 100 episodes: -99.95 state values: tensor(0.8940) 1000
22 1000 -1000.0 -99.99568287525881 number episode from 10: 22 avegar over 10 episode: -99.952 avegare return across last 100 episodes: -99.952 state values: tensor(0.8924) 1000
23 1000 -1000.0 -99.99568287525881 number episode from 10: 23 avegar over 10 episode: -99.954 avegare return across last 100 episodes: -99.954 state values: tensor(0.8940) 1000
24 1000 -1000.0 -99.99568287525881 number episode from 10: 24 avegar over 10 episode: -99.956 avegare return across last 100 episodes: -99.956 state values: tensor(0.8939) 1000
25 1000 -1000.0 -99.99568287525881 number episode from 10: 25 avegar over 10 episode: -99.957 avegare return across last 100 episodes: -99.957 state values: tensor(0.8943) 1000
26 1000 -1000.0 -99.99568287525881 number episode from 10: 26 avegar over 10 episode: -99.959 avegare return across last 100 episodes: -99.959 state values: tensor(0.8940) 1000
27 1000 -1000.0 -99.99568287525881 number episode from 10: 27 avegar over 10 episode: -99.96 avegare return across last 100 episodes: -99.96 state values: tensor(0.8940) 1000
28 1000 -1000.0 -99.99568287525881 number episode from 10: 28 avegar over 10 episode: -99.961 avegare return across last 100 episodes: -99.961 state values: tensor(0.8939) 1000
29 1000 -1000.0 -99.99568287525881 number episode from 10: 29 avegar over 10 episode: -99.962 avegare return across last 100 episodes: -99.962 state values: tensor(0.8919) 1000
30 1000 -1000.0 -99.99568287525881 number episode from 10: 30 avegar over 10 episode: -99.963 avegare return across last 100 episodes: -99.963 state values: tensor(0.8939) 1000
31 1000 -1000.0 -99.99568287525881 number episode from 10: 31 avegar over 10 episode: -99.964 avegare return across last 100 episodes: -99.964 state values: tensor(0.8939) 1000
32 1000 -1000.0 -99.99568287525881 number episode from 10: 32 avegar over 10 episode: -99.965 avegare return across last 100 episodes: -99.965 state values: tensor(0.8880) 1000
33 1000 -1000.0 -99.99568287525881 number episode from 10: 33 avegar over 10 episode: -99.966 avegare return across last 100 episodes: -99.966 state values: tensor(0.8942) 1000
34 1000 -1000.0 -99.99568287525881 number episode from 10: 34 avegar over 10 episode: -99.967 avegare return across last 100 episodes: -99.967 state values: tensor(0.8941) 1000
35 1000 -1000.0 -99.99568287525881 number episode from 10: 35 avegar over 10 episode: -99.968 avegare return across last 100 episodes: -99.968 state values: tensor(0.8938) 1000
36 1000 -1000.0 -99.99568287525881 number episode from 10: 36 avegar over 10 episode: -99.969 avegare return across last 100 episodes: -99.969 state values: tensor(0.8938) 1000
37 1000 -1000.0 -99.99568287525881 number episode from 10: 37 avegar over 10 episode: -99.969 avegare return across last 100 episodes: -99.969 state values: tensor(0.8897) 1000
38 1000 -1000.0 -99.99568287525881 number episode from 10: 38 avegar over 10 episode: -99.97 avegare return across last 100 episodes: -99.97 state values: tensor(0.8942) 1000
39 1000 -1000.0 -99.99568287525881 number episode from 10: 39 avegar over 10 episode: -99.971 avegare return across last 100 episodes: -99.971 state values: tensor(0.8944) 1000
40 1000 -1000.0 -99.99568287525881 number episode from 10: 40 avegar over 10 episode: -99.971 avegare return across last 100 episodes: -99.971 state values: tensor(0.8939) 1000
41 1000 -1000.0 -99.99568287525881 number episode from 10: 41 avegar over 10 episode: -99.972 avegare return across last 100 episodes: -99.972 state values: tensor(0.8940) 1000
42 1000 -1000.0 -99.99568287525881 number episode from 10: 42 avegar over 10 episode: -99.972 avegare return across last 100 episodes: -99.972 state values: tensor(0.8940) 1000
43 1000 -1000.0 -99.99568287525881 number episode from 10: 43 avegar over 10 episode: -99.973 avegare return across last 100 episodes: -99.973 state values: tensor(0.8943) 1000
44 1000 -1000.0 -99.99568287525881 number episode from 10: 44 avegar over 10 episode: -99.973 avegare return across last 100 episodes: -99.973 state values: tensor(0.8938) 1000
45 1000 -1000.0 -99.99568287525881 number episode from 10: 45 avegar over 10 episode: -99.974 avegare return across last 100 episodes: -99.974 state values: tensor(0.8929) 1000
46 1000 -1000.0 -99.99568287525881 number episode from 10: 46 avegar over 10 episode: -99.974 avegare return across last 100 episodes: -99.974 state values: tensor(0.8940) 1000
47 1000 -1000.0 -99.99568287525881 number episode from 10: 47 avegar over 10 episode: -99.975 avegare return across last 100 episodes: -99.975 state values: tensor(0.8939) 1000
48 1000 -1000.0 -99.99568287525881 number episode from 10: 48 avegar over 10 episode: -99.975 avegare return across last 100 episodes: -99.975 state values: tensor(0.8939) 1000
49 1000 -1000.0 -99.99568287525881 number episode from 10: 49 avegar over 10 episode: -99.976 avegare return across last 100 episodes: -99.976 state values: tensor(0.8939) 1000
50 1000 -1000.0 -99.99568287525881 number episode from 10: 50 avegar over 10 episode: -99.976 avegare return across last 100 episodes: -99.976 state values: tensor(0.8942) 1000
51 1000 -1000.0 -99.99568287525881 number episode from 10: 51 avegar over 10 episode: -99.976 avegare return across last 100 episodes: -99.976 state values: tensor(0.8939) 1000
52 1000 -1000.0 -99.99568287525881 number episode from 10: 52 avegar over 10 episode: -99.977 avegare return across last 100 episodes: -99.977 state values: tensor(0.8929) 1000
53 1000 -1000.0 -99.99568287525881 number episode from 10: 53 avegar over 10 episode: -99.977 avegare return across last 100 episodes: -99.977 state values: tensor(0.8918) 1000
54 1000 -1000.0 -99.99568287525881 number episode from 10: 54 avegar over 10 episode: -99.978 avegare return across last 100 episodes: -99.978 state values: tensor(0.8925) 1000
55 1000 -1000.0 -99.99568287525881 number episode from 10: 55 avegar over 10 episode: -99.978 avegare return across last 100 episodes: -99.978 state values: tensor(0.8941) 1000
56 1000 -1000.0 -99.99568287525881 number episode from 10: 56 avegar over 10 episode: -99.978 avegare return across last 100 episodes: -99.978 state values: tensor(0.8928) 1000
57 1000 -1000.0 -99.99568287525881 number episode from 10: 57 avegar over 10 episode: -99.978 avegare return across last 100 episodes: -99.978 state values: tensor(0.8931) 1000
58 1000 -1000.0 -99.99568287525881 number episode from 10: 58 avegar over 10 episode: -99.979 avegare return across last 100 episodes: -99.979 state values: tensor(0.8940) 1000
59 1000 -1000.0 -99.99568287525881 number episode from 10: 59 avegar over 10 episode: -99.979 avegare return across last 100 episodes: -99.979 state values: tensor(0.8939) 1000
60 1000 -1000.0 -99.99568287525881 number episode from 10: 60 avegar over 10 episode: -99.979 avegare return across last 100 episodes: -99.979 state values: tensor(0.8941) 1000
61 1000 -1000.0 -99.99568287525881 number episode from 10: 61 avegar over 10 episode: -99.98 avegare return across last 100 episodes: -99.98 state values: tensor(0.8939) 1000
62 1000 -1000.0 -99.99568287525881 number episode from 10: 62 avegar over 10 episode: -99.98 avegare return across last 100 episodes: -99.98 state values: tensor(0.8908) 1000
63 1000 -1000.0 -99.99568287525881 number episode from 10: 63 avegar over 10 episode: -99.98 avegare return across last 100 episodes: -99.98 state values: tensor(0.8939) 1000
64 1000 -1000.0 -99.99568287525881 number episode from 10: 64 avegar over 10 episode: -99.98 avegare return across last 100 episodes: -99.98 state values: tensor(0.8929) 1000
65 1000 -1000.0 -99.99568287525881 number episode from 10: 65 avegar over 10 episode: -99.981 avegare return across last 100 episodes: -99.981 state values: tensor(0.8941) 1000
66 1000 -1000.0 -99.99568287525881 number episode from 10: 66 avegar over 10 episode: -99.981 avegare return across last 100 episodes: -99.981 state values: tensor(0.8939) 1000
67 1000 -1000.0 -99.99568287525881 number episode from 10: 67 avegar over 10 episode: -99.981 avegare return across last 100 episodes: -99.981 state values: tensor(0.8940) 1000
68 1000 -1000.0 -99.99568287525881 number episode from 10: 68 avegar over 10 episode: -99.981 avegare return across last 100 episodes: -99.981 state values: tensor(0.8915) 1000
69 1000 -1000.0 -99.99568287525881 number episode from 10: 69 avegar over 10 episode: -99.981 avegare return across last 100 episodes: -99.981 state values: tensor(0.8939) 1000
70 1000 -1000.0 -99.99568287525881 number episode from 10: 70 avegar over 10 episode: -99.982 avegare return across last 100 episodes: -99.982 state values: tensor(0.8940) 1000
71 1000 -1000.0 -99.99568287525881 number episode from 10: 71 avegar over 10 episode: -99.982 avegare return across last 100 episodes: -99.982 state values: tensor(0.8940) 1000
72 1000 -1000.0 -99.99568287525881 number episode from 10: 72 avegar over 10 episode: -99.982 avegare return across last 100 episodes: -99.982 state values: tensor(0.8941) 1000
73 1000 -1000.0 -99.99568287525881 number episode from 10: 73 avegar over 10 episode: -99.982 avegare return across last 100 episodes: -99.982 state values: tensor(0.8941) 1000
74 1000 -1000.0 -99.99568287525881 number episode from 10: 74 avegar over 10 episode: -99.982 avegare return across last 100 episodes: -99.982 state values: tensor(0.8941) 1000
75 1000 -1000.0 -99.99568287525881 number episode from 10: 75 avegar over 10 episode: -99.983 avegare return across last 100 episodes: -99.983 state values: tensor(0.8941) 1000
76 1000 -1000.0 -99.99568287525881 number episode from 10: 76 avegar over 10 episode: -99.983 avegare return across last 100 episodes: -99.983 state values: tensor(0.8934) 1000
77 1000 -1000.0 -99.99568287525881 number episode from 10: 77 avegar over 10 episode: -99.983 avegare return across last 100 episodes: -99.983 state values: tensor(0.8941) 1000
78 1000 -1000.0 -99.99568287525881 number episode from 10: 78 avegar over 10 episode: -99.983 avegare return across last 100 episodes: -99.983 state values: tensor(0.8941) 1000
79 1000 -1000.0 -99.99568287525881 number episode from 10: 79 avegar over 10 episode: -99.983 avegare return across last 100 episodes: -99.983 state values: tensor(0.8940) 1000
80 1000 -1000.0 -99.99568287525881 number episode from 10: 80 avegar over 10 episode: -99.983 avegare return across last 100 episodes: -99.983 state values: tensor(0.8940) 1000
81 1000 -1000.0 -99.99568287525881 number episode from 10: 81 avegar over 10 episode: -99.983 avegare return across last 100 episodes: -99.983 state values: tensor(0.8939) 1000
82 1000 -1000.0 -99.99568287525881 number episode from 10: 82 avegar over 10 episode: -99.984 avegare return across last 100 episodes: -99.984 state values: tensor(0.8941) 1000
83 1000 -1000.0 -99.99568287525881 number episode from 10: 83 avegar over 10 episode: -99.984 avegare return across last 100 episodes: -99.984 state values: tensor(0.8930) 1000
84 1000 -1000.0 -99.99568287525881 number episode from 10: 84 avegar over 10 episode: -99.984 avegare return across last 100 episodes: -99.984 state values: tensor(0.8942) 1000
85 1000 -1000.0 -99.99568287525881 number episode from 10: 85 avegar over 10 episode: -99.984 avegare return across last 100 episodes: -99.984 state values: tensor(0.8931) 1000
86 1000 -1000.0 -99.99568287525881 number episode from 10: 86 avegar over 10 episode: -99.984 avegare return across last 100 episodes: -99.984 state values: tensor(0.8939) 1000
87 1000 -1000.0 -99.99568287525881 number episode from 10: 87 avegar over 10 episode: -99.984 avegare return across last 100 episodes: -99.984 state values: tensor(0.8941) 1000
88 1000 -1000.0 -99.99568287525881 number episode from 10: 88 avegar over 10 episode: -99.984 avegare return across last 100 episodes: -99.984 state values: tensor(0.8940) 1000
89 1000 -1000.0 -99.99568287525881 number episode from 10: 89 avegar over 10 episode: -99.985 avegare return across last 100 episodes: -99.985 state values: tensor(0.8939) 1000
90 1000 -1000.0 -99.99568287525881 number episode from 10: 90 avegar over 10 episode: -99.985 avegare return across last 100 episodes: -99.985 state values: tensor(0.8940) 1000
91 1000 -1000.0 -99.99568287525881 number episode from 10: 91 avegar over 10 episode: -99.985 avegare return across last 100 episodes: -99.985 state values: tensor(0.8941) 1000
92 1000 -1000.0 -99.99568287525881 number episode from 10: 92 avegar over 10 episode: -99.985 avegare return across last 100 episodes: -99.985 state values: tensor(0.8940) 1000
93 1000 -1000.0 -99.99568287525881 number episode from 10: 93 avegar over 10 episode: -99.985 avegare return across last 100 episodes: -99.985 state values: tensor(0.8940) 1000
94 1000 -1000.0 -99.99568287525881 number episode from 10: 94 avegar over 10 episode: -99.985 avegare return across last 100 episodes: -99.985 state values: tensor(0.8942) 1000
95 1000 -1000.0 -99.99568287525881 number episode from 10: 95 avegar over 10 episode: -99.985 avegare return across last 100 episodes: -99.985 state values: tensor(0.8939) 1000
96 1000 -1000.0 -99.99568287525881 number episode from 10: 96 avegar over 10 episode: -99.985 avegare return across last 100 episodes: -99.985 state values: tensor(0.8882) 1000
97 1000 -1000.0 -99.99568287525881 number episode from 10: 97 avegar over 10 episode: -99.985 avegare return across last 100 episodes: -99.985 state values: tensor(0.8940) 1000
98 1000 -1000.0 -99.99568287525881 number episode from 10: 98 avegar over 10 episode: -99.986 avegare return across last 100 episodes: -99.986 state values: tensor(0.8941) 1000
99 1000 -1000.0 -99.99568287525881 number episode from 10: 99 avegar over 10 episode: -99.986 avegare return across last 100 episodes: -99.986 state values: tensor(0.8940) 1000
100 1000 -1000.0 -99.99568287525881 number episode from 10: 100 avegar over 10 episode: -99.986 avegare return across last 100 episodes: -99.996 state values: tensor(0.8939) 1000
101 1000 -1000.0 -99.99568287525881 number episode from 10: 101 avegar over 10 episode: -99.986 avegare return across last 100 episodes: -99.996 state values: tensor(0.8940) 1000
102 1000 -1000.0 -99.99568287525881 number episode from 10: 102 avegar over 10 episode: -99.986 avegare return across last 100 episodes: -99.996 state values: tensor(0.8941) 1000
103 1000 -1000.0 -99.99568287525881 number episode from 10: 103 avegar over 10 episode: -99.986 avegare return across last 100 episodes: -99.996 state values: tensor(0.8940) 1000
104 1000 -1000.0 -99.99568287525881 number episode from 10: 104 avegar over 10 episode: -99.986 avegare return across last 100 episodes: -99.996 state values: tensor(0.8941) 1000
105 1000 -1000.0 -99.99568287525881 number episode from 10: 105 avegar over 10 episode: -99.986 avegare return across last 100 episodes: -99.996 state values: tensor(0.8942) 1000
106 1000 -1000.0 -99.99568287525881 number episode from 10: 106 avegar over 10 episode: -99.986 avegare return across last 100 episodes: -99.996 state values: tensor(0.8940) 1000
107 1000 -1000.0 -99.99568287525881 number episode from 10: 107 avegar over 10 episode: -99.986 avegare return across last 100 episodes: -99.996 state values: tensor(0.8941) 1000
108 1000 -1000.0 -99.99568287525881 number episode from 10: 108 avegar over 10 episode: -99.987 avegare return across last 100 episodes: -99.996 state values: tensor(0.8939) 1000
109 1000 -1000.0 -99.99568287525881 number episode from 10: 109 avegar over 10 episode: -99.987 avegare return across last 100 episodes: -99.996 state values: tensor(0.8939) 1000
110 1000 -1000.0 -99.99568287525881 number episode from 10: 110 avegar over 10 episode: -99.987 avegare return across last 100 episodes: -99.996 state values: tensor(0.8929) 1000
111 1000 -1000.0 -99.99568287525881 number episode from 10: 111 avegar over 10 episode: -99.987 avegare return across last 100 episodes: -99.996 state values: tensor(0.8899) 1000
112 1000 -1000.0 -99.99568287525881 number episode from 10: 112 avegar over 10 episode: -99.987 avegare return across last 100 episodes: -99.996 state values: tensor(0.8940) 1000
113 1000 -1000.0 -99.99568287525881 number episode from 10: 113 avegar over 10 episode: -99.987 avegare return across last 100 episodes: -99.996 state values: tensor(0.8941) 1000
114 1000 -1000.0 -99.99568287525881 number episode from 10: 114 avegar over 10 episode: -99.987 avegare return across last 100 episodes: -99.996 state values: tensor(0.8915) 1000
115 1000 -1000.0 -99.99568287525881 number episode from 10: 115 avegar over 10 episode: -99.987 avegare return across last 100 episodes: -99.996 state values: tensor(0.8940) 1000
116 1000 -1000.0 -99.99568287525881 number episode from 10: 116 avegar over 10 episode: -99.987 avegare return across last 100 episodes: -99.996 state values: tensor(0.8904) 1000
117 1000 -1000.0 -99.99568287525881 number episode from 10: 117 avegar over 10 episode: -99.987 avegare return across last 100 episodes: -99.996 state values: tensor(0.8942) 1000
118 1000 -1000.0 -99.99568287525881 number episode from 10: 118 avegar over 10 episode: -99.987 avegare return across last 100 episodes: -99.996 state values: tensor(0.8939) 1000
119 1000 -1000.0 -99.99568287525881 number episode from 10: 119 avegar over 10 episode: -99.987 avegare return across last 100 episodes: -99.996 state values: tensor(0.8939) 1000
120 1000 -1000.0 -99.99568287525881 number episode from 10: 120 avegar over 10 episode: -99.987 avegare return across last 100 episodes: -99.996 state values: tensor(0.8908) 1000
121 1000 -1000.0 -99.99568287525881 number episode from 10: 121 avegar over 10 episode: -99.987 avegare return across last 100 episodes: -99.996 state values: tensor(0.8941) 1000
122 1000 -1000.0 -99.99568287525881 number episode from 10: 122 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.8912) 1000
123 1000 -1000.0 -99.99568287525881 number episode from 10: 123 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.8925) 1000
124 1000 -1000.0 -99.99568287525881 number episode from 10: 124 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.8939) 1000
125 1000 -1000.0 -99.99568287525881 number episode from 10: 125 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.8939) 1000
126 1000 -1000.0 -99.99568287525881 number episode from 10: 126 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.8940) 1000
127 1000 -1000.0 -99.99568287525881 number episode from 10: 127 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.8939) 1000
128 1000 -1000.0 -99.99568287525881 number episode from 10: 128 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.8941) 1000
129 1000 -1000.0 -99.99568287525881 number episode from 10: 129 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.8943) 1000
130 1000 -1000.0 -99.99568287525881 number episode from 10: 130 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.8939) 1000
131 1000 -1000.0 -99.99568287525881 number episode from 10: 131 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.8918) 1000
132 1000 -1000.0 -99.99568287525881 number episode from 10: 132 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.8942) 1000
133 1000 -1000.0 -99.99568287525881 number episode from 10: 133 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.8938) 1000
134 1000 -1000.0 -99.99568287525881 number episode from 10: 134 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.8939) 1000
135 1000 -1000.0 -99.99568287525881 number episode from 10: 135 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.8940) 1000
136 1000 -1000.0 -99.99568287525881 number episode from 10: 136 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.8938) 1000
137 1000 -1000.0 -99.99568287525881 number episode from 10: 137 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.8934) 1000
138 1000 -1000.0 -99.99568287525881 number episode from 10: 138 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.8940) 1000
139 1000 -1000.0 -99.99568287525881 number episode from 10: 139 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.8913) 1000
140 1000 -1000.0 -99.99568287525881 number episode from 10: 140 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.8940) 1000
141 1000 -1000.0 -99.99568287525881 number episode from 10: 141 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.8943) 1000
142 1000 -1000.0 -99.99568287525881 number episode from 10: 142 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.8920) 1000
143 1000 -1000.0 -99.99568287525881 number episode from 10: 143 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.8939) 1000
144 1000 -1000.0 -99.99568287525881 number episode from 10: 144 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.8941) 1000
145 1000 -1000.0 -99.99568287525881 number episode from 10: 145 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.8903) 1000
146 1000 -1000.0 -99.99568287525881 number episode from 10: 146 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.8942) 1000
147 1000 -1000.0 -99.99568287525881 number episode from 10: 147 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.8939) 1000
148 1000 -1000.0 -99.99568287525881 number episode from 10: 148 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.8941) 1000
149 1000 -1000.0 -99.99568287525881 number episode from 10: 149 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.8939) 1000
150 1000 -1000.0 -99.99568287525881 number episode from 10: 150 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.8940) 1000
151 1000 -1000.0 -99.99568287525881 number episode from 10: 151 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.8882) 1000
152 1000 -1000.0 -99.99568287525881 number episode from 10: 152 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.8942) 1000
153 1000 -1000.0 -99.99568287525881 number episode from 10: 153 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.8942) 1000
154 1000 -1000.0 -99.99568287525881 number episode from 10: 154 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.8939) 1000
155 1000 -1000.0 -99.99568287525881 number episode from 10: 155 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.8940) 1000
156 1000 -1000.0 -99.99568287525881 number episode from 10: 156 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.8940) 1000
157 1000 -1000.0 -99.99568287525881 number episode from 10: 157 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.8939) 1000
158 1000 -1000.0 -99.99568287525881 number episode from 10: 158 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.8941) 1000
159 1000 -1000.0 -99.99568287525881 number episode from 10: 159 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.8939) 1000
160 1000 -1000.0 -99.99568287525881 number episode from 10: 160 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.8939) 1000
161 1000 -1000.0 -99.99568287525881 number episode from 10: 161 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.8940) 1000
162 1000 -1000.0 -99.99568287525881 number episode from 10: 162 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.8941) 1000
163 1000 -1000.0 -99.99568287525881 number episode from 10: 163 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.8939) 1000
164 1000 -1000.0 -99.99568287525881 number episode from 10: 164 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.8940) 1000
165 1000 -1000.0 -99.99568287525881 number episode from 10: 165 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.8939) 1000
166 1000 -1000.0 -99.99568287525881 number episode from 10: 166 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.8941) 1000
167 1000 -1000.0 -99.99568287525881 number episode from 10: 167 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.8930) 1000
168 1000 -1000.0 -99.99568287525881 number episode from 10: 168 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.8940) 1000
169 1000 -1000.0 -99.99568287525881 number episode from 10: 169 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.8940) 1000
170 1000 -1000.0 -99.99568287525881 number episode from 10: 170 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.8900) 1000
171 1000 -1000.0 -99.99568287525881 number episode from 10: 171 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.8940) 1000
172 1000 -1000.0 -99.99568287525881 number episode from 10: 172 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.8940) 1000
173 1000 -1000.0 -99.99568287525881 number episode from 10: 173 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.8939) 1000
174 1000 -1000.0 -99.99568287525881 number episode from 10: 174 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.8940) 1000
175 1000 -1000.0 -99.99568287525881 number episode from 10: 175 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.8938) 1000
176 1000 -1000.0 -99.99568287525881 number episode from 10: 176 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.8941) 1000
177 1000 -1000.0 -99.99568287525881 number episode from 10: 177 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.8938) 1000
178 1000 -1000.0 -99.99568287525881 number episode from 10: 178 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.8939) 1000
179 1000 -1000.0 -99.99568287525881 number episode from 10: 179 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.8939) 1000
180 1000 -1000.0 -99.99568287525881 number episode from 10: 180 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.8940) 1000
181 1000 -1000.0 -99.99568287525881 number episode from 10: 181 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.8941) 1000
182 1000 -1000.0 -99.99568287525881 number episode from 10: 182 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.8923) 1000
183 1000 -1000.0 -99.99568287525881 number episode from 10: 183 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.8881) 1000
184 1000 -1000.0 -99.99568287525881 number episode from 10: 184 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.8889) 1000
185 1000 -1000.0 -99.99568287525881 number episode from 10: 185 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.8939) 1000
186 1000 -1000.0 -99.99568287525881 number episode from 10: 186 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.8940) 1000
187 1000 -1000.0 -99.99568287525881 number episode from 10: 187 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.8942) 1000
188 1000 -1000.0 -99.99568287525881 number episode from 10: 188 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.8880) 1000
189 1000 -1000.0 -99.99568287525881 number episode from 10: 189 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.8940) 1000
190 1000 -1000.0 -99.99568287525881 number episode from 10: 190 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.8942) 1000
191 1000 -1000.0 -99.99568287525881 number episode from 10: 191 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.8943) 1000
192 1000 -1000.0 -99.99568287525881 number episode from 10: 192 avegar over 10 episode: -99.991 avegare return across last 100 episodes: -99.996 state values: tensor(0.8881) 1000
193 1000 -1000.0 -99.99568287525881 number episode from 10: 193 avegar over 10 episode: -99.991 avegare return across last 100 episodes: -99.996 state values: tensor(0.8941) 1000
194 1000 -1000.0 -99.99568287525881 number episode from 10: 194 avegar over 10 episode: -99.991 avegare return across last 100 episodes: -99.996 state values: tensor(0.8906) 1000
195 1000 -1000.0 -99.99568287525881 number episode from 10: 195 avegar over 10 episode: -99.991 avegare return across last 100 episodes: -99.996 state values: tensor(0.8941) 1000
196 1000 -1000.0 -99.99568287525881 number episode from 10: 196 avegar over 10 episode: -99.991 avegare return across last 100 episodes: -99.996 state values: tensor(0.8938) 1000
197 1000 -1000.0 -99.99568287525881 number episode from 10: 197 avegar over 10 episode: -99.991 avegare return across last 100 episodes: -99.996 state values: tensor(0.8939) 1000
198 1000 -1000.0 -99.99568287525881 number episode from 10: 198 avegar over 10 episode: -99.991 avegare return across last 100 episodes: -99.996 state values: tensor(0.8944) 1000
199 1000 -1000.0 -99.99568287525881 number episode from 10: 199 avegar over 10 episode: -99.991 avegare return across last 100 episodes: -99.996 state values: tensor(0.8943) 1000
200 1000 -1000.0 -99.99568287525881 number episode from 10: 200 avegar over 10 episode: -99.991 avegare return across last 100 episodes: -99.996 state values: tensor(0.8940) 1000
load offline data!!!!!
mem_cntr: 50000 ; mem_size: 50000
nn.learn_nn_feature_fqi FQI:  998
nn.learn_nn_feature_fqi FQI:  1998
nn.learn_nn_feature_fqi FQI:  2998
nn.learn_nn_feature_fqi FQI:  3998
nn.learn_nn_feature_fqi FQI:  4998
nn.learn_nn_feature_fqi FQI:  5998
nn.learn_nn_feature_fqi FQI:  6998
nn.learn_nn_feature_fqi FQI:  7998
nn.learn_nn_feature_fqi FQI:  8998
nn.learn_nn_feature_fqi FQI:  9998
nn.learn_nn_feature_fqi FQI:  10998
nn.learn_nn_feature_fqi FQI:  11998
nn.learn_nn_feature_fqi FQI:  12998
nn.learn_nn_feature_fqi FQI:  13998
nn.learn_nn_feature_fqi FQI:  14998
nn.learn_nn_feature_fqi FQI:  15998
nn.learn_nn_feature_fqi FQI:  16998
nn.learn_nn_feature_fqi FQI:  17998
nn.learn_nn_feature_fqi FQI:  18998
nn.learn_nn_feature_fqi FQI:  19998
nn.learn_nn_feature_fqi FQI:  20998
nn.learn_nn_feature_fqi FQI:  21998
nn.learn_nn_feature_fqi FQI:  22998
nn.learn_nn_feature_fqi FQI:  23998
nn.learn_nn_feature_fqi FQI:  24998
nn.learn_nn_feature_fqi FQI:  25998
nn.learn_nn_feature_fqi FQI:  26998
nn.learn_nn_feature_fqi FQI:  27998
nn.learn_nn_feature_fqi FQI:  28998
nn.learn_nn_feature_fqi FQI:  29998
nn.learn_nn_feature_fqi FQI:  30998
nn.learn_nn_feature_fqi FQI:  31998
nn.learn_nn_feature_fqi FQI:  32998
nn.learn_nn_feature_fqi FQI:  33998
nn.learn_nn_feature_fqi FQI:  34998
nn.learn_nn_feature_fqi FQI:  35998
nn.learn_nn_feature_fqi FQI:  36998
nn.learn_nn_feature_fqi FQI:  37998
nn.learn_nn_feature_fqi FQI:  38998
nn.learn_nn_feature_fqi FQI:  39998
nn.learn_nn_feature_fqi FQI:  40998
nn.learn_nn_feature_fqi FQI:  41998
nn.learn_nn_feature_fqi FQI:  42998
nn.learn_nn_feature_fqi FQI:  43998
nn.learn_nn_feature_fqi FQI:  44998
nn.learn_nn_feature_fqi FQI:  45998
nn.learn_nn_feature_fqi FQI:  46998
nn.learn_nn_feature_fqi FQI:  47998
nn.learn_nn_feature_fqi FQI:  48998
nn.learn_nn_feature_fqi FQI:  49998
nn.learn_nn_feature_fqi FQI:  50998
nn.learn_nn_feature_fqi FQI:  51998
nn.learn_nn_feature_fqi FQI:  52998
nn.learn_nn_feature_fqi FQI:  53998
nn.learn_nn_feature_fqi FQI:  54998
nn.learn_nn_feature_fqi FQI:  55998
nn.learn_nn_feature_fqi FQI:  56998
nn.learn_nn_feature_fqi FQI:  57998
nn.learn_nn_feature_fqi FQI:  58998
nn.learn_nn_feature_fqi FQI:  59998
nn.learn_nn_feature_fqi FQI:  60998
nn.learn_nn_feature_fqi FQI:  61998
nn.learn_nn_feature_fqi FQI:  62998
nn.learn_nn_feature_fqi FQI:  63998
nn.learn_nn_feature_fqi FQI:  64998
nn.learn_nn_feature_fqi FQI:  65998
nn.learn_nn_feature_fqi FQI:  66998
nn.learn_nn_feature_fqi FQI:  67998
nn.learn_nn_feature_fqi FQI:  68998
nn.learn_nn_feature_fqi FQI:  69998
nn.learn_nn_feature_fqi FQI:  70998
nn.learn_nn_feature_fqi FQI:  71998
nn.learn_nn_feature_fqi FQI:  72998
nn.learn_nn_feature_fqi FQI:  73998
nn.learn_nn_feature_fqi FQI:  74998
nn.learn_nn_feature_fqi FQI:  75998
nn.learn_nn_feature_fqi FQI:  76998
nn.learn_nn_feature_fqi FQI:  77998
nn.learn_nn_feature_fqi FQI:  78998
nn.learn_nn_feature_fqi FQI:  79998
nn.learn_nn_feature_fqi FQI:  80998
nn.learn_nn_feature_fqi FQI:  81998
nn.learn_nn_feature_fqi FQI:  82998
nn.learn_nn_feature_fqi FQI:  83998
nn.learn_nn_feature_fqi FQI:  84998
nn.learn_nn_feature_fqi FQI:  85998
nn.learn_nn_feature_fqi FQI:  86998
nn.learn_nn_feature_fqi FQI:  87998
nn.learn_nn_feature_fqi FQI:  88998
nn.learn_nn_feature_fqi FQI:  89998
nn.learn_nn_feature_fqi FQI:  90998
nn.learn_nn_feature_fqi FQI:  91998
nn.learn_nn_feature_fqi FQI:  92998
nn.learn_nn_feature_fqi FQI:  93998
nn.learn_nn_feature_fqi FQI:  94998
nn.learn_nn_feature_fqi FQI:  95998
nn.learn_nn_feature_fqi FQI:  96998
nn.learn_nn_feature_fqi FQI:  97998
nn.learn_nn_feature_fqi FQI:  98998
nn.learn_nn_feature_fqi FQI:  99998
nn.learn_nn_feature_fqi FQI:  100998
nn.learn_nn_feature_fqi FQI:  101998
nn.learn_nn_feature_fqi FQI:  102998
nn.learn_nn_feature_fqi FQI:  103998
nn.learn_nn_feature_fqi FQI:  104998
nn.learn_nn_feature_fqi FQI:  105998
nn.learn_nn_feature_fqi FQI:  106998
nn.learn_nn_feature_fqi FQI:  107998
nn.learn_nn_feature_fqi FQI:  108998
nn.learn_nn_feature_fqi FQI:  109998
nn.learn_nn_feature_fqi FQI:  110998
nn.learn_nn_feature_fqi FQI:  111998
nn.learn_nn_feature_fqi FQI:  112998
nn.learn_nn_feature_fqi FQI:  113998
nn.learn_nn_feature_fqi FQI:  114998
nn.learn_nn_feature_fqi FQI:  115998
nn.learn_nn_feature_fqi FQI:  116998
nn.learn_nn_feature_fqi FQI:  117998
nn.learn_nn_feature_fqi FQI:  118998
nn.learn_nn_feature_fqi FQI:  119998
nn.learn_nn_feature_fqi FQI:  120998
nn.learn_nn_feature_fqi FQI:  121998
nn.learn_nn_feature_fqi FQI:  122998
nn.learn_nn_feature_fqi FQI:  123998
nn.learn_nn_feature_fqi FQI:  124998
nn.learn_nn_feature_fqi FQI:  125998
nn.learn_nn_feature_fqi FQI:  126998
nn.learn_nn_feature_fqi FQI:  127998
nn.learn_nn_feature_fqi FQI:  128998
nn.learn_nn_feature_fqi FQI:  129998
nn.learn_nn_feature_fqi FQI:  130998
nn.learn_nn_feature_fqi FQI:  131998
nn.learn_nn_feature_fqi FQI:  132998
nn.learn_nn_feature_fqi FQI:  133998
nn.learn_nn_feature_fqi FQI:  134998
nn.learn_nn_feature_fqi FQI:  135998
nn.learn_nn_feature_fqi FQI:  136998
nn.learn_nn_feature_fqi FQI:  137998
nn.learn_nn_feature_fqi FQI:  138998
nn.learn_nn_feature_fqi FQI:  139998
nn.learn_nn_feature_fqi FQI:  140998
nn.learn_nn_feature_fqi FQI:  141998
nn.learn_nn_feature_fqi FQI:  142998
nn.learn_nn_feature_fqi FQI:  143998
nn.learn_nn_feature_fqi FQI:  144998
nn.learn_nn_feature_fqi FQI:  145998
nn.learn_nn_feature_fqi FQI:  146998
nn.learn_nn_feature_fqi FQI:  147998
nn.learn_nn_feature_fqi FQI:  148998
nn.learn_nn_feature_fqi FQI:  149998
nn.learn_nn_feature_fqi FQI:  150998
nn.learn_nn_feature_fqi FQI:  151998
nn.learn_nn_feature_fqi FQI:  152998
nn.learn_nn_feature_fqi FQI:  153998
nn.learn_nn_feature_fqi FQI:  154998
nn.learn_nn_feature_fqi FQI:  155998
0 1001 -1000.0 -98.99572604650622 number episode from 10: 0 avegar over 10 episode: -98.996 avegare return across last 100 episodes: -98.996 state values: tensor(0.6733) 1000
1 1000 -1000.0 -99.99568287525881 number episode from 10: 1 avegar over 10 episode: -99.496 avegare return across last 100 episodes: -99.496 state values: tensor(0.6755) 1000
2 1000 -1000.0 -99.99568287525881 number episode from 10: 2 avegar over 10 episode: -99.662 avegare return across last 100 episodes: -99.662 state values: tensor(0.6803) 1000
3 1000 -1000.0 -99.99568287525881 number episode from 10: 3 avegar over 10 episode: -99.746 avegare return across last 100 episodes: -99.746 state values: tensor(0.6787) 1000
4 1000 -1000.0 -99.99568287525881 number episode from 10: 4 avegar over 10 episode: -99.796 avegare return across last 100 episodes: -99.796 state values: tensor(0.6735) 1000
5 1000 -1000.0 -99.99568287525881 number episode from 10: 5 avegar over 10 episode: -99.829 avegare return across last 100 episodes: -99.829 state values: tensor(0.6732) 1000
6 1000 -1000.0 -99.99568287525881 number episode from 10: 6 avegar over 10 episode: -99.853 avegare return across last 100 episodes: -99.853 state values: tensor(0.6742) 1000
7 1000 -1000.0 -99.99568287525881 number episode from 10: 7 avegar over 10 episode: -99.871 avegare return across last 100 episodes: -99.871 state values: tensor(0.6797) 1000
8 1000 -1000.0 -99.99568287525881 number episode from 10: 8 avegar over 10 episode: -99.885 avegare return across last 100 episodes: -99.885 state values: tensor(0.6742) 1000
9 1000 -1000.0 -99.99568287525881 number episode from 10: 9 avegar over 10 episode: -99.896 avegare return across last 100 episodes: -99.896 state values: tensor(0.6747) 1000
10 1000 -1000.0 -99.99568287525881 number episode from 10: 10 avegar over 10 episode: -99.905 avegare return across last 100 episodes: -99.905 state values: tensor(0.6734) 1000
11 1000 -1000.0 -99.99568287525881 number episode from 10: 11 avegar over 10 episode: -99.912 avegare return across last 100 episodes: -99.912 state values: tensor(0.6762) 1000
12 1000 -1000.0 -99.99568287525881 number episode from 10: 12 avegar over 10 episode: -99.919 avegare return across last 100 episodes: -99.919 state values: tensor(0.6745) 1000
13 1000 -1000.0 -99.99568287525881 number episode from 10: 13 avegar over 10 episode: -99.924 avegare return across last 100 episodes: -99.924 state values: tensor(0.6764) 1000
14 1000 -1000.0 -99.99568287525881 number episode from 10: 14 avegar over 10 episode: -99.929 avegare return across last 100 episodes: -99.929 state values: tensor(0.6751) 1000
15 1000 -1000.0 -99.99568287525881 number episode from 10: 15 avegar over 10 episode: -99.933 avegare return across last 100 episodes: -99.933 state values: tensor(0.6756) 1000
16 1000 -1000.0 -99.99568287525881 number episode from 10: 16 avegar over 10 episode: -99.937 avegare return across last 100 episodes: -99.937 state values: tensor(0.6768) 1000
17 1000 -1000.0 -99.99568287525881 number episode from 10: 17 avegar over 10 episode: -99.94 avegare return across last 100 episodes: -99.94 state values: tensor(0.6742) 1000
18 1000 -1000.0 -99.99568287525881 number episode from 10: 18 avegar over 10 episode: -99.943 avegare return across last 100 episodes: -99.943 state values: tensor(0.6803) 1000
19 1000 -1000.0 -99.99568287525881 number episode from 10: 19 avegar over 10 episode: -99.946 avegare return across last 100 episodes: -99.946 state values: tensor(0.6807) 1000
20 1000 -1000.0 -99.99568287525881 number episode from 10: 20 avegar over 10 episode: -99.948 avegare return across last 100 episodes: -99.948 state values: tensor(0.6765) 1000
21 1000 -1000.0 -99.99568287525881 number episode from 10: 21 avegar over 10 episode: -99.95 avegare return across last 100 episodes: -99.95 state values: tensor(0.6737) 1000
22 1000 -1000.0 -99.99568287525881 number episode from 10: 22 avegar over 10 episode: -99.952 avegare return across last 100 episodes: -99.952 state values: tensor(0.6737) 1000
23 1000 -1000.0 -99.99568287525881 number episode from 10: 23 avegar over 10 episode: -99.954 avegare return across last 100 episodes: -99.954 state values: tensor(0.6772) 1000
24 1000 -1000.0 -99.99568287525881 number episode from 10: 24 avegar over 10 episode: -99.956 avegare return across last 100 episodes: -99.956 state values: tensor(0.6781) 1000
25 1000 -1000.0 -99.99568287525881 number episode from 10: 25 avegar over 10 episode: -99.957 avegare return across last 100 episodes: -99.957 state values: tensor(0.6782) 1000
26 1000 -1000.0 -99.99568287525881 number episode from 10: 26 avegar over 10 episode: -99.959 avegare return across last 100 episodes: -99.959 state values: tensor(0.6740) 1000
27 1000 -1000.0 -99.99568287525881 number episode from 10: 27 avegar over 10 episode: -99.96 avegare return across last 100 episodes: -99.96 state values: tensor(0.6765) 1000
28 1000 -1000.0 -99.99568287525881 number episode from 10: 28 avegar over 10 episode: -99.961 avegare return across last 100 episodes: -99.961 state values: tensor(0.6746) 1000
29 1000 -1000.0 -99.99568287525881 number episode from 10: 29 avegar over 10 episode: -99.962 avegare return across last 100 episodes: -99.962 state values: tensor(0.6815) 1000
30 1000 -1000.0 -99.99568287525881 number episode from 10: 30 avegar over 10 episode: -99.963 avegare return across last 100 episodes: -99.963 state values: tensor(0.6733) 1000
31 1000 -1000.0 -99.99568287525881 number episode from 10: 31 avegar over 10 episode: -99.964 avegare return across last 100 episodes: -99.964 state values: tensor(0.6787) 1000
32 1000 -1000.0 -99.99568287525881 number episode from 10: 32 avegar over 10 episode: -99.965 avegare return across last 100 episodes: -99.965 state values: tensor(0.6751) 1000
33 1000 -1000.0 -99.99568287525881 number episode from 10: 33 avegar over 10 episode: -99.966 avegare return across last 100 episodes: -99.966 state values: tensor(0.6733) 1000
34 1000 -1000.0 -99.99568287525881 number episode from 10: 34 avegar over 10 episode: -99.967 avegare return across last 100 episodes: -99.967 state values: tensor(0.6736) 1000
35 1000 -1000.0 -99.99568287525881 number episode from 10: 35 avegar over 10 episode: -99.968 avegare return across last 100 episodes: -99.968 state values: tensor(0.6758) 1000
36 1000 -1000.0 -99.99568287525881 number episode from 10: 36 avegar over 10 episode: -99.969 avegare return across last 100 episodes: -99.969 state values: tensor(0.6806) 1000
37 1000 -1000.0 -99.99568287525881 number episode from 10: 37 avegar over 10 episode: -99.969 avegare return across last 100 episodes: -99.969 state values: tensor(0.6733) 1000
38 1000 -1000.0 -99.99568287525881 number episode from 10: 38 avegar over 10 episode: -99.97 avegare return across last 100 episodes: -99.97 state values: tensor(0.6733) 1000
39 1000 -1000.0 -99.99568287525881 number episode from 10: 39 avegar over 10 episode: -99.971 avegare return across last 100 episodes: -99.971 state values: tensor(0.6738) 1000
40 1000 -1000.0 -99.99568287525881 number episode from 10: 40 avegar over 10 episode: -99.971 avegare return across last 100 episodes: -99.971 state values: tensor(0.6778) 1000
41 1000 -1000.0 -99.99568287525881 number episode from 10: 41 avegar over 10 episode: -99.972 avegare return across last 100 episodes: -99.972 state values: tensor(0.6734) 1000
42 1000 -1000.0 -99.99568287525881 number episode from 10: 42 avegar over 10 episode: -99.972 avegare return across last 100 episodes: -99.972 state values: tensor(0.6738) 1000
43 1000 -1000.0 -99.99568287525881 number episode from 10: 43 avegar over 10 episode: -99.973 avegare return across last 100 episodes: -99.973 state values: tensor(0.6732) 1000
44 1000 -1000.0 -99.99568287525881 number episode from 10: 44 avegar over 10 episode: -99.973 avegare return across last 100 episodes: -99.973 state values: tensor(0.6732) 1000
45 1000 -1000.0 -99.99568287525881 number episode from 10: 45 avegar over 10 episode: -99.974 avegare return across last 100 episodes: -99.974 state values: tensor(0.6755) 1000
46 1000 -1000.0 -99.99568287525881 number episode from 10: 46 avegar over 10 episode: -99.974 avegare return across last 100 episodes: -99.974 state values: tensor(0.6732) 1000
47 1000 -1000.0 -99.99568287525881 number episode from 10: 47 avegar over 10 episode: -99.975 avegare return across last 100 episodes: -99.975 state values: tensor(0.6735) 1000
48 1000 -1000.0 -99.99568287525881 number episode from 10: 48 avegar over 10 episode: -99.975 avegare return across last 100 episodes: -99.975 state values: tensor(0.6744) 1000
49 1000 -1000.0 -99.99568287525881 number episode from 10: 49 avegar over 10 episode: -99.976 avegare return across last 100 episodes: -99.976 state values: tensor(0.6735) 1000
50 1000 -1000.0 -99.99568287525881 number episode from 10: 50 avegar over 10 episode: -99.976 avegare return across last 100 episodes: -99.976 state values: tensor(0.6733) 1000
51 1000 -1000.0 -99.99568287525881 number episode from 10: 51 avegar over 10 episode: -99.976 avegare return across last 100 episodes: -99.976 state values: tensor(0.6767) 1000
52 1000 -1000.0 -99.99568287525881 number episode from 10: 52 avegar over 10 episode: -99.977 avegare return across last 100 episodes: -99.977 state values: tensor(0.6737) 1000
53 1000 -1000.0 -99.99568287525881 number episode from 10: 53 avegar over 10 episode: -99.977 avegare return across last 100 episodes: -99.977 state values: tensor(0.6736) 1000
54 1000 -1000.0 -99.99568287525881 number episode from 10: 54 avegar over 10 episode: -99.978 avegare return across last 100 episodes: -99.978 state values: tensor(0.6766) 1000
55 1000 -1000.0 -99.99568287525881 number episode from 10: 55 avegar over 10 episode: -99.978 avegare return across last 100 episodes: -99.978 state values: tensor(0.6734) 1000
56 1000 -1000.0 -99.99568287525881 number episode from 10: 56 avegar over 10 episode: -99.978 avegare return across last 100 episodes: -99.978 state values: tensor(0.6736) 1000
57 1000 -1000.0 -99.99568287525881 number episode from 10: 57 avegar over 10 episode: -99.978 avegare return across last 100 episodes: -99.978 state values: tensor(0.6803) 1000
58 1000 -1000.0 -99.99568287525881 number episode from 10: 58 avegar over 10 episode: -99.979 avegare return across last 100 episodes: -99.979 state values: tensor(0.6800) 1000
59 1000 -1000.0 -99.99568287525881 number episode from 10: 59 avegar over 10 episode: -99.979 avegare return across last 100 episodes: -99.979 state values: tensor(0.6808) 1000
60 1000 -1000.0 -99.99568287525881 number episode from 10: 60 avegar over 10 episode: -99.979 avegare return across last 100 episodes: -99.979 state values: tensor(0.6735) 1000
61 1000 -1000.0 -99.99568287525881 number episode from 10: 61 avegar over 10 episode: -99.98 avegare return across last 100 episodes: -99.98 state values: tensor(0.6743) 1000
62 1000 -1000.0 -99.99568287525881 number episode from 10: 62 avegar over 10 episode: -99.98 avegare return across last 100 episodes: -99.98 state values: tensor(0.6733) 1000
63 1000 -1000.0 -99.99568287525881 number episode from 10: 63 avegar over 10 episode: -99.98 avegare return across last 100 episodes: -99.98 state values: tensor(0.6767) 1000
64 1000 -1000.0 -99.99568287525881 number episode from 10: 64 avegar over 10 episode: -99.98 avegare return across last 100 episodes: -99.98 state values: tensor(0.6743) 1000
65 1000 -1000.0 -99.99568287525881 number episode from 10: 65 avegar over 10 episode: -99.981 avegare return across last 100 episodes: -99.981 state values: tensor(0.6785) 1000
66 1000 -1000.0 -99.99568287525881 number episode from 10: 66 avegar over 10 episode: -99.981 avegare return across last 100 episodes: -99.981 state values: tensor(0.6804) 1000
67 1000 -1000.0 -99.99568287525881 number episode from 10: 67 avegar over 10 episode: -99.981 avegare return across last 100 episodes: -99.981 state values: tensor(0.6737) 1000
68 1000 -1000.0 -99.99568287525881 number episode from 10: 68 avegar over 10 episode: -99.981 avegare return across last 100 episodes: -99.981 state values: tensor(0.6760) 1000
69 1000 -1000.0 -99.99568287525881 number episode from 10: 69 avegar over 10 episode: -99.981 avegare return across last 100 episodes: -99.981 state values: tensor(0.6737) 1000
70 1000 -1000.0 -99.99568287525881 number episode from 10: 70 avegar over 10 episode: -99.982 avegare return across last 100 episodes: -99.982 state values: tensor(0.6737) 1000
71 1000 -1000.0 -99.99568287525881 number episode from 10: 71 avegar over 10 episode: -99.982 avegare return across last 100 episodes: -99.982 state values: tensor(0.6780) 1000
72 1000 -1000.0 -99.99568287525881 number episode from 10: 72 avegar over 10 episode: -99.982 avegare return across last 100 episodes: -99.982 state values: tensor(0.6734) 1000
73 1000 -1000.0 -99.99568287525881 number episode from 10: 73 avegar over 10 episode: -99.982 avegare return across last 100 episodes: -99.982 state values: tensor(0.6735) 1000
74 1000 -1000.0 -99.99568287525881 number episode from 10: 74 avegar over 10 episode: -99.982 avegare return across last 100 episodes: -99.982 state values: tensor(0.6740) 1000
75 1000 -1000.0 -99.99568287525881 number episode from 10: 75 avegar over 10 episode: -99.983 avegare return across last 100 episodes: -99.983 state values: tensor(0.6763) 1000
76 1000 -1000.0 -99.99568287525881 number episode from 10: 76 avegar over 10 episode: -99.983 avegare return across last 100 episodes: -99.983 state values: tensor(0.6746) 1000
77 1000 -1000.0 -99.99568287525881 number episode from 10: 77 avegar over 10 episode: -99.983 avegare return across last 100 episodes: -99.983 state values: tensor(0.6768) 1000
78 1000 -1000.0 -99.99568287525881 number episode from 10: 78 avegar over 10 episode: -99.983 avegare return across last 100 episodes: -99.983 state values: tensor(0.6759) 1000
79 1000 -1000.0 -99.99568287525881 number episode from 10: 79 avegar over 10 episode: -99.983 avegare return across last 100 episodes: -99.983 state values: tensor(0.6777) 1000
80 1000 -1000.0 -99.99568287525881 number episode from 10: 80 avegar over 10 episode: -99.983 avegare return across last 100 episodes: -99.983 state values: tensor(0.6734) 1000
81 1000 -1000.0 -99.99568287525881 number episode from 10: 81 avegar over 10 episode: -99.983 avegare return across last 100 episodes: -99.983 state values: tensor(0.6734) 1000
82 1000 -1000.0 -99.99568287525881 number episode from 10: 82 avegar over 10 episode: -99.984 avegare return across last 100 episodes: -99.984 state values: tensor(0.6793) 1000
83 1000 -1000.0 -99.99568287525881 number episode from 10: 83 avegar over 10 episode: -99.984 avegare return across last 100 episodes: -99.984 state values: tensor(0.6786) 1000
84 1000 -1000.0 -99.99568287525881 number episode from 10: 84 avegar over 10 episode: -99.984 avegare return across last 100 episodes: -99.984 state values: tensor(0.6763) 1000
85 1000 -1000.0 -99.99568287525881 number episode from 10: 85 avegar over 10 episode: -99.984 avegare return across last 100 episodes: -99.984 state values: tensor(0.6757) 1000
86 1000 -1000.0 -99.99568287525881 number episode from 10: 86 avegar over 10 episode: -99.984 avegare return across last 100 episodes: -99.984 state values: tensor(0.6733) 1000
87 1000 -1000.0 -99.99568287525881 number episode from 10: 87 avegar over 10 episode: -99.984 avegare return across last 100 episodes: -99.984 state values: tensor(0.6737) 1000
88 1000 -1000.0 -99.99568287525881 number episode from 10: 88 avegar over 10 episode: -99.984 avegare return across last 100 episodes: -99.984 state values: tensor(0.6734) 1000
89 1000 -1000.0 -99.99568287525881 number episode from 10: 89 avegar over 10 episode: -99.985 avegare return across last 100 episodes: -99.985 state values: tensor(0.6736) 1000
90 1000 -1000.0 -99.99568287525881 number episode from 10: 90 avegar over 10 episode: -99.985 avegare return across last 100 episodes: -99.985 state values: tensor(0.6757) 1000
91 1000 -1000.0 -99.99568287525881 number episode from 10: 91 avegar over 10 episode: -99.985 avegare return across last 100 episodes: -99.985 state values: tensor(0.6775) 1000
92 1000 -1000.0 -99.99568287525881 number episode from 10: 92 avegar over 10 episode: -99.985 avegare return across last 100 episodes: -99.985 state values: tensor(0.6764) 1000
93 1000 -1000.0 -99.99568287525881 number episode from 10: 93 avegar over 10 episode: -99.985 avegare return across last 100 episodes: -99.985 state values: tensor(0.6734) 1000
94 1000 -1000.0 -99.99568287525881 number episode from 10: 94 avegar over 10 episode: -99.985 avegare return across last 100 episodes: -99.985 state values: tensor(0.6793) 1000
95 1000 -1000.0 -99.99568287525881 number episode from 10: 95 avegar over 10 episode: -99.985 avegare return across last 100 episodes: -99.985 state values: tensor(0.6737) 1000
96 1000 -1000.0 -99.99568287525881 number episode from 10: 96 avegar over 10 episode: -99.985 avegare return across last 100 episodes: -99.985 state values: tensor(0.6735) 1000
97 1000 -1000.0 -99.99568287525881 number episode from 10: 97 avegar over 10 episode: -99.985 avegare return across last 100 episodes: -99.985 state values: tensor(0.6733) 1000
98 1000 -1000.0 -99.99568287525881 number episode from 10: 98 avegar over 10 episode: -99.986 avegare return across last 100 episodes: -99.986 state values: tensor(0.6737) 1000
99 1000 -1000.0 -99.99568287525881 number episode from 10: 99 avegar over 10 episode: -99.986 avegare return across last 100 episodes: -99.986 state values: tensor(0.6793) 1000
100 1000 -1000.0 -99.99568287525881 number episode from 10: 100 avegar over 10 episode: -99.986 avegare return across last 100 episodes: -99.996 state values: tensor(0.6738) 1000
101 1000 -1000.0 -99.99568287525881 number episode from 10: 101 avegar over 10 episode: -99.986 avegare return across last 100 episodes: -99.996 state values: tensor(0.6754) 1000
102 1000 -1000.0 -99.99568287525881 number episode from 10: 102 avegar over 10 episode: -99.986 avegare return across last 100 episodes: -99.996 state values: tensor(0.6734) 1000
103 1000 -1000.0 -99.99568287525881 number episode from 10: 103 avegar over 10 episode: -99.986 avegare return across last 100 episodes: -99.996 state values: tensor(0.6754) 1000
104 1000 -1000.0 -99.99568287525881 number episode from 10: 104 avegar over 10 episode: -99.986 avegare return across last 100 episodes: -99.996 state values: tensor(0.6735) 1000
105 1000 -1000.0 -99.99568287525881 number episode from 10: 105 avegar over 10 episode: -99.986 avegare return across last 100 episodes: -99.996 state values: tensor(0.6733) 1000
106 1000 -1000.0 -99.99568287525881 number episode from 10: 106 avegar over 10 episode: -99.986 avegare return across last 100 episodes: -99.996 state values: tensor(0.6746) 1000
107 1000 -1000.0 -99.99568287525881 number episode from 10: 107 avegar over 10 episode: -99.986 avegare return across last 100 episodes: -99.996 state values: tensor(0.6732) 1000
108 1000 -1000.0 -99.99568287525881 number episode from 10: 108 avegar over 10 episode: -99.987 avegare return across last 100 episodes: -99.996 state values: tensor(0.6745) 1000
109 1000 -1000.0 -99.99568287525881 number episode from 10: 109 avegar over 10 episode: -99.987 avegare return across last 100 episodes: -99.996 state values: tensor(0.6731) 1000
110 1000 -1000.0 -99.99568287525881 number episode from 10: 110 avegar over 10 episode: -99.987 avegare return across last 100 episodes: -99.996 state values: tensor(0.6745) 1000
111 1000 -1000.0 -99.99568287525881 number episode from 10: 111 avegar over 10 episode: -99.987 avegare return across last 100 episodes: -99.996 state values: tensor(0.6776) 1000
112 1000 -1000.0 -99.99568287525881 number episode from 10: 112 avegar over 10 episode: -99.987 avegare return across last 100 episodes: -99.996 state values: tensor(0.6758) 1000
113 1000 -1000.0 -99.99568287525881 number episode from 10: 113 avegar over 10 episode: -99.987 avegare return across last 100 episodes: -99.996 state values: tensor(0.6776) 1000
114 1000 -1000.0 -99.99568287525881 number episode from 10: 114 avegar over 10 episode: -99.987 avegare return across last 100 episodes: -99.996 state values: tensor(0.6747) 1000
115 1000 -1000.0 -99.99568287525881 number episode from 10: 115 avegar over 10 episode: -99.987 avegare return across last 100 episodes: -99.996 state values: tensor(0.6736) 1000
116 1000 -1000.0 -99.99568287525881 number episode from 10: 116 avegar over 10 episode: -99.987 avegare return across last 100 episodes: -99.996 state values: tensor(0.6732) 1000
117 1000 -1000.0 -99.99568287525881 number episode from 10: 117 avegar over 10 episode: -99.987 avegare return across last 100 episodes: -99.996 state values: tensor(0.6733) 1000
118 1000 -1000.0 -99.99568287525881 number episode from 10: 118 avegar over 10 episode: -99.987 avegare return across last 100 episodes: -99.996 state values: tensor(0.6732) 1000
119 1000 -1000.0 -99.99568287525881 number episode from 10: 119 avegar over 10 episode: -99.987 avegare return across last 100 episodes: -99.996 state values: tensor(0.6736) 1000
120 1000 -1000.0 -99.99568287525881 number episode from 10: 120 avegar over 10 episode: -99.987 avegare return across last 100 episodes: -99.996 state values: tensor(0.6736) 1000
121 1000 -1000.0 -99.99568287525881 number episode from 10: 121 avegar over 10 episode: -99.987 avegare return across last 100 episodes: -99.996 state values: tensor(0.6754) 1000
122 1000 -1000.0 -99.99568287525881 number episode from 10: 122 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.6781) 1000
123 1000 -1000.0 -99.99568287525881 number episode from 10: 123 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.6731) 1000
124 1000 -1000.0 -99.99568287525881 number episode from 10: 124 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.6755) 1000
125 1000 -1000.0 -99.99568287525881 number episode from 10: 125 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.6735) 1000
126 1000 -1000.0 -99.99568287525881 number episode from 10: 126 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.6780) 1000
127 1000 -1000.0 -99.99568287525881 number episode from 10: 127 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.6736) 1000
128 1000 -1000.0 -99.99568287525881 number episode from 10: 128 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.6740) 1000
129 1000 -1000.0 -99.99568287525881 number episode from 10: 129 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.6781) 1000
130 1000 -1000.0 -99.99568287525881 number episode from 10: 130 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.6738) 1000
131 1000 -1000.0 -99.99568287525881 number episode from 10: 131 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.6769) 1000
132 1000 -1000.0 -99.99568287525881 number episode from 10: 132 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.6734) 1000
133 1000 -1000.0 -99.99568287525881 number episode from 10: 133 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.6734) 1000
134 1000 -1000.0 -99.99568287525881 number episode from 10: 134 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.6785) 1000
135 1000 -1000.0 -99.99568287525881 number episode from 10: 135 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.6766) 1000
136 1000 -1000.0 -99.99568287525881 number episode from 10: 136 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.6736) 1000
137 1000 -1000.0 -99.99568287525881 number episode from 10: 137 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.6763) 1000
138 1000 -1000.0 -99.99568287525881 number episode from 10: 138 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.6770) 1000
139 1000 -1000.0 -99.99568287525881 number episode from 10: 139 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.6800) 1000
140 1000 -1000.0 -99.99568287525881 number episode from 10: 140 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.6756) 1000
141 1000 -1000.0 -99.99568287525881 number episode from 10: 141 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.6734) 1000
142 1000 -1000.0 -99.99568287525881 number episode from 10: 142 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.6822) 1000
143 1000 -1000.0 -99.99568287525881 number episode from 10: 143 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.6758) 1000
144 1000 -1000.0 -99.99568287525881 number episode from 10: 144 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.6802) 1000
145 1000 -1000.0 -99.99568287525881 number episode from 10: 145 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.6780) 1000
146 1000 -1000.0 -99.99568287525881 number episode from 10: 146 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.6791) 1000
147 1000 -1000.0 -99.99568287525881 number episode from 10: 147 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.6734) 1000
148 1000 -1000.0 -99.99568287525881 number episode from 10: 148 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.6735) 1000
149 1000 -1000.0 -99.99568287525881 number episode from 10: 149 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.6763) 1000
150 1000 -1000.0 -99.99568287525881 number episode from 10: 150 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.6757) 1000
151 1000 -1000.0 -99.99568287525881 number episode from 10: 151 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.6740) 1000
152 1000 -1000.0 -99.99568287525881 number episode from 10: 152 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.6791) 1000
153 1000 -1000.0 -99.99568287525881 number episode from 10: 153 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.6732) 1000
154 1000 -1000.0 -99.99568287525881 number episode from 10: 154 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.6762) 1000
155 1000 -1000.0 -99.99568287525881 number episode from 10: 155 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.6776) 1000
156 1000 -1000.0 -99.99568287525881 number episode from 10: 156 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.6789) 1000
157 1000 -1000.0 -99.99568287525881 number episode from 10: 157 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.6740) 1000
158 1000 -1000.0 -99.99568287525881 number episode from 10: 158 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.6749) 1000
159 1000 -1000.0 -99.99568287525881 number episode from 10: 159 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.6755) 1000
160 1000 -1000.0 -99.99568287525881 number episode from 10: 160 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.6756) 1000
161 1000 -1000.0 -99.99568287525881 number episode from 10: 161 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.6742) 1000
162 1000 -1000.0 -99.99568287525881 number episode from 10: 162 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.6777) 1000
163 1000 -1000.0 -99.99568287525881 number episode from 10: 163 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.6792) 1000
164 1000 -1000.0 -99.99568287525881 number episode from 10: 164 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.6732) 1000
165 1000 -1000.0 -99.99568287525881 number episode from 10: 165 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.6760) 1000
166 1000 -1000.0 -99.99568287525881 number episode from 10: 166 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.6778) 1000
167 1000 -1000.0 -99.99568287525881 number episode from 10: 167 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.6772) 1000
168 1000 -1000.0 -99.99568287525881 number episode from 10: 168 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.6807) 1000
169 1000 -1000.0 -99.99568287525881 number episode from 10: 169 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.6801) 1000
170 1000 -1000.0 -99.99568287525881 number episode from 10: 170 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.6734) 1000
171 1000 -1000.0 -99.99568287525881 number episode from 10: 171 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.6761) 1000
172 1000 -1000.0 -99.99568287525881 number episode from 10: 172 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.6798) 1000
173 1000 -1000.0 -99.99568287525881 number episode from 10: 173 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.6802) 1000
174 1000 -1000.0 -99.99568287525881 number episode from 10: 174 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.6754) 1000
175 1000 -1000.0 -99.99568287525881 number episode from 10: 175 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.6780) 1000
176 1000 -1000.0 -99.99568287525881 number episode from 10: 176 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.6734) 1000
177 1000 -1000.0 -99.99568287525881 number episode from 10: 177 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.6798) 1000
178 1000 -1000.0 -99.99568287525881 number episode from 10: 178 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.6738) 1000
179 1000 -1000.0 -99.99568287525881 number episode from 10: 179 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.6799) 1000
180 1000 -1000.0 -99.99568287525881 number episode from 10: 180 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.6769) 1000
181 1000 -1000.0 -99.99568287525881 number episode from 10: 181 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.6748) 1000
182 1000 -1000.0 -99.99568287525881 number episode from 10: 182 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.6737) 1000
183 1000 -1000.0 -99.99568287525881 number episode from 10: 183 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.6735) 1000
184 1000 -1000.0 -99.99568287525881 number episode from 10: 184 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.6778) 1000
185 1000 -1000.0 -99.99568287525881 number episode from 10: 185 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.6734) 1000
186 1000 -1000.0 -99.99568287525881 number episode from 10: 186 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.6733) 1000
187 1000 -1000.0 -99.99568287525881 number episode from 10: 187 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.6810) 1000
188 1000 -1000.0 -99.99568287525881 number episode from 10: 188 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.6732) 1000
189 1000 -1000.0 -99.99568287525881 number episode from 10: 189 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.6735) 1000
190 1000 -1000.0 -99.99568287525881 number episode from 10: 190 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.6734) 1000
191 1000 -1000.0 -99.99568287525881 number episode from 10: 191 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.6733) 1000
192 1000 -1000.0 -99.99568287525881 number episode from 10: 192 avegar over 10 episode: -99.991 avegare return across last 100 episodes: -99.996 state values: tensor(0.6770) 1000
193 1000 -1000.0 -99.99568287525881 number episode from 10: 193 avegar over 10 episode: -99.991 avegare return across last 100 episodes: -99.996 state values: tensor(0.6807) 1000
194 1000 -1000.0 -99.99568287525881 number episode from 10: 194 avegar over 10 episode: -99.991 avegare return across last 100 episodes: -99.996 state values: tensor(0.6803) 1000
195 1000 -1000.0 -99.99568287525881 number episode from 10: 195 avegar over 10 episode: -99.991 avegare return across last 100 episodes: -99.996 state values: tensor(0.6780) 1000
196 1000 -1000.0 -99.99568287525881 number episode from 10: 196 avegar over 10 episode: -99.991 avegare return across last 100 episodes: -99.996 state values: tensor(0.6736) 1000
197 1000 -1000.0 -99.99568287525881 number episode from 10: 197 avegar over 10 episode: -99.991 avegare return across last 100 episodes: -99.996 state values: tensor(0.6744) 1000
198 1000 -1000.0 -99.99568287525881 number episode from 10: 198 avegar over 10 episode: -99.991 avegare return across last 100 episodes: -99.996 state values: tensor(0.6751) 1000
199 1000 -1000.0 -99.99568287525881 number episode from 10: 199 avegar over 10 episode: -99.991 avegare return across last 100 episodes: -99.996 state values: tensor(0.6776) 1000
200 1000 -1000.0 -99.99568287525881 number episode from 10: 200 avegar over 10 episode: -99.991 avegare return across last 100 episodes: -99.996 state values: tensor(0.6771) 1000
