OrderedDict([('nn_lr', 0.0001), ('reg_A', 0.001), ('eps_decay_steps', 1), ('update_freq', 1000), ('data_length', 50000), ('fqi_rep', 1)])
Data already exists at: Data/Mountaincar_50000+.npy
offline 15 Mountaincar 50000
Parameters: OrderedDict([('nn_lr', 0.001), ('reg_A', 0.001), ('eps_decay_steps', 1), ('update_freq', 1000), ('data_length', 50000), ('fqi_rep', 1)])
Nnet params: {'loss_features': 'semi_MSTDE', 'beta1': 0.0, 'beta2': 0.99, 'eps_init': 1.0, 'eps_final': 0.01, 'num_actions': 3, 'replay_memory_size': 50000, 'replay_init_size': 5000, 'batch_size': 32, 'fqi_reg_type': 'prev', 'data_aug_type': 'ras', 'data_aug_prob': 0.1, 'random_shift_pad': 4, 'ras_alpha': 0.8, 'ras_beta': 1.2}
load offline data!!!!!
/project/6029407/janjua/Offline-Online-RL-Augmentation/Offline-Online-RL/replay_memory.py:52: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  temp = T.tensor((d.item().get('state')), dtype=T.float32)
/project/6029407/janjua/Offline-Online-RL-Augmentation/Offline-Online-RL/replay_memory.py:54: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.state_memory[:len(temp), :] = T.tensor((d.item().get('state')), dtype=T.float32)
/project/6029407/janjua/Offline-Online-RL-Augmentation/Offline-Online-RL/replay_memory.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.new_state_memory[:len(temp), :] = T.tensor((d.item().get('nstate')), dtype=T.float32)
/project/6029407/janjua/Offline-Online-RL-Augmentation/Offline-Online-RL/replay_memory.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.action_memory[:len(temp)] = T.tensor((d.item().get('action')), dtype=T.int64)
/project/6029407/janjua/Offline-Online-RL-Augmentation/Offline-Online-RL/replay_memory.py:57: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.new_action_memory[:len(temp)] = T.tensor((d.item().get('naction')), dtype=T.int64)
/project/6029407/janjua/Offline-Online-RL-Augmentation/Offline-Online-RL/replay_memory.py:58: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.reward_memory[:len(temp)] = T.tensor((d.item().get('reward')), dtype=T.float32)
/project/6029407/janjua/Offline-Online-RL-Augmentation/Offline-Online-RL/replay_memory.py:59: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.terminal_memory[:len(temp)] = T.tensor((d.item().get('done')), dtype=T.bool)
mem_cntr: 50000 ; mem_size: 50000
/project/6029407/janjua/Offline-Online-RL-Augmentation/Offline-Online-RL/replay_memory.py:249: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  temp = T.tensor((d.item().get('state')), dtype=T.float32)
/project/6029407/janjua/Offline-Online-RL-Augmentation/Offline-Online-RL/replay_memory.py:251: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.state_memory[:len(temp), :] = T.tensor((d.item().get('state')), dtype=T.float32)
/project/6029407/janjua/Offline-Online-RL-Augmentation/Offline-Online-RL/replay_memory.py:252: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.new_state_memory[:len(temp), :] = T.tensor((d.item().get('nstate')), dtype=T.float32)
/project/6029407/janjua/Offline-Online-RL-Augmentation/Offline-Online-RL/replay_memory.py:253: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.action_memory[:len(temp)] = T.tensor((d.item().get('action')), dtype=T.int64)
/project/6029407/janjua/Offline-Online-RL-Augmentation/Offline-Online-RL/replay_memory.py:254: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.new_action_memory[:len(temp)] = T.tensor((d.item().get('naction')), dtype=T.int64)
/project/6029407/janjua/Offline-Online-RL-Augmentation/Offline-Online-RL/replay_memory.py:255: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.reward_memory[:len(temp)] = T.tensor((d.item().get('reward')), dtype=T.float32)
/project/6029407/janjua/Offline-Online-RL-Augmentation/Offline-Online-RL/replay_memory.py:256: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.terminal_memory[:len(temp)] = T.tensor((d.item().get('done')), dtype=T.bool)
/project/6029407/janjua/Offline-Online-RL-Augmentation/Offline-Online-RL/mix_ttn_agent_online_offline.py:155: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  states = T.tensor(state).to(self.q_eval.device)
/project/6029407/janjua/Offline-Online-RL-Augmentation/Offline-Online-RL/mix_ttn_agent_online_offline.py:156: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  rewards = T.tensor(reward).to(self.q_eval.device)
/project/6029407/janjua/Offline-Online-RL-Augmentation/Offline-Online-RL/mix_ttn_agent_online_offline.py:157: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  dones = T.tensor(done).to(self.q_eval.device)
/project/6029407/janjua/Offline-Online-RL-Augmentation/Offline-Online-RL/mix_ttn_agent_online_offline.py:158: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  actions = T.tensor(action).to(self.q_eval.device)
/project/6029407/janjua/Offline-Online-RL-Augmentation/Offline-Online-RL/mix_ttn_agent_online_offline.py:159: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  states_ = T.tensor(new_state).to(self.q_eval.device)
/project/6029407/janjua/Offline-Online-RL-Augmentation/Offline-Online-RL/mix_ttn_agent_online_offline.py:160: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  actions_ = T.tensor(new_action).to(self.q_eval.device)
/project/6029407/janjua/Offline-Online-RL-Augmentation/Offline-Online-RL/mix_ttn_agent_online_offline.py:169: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  states = T.tensor(state).to(self.q_eval.device)
/project/6029407/janjua/Offline-Online-RL-Augmentation/Offline-Online-RL/mix_ttn_agent_online_offline.py:170: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  rewards = T.tensor(reward).to(self.q_eval.device)
/project/6029407/janjua/Offline-Online-RL-Augmentation/Offline-Online-RL/mix_ttn_agent_online_offline.py:171: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  dones = T.tensor(done).to(self.q_eval.device)
/project/6029407/janjua/Offline-Online-RL-Augmentation/Offline-Online-RL/mix_ttn_agent_online_offline.py:172: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  actions = T.tensor(action).to(self.q_eval.device)
/project/6029407/janjua/Offline-Online-RL-Augmentation/Offline-Online-RL/mix_ttn_agent_online_offline.py:173: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  states_ = T.tensor(new_state).to(self.q_eval.device)
/project/6029407/janjua/Offline-Online-RL-Augmentation/Offline-Online-RL/mix_ttn_agent_online_offline.py:174: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  actions_ = T.tensor(new_action).to(self.q_eval.device)
nn.learn_nn_feature_fqi FQI:  998
/project/6029407/janjua/Offline-Online-RL-Augmentation/Offline-Online-RL/mix_ttn_agent_online_offline.py:689: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  states_all = T.tensor(self.memory.state_memory[:mem_index, :]).to(self.q_eval.device)
/project/6029407/janjua/Offline-Online-RL-Augmentation/Offline-Online-RL/mix_ttn_agent_online_offline.py:690: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  actions_all = T.tensor(self.memory.action_memory[:mem_index]).to(self.q_eval.device)
/project/6029407/janjua/Offline-Online-RL-Augmentation/Offline-Online-RL/mix_ttn_agent_online_offline.py:691: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  rewards_all = T.tensor(self.memory.reward_memory[:mem_index]).to(self.q_eval.device)
/project/6029407/janjua/Offline-Online-RL-Augmentation/Offline-Online-RL/mix_ttn_agent_online_offline.py:692: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  states_all_ = T.tensor(self.memory.new_state_memory[:mem_index, :]).to(self.q_eval.device)
/project/6029407/janjua/Offline-Online-RL-Augmentation/Offline-Online-RL/mix_ttn_agent_online_offline.py:693: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  actions_all_ = T.tensor(self.memory.new_action_memory[:mem_index]).to(self.q_eval.device)
/project/6029407/janjua/Offline-Online-RL-Augmentation/Offline-Online-RL/mix_ttn_agent_online_offline.py:694: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  dones_all = T.tensor(self.memory.terminal_memory[:mem_index]).to(self.q_eval.device)
/project/6029407/janjua/Offline-Online-RL-Augmentation/Offline-Online-RL/mix_ttn_agent_online_offline.py:779: UserWarning: torch.lstsq is deprecated in favor of torch.linalg.lstsq and will be removed in a future PyTorch release.
torch.linalg.lstsq has reversed arguments and does not return the QR decomposition in the returned tuple (although it returns other information about the problem).
To get the qr decomposition consider using torch.linalg.qr.
The returned solution in torch.lstsq stored the residuals of the solution in the last m - n columns of the returned value whenever m > n. In torch.linalg.lstsq, the residuals in the field 'residuals' of the returned named tuple.
The unpacking of the solution, as in
X, _ = torch.lstsq(B, A).solution[:A.size(1)]
should be replaced with
X = torch.linalg.lstsq(A, B).solution (Triggered internally at  /tmp/coulombc/pytorch_build_2021-11-09_14-57-01/avx2/python3.7/pytorch/aten/src/ATen/native/BatchLinearAlgebra.cpp:3657.)
  new_weights = T.lstsq(b, A)[0]  # T.mm(A.inverse(), b) #T.lstsq(b, A)[0]  #T.mm(A.inverse(), b) #tf.matrix_solve(A, b)
nn.learn_nn_feature_fqi FQI:  1998
nn.learn_nn_feature_fqi FQI:  2998
nn.learn_nn_feature_fqi FQI:  3998
nn.learn_nn_feature_fqi FQI:  4998
nn.learn_nn_feature_fqi FQI:  5998
nn.learn_nn_feature_fqi FQI:  6998
nn.learn_nn_feature_fqi FQI:  7998
nn.learn_nn_feature_fqi FQI:  8998
nn.learn_nn_feature_fqi FQI:  9998
nn.learn_nn_feature_fqi FQI:  10998
nn.learn_nn_feature_fqi FQI:  11998
nn.learn_nn_feature_fqi FQI:  12998
nn.learn_nn_feature_fqi FQI:  13998
nn.learn_nn_feature_fqi FQI:  14998
nn.learn_nn_feature_fqi FQI:  15998
nn.learn_nn_feature_fqi FQI:  16998
nn.learn_nn_feature_fqi FQI:  17998
nn.learn_nn_feature_fqi FQI:  18998
nn.learn_nn_feature_fqi FQI:  19998
nn.learn_nn_feature_fqi FQI:  20998
nn.learn_nn_feature_fqi FQI:  21998
nn.learn_nn_feature_fqi FQI:  22998
nn.learn_nn_feature_fqi FQI:  23998
nn.learn_nn_feature_fqi FQI:  24998
nn.learn_nn_feature_fqi FQI:  25998
nn.learn_nn_feature_fqi FQI:  26998
nn.learn_nn_feature_fqi FQI:  27998
nn.learn_nn_feature_fqi FQI:  28998
nn.learn_nn_feature_fqi FQI:  29998
nn.learn_nn_feature_fqi FQI:  30998
nn.learn_nn_feature_fqi FQI:  31998
nn.learn_nn_feature_fqi FQI:  32998
nn.learn_nn_feature_fqi FQI:  33998
nn.learn_nn_feature_fqi FQI:  34998
nn.learn_nn_feature_fqi FQI:  35998
nn.learn_nn_feature_fqi FQI:  36998
nn.learn_nn_feature_fqi FQI:  37998
nn.learn_nn_feature_fqi FQI:  38998
nn.learn_nn_feature_fqi FQI:  39998
nn.learn_nn_feature_fqi FQI:  40998
nn.learn_nn_feature_fqi FQI:  41998
nn.learn_nn_feature_fqi FQI:  42998
nn.learn_nn_feature_fqi FQI:  43998
nn.learn_nn_feature_fqi FQI:  44998
nn.learn_nn_feature_fqi FQI:  45998
nn.learn_nn_feature_fqi FQI:  46998
nn.learn_nn_feature_fqi FQI:  47998
nn.learn_nn_feature_fqi FQI:  48998
nn.learn_nn_feature_fqi FQI:  49998
nn.learn_nn_feature_fqi FQI:  50998
nn.learn_nn_feature_fqi FQI:  51998
nn.learn_nn_feature_fqi FQI:  52998
nn.learn_nn_feature_fqi FQI:  53998
nn.learn_nn_feature_fqi FQI:  54998
nn.learn_nn_feature_fqi FQI:  55998
nn.learn_nn_feature_fqi FQI:  56998
nn.learn_nn_feature_fqi FQI:  57998
nn.learn_nn_feature_fqi FQI:  58998
nn.learn_nn_feature_fqi FQI:  59998
nn.learn_nn_feature_fqi FQI:  60998
nn.learn_nn_feature_fqi FQI:  61998
nn.learn_nn_feature_fqi FQI:  62998
nn.learn_nn_feature_fqi FQI:  63998
nn.learn_nn_feature_fqi FQI:  64998
nn.learn_nn_feature_fqi FQI:  65998
nn.learn_nn_feature_fqi FQI:  66998
nn.learn_nn_feature_fqi FQI:  67998
nn.learn_nn_feature_fqi FQI:  68998
nn.learn_nn_feature_fqi FQI:  69998
nn.learn_nn_feature_fqi FQI:  70998
nn.learn_nn_feature_fqi FQI:  71998
nn.learn_nn_feature_fqi FQI:  72998
nn.learn_nn_feature_fqi FQI:  73998
nn.learn_nn_feature_fqi FQI:  74998
nn.learn_nn_feature_fqi FQI:  75998
nn.learn_nn_feature_fqi FQI:  76998
nn.learn_nn_feature_fqi FQI:  77998
nn.learn_nn_feature_fqi FQI:  78998
nn.learn_nn_feature_fqi FQI:  79998
nn.learn_nn_feature_fqi FQI:  80998
nn.learn_nn_feature_fqi FQI:  81998
nn.learn_nn_feature_fqi FQI:  82998
nn.learn_nn_feature_fqi FQI:  83998
nn.learn_nn_feature_fqi FQI:  84998
nn.learn_nn_feature_fqi FQI:  85998
nn.learn_nn_feature_fqi FQI:  86998
nn.learn_nn_feature_fqi FQI:  87998
nn.learn_nn_feature_fqi FQI:  88998
nn.learn_nn_feature_fqi FQI:  89998
nn.learn_nn_feature_fqi FQI:  90998
nn.learn_nn_feature_fqi FQI:  91998
nn.learn_nn_feature_fqi FQI:  92998
nn.learn_nn_feature_fqi FQI:  93998
nn.learn_nn_feature_fqi FQI:  94998
nn.learn_nn_feature_fqi FQI:  95998
nn.learn_nn_feature_fqi FQI:  96998
nn.learn_nn_feature_fqi FQI:  97998
nn.learn_nn_feature_fqi FQI:  98998
nn.learn_nn_feature_fqi FQI:  99998
nn.learn_nn_feature_fqi FQI:  100998
nn.learn_nn_feature_fqi FQI:  101998
nn.learn_nn_feature_fqi FQI:  102998
nn.learn_nn_feature_fqi FQI:  103998
nn.learn_nn_feature_fqi FQI:  104998
nn.learn_nn_feature_fqi FQI:  105998
nn.learn_nn_feature_fqi FQI:  106998
nn.learn_nn_feature_fqi FQI:  107998
nn.learn_nn_feature_fqi FQI:  108998
nn.learn_nn_feature_fqi FQI:  109998
nn.learn_nn_feature_fqi FQI:  110998
nn.learn_nn_feature_fqi FQI:  111998
nn.learn_nn_feature_fqi FQI:  112998
nn.learn_nn_feature_fqi FQI:  113998
nn.learn_nn_feature_fqi FQI:  114998
nn.learn_nn_feature_fqi FQI:  115998
nn.learn_nn_feature_fqi FQI:  116998
nn.learn_nn_feature_fqi FQI:  117998
nn.learn_nn_feature_fqi FQI:  118998
nn.learn_nn_feature_fqi FQI:  119998
nn.learn_nn_feature_fqi FQI:  120998
nn.learn_nn_feature_fqi FQI:  121998
nn.learn_nn_feature_fqi FQI:  122998
nn.learn_nn_feature_fqi FQI:  123998
nn.learn_nn_feature_fqi FQI:  124998
nn.learn_nn_feature_fqi FQI:  125998
nn.learn_nn_feature_fqi FQI:  126998
nn.learn_nn_feature_fqi FQI:  127998
nn.learn_nn_feature_fqi FQI:  128998
nn.learn_nn_feature_fqi FQI:  129998
nn.learn_nn_feature_fqi FQI:  130998
nn.learn_nn_feature_fqi FQI:  131998
nn.learn_nn_feature_fqi FQI:  132998
nn.learn_nn_feature_fqi FQI:  133998
nn.learn_nn_feature_fqi FQI:  134998
nn.learn_nn_feature_fqi FQI:  135998
nn.learn_nn_feature_fqi FQI:  136998
nn.learn_nn_feature_fqi FQI:  137998
nn.learn_nn_feature_fqi FQI:  138998
nn.learn_nn_feature_fqi FQI:  139998
nn.learn_nn_feature_fqi FQI:  140998
nn.learn_nn_feature_fqi FQI:  141998
nn.learn_nn_feature_fqi FQI:  142998
nn.learn_nn_feature_fqi FQI:  143998
nn.learn_nn_feature_fqi FQI:  144998
nn.learn_nn_feature_fqi FQI:  145998
nn.learn_nn_feature_fqi FQI:  146998
nn.learn_nn_feature_fqi FQI:  147998
nn.learn_nn_feature_fqi FQI:  148998
nn.learn_nn_feature_fqi FQI:  149998
nn.learn_nn_feature_fqi FQI:  150998
nn.learn_nn_feature_fqi FQI:  151998
nn.learn_nn_feature_fqi FQI:  152998
nn.learn_nn_feature_fqi FQI:  153998
nn.learn_nn_feature_fqi FQI:  154998
nn.learn_nn_feature_fqi FQI:  155998
/project/6029407/janjua/Offline-Online-RL-Augmentation/Offline-Online-RL/mix_ttn_agent_online_offline.py:213: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /tmp/coulombc/pytorch_build_2021-11-09_14-57-01/avx2/python3.7/pytorch/torch/csrc/utils/tensor_new.cpp:198.)
  state = T.tensor([observation], dtype=T.float).to(self.q_eval.device)
0 1001 -1000.0 -98.99572604650622 number episode from 10: 0 avegar over 10 episode: -98.996 avegare return across last 100 episodes: -98.996 state values: tensor(0.6221) 1000
1 1000 -1000.0 -99.99568287525881 number episode from 10: 1 avegar over 10 episode: -99.496 avegare return across last 100 episodes: -99.496 state values: tensor(0.5913) 1000
2 1000 -1000.0 -99.99568287525881 number episode from 10: 2 avegar over 10 episode: -99.662 avegare return across last 100 episodes: -99.662 state values: tensor(0.6023) 1000
3 1000 -1000.0 -99.99568287525881 number episode from 10: 3 avegar over 10 episode: -99.746 avegare return across last 100 episodes: -99.746 state values: tensor(0.6037) 1000
4 1000 -1000.0 -99.99568287525881 number episode from 10: 4 avegar over 10 episode: -99.796 avegare return across last 100 episodes: -99.796 state values: tensor(0.6026) 1000
5 1000 -1000.0 -99.99568287525881 number episode from 10: 5 avegar over 10 episode: -99.829 avegare return across last 100 episodes: -99.829 state values: tensor(0.6195) 1000
6 1000 -1000.0 -99.99568287525881 number episode from 10: 6 avegar over 10 episode: -99.853 avegare return across last 100 episodes: -99.853 state values: tensor(0.6038) 1000
7 1000 -1000.0 -99.99568287525881 number episode from 10: 7 avegar over 10 episode: -99.871 avegare return across last 100 episodes: -99.871 state values: tensor(0.6099) 1000
8 1000 -1000.0 -99.99568287525881 number episode from 10: 8 avegar over 10 episode: -99.885 avegare return across last 100 episodes: -99.885 state values: tensor(0.6165) 1000
9 1000 -1000.0 -99.99568287525881 number episode from 10: 9 avegar over 10 episode: -99.896 avegare return across last 100 episodes: -99.896 state values: tensor(0.6208) 1000
10 1000 -1000.0 -99.99568287525881 number episode from 10: 10 avegar over 10 episode: -99.905 avegare return across last 100 episodes: -99.905 state values: tensor(0.5868) 1000
11 1000 -1000.0 -99.99568287525881 number episode from 10: 11 avegar over 10 episode: -99.912 avegare return across last 100 episodes: -99.912 state values: tensor(0.6064) 1000
12 1000 -1000.0 -99.99568287525881 number episode from 10: 12 avegar over 10 episode: -99.919 avegare return across last 100 episodes: -99.919 state values: tensor(0.6133) 1000
13 1000 -1000.0 -99.99568287525881 number episode from 10: 13 avegar over 10 episode: -99.924 avegare return across last 100 episodes: -99.924 state values: tensor(0.5888) 1000
14 1000 -1000.0 -99.99568287525881 number episode from 10: 14 avegar over 10 episode: -99.929 avegare return across last 100 episodes: -99.929 state values: tensor(0.5926) 1000
15 1000 -1000.0 -99.99568287525881 number episode from 10: 15 avegar over 10 episode: -99.933 avegare return across last 100 episodes: -99.933 state values: tensor(0.5930) 1000
16 1000 -1000.0 -99.99568287525881 number episode from 10: 16 avegar over 10 episode: -99.937 avegare return across last 100 episodes: -99.937 state values: tensor(0.6189) 1000
17 1000 -1000.0 -99.99568287525881 number episode from 10: 17 avegar over 10 episode: -99.94 avegare return across last 100 episodes: -99.94 state values: tensor(0.5954) 1000
18 1000 -1000.0 -99.99568287525881 number episode from 10: 18 avegar over 10 episode: -99.943 avegare return across last 100 episodes: -99.943 state values: tensor(0.5946) 1000
19 1000 -1000.0 -99.99568287525881 number episode from 10: 19 avegar over 10 episode: -99.946 avegare return across last 100 episodes: -99.946 state values: tensor(0.5968) 1000
20 1000 -1000.0 -99.99568287525881 number episode from 10: 20 avegar over 10 episode: -99.948 avegare return across last 100 episodes: -99.948 state values: tensor(0.6265) 1000
21 1000 -1000.0 -99.99568287525881 number episode from 10: 21 avegar over 10 episode: -99.95 avegare return across last 100 episodes: -99.95 state values: tensor(0.5920) 1000
22 1000 -1000.0 -99.99568287525881 number episode from 10: 22 avegar over 10 episode: -99.952 avegare return across last 100 episodes: -99.952 state values: tensor(0.5935) 1000
23 1000 -1000.0 -99.99568287525881 number episode from 10: 23 avegar over 10 episode: -99.954 avegare return across last 100 episodes: -99.954 state values: tensor(0.6104) 1000
24 1000 -1000.0 -99.99568287525881 number episode from 10: 24 avegar over 10 episode: -99.956 avegare return across last 100 episodes: -99.956 state values: tensor(0.6173) 1000
25 1000 -1000.0 -99.99568287525881 number episode from 10: 25 avegar over 10 episode: -99.957 avegare return across last 100 episodes: -99.957 state values: tensor(0.5918) 1000
26 1000 -1000.0 -99.99568287525881 number episode from 10: 26 avegar over 10 episode: -99.959 avegare return across last 100 episodes: -99.959 state values: tensor(0.5934) 1000
27 1000 -1000.0 -99.99568287525881 number episode from 10: 27 avegar over 10 episode: -99.96 avegare return across last 100 episodes: -99.96 state values: tensor(0.5941) 1000
28 1000 -1000.0 -99.99568287525881 number episode from 10: 28 avegar over 10 episode: -99.961 avegare return across last 100 episodes: -99.961 state values: tensor(0.6168) 1000
29 1000 -1000.0 -99.99568287525881 number episode from 10: 29 avegar over 10 episode: -99.962 avegare return across last 100 episodes: -99.962 state values: tensor(0.5902) 1000
30 1000 -1000.0 -99.99568287525881 number episode from 10: 30 avegar over 10 episode: -99.963 avegare return across last 100 episodes: -99.963 state values: tensor(0.5889) 1000
31 1000 -1000.0 -99.99568287525881 number episode from 10: 31 avegar over 10 episode: -99.964 avegare return across last 100 episodes: -99.964 state values: tensor(0.6106) 1000
32 1000 -1000.0 -99.99568287525881 number episode from 10: 32 avegar over 10 episode: -99.965 avegare return across last 100 episodes: -99.965 state values: tensor(0.5878) 1000
33 1000 -1000.0 -99.99568287525881 number episode from 10: 33 avegar over 10 episode: -99.966 avegare return across last 100 episodes: -99.966 state values: tensor(0.5984) 1000
34 1000 -1000.0 -99.99568287525881 number episode from 10: 34 avegar over 10 episode: -99.967 avegare return across last 100 episodes: -99.967 state values: tensor(0.6135) 1000
35 1000 -1000.0 -99.99568287525881 number episode from 10: 35 avegar over 10 episode: -99.968 avegare return across last 100 episodes: -99.968 state values: tensor(0.6108) 1000
36 1000 -1000.0 -99.99568287525881 number episode from 10: 36 avegar over 10 episode: -99.969 avegare return across last 100 episodes: -99.969 state values: tensor(0.6007) 1000
37 1000 -1000.0 -99.99568287525881 number episode from 10: 37 avegar over 10 episode: -99.969 avegare return across last 100 episodes: -99.969 state values: tensor(0.5997) 1000
38 1000 -1000.0 -99.99568287525881 number episode from 10: 38 avegar over 10 episode: -99.97 avegare return across last 100 episodes: -99.97 state values: tensor(0.6288) 1000
39 1000 -1000.0 -99.99568287525881 number episode from 10: 39 avegar over 10 episode: -99.971 avegare return across last 100 episodes: -99.971 state values: tensor(0.6031) 1000
40 1000 -1000.0 -99.99568287525881 number episode from 10: 40 avegar over 10 episode: -99.971 avegare return across last 100 episodes: -99.971 state values: tensor(0.6123) 1000
41 1000 -1000.0 -99.99568287525881 number episode from 10: 41 avegar over 10 episode: -99.972 avegare return across last 100 episodes: -99.972 state values: tensor(0.5998) 1000
42 1000 -1000.0 -99.99568287525881 number episode from 10: 42 avegar over 10 episode: -99.972 avegare return across last 100 episodes: -99.972 state values: tensor(0.6058) 1000
43 1000 -1000.0 -99.99568287525881 number episode from 10: 43 avegar over 10 episode: -99.973 avegare return across last 100 episodes: -99.973 state values: tensor(0.6118) 1000
44 1000 -1000.0 -99.99568287525881 number episode from 10: 44 avegar over 10 episode: -99.973 avegare return across last 100 episodes: -99.973 state values: tensor(0.5995) 1000
45 1000 -1000.0 -99.99568287525881 number episode from 10: 45 avegar over 10 episode: -99.974 avegare return across last 100 episodes: -99.974 state values: tensor(0.5876) 1000
46 1000 -1000.0 -99.99568287525881 number episode from 10: 46 avegar over 10 episode: -99.974 avegare return across last 100 episodes: -99.974 state values: tensor(0.6006) 1000
47 1000 -1000.0 -99.99568287525881 number episode from 10: 47 avegar over 10 episode: -99.975 avegare return across last 100 episodes: -99.975 state values: tensor(0.6228) 1000
48 1000 -1000.0 -99.99568287525881 number episode from 10: 48 avegar over 10 episode: -99.975 avegare return across last 100 episodes: -99.975 state values: tensor(0.6185) 1000
49 1000 -1000.0 -99.99568287525881 number episode from 10: 49 avegar over 10 episode: -99.976 avegare return across last 100 episodes: -99.976 state values: tensor(0.5932) 1000
50 1000 -1000.0 -99.99568287525881 number episode from 10: 50 avegar over 10 episode: -99.976 avegare return across last 100 episodes: -99.976 state values: tensor(0.5945) 1000
51 1000 -1000.0 -99.99568287525881 number episode from 10: 51 avegar over 10 episode: -99.976 avegare return across last 100 episodes: -99.976 state values: tensor(0.6098) 1000
52 1000 -1000.0 -99.99568287525881 number episode from 10: 52 avegar over 10 episode: -99.977 avegare return across last 100 episodes: -99.977 state values: tensor(0.5939) 1000
53 1000 -1000.0 -99.99568287525881 number episode from 10: 53 avegar over 10 episode: -99.977 avegare return across last 100 episodes: -99.977 state values: tensor(0.5949) 1000
54 1000 -1000.0 -99.99568287525881 number episode from 10: 54 avegar over 10 episode: -99.978 avegare return across last 100 episodes: -99.978 state values: tensor(0.6155) 1000
55 1000 -1000.0 -99.99568287525881 number episode from 10: 55 avegar over 10 episode: -99.978 avegare return across last 100 episodes: -99.978 state values: tensor(0.5988) 1000
56 1000 -1000.0 -99.99568287525881 number episode from 10: 56 avegar over 10 episode: -99.978 avegare return across last 100 episodes: -99.978 state values: tensor(0.6143) 1000
57 1000 -1000.0 -99.99568287525881 number episode from 10: 57 avegar over 10 episode: -99.978 avegare return across last 100 episodes: -99.978 state values: tensor(0.6146) 1000
58 1000 -1000.0 -99.99568287525881 number episode from 10: 58 avegar over 10 episode: -99.979 avegare return across last 100 episodes: -99.979 state values: tensor(0.5986) 1000
59 1000 -1000.0 -99.99568287525881 number episode from 10: 59 avegar over 10 episode: -99.979 avegare return across last 100 episodes: -99.979 state values: tensor(0.6094) 1000
60 1000 -1000.0 -99.99568287525881 number episode from 10: 60 avegar over 10 episode: -99.979 avegare return across last 100 episodes: -99.979 state values: tensor(0.5983) 1000
61 1000 -1000.0 -99.99568287525881 number episode from 10: 61 avegar over 10 episode: -99.98 avegare return across last 100 episodes: -99.98 state values: tensor(0.5893) 1000
62 1000 -1000.0 -99.99568287525881 number episode from 10: 62 avegar over 10 episode: -99.98 avegare return across last 100 episodes: -99.98 state values: tensor(0.6163) 1000
63 1000 -1000.0 -99.99568287525881 number episode from 10: 63 avegar over 10 episode: -99.98 avegare return across last 100 episodes: -99.98 state values: tensor(0.6090) 1000
64 1000 -1000.0 -99.99568287525881 number episode from 10: 64 avegar over 10 episode: -99.98 avegare return across last 100 episodes: -99.98 state values: tensor(0.5866) 1000
65 1000 -1000.0 -99.99568287525881 number episode from 10: 65 avegar over 10 episode: -99.981 avegare return across last 100 episodes: -99.981 state values: tensor(0.5872) 1000
66 1000 -1000.0 -99.99568287525881 number episode from 10: 66 avegar over 10 episode: -99.981 avegare return across last 100 episodes: -99.981 state values: tensor(0.5886) 1000
67 1000 -1000.0 -99.99568287525881 number episode from 10: 67 avegar over 10 episode: -99.981 avegare return across last 100 episodes: -99.981 state values: tensor(0.6065) 1000
68 1000 -1000.0 -99.99568287525881 number episode from 10: 68 avegar over 10 episode: -99.981 avegare return across last 100 episodes: -99.981 state values: tensor(0.5879) 1000
69 1000 -1000.0 -99.99568287525881 number episode from 10: 69 avegar over 10 episode: -99.981 avegare return across last 100 episodes: -99.981 state values: tensor(0.5970) 1000
70 1000 -1000.0 -99.99568287525881 number episode from 10: 70 avegar over 10 episode: -99.982 avegare return across last 100 episodes: -99.982 state values: tensor(0.6050) 1000
71 1000 -1000.0 -99.99568287525881 number episode from 10: 71 avegar over 10 episode: -99.982 avegare return across last 100 episodes: -99.982 state values: tensor(0.5910) 1000
72 1000 -1000.0 -99.99568287525881 number episode from 10: 72 avegar over 10 episode: -99.982 avegare return across last 100 episodes: -99.982 state values: tensor(0.5882) 1000
73 1000 -1000.0 -99.99568287525881 number episode from 10: 73 avegar over 10 episode: -99.982 avegare return across last 100 episodes: -99.982 state values: tensor(0.6157) 1000
74 1000 -1000.0 -99.99568287525881 number episode from 10: 74 avegar over 10 episode: -99.982 avegare return across last 100 episodes: -99.982 state values: tensor(0.6126) 1000
75 1000 -1000.0 -99.99568287525881 number episode from 10: 75 avegar over 10 episode: -99.983 avegare return across last 100 episodes: -99.983 state values: tensor(0.5919) 1000
76 1000 -1000.0 -99.99568287525881 number episode from 10: 76 avegar over 10 episode: -99.983 avegare return across last 100 episodes: -99.983 state values: tensor(0.5876) 1000
77 1000 -1000.0 -99.99568287525881 number episode from 10: 77 avegar over 10 episode: -99.983 avegare return across last 100 episodes: -99.983 state values: tensor(0.5950) 1000
78 1000 -1000.0 -99.99568287525881 number episode from 10: 78 avegar over 10 episode: -99.983 avegare return across last 100 episodes: -99.983 state values: tensor(0.6097) 1000
79 1000 -1000.0 -99.99568287525881 number episode from 10: 79 avegar over 10 episode: -99.983 avegare return across last 100 episodes: -99.983 state values: tensor(0.5900) 1000
80 1000 -1000.0 -99.99568287525881 number episode from 10: 80 avegar over 10 episode: -99.983 avegare return across last 100 episodes: -99.983 state values: tensor(0.6206) 1000
81 1000 -1000.0 -99.99568287525881 number episode from 10: 81 avegar over 10 episode: -99.983 avegare return across last 100 episodes: -99.983 state values: tensor(0.6182) 1000
82 1000 -1000.0 -99.99568287525881 number episode from 10: 82 avegar over 10 episode: -99.984 avegare return across last 100 episodes: -99.984 state values: tensor(0.6139) 1000
83 1000 -1000.0 -99.99568287525881 number episode from 10: 83 avegar over 10 episode: -99.984 avegare return across last 100 episodes: -99.984 state values: tensor(0.6187) 1000
84 1000 -1000.0 -99.99568287525881 number episode from 10: 84 avegar over 10 episode: -99.984 avegare return across last 100 episodes: -99.984 state values: tensor(0.5922) 1000
85 1000 -1000.0 -99.99568287525881 number episode from 10: 85 avegar over 10 episode: -99.984 avegare return across last 100 episodes: -99.984 state values: tensor(0.5907) 1000
86 1000 -1000.0 -99.99568287525881 number episode from 10: 86 avegar over 10 episode: -99.984 avegare return across last 100 episodes: -99.984 state values: tensor(0.6049) 1000
87 1000 -1000.0 -99.99568287525881 number episode from 10: 87 avegar over 10 episode: -99.984 avegare return across last 100 episodes: -99.984 state values: tensor(0.5969) 1000
88 1000 -1000.0 -99.99568287525881 number episode from 10: 88 avegar over 10 episode: -99.984 avegare return across last 100 episodes: -99.984 state values: tensor(0.6225) 1000
89 1000 -1000.0 -99.99568287525881 number episode from 10: 89 avegar over 10 episode: -99.985 avegare return across last 100 episodes: -99.985 state values: tensor(0.5977) 1000
90 1000 -1000.0 -99.99568287525881 number episode from 10: 90 avegar over 10 episode: -99.985 avegare return across last 100 episodes: -99.985 state values: tensor(0.6056) 1000
91 1000 -1000.0 -99.99568287525881 number episode from 10: 91 avegar over 10 episode: -99.985 avegare return across last 100 episodes: -99.985 state values: tensor(0.5887) 1000
92 1000 -1000.0 -99.99568287525881 number episode from 10: 92 avegar over 10 episode: -99.985 avegare return across last 100 episodes: -99.985 state values: tensor(0.5986) 1000
93 1000 -1000.0 -99.99568287525881 number episode from 10: 93 avegar over 10 episode: -99.985 avegare return across last 100 episodes: -99.985 state values: tensor(0.5870) 1000
94 1000 -1000.0 -99.99568287525881 number episode from 10: 94 avegar over 10 episode: -99.985 avegare return across last 100 episodes: -99.985 state values: tensor(0.6169) 1000
95 1000 -1000.0 -99.99568287525881 number episode from 10: 95 avegar over 10 episode: -99.985 avegare return across last 100 episodes: -99.985 state values: tensor(0.5901) 1000
96 1000 -1000.0 -99.99568287525881 number episode from 10: 96 avegar over 10 episode: -99.985 avegare return across last 100 episodes: -99.985 state values: tensor(0.5950) 1000
97 1000 -1000.0 -99.99568287525881 number episode from 10: 97 avegar over 10 episode: -99.985 avegare return across last 100 episodes: -99.985 state values: tensor(0.5989) 1000
98 1000 -1000.0 -99.99568287525881 number episode from 10: 98 avegar over 10 episode: -99.986 avegare return across last 100 episodes: -99.986 state values: tensor(0.5859) 1000
99 1000 -1000.0 -99.99568287525881 number episode from 10: 99 avegar over 10 episode: -99.986 avegare return across last 100 episodes: -99.986 state values: tensor(0.6168) 1000
100 1000 -1000.0 -99.99568287525881 number episode from 10: 100 avegar over 10 episode: -99.986 avegare return across last 100 episodes: -99.996 state values: tensor(0.6169) 1000
101 1000 -1000.0 -99.99568287525881 number episode from 10: 101 avegar over 10 episode: -99.986 avegare return across last 100 episodes: -99.996 state values: tensor(0.6057) 1000
102 1000 -1000.0 -99.99568287525881 number episode from 10: 102 avegar over 10 episode: -99.986 avegare return across last 100 episodes: -99.996 state values: tensor(0.6099) 1000
103 1000 -1000.0 -99.99568287525881 number episode from 10: 103 avegar over 10 episode: -99.986 avegare return across last 100 episodes: -99.996 state values: tensor(0.6032) 1000
104 1000 -1000.0 -99.99568287525881 number episode from 10: 104 avegar over 10 episode: -99.986 avegare return across last 100 episodes: -99.996 state values: tensor(0.6058) 1000
105 1000 -1000.0 -99.99568287525881 number episode from 10: 105 avegar over 10 episode: -99.986 avegare return across last 100 episodes: -99.996 state values: tensor(0.6244) 1000
106 1000 -1000.0 -99.99568287525881 number episode from 10: 106 avegar over 10 episode: -99.986 avegare return across last 100 episodes: -99.996 state values: tensor(0.6161) 1000
107 1000 -1000.0 -99.99568287525881 number episode from 10: 107 avegar over 10 episode: -99.986 avegare return across last 100 episodes: -99.996 state values: tensor(0.6069) 1000
108 1000 -1000.0 -99.99568287525881 number episode from 10: 108 avegar over 10 episode: -99.987 avegare return across last 100 episodes: -99.996 state values: tensor(0.6118) 1000
109 1000 -1000.0 -99.99568287525881 number episode from 10: 109 avegar over 10 episode: -99.987 avegare return across last 100 episodes: -99.996 state values: tensor(0.6012) 1000
110 1000 -1000.0 -99.99568287525881 number episode from 10: 110 avegar over 10 episode: -99.987 avegare return across last 100 episodes: -99.996 state values: tensor(0.5931) 1000
111 1000 -1000.0 -99.99568287525881 number episode from 10: 111 avegar over 10 episode: -99.987 avegare return across last 100 episodes: -99.996 state values: tensor(0.6105) 1000
112 1000 -1000.0 -99.99568287525881 number episode from 10: 112 avegar over 10 episode: -99.987 avegare return across last 100 episodes: -99.996 state values: tensor(0.6141) 1000
113 1000 -1000.0 -99.99568287525881 number episode from 10: 113 avegar over 10 episode: -99.987 avegare return across last 100 episodes: -99.996 state values: tensor(0.5997) 1000
114 1000 -1000.0 -99.99568287525881 number episode from 10: 114 avegar over 10 episode: -99.987 avegare return across last 100 episodes: -99.996 state values: tensor(0.5913) 1000
115 1000 -1000.0 -99.99568287525881 number episode from 10: 115 avegar over 10 episode: -99.987 avegare return across last 100 episodes: -99.996 state values: tensor(0.5877) 1000
116 1000 -1000.0 -99.99568287525881 number episode from 10: 116 avegar over 10 episode: -99.987 avegare return across last 100 episodes: -99.996 state values: tensor(0.5900) 1000
117 1000 -1000.0 -99.99568287525881 number episode from 10: 117 avegar over 10 episode: -99.987 avegare return across last 100 episodes: -99.996 state values: tensor(0.5991) 1000
118 1000 -1000.0 -99.99568287525881 number episode from 10: 118 avegar over 10 episode: -99.987 avegare return across last 100 episodes: -99.996 state values: tensor(0.5990) 1000
119 1000 -1000.0 -99.99568287525881 number episode from 10: 119 avegar over 10 episode: -99.987 avegare return across last 100 episodes: -99.996 state values: tensor(0.6068) 1000
120 1000 -1000.0 -99.99568287525881 number episode from 10: 120 avegar over 10 episode: -99.987 avegare return across last 100 episodes: -99.996 state values: tensor(0.5886) 1000
121 1000 -1000.0 -99.99568287525881 number episode from 10: 121 avegar over 10 episode: -99.987 avegare return across last 100 episodes: -99.996 state values: tensor(0.6032) 1000
122 1000 -1000.0 -99.99568287525881 number episode from 10: 122 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.6055) 1000
123 1000 -1000.0 -99.99568287525881 number episode from 10: 123 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.5884) 1000
124 1000 -1000.0 -99.99568287525881 number episode from 10: 124 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.6028) 1000
125 1000 -1000.0 -99.99568287525881 number episode from 10: 125 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.6058) 1000
126 1000 -1000.0 -99.99568287525881 number episode from 10: 126 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.6071) 1000
127 1000 -1000.0 -99.99568287525881 number episode from 10: 127 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.6083) 1000
128 1000 -1000.0 -99.99568287525881 number episode from 10: 128 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.6112) 1000
129 1000 -1000.0 -99.99568287525881 number episode from 10: 129 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.5909) 1000
130 1000 -1000.0 -99.99568287525881 number episode from 10: 130 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.5889) 1000
131 1000 -1000.0 -99.99568287525881 number episode from 10: 131 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.5925) 1000
132 1000 -1000.0 -99.99568287525881 number episode from 10: 132 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.6132) 1000
133 1000 -1000.0 -99.99568287525881 number episode from 10: 133 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.6177) 1000
134 1000 -1000.0 -99.99568287525881 number episode from 10: 134 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.6012) 1000
135 1000 -1000.0 -99.99568287525881 number episode from 10: 135 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.5877) 1000
136 1000 -1000.0 -99.99568287525881 number episode from 10: 136 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.5909) 1000
137 1000 -1000.0 -99.99568287525881 number episode from 10: 137 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.6143) 1000
138 1000 -1000.0 -99.99568287525881 number episode from 10: 138 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.6111) 1000
139 1000 -1000.0 -99.99568287525881 number episode from 10: 139 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.6085) 1000
140 1000 -1000.0 -99.99568287525881 number episode from 10: 140 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.6012) 1000
141 1000 -1000.0 -99.99568287525881 number episode from 10: 141 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.5915) 1000
142 1000 -1000.0 -99.99568287525881 number episode from 10: 142 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.5897) 1000
143 1000 -1000.0 -99.99568287525881 number episode from 10: 143 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.5963) 1000
144 1000 -1000.0 -99.99568287525881 number episode from 10: 144 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.5914) 1000
145 1000 -1000.0 -99.99568287525881 number episode from 10: 145 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.6187) 1000
146 1000 -1000.0 -99.99568287525881 number episode from 10: 146 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.5880) 1000
147 1000 -1000.0 -99.99568287525881 number episode from 10: 147 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.5888) 1000
148 1000 -1000.0 -99.99568287525881 number episode from 10: 148 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.6173) 1000
149 1000 -1000.0 -99.99568287525881 number episode from 10: 149 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.6197) 1000
150 1000 -1000.0 -99.99568287525881 number episode from 10: 150 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.6009) 1000
151 1000 -1000.0 -99.99568287525881 number episode from 10: 151 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.6122) 1000
152 1000 -1000.0 -99.99568287525881 number episode from 10: 152 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.6202) 1000
153 1000 -1000.0 -99.99568287525881 number episode from 10: 153 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.5891) 1000
154 1000 -1000.0 -99.99568287525881 number episode from 10: 154 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.6281) 1000
155 1000 -1000.0 -99.99568287525881 number episode from 10: 155 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.6267) 1000
156 1000 -1000.0 -99.99568287525881 number episode from 10: 156 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.6240) 1000
157 1000 -1000.0 -99.99568287525881 number episode from 10: 157 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.5889) 1000
158 1000 -1000.0 -99.99568287525881 number episode from 10: 158 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.5966) 1000
159 1000 -1000.0 -99.99568287525881 number episode from 10: 159 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.5882) 1000
160 1000 -1000.0 -99.99568287525881 number episode from 10: 160 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.5887) 1000
161 1000 -1000.0 -99.99568287525881 number episode from 10: 161 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.6170) 1000
162 1000 -1000.0 -99.99568287525881 number episode from 10: 162 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.6195) 1000
163 1000 -1000.0 -99.99568287525881 number episode from 10: 163 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.6066) 1000
164 1000 -1000.0 -99.99568287525881 number episode from 10: 164 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.5915) 1000
165 1000 -1000.0 -99.99568287525881 number episode from 10: 165 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.6036) 1000
166 1000 -1000.0 -99.99568287525881 number episode from 10: 166 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.6172) 1000
167 1000 -1000.0 -99.99568287525881 number episode from 10: 167 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.5941) 1000
168 1000 -1000.0 -99.99568287525881 number episode from 10: 168 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.6183) 1000
169 1000 -1000.0 -99.99568287525881 number episode from 10: 169 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.6147) 1000
170 1000 -1000.0 -99.99568287525881 number episode from 10: 170 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.6284) 1000
171 1000 -1000.0 -99.99568287525881 number episode from 10: 171 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.5981) 1000
172 1000 -1000.0 -99.99568287525881 number episode from 10: 172 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.5934) 1000
173 1000 -1000.0 -99.99568287525881 number episode from 10: 173 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.6163) 1000
174 1000 -1000.0 -99.99568287525881 number episode from 10: 174 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.6072) 1000
175 1000 -1000.0 -99.99568287525881 number episode from 10: 175 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.5944) 1000
176 1000 -1000.0 -99.99568287525881 number episode from 10: 176 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.6074) 1000
177 1000 -1000.0 -99.99568287525881 number episode from 10: 177 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.6024) 1000
178 1000 -1000.0 -99.99568287525881 number episode from 10: 178 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.6011) 1000
179 1000 -1000.0 -99.99568287525881 number episode from 10: 179 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.6058) 1000
180 1000 -1000.0 -99.99568287525881 number episode from 10: 180 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.6014) 1000
181 1000 -1000.0 -99.99568287525881 number episode from 10: 181 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.6073) 1000
182 1000 -1000.0 -99.99568287525881 number episode from 10: 182 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.6016) 1000
183 1000 -1000.0 -99.99568287525881 number episode from 10: 183 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.6103) 1000
184 1000 -1000.0 -99.99568287525881 number episode from 10: 184 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.6096) 1000
185 1000 -1000.0 -99.99568287525881 number episode from 10: 185 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.5948) 1000
186 1000 -1000.0 -99.99568287525881 number episode from 10: 186 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.5999) 1000
187 1000 -1000.0 -99.99568287525881 number episode from 10: 187 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.5870) 1000
188 1000 -1000.0 -99.99568287525881 number episode from 10: 188 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.6164) 1000
189 1000 -1000.0 -99.99568287525881 number episode from 10: 189 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.5900) 1000
190 1000 -1000.0 -99.99568287525881 number episode from 10: 190 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.5889) 1000
191 1000 -1000.0 -99.99568287525881 number episode from 10: 191 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.6166) 1000
192 1000 -1000.0 -99.99568287525881 number episode from 10: 192 avegar over 10 episode: -99.991 avegare return across last 100 episodes: -99.996 state values: tensor(0.6146) 1000
193 1000 -1000.0 -99.99568287525881 number episode from 10: 193 avegar over 10 episode: -99.991 avegare return across last 100 episodes: -99.996 state values: tensor(0.6163) 1000
194 1000 -1000.0 -99.99568287525881 number episode from 10: 194 avegar over 10 episode: -99.991 avegare return across last 100 episodes: -99.996 state values: tensor(0.6061) 1000
195 1000 -1000.0 -99.99568287525881 number episode from 10: 195 avegar over 10 episode: -99.991 avegare return across last 100 episodes: -99.996 state values: tensor(0.5960) 1000
196 1000 -1000.0 -99.99568287525881 number episode from 10: 196 avegar over 10 episode: -99.991 avegare return across last 100 episodes: -99.996 state values: tensor(0.5893) 1000
197 1000 -1000.0 -99.99568287525881 number episode from 10: 197 avegar over 10 episode: -99.991 avegare return across last 100 episodes: -99.996 state values: tensor(0.6130) 1000
198 1000 -1000.0 -99.99568287525881 number episode from 10: 198 avegar over 10 episode: -99.991 avegare return across last 100 episodes: -99.996 state values: tensor(0.5920) 1000
199 1000 -1000.0 -99.99568287525881 number episode from 10: 199 avegar over 10 episode: -99.991 avegare return across last 100 episodes: -99.996 state values: tensor(0.5920) 1000
200 1000 -1000.0 -99.99568287525881 number episode from 10: 200 avegar over 10 episode: -99.991 avegare return across last 100 episodes: -99.996 state values: tensor(0.6023) 1000
load offline data!!!!!
mem_cntr: 50000 ; mem_size: 50000
nn.learn_nn_feature_fqi FQI:  998
nn.learn_nn_feature_fqi FQI:  1998
nn.learn_nn_feature_fqi FQI:  2998
nn.learn_nn_feature_fqi FQI:  3998
nn.learn_nn_feature_fqi FQI:  4998
nn.learn_nn_feature_fqi FQI:  5998
nn.learn_nn_feature_fqi FQI:  6998
nn.learn_nn_feature_fqi FQI:  7998
nn.learn_nn_feature_fqi FQI:  8998
nn.learn_nn_feature_fqi FQI:  9998
nn.learn_nn_feature_fqi FQI:  10998
nn.learn_nn_feature_fqi FQI:  11998
nn.learn_nn_feature_fqi FQI:  12998
nn.learn_nn_feature_fqi FQI:  13998
nn.learn_nn_feature_fqi FQI:  14998
nn.learn_nn_feature_fqi FQI:  15998
nn.learn_nn_feature_fqi FQI:  16998
nn.learn_nn_feature_fqi FQI:  17998
nn.learn_nn_feature_fqi FQI:  18998
nn.learn_nn_feature_fqi FQI:  19998
nn.learn_nn_feature_fqi FQI:  20998
nn.learn_nn_feature_fqi FQI:  21998
nn.learn_nn_feature_fqi FQI:  22998
nn.learn_nn_feature_fqi FQI:  23998
nn.learn_nn_feature_fqi FQI:  24998
nn.learn_nn_feature_fqi FQI:  25998
nn.learn_nn_feature_fqi FQI:  26998
nn.learn_nn_feature_fqi FQI:  27998
nn.learn_nn_feature_fqi FQI:  28998
nn.learn_nn_feature_fqi FQI:  29998
nn.learn_nn_feature_fqi FQI:  30998
nn.learn_nn_feature_fqi FQI:  31998
nn.learn_nn_feature_fqi FQI:  32998
nn.learn_nn_feature_fqi FQI:  33998
nn.learn_nn_feature_fqi FQI:  34998
nn.learn_nn_feature_fqi FQI:  35998
nn.learn_nn_feature_fqi FQI:  36998
nn.learn_nn_feature_fqi FQI:  37998
nn.learn_nn_feature_fqi FQI:  38998
nn.learn_nn_feature_fqi FQI:  39998
nn.learn_nn_feature_fqi FQI:  40998
nn.learn_nn_feature_fqi FQI:  41998
nn.learn_nn_feature_fqi FQI:  42998
nn.learn_nn_feature_fqi FQI:  43998
nn.learn_nn_feature_fqi FQI:  44998
nn.learn_nn_feature_fqi FQI:  45998
nn.learn_nn_feature_fqi FQI:  46998
nn.learn_nn_feature_fqi FQI:  47998
nn.learn_nn_feature_fqi FQI:  48998
nn.learn_nn_feature_fqi FQI:  49998
nn.learn_nn_feature_fqi FQI:  50998
nn.learn_nn_feature_fqi FQI:  51998
nn.learn_nn_feature_fqi FQI:  52998
nn.learn_nn_feature_fqi FQI:  53998
nn.learn_nn_feature_fqi FQI:  54998
nn.learn_nn_feature_fqi FQI:  55998
nn.learn_nn_feature_fqi FQI:  56998
nn.learn_nn_feature_fqi FQI:  57998
nn.learn_nn_feature_fqi FQI:  58998
nn.learn_nn_feature_fqi FQI:  59998
nn.learn_nn_feature_fqi FQI:  60998
nn.learn_nn_feature_fqi FQI:  61998
nn.learn_nn_feature_fqi FQI:  62998
nn.learn_nn_feature_fqi FQI:  63998
nn.learn_nn_feature_fqi FQI:  64998
nn.learn_nn_feature_fqi FQI:  65998
nn.learn_nn_feature_fqi FQI:  66998
nn.learn_nn_feature_fqi FQI:  67998
nn.learn_nn_feature_fqi FQI:  68998
nn.learn_nn_feature_fqi FQI:  69998
nn.learn_nn_feature_fqi FQI:  70998
nn.learn_nn_feature_fqi FQI:  71998
nn.learn_nn_feature_fqi FQI:  72998
nn.learn_nn_feature_fqi FQI:  73998
nn.learn_nn_feature_fqi FQI:  74998
nn.learn_nn_feature_fqi FQI:  75998
nn.learn_nn_feature_fqi FQI:  76998
nn.learn_nn_feature_fqi FQI:  77998
nn.learn_nn_feature_fqi FQI:  78998
nn.learn_nn_feature_fqi FQI:  79998
nn.learn_nn_feature_fqi FQI:  80998
nn.learn_nn_feature_fqi FQI:  81998
nn.learn_nn_feature_fqi FQI:  82998
nn.learn_nn_feature_fqi FQI:  83998
nn.learn_nn_feature_fqi FQI:  84998
nn.learn_nn_feature_fqi FQI:  85998
nn.learn_nn_feature_fqi FQI:  86998
nn.learn_nn_feature_fqi FQI:  87998
nn.learn_nn_feature_fqi FQI:  88998
nn.learn_nn_feature_fqi FQI:  89998
nn.learn_nn_feature_fqi FQI:  90998
nn.learn_nn_feature_fqi FQI:  91998
nn.learn_nn_feature_fqi FQI:  92998
nn.learn_nn_feature_fqi FQI:  93998
nn.learn_nn_feature_fqi FQI:  94998
nn.learn_nn_feature_fqi FQI:  95998
nn.learn_nn_feature_fqi FQI:  96998
nn.learn_nn_feature_fqi FQI:  97998
nn.learn_nn_feature_fqi FQI:  98998
nn.learn_nn_feature_fqi FQI:  99998
nn.learn_nn_feature_fqi FQI:  100998
nn.learn_nn_feature_fqi FQI:  101998
nn.learn_nn_feature_fqi FQI:  102998
nn.learn_nn_feature_fqi FQI:  103998
nn.learn_nn_feature_fqi FQI:  104998
nn.learn_nn_feature_fqi FQI:  105998
nn.learn_nn_feature_fqi FQI:  106998
nn.learn_nn_feature_fqi FQI:  107998
nn.learn_nn_feature_fqi FQI:  108998
nn.learn_nn_feature_fqi FQI:  109998
nn.learn_nn_feature_fqi FQI:  110998
nn.learn_nn_feature_fqi FQI:  111998
nn.learn_nn_feature_fqi FQI:  112998
nn.learn_nn_feature_fqi FQI:  113998
nn.learn_nn_feature_fqi FQI:  114998
nn.learn_nn_feature_fqi FQI:  115998
nn.learn_nn_feature_fqi FQI:  116998
nn.learn_nn_feature_fqi FQI:  117998
nn.learn_nn_feature_fqi FQI:  118998
nn.learn_nn_feature_fqi FQI:  119998
nn.learn_nn_feature_fqi FQI:  120998
nn.learn_nn_feature_fqi FQI:  121998
nn.learn_nn_feature_fqi FQI:  122998
nn.learn_nn_feature_fqi FQI:  123998
nn.learn_nn_feature_fqi FQI:  124998
nn.learn_nn_feature_fqi FQI:  125998
nn.learn_nn_feature_fqi FQI:  126998
nn.learn_nn_feature_fqi FQI:  127998
nn.learn_nn_feature_fqi FQI:  128998
nn.learn_nn_feature_fqi FQI:  129998
nn.learn_nn_feature_fqi FQI:  130998
nn.learn_nn_feature_fqi FQI:  131998
nn.learn_nn_feature_fqi FQI:  132998
nn.learn_nn_feature_fqi FQI:  133998
nn.learn_nn_feature_fqi FQI:  134998
nn.learn_nn_feature_fqi FQI:  135998
nn.learn_nn_feature_fqi FQI:  136998
nn.learn_nn_feature_fqi FQI:  137998
nn.learn_nn_feature_fqi FQI:  138998
nn.learn_nn_feature_fqi FQI:  139998
nn.learn_nn_feature_fqi FQI:  140998
nn.learn_nn_feature_fqi FQI:  141998
nn.learn_nn_feature_fqi FQI:  142998
nn.learn_nn_feature_fqi FQI:  143998
nn.learn_nn_feature_fqi FQI:  144998
nn.learn_nn_feature_fqi FQI:  145998
nn.learn_nn_feature_fqi FQI:  146998
nn.learn_nn_feature_fqi FQI:  147998
nn.learn_nn_feature_fqi FQI:  148998
nn.learn_nn_feature_fqi FQI:  149998
nn.learn_nn_feature_fqi FQI:  150998
nn.learn_nn_feature_fqi FQI:  151998
nn.learn_nn_feature_fqi FQI:  152998
nn.learn_nn_feature_fqi FQI:  153998
nn.learn_nn_feature_fqi FQI:  154998
nn.learn_nn_feature_fqi FQI:  155998
0 1001 -1000.0 -98.99572604650622 number episode from 10: 0 avegar over 10 episode: -98.996 avegare return across last 100 episodes: -98.996 state values: tensor(0.6457) 1000
1 1000 -1000.0 -99.99568287525881 number episode from 10: 1 avegar over 10 episode: -99.496 avegare return across last 100 episodes: -99.496 state values: tensor(0.7487) 1000
2 1000 -1000.0 -99.99568287525881 number episode from 10: 2 avegar over 10 episode: -99.662 avegare return across last 100 episodes: -99.662 state values: tensor(0.7457) 1000
3 1000 -1000.0 -99.99568287525881 number episode from 10: 3 avegar over 10 episode: -99.746 avegare return across last 100 episodes: -99.746 state values: tensor(0.7473) 1000
4 1000 -1000.0 -99.99568287525881 number episode from 10: 4 avegar over 10 episode: -99.796 avegare return across last 100 episodes: -99.796 state values: tensor(0.7492) 1000
5 1000 -1000.0 -99.99568287525881 number episode from 10: 5 avegar over 10 episode: -99.829 avegare return across last 100 episodes: -99.829 state values: tensor(0.6453) 1000
6 1000 -1000.0 -99.99568287525881 number episode from 10: 6 avegar over 10 episode: -99.853 avegare return across last 100 episodes: -99.853 state values: tensor(0.7484) 1000
7 1000 -1000.0 -99.99568287525881 number episode from 10: 7 avegar over 10 episode: -99.871 avegare return across last 100 episodes: -99.871 state values: tensor(0.7497) 1000
8 1000 -1000.0 -99.99568287525881 number episode from 10: 8 avegar over 10 episode: -99.885 avegare return across last 100 episodes: -99.885 state values: tensor(0.7487) 1000
9 1000 -1000.0 -99.99568287525881 number episode from 10: 9 avegar over 10 episode: -99.896 avegare return across last 100 episodes: -99.896 state values: tensor(0.6478) 1000
10 1000 -1000.0 -99.99568287525881 number episode from 10: 10 avegar over 10 episode: -99.905 avegare return across last 100 episodes: -99.905 state values: tensor(0.7499) 1000
11 1000 -1000.0 -99.99568287525881 number episode from 10: 11 avegar over 10 episode: -99.912 avegare return across last 100 episodes: -99.912 state values: tensor(0.7443) 1000
12 1000 -1000.0 -99.99568287525881 number episode from 10: 12 avegar over 10 episode: -99.919 avegare return across last 100 episodes: -99.919 state values: tensor(0.7472) 1000
13 1000 -1000.0 -99.99568287525881 number episode from 10: 13 avegar over 10 episode: -99.924 avegare return across last 100 episodes: -99.924 state values: tensor(0.7492) 1000
14 1000 -1000.0 -99.99568287525881 number episode from 10: 14 avegar over 10 episode: -99.929 avegare return across last 100 episodes: -99.929 state values: tensor(0.6456) 1000
15 1000 -1000.0 -99.99568287525881 number episode from 10: 15 avegar over 10 episode: -99.933 avegare return across last 100 episodes: -99.933 state values: tensor(0.7504) 1000
16 1000 -1000.0 -99.99568287525881 number episode from 10: 16 avegar over 10 episode: -99.937 avegare return across last 100 episodes: -99.937 state values: tensor(0.7220) 1000
17 1000 -1000.0 -99.99568287525881 number episode from 10: 17 avegar over 10 episode: -99.94 avegare return across last 100 episodes: -99.94 state values: tensor(0.7473) 1000
18 1000 -1000.0 -99.99568287525881 number episode from 10: 18 avegar over 10 episode: -99.943 avegare return across last 100 episodes: -99.943 state values: tensor(0.7454) 1000
19 1000 -1000.0 -99.99568287525881 number episode from 10: 19 avegar over 10 episode: -99.946 avegare return across last 100 episodes: -99.946 state values: tensor(0.6468) 1000
20 1000 -1000.0 -99.99568287525881 number episode from 10: 20 avegar over 10 episode: -99.948 avegare return across last 100 episodes: -99.948 state values: tensor(0.7475) 1000
21 1000 -1000.0 -99.99568287525881 number episode from 10: 21 avegar over 10 episode: -99.95 avegare return across last 100 episodes: -99.95 state values: tensor(0.6742) 1000
22 1000 -1000.0 -99.99568287525881 number episode from 10: 22 avegar over 10 episode: -99.952 avegare return across last 100 episodes: -99.952 state values: tensor(0.6474) 1000
23 1000 -1000.0 -99.99568287525881 number episode from 10: 23 avegar over 10 episode: -99.954 avegare return across last 100 episodes: -99.954 state values: tensor(0.7515) 1000
24 1000 -1000.0 -99.99568287525881 number episode from 10: 24 avegar over 10 episode: -99.956 avegare return across last 100 episodes: -99.956 state values: tensor(0.6477) 1000
25 1000 -1000.0 -99.99568287525881 number episode from 10: 25 avegar over 10 episode: -99.957 avegare return across last 100 episodes: -99.957 state values: tensor(0.7476) 1000
26 1000 -1000.0 -99.99568287525881 number episode from 10: 26 avegar over 10 episode: -99.959 avegare return across last 100 episodes: -99.959 state values: tensor(0.7485) 1000
27 1000 -1000.0 -99.99568287525881 number episode from 10: 27 avegar over 10 episode: -99.96 avegare return across last 100 episodes: -99.96 state values: tensor(0.7477) 1000
28 1000 -1000.0 -99.99568287525881 number episode from 10: 28 avegar over 10 episode: -99.961 avegare return across last 100 episodes: -99.961 state values: tensor(0.6458) 1000
29 1000 -1000.0 -99.99568287525881 number episode from 10: 29 avegar over 10 episode: -99.962 avegare return across last 100 episodes: -99.962 state values: tensor(0.6453) 1000
30 1000 -1000.0 -99.99568287525881 number episode from 10: 30 avegar over 10 episode: -99.963 avegare return across last 100 episodes: -99.963 state values: tensor(0.7437) 1000
31 1000 -1000.0 -99.99568287525881 number episode from 10: 31 avegar over 10 episode: -99.964 avegare return across last 100 episodes: -99.964 state values: tensor(0.7472) 1000
32 1000 -1000.0 -99.99568287525881 number episode from 10: 32 avegar over 10 episode: -99.965 avegare return across last 100 episodes: -99.965 state values: tensor(0.7437) 1000
33 1000 -1000.0 -99.99568287525881 number episode from 10: 33 avegar over 10 episode: -99.966 avegare return across last 100 episodes: -99.966 state values: tensor(0.7463) 1000
34 1000 -1000.0 -99.99568287525881 number episode from 10: 34 avegar over 10 episode: -99.967 avegare return across last 100 episodes: -99.967 state values: tensor(0.7459) 1000
35 1000 -1000.0 -99.99568287525881 number episode from 10: 35 avegar over 10 episode: -99.968 avegare return across last 100 episodes: -99.968 state values: tensor(0.7485) 1000
36 1000 -1000.0 -99.99568287525881 number episode from 10: 36 avegar over 10 episode: -99.969 avegare return across last 100 episodes: -99.969 state values: tensor(0.6458) 1000
37 1000 -1000.0 -99.99568287525881 number episode from 10: 37 avegar over 10 episode: -99.969 avegare return across last 100 episodes: -99.969 state values: tensor(0.7460) 1000
38 1000 -1000.0 -99.99568287525881 number episode from 10: 38 avegar over 10 episode: -99.97 avegare return across last 100 episodes: -99.97 state values: tensor(0.7472) 1000
39 1000 -1000.0 -99.99568287525881 number episode from 10: 39 avegar over 10 episode: -99.971 avegare return across last 100 episodes: -99.971 state values: tensor(0.7434) 1000
40 1000 -1000.0 -99.99568287525881 number episode from 10: 40 avegar over 10 episode: -99.971 avegare return across last 100 episodes: -99.971 state values: tensor(0.6657) 1000
41 1000 -1000.0 -99.99568287525881 number episode from 10: 41 avegar over 10 episode: -99.972 avegare return across last 100 episodes: -99.972 state values: tensor(0.6482) 1000
42 1000 -1000.0 -99.99568287525881 number episode from 10: 42 avegar over 10 episode: -99.972 avegare return across last 100 episodes: -99.972 state values: tensor(0.7467) 1000
43 1000 -1000.0 -99.99568287525881 number episode from 10: 43 avegar over 10 episode: -99.973 avegare return across last 100 episodes: -99.973 state values: tensor(0.6588) 1000
44 1000 -1000.0 -99.99568287525881 number episode from 10: 44 avegar over 10 episode: -99.973 avegare return across last 100 episodes: -99.973 state values: tensor(0.6458) 1000
45 1000 -1000.0 -99.99568287525881 number episode from 10: 45 avegar over 10 episode: -99.974 avegare return across last 100 episodes: -99.974 state values: tensor(0.6668) 1000
46 1000 -1000.0 -99.99568287525881 number episode from 10: 46 avegar over 10 episode: -99.974 avegare return across last 100 episodes: -99.974 state values: tensor(0.6459) 1000
47 1000 -1000.0 -99.99568287525881 number episode from 10: 47 avegar over 10 episode: -99.975 avegare return across last 100 episodes: -99.975 state values: tensor(0.7435) 1000
48 1000 -1000.0 -99.99568287525881 number episode from 10: 48 avegar over 10 episode: -99.975 avegare return across last 100 episodes: -99.975 state values: tensor(0.7474) 1000
49 1000 -1000.0 -99.99568287525881 number episode from 10: 49 avegar over 10 episode: -99.976 avegare return across last 100 episodes: -99.976 state values: tensor(0.6466) 1000
50 1000 -1000.0 -99.99568287525881 number episode from 10: 50 avegar over 10 episode: -99.976 avegare return across last 100 episodes: -99.976 state values: tensor(0.6458) 1000
51 1000 -1000.0 -99.99568287525881 number episode from 10: 51 avegar over 10 episode: -99.976 avegare return across last 100 episodes: -99.976 state values: tensor(0.7467) 1000
52 1000 -1000.0 -99.99568287525881 number episode from 10: 52 avegar over 10 episode: -99.977 avegare return across last 100 episodes: -99.977 state values: tensor(0.6928) 1000
53 1000 -1000.0 -99.99568287525881 number episode from 10: 53 avegar over 10 episode: -99.977 avegare return across last 100 episodes: -99.977 state values: tensor(0.7442) 1000
54 1000 -1000.0 -99.99568287525881 number episode from 10: 54 avegar over 10 episode: -99.978 avegare return across last 100 episodes: -99.978 state values: tensor(0.7463) 1000
55 1000 -1000.0 -99.99568287525881 number episode from 10: 55 avegar over 10 episode: -99.978 avegare return across last 100 episodes: -99.978 state values: tensor(0.7483) 1000
56 1000 -1000.0 -99.99568287525881 number episode from 10: 56 avegar over 10 episode: -99.978 avegare return across last 100 episodes: -99.978 state values: tensor(0.6568) 1000
57 1000 -1000.0 -99.99568287525881 number episode from 10: 57 avegar over 10 episode: -99.978 avegare return across last 100 episodes: -99.978 state values: tensor(0.7484) 1000
58 1000 -1000.0 -99.99568287525881 number episode from 10: 58 avegar over 10 episode: -99.979 avegare return across last 100 episodes: -99.979 state values: tensor(0.7461) 1000
59 1000 -1000.0 -99.99568287525881 number episode from 10: 59 avegar over 10 episode: -99.979 avegare return across last 100 episodes: -99.979 state values: tensor(0.6459) 1000
60 1000 -1000.0 -99.99568287525881 number episode from 10: 60 avegar over 10 episode: -99.979 avegare return across last 100 episodes: -99.979 state values: tensor(0.6457) 1000
61 1000 -1000.0 -99.99568287525881 number episode from 10: 61 avegar over 10 episode: -99.98 avegare return across last 100 episodes: -99.98 state values: tensor(0.7465) 1000
62 1000 -1000.0 -99.99568287525881 number episode from 10: 62 avegar over 10 episode: -99.98 avegare return across last 100 episodes: -99.98 state values: tensor(0.7468) 1000
63 1000 -1000.0 -99.99568287525881 number episode from 10: 63 avegar over 10 episode: -99.98 avegare return across last 100 episodes: -99.98 state values: tensor(0.7431) 1000
64 1000 -1000.0 -99.99568287525881 number episode from 10: 64 avegar over 10 episode: -99.98 avegare return across last 100 episodes: -99.98 state values: tensor(0.7439) 1000
65 1000 -1000.0 -99.99568287525881 number episode from 10: 65 avegar over 10 episode: -99.981 avegare return across last 100 episodes: -99.981 state values: tensor(0.7499) 1000
66 1000 -1000.0 -99.99568287525881 number episode from 10: 66 avegar over 10 episode: -99.981 avegare return across last 100 episodes: -99.981 state values: tensor(0.7263) 1000
67 1000 -1000.0 -99.99568287525881 number episode from 10: 67 avegar over 10 episode: -99.981 avegare return across last 100 episodes: -99.981 state values: tensor(0.6457) 1000
68 1000 -1000.0 -99.99568287525881 number episode from 10: 68 avegar over 10 episode: -99.981 avegare return across last 100 episodes: -99.981 state values: tensor(0.6989) 1000
69 1000 -1000.0 -99.99568287525881 number episode from 10: 69 avegar over 10 episode: -99.981 avegare return across last 100 episodes: -99.981 state values: tensor(0.7454) 1000
70 1000 -1000.0 -99.99568287525881 number episode from 10: 70 avegar over 10 episode: -99.982 avegare return across last 100 episodes: -99.982 state values: tensor(0.6511) 1000
71 1000 -1000.0 -99.99568287525881 number episode from 10: 71 avegar over 10 episode: -99.982 avegare return across last 100 episodes: -99.982 state values: tensor(0.6466) 1000
72 1000 -1000.0 -99.99568287525881 number episode from 10: 72 avegar over 10 episode: -99.982 avegare return across last 100 episodes: -99.982 state values: tensor(0.7484) 1000
73 1000 -1000.0 -99.99568287525881 number episode from 10: 73 avegar over 10 episode: -99.982 avegare return across last 100 episodes: -99.982 state values: tensor(0.7425) 1000
74 1000 -1000.0 -99.99568287525881 number episode from 10: 74 avegar over 10 episode: -99.982 avegare return across last 100 episodes: -99.982 state values: tensor(0.7473) 1000
75 1000 -1000.0 -99.99568287525881 number episode from 10: 75 avegar over 10 episode: -99.983 avegare return across last 100 episodes: -99.983 state values: tensor(0.6471) 1000
76 1000 -1000.0 -99.99568287525881 number episode from 10: 76 avegar over 10 episode: -99.983 avegare return across last 100 episodes: -99.983 state values: tensor(0.6461) 1000
77 1000 -1000.0 -99.99568287525881 number episode from 10: 77 avegar over 10 episode: -99.983 avegare return across last 100 episodes: -99.983 state values: tensor(0.6488) 1000
78 1000 -1000.0 -99.99568287525881 number episode from 10: 78 avegar over 10 episode: -99.983 avegare return across last 100 episodes: -99.983 state values: tensor(0.6459) 1000
79 1000 -1000.0 -99.99568287525881 number episode from 10: 79 avegar over 10 episode: -99.983 avegare return across last 100 episodes: -99.983 state values: tensor(0.6745) 1000
80 1000 -1000.0 -99.99568287525881 number episode from 10: 80 avegar over 10 episode: -99.983 avegare return across last 100 episodes: -99.983 state values: tensor(0.7490) 1000
81 1000 -1000.0 -99.99568287525881 number episode from 10: 81 avegar over 10 episode: -99.983 avegare return across last 100 episodes: -99.983 state values: tensor(0.7475) 1000
82 1000 -1000.0 -99.99568287525881 number episode from 10: 82 avegar over 10 episode: -99.984 avegare return across last 100 episodes: -99.984 state values: tensor(0.7504) 1000
83 1000 -1000.0 -99.99568287525881 number episode from 10: 83 avegar over 10 episode: -99.984 avegare return across last 100 episodes: -99.984 state values: tensor(0.6473) 1000
84 1000 -1000.0 -99.99568287525881 number episode from 10: 84 avegar over 10 episode: -99.984 avegare return across last 100 episodes: -99.984 state values: tensor(0.7445) 1000
85 1000 -1000.0 -99.99568287525881 number episode from 10: 85 avegar over 10 episode: -99.984 avegare return across last 100 episodes: -99.984 state values: tensor(0.6451) 1000
86 1000 -1000.0 -99.99568287525881 number episode from 10: 86 avegar over 10 episode: -99.984 avegare return across last 100 episodes: -99.984 state values: tensor(0.7463) 1000
87 1000 -1000.0 -99.99568287525881 number episode from 10: 87 avegar over 10 episode: -99.984 avegare return across last 100 episodes: -99.984 state values: tensor(0.6757) 1000
88 1000 -1000.0 -99.99568287525881 number episode from 10: 88 avegar over 10 episode: -99.984 avegare return across last 100 episodes: -99.984 state values: tensor(0.6931) 1000
89 1000 -1000.0 -99.99568287525881 number episode from 10: 89 avegar over 10 episode: -99.985 avegare return across last 100 episodes: -99.985 state values: tensor(0.6451) 1000
90 1000 -1000.0 -99.99568287525881 number episode from 10: 90 avegar over 10 episode: -99.985 avegare return across last 100 episodes: -99.985 state values: tensor(0.7419) 1000
91 1000 -1000.0 -99.99568287525881 number episode from 10: 91 avegar over 10 episode: -99.985 avegare return across last 100 episodes: -99.985 state values: tensor(0.7438) 1000
92 1000 -1000.0 -99.99568287525881 number episode from 10: 92 avegar over 10 episode: -99.985 avegare return across last 100 episodes: -99.985 state values: tensor(0.7448) 1000
93 1000 -1000.0 -99.99568287525881 number episode from 10: 93 avegar over 10 episode: -99.985 avegare return across last 100 episodes: -99.985 state values: tensor(0.7463) 1000
94 1000 -1000.0 -99.99568287525881 number episode from 10: 94 avegar over 10 episode: -99.985 avegare return across last 100 episodes: -99.985 state values: tensor(0.6460) 1000
95 1000 -1000.0 -99.99568287525881 number episode from 10: 95 avegar over 10 episode: -99.985 avegare return across last 100 episodes: -99.985 state values: tensor(0.7454) 1000
96 1000 -1000.0 -99.99568287525881 number episode from 10: 96 avegar over 10 episode: -99.985 avegare return across last 100 episodes: -99.985 state values: tensor(0.6457) 1000
97 1000 -1000.0 -99.99568287525881 number episode from 10: 97 avegar over 10 episode: -99.985 avegare return across last 100 episodes: -99.985 state values: tensor(0.7443) 1000
98 1000 -1000.0 -99.99568287525881 number episode from 10: 98 avegar over 10 episode: -99.986 avegare return across last 100 episodes: -99.986 state values: tensor(0.6451) 1000
99 1000 -1000.0 -99.99568287525881 number episode from 10: 99 avegar over 10 episode: -99.986 avegare return across last 100 episodes: -99.986 state values: tensor(0.6488) 1000
100 1000 -1000.0 -99.99568287525881 number episode from 10: 100 avegar over 10 episode: -99.986 avegare return across last 100 episodes: -99.996 state values: tensor(0.6453) 1000
101 1000 -1000.0 -99.99568287525881 number episode from 10: 101 avegar over 10 episode: -99.986 avegare return across last 100 episodes: -99.996 state values: tensor(0.6467) 1000
102 1000 -1000.0 -99.99568287525881 number episode from 10: 102 avegar over 10 episode: -99.986 avegare return across last 100 episodes: -99.996 state values: tensor(0.7443) 1000
103 1000 -1000.0 -99.99568287525881 number episode from 10: 103 avegar over 10 episode: -99.986 avegare return across last 100 episodes: -99.996 state values: tensor(0.6741) 1000
104 1000 -1000.0 -99.99568287525881 number episode from 10: 104 avegar over 10 episode: -99.986 avegare return across last 100 episodes: -99.996 state values: tensor(0.7492) 1000
105 1000 -1000.0 -99.99568287525881 number episode from 10: 105 avegar over 10 episode: -99.986 avegare return across last 100 episodes: -99.996 state values: tensor(0.7523) 1000
106 1000 -1000.0 -99.99568287525881 number episode from 10: 106 avegar over 10 episode: -99.986 avegare return across last 100 episodes: -99.996 state values: tensor(0.7427) 1000
107 1000 -1000.0 -99.99568287525881 number episode from 10: 107 avegar over 10 episode: -99.986 avegare return across last 100 episodes: -99.996 state values: tensor(0.7062) 1000
108 1000 -1000.0 -99.99568287525881 number episode from 10: 108 avegar over 10 episode: -99.987 avegare return across last 100 episodes: -99.996 state values: tensor(0.6471) 1000
109 1000 -1000.0 -99.99568287525881 number episode from 10: 109 avegar over 10 episode: -99.987 avegare return across last 100 episodes: -99.996 state values: tensor(0.7470) 1000
110 1000 -1000.0 -99.99568287525881 number episode from 10: 110 avegar over 10 episode: -99.987 avegare return across last 100 episodes: -99.996 state values: tensor(0.7489) 1000
111 1000 -1000.0 -99.99568287525881 number episode from 10: 111 avegar over 10 episode: -99.987 avegare return across last 100 episodes: -99.996 state values: tensor(0.7460) 1000
112 1000 -1000.0 -99.99568287525881 number episode from 10: 112 avegar over 10 episode: -99.987 avegare return across last 100 episodes: -99.996 state values: tensor(0.7425) 1000
113 1000 -1000.0 -99.99568287525881 number episode from 10: 113 avegar over 10 episode: -99.987 avegare return across last 100 episodes: -99.996 state values: tensor(0.6463) 1000
114 1000 -1000.0 -99.99568287525881 number episode from 10: 114 avegar over 10 episode: -99.987 avegare return across last 100 episodes: -99.996 state values: tensor(0.6592) 1000
115 1000 -1000.0 -99.99568287525881 number episode from 10: 115 avegar over 10 episode: -99.987 avegare return across last 100 episodes: -99.996 state values: tensor(0.7510) 1000
116 1000 -1000.0 -99.99568287525881 number episode from 10: 116 avegar over 10 episode: -99.987 avegare return across last 100 episodes: -99.996 state values: tensor(0.6452) 1000
117 1000 -1000.0 -99.99568287525881 number episode from 10: 117 avegar over 10 episode: -99.987 avegare return across last 100 episodes: -99.996 state values: tensor(0.7491) 1000
118 1000 -1000.0 -99.99568287525881 number episode from 10: 118 avegar over 10 episode: -99.987 avegare return across last 100 episodes: -99.996 state values: tensor(0.6459) 1000
119 1000 -1000.0 -99.99568287525881 number episode from 10: 119 avegar over 10 episode: -99.987 avegare return across last 100 episodes: -99.996 state values: tensor(0.7458) 1000
120 1000 -1000.0 -99.99568287525881 number episode from 10: 120 avegar over 10 episode: -99.987 avegare return across last 100 episodes: -99.996 state values: tensor(0.6466) 1000
121 1000 -1000.0 -99.99568287525881 number episode from 10: 121 avegar over 10 episode: -99.987 avegare return across last 100 episodes: -99.996 state values: tensor(0.7451) 1000
122 1000 -1000.0 -99.99568287525881 number episode from 10: 122 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.7460) 1000
123 1000 -1000.0 -99.99568287525881 number episode from 10: 123 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.7483) 1000
124 1000 -1000.0 -99.99568287525881 number episode from 10: 124 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.7456) 1000
125 1000 -1000.0 -99.99568287525881 number episode from 10: 125 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.7494) 1000
126 1000 -1000.0 -99.99568287525881 number episode from 10: 126 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.7474) 1000
127 1000 -1000.0 -99.99568287525881 number episode from 10: 127 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.7475) 1000
128 1000 -1000.0 -99.99568287525881 number episode from 10: 128 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.7451) 1000
129 1000 -1000.0 -99.99568287525881 number episode from 10: 129 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.7487) 1000
130 1000 -1000.0 -99.99568287525881 number episode from 10: 130 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.7485) 1000
131 1000 -1000.0 -99.99568287525881 number episode from 10: 131 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.7488) 1000
132 1000 -1000.0 -99.99568287525881 number episode from 10: 132 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.7496) 1000
133 1000 -1000.0 -99.99568287525881 number episode from 10: 133 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.6452) 1000
134 1000 -1000.0 -99.99568287525881 number episode from 10: 134 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.7463) 1000
135 1000 -1000.0 -99.99568287525881 number episode from 10: 135 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.7497) 1000
136 1000 -1000.0 -99.99568287525881 number episode from 10: 136 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.7494) 1000
137 1000 -1000.0 -99.99568287525881 number episode from 10: 137 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.7514) 1000
138 1000 -1000.0 -99.99568287525881 number episode from 10: 138 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.6996) 1000
139 1000 -1000.0 -99.99568287525881 number episode from 10: 139 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.7447) 1000
140 1000 -1000.0 -99.99568287525881 number episode from 10: 140 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.7483) 1000
141 1000 -1000.0 -99.99568287525881 number episode from 10: 141 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.7485) 1000
142 1000 -1000.0 -99.99568287525881 number episode from 10: 142 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.7459) 1000
143 1000 -1000.0 -99.99568287525881 number episode from 10: 143 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.6460) 1000
144 1000 -1000.0 -99.99568287525881 number episode from 10: 144 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.7455) 1000
145 1000 -1000.0 -99.99568287525881 number episode from 10: 145 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.7493) 1000
146 1000 -1000.0 -99.99568287525881 number episode from 10: 146 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.7501) 1000
147 1000 -1000.0 -99.99568287525881 number episode from 10: 147 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.7506) 1000
148 1000 -1000.0 -99.99568287525881 number episode from 10: 148 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.7486) 1000
149 1000 -1000.0 -99.99568287525881 number episode from 10: 149 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.7454) 1000
150 1000 -1000.0 -99.99568287525881 number episode from 10: 150 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.7477) 1000
151 1000 -1000.0 -99.99568287525881 number episode from 10: 151 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.7456) 1000
152 1000 -1000.0 -99.99568287525881 number episode from 10: 152 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.7490) 1000
153 1000 -1000.0 -99.99568287525881 number episode from 10: 153 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.6467) 1000
154 1000 -1000.0 -99.99568287525881 number episode from 10: 154 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.7171) 1000
155 1000 -1000.0 -99.99568287525881 number episode from 10: 155 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.7457) 1000
156 1000 -1000.0 -99.99568287525881 number episode from 10: 156 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.6456) 1000
157 1000 -1000.0 -99.99568287525881 number episode from 10: 157 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.6530) 1000
158 1000 -1000.0 -99.99568287525881 number episode from 10: 158 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.7457) 1000
159 1000 -1000.0 -99.99568287525881 number episode from 10: 159 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.6471) 1000
160 1000 -1000.0 -99.99568287525881 number episode from 10: 160 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.6459) 1000
161 1000 -1000.0 -99.99568287525881 number episode from 10: 161 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.6464) 1000
162 1000 -1000.0 -99.99568287525881 number episode from 10: 162 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.7183) 1000
163 1000 -1000.0 -99.99568287525881 number episode from 10: 163 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.7483) 1000
164 1000 -1000.0 -99.99568287525881 number episode from 10: 164 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.7489) 1000
165 1000 -1000.0 -99.99568287525881 number episode from 10: 165 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.6455) 1000
166 1000 -1000.0 -99.99568287525881 number episode from 10: 166 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.7474) 1000
167 1000 -1000.0 -99.99568287525881 number episode from 10: 167 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.6467) 1000
168 1000 -1000.0 -99.99568287525881 number episode from 10: 168 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.6458) 1000
169 1000 -1000.0 -99.99568287525881 number episode from 10: 169 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.6472) 1000
170 1000 -1000.0 -99.99568287525881 number episode from 10: 170 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.7495) 1000
171 1000 -1000.0 -99.99568287525881 number episode from 10: 171 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.7461) 1000
172 1000 -1000.0 -99.99568287525881 number episode from 10: 172 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.7489) 1000
173 1000 -1000.0 -99.99568287525881 number episode from 10: 173 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.6487) 1000
174 1000 -1000.0 -99.99568287525881 number episode from 10: 174 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.7485) 1000
175 1000 -1000.0 -99.99568287525881 number episode from 10: 175 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.6457) 1000
176 1000 -1000.0 -99.99568287525881 number episode from 10: 176 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.7450) 1000
177 1000 -1000.0 -99.99568287525881 number episode from 10: 177 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.7453) 1000
178 1000 -1000.0 -99.99568287525881 number episode from 10: 178 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.7438) 1000
179 1000 -1000.0 -99.99568287525881 number episode from 10: 179 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.7492) 1000
180 1000 -1000.0 -99.99568287525881 number episode from 10: 180 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.6452) 1000
181 1000 -1000.0 -99.99568287525881 number episode from 10: 181 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.7488) 1000
182 1000 -1000.0 -99.99568287525881 number episode from 10: 182 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.6456) 1000
183 1000 -1000.0 -99.99568287525881 number episode from 10: 183 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.7462) 1000
184 1000 -1000.0 -99.99568287525881 number episode from 10: 184 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.7452) 1000
185 1000 -1000.0 -99.99568287525881 number episode from 10: 185 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.7476) 1000
186 1000 -1000.0 -99.99568287525881 number episode from 10: 186 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.6459) 1000
187 1000 -1000.0 -99.99568287525881 number episode from 10: 187 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.6458) 1000
188 1000 -1000.0 -99.99568287525881 number episode from 10: 188 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.7473) 1000
189 1000 -1000.0 -99.99568287525881 number episode from 10: 189 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.7427) 1000
190 1000 -1000.0 -99.99568287525881 number episode from 10: 190 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.7492) 1000
191 1000 -1000.0 -99.99568287525881 number episode from 10: 191 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.7466) 1000
192 1000 -1000.0 -99.99568287525881 number episode from 10: 192 avegar over 10 episode: -99.991 avegare return across last 100 episodes: -99.996 state values: tensor(0.6463) 1000
193 1000 -1000.0 -99.99568287525881 number episode from 10: 193 avegar over 10 episode: -99.991 avegare return across last 100 episodes: -99.996 state values: tensor(0.7439) 1000
194 1000 -1000.0 -99.99568287525881 number episode from 10: 194 avegar over 10 episode: -99.991 avegare return across last 100 episodes: -99.996 state values: tensor(0.7499) 1000
195 1000 -1000.0 -99.99568287525881 number episode from 10: 195 avegar over 10 episode: -99.991 avegare return across last 100 episodes: -99.996 state values: tensor(0.7472) 1000
196 1000 -1000.0 -99.99568287525881 number episode from 10: 196 avegar over 10 episode: -99.991 avegare return across last 100 episodes: -99.996 state values: tensor(0.6469) 1000
197 1000 -1000.0 -99.99568287525881 number episode from 10: 197 avegar over 10 episode: -99.991 avegare return across last 100 episodes: -99.996 state values: tensor(0.7464) 1000
198 1000 -1000.0 -99.99568287525881 number episode from 10: 198 avegar over 10 episode: -99.991 avegare return across last 100 episodes: -99.996 state values: tensor(0.6456) 1000
199 1000 -1000.0 -99.99568287525881 number episode from 10: 199 avegar over 10 episode: -99.991 avegare return across last 100 episodes: -99.996 state values: tensor(0.7486) 1000
200 1000 -1000.0 -99.99568287525881 number episode from 10: 200 avegar over 10 episode: -99.991 avegare return across last 100 episodes: -99.996 state values: tensor(0.7461) 1000
load offline data!!!!!
mem_cntr: 50000 ; mem_size: 50000
nn.learn_nn_feature_fqi FQI:  998
nn.learn_nn_feature_fqi FQI:  1998
nn.learn_nn_feature_fqi FQI:  2998
nn.learn_nn_feature_fqi FQI:  3998
nn.learn_nn_feature_fqi FQI:  4998
nn.learn_nn_feature_fqi FQI:  5998
nn.learn_nn_feature_fqi FQI:  6998
nn.learn_nn_feature_fqi FQI:  7998
nn.learn_nn_feature_fqi FQI:  8998
nn.learn_nn_feature_fqi FQI:  9998
nn.learn_nn_feature_fqi FQI:  10998
nn.learn_nn_feature_fqi FQI:  11998
nn.learn_nn_feature_fqi FQI:  12998
nn.learn_nn_feature_fqi FQI:  13998
nn.learn_nn_feature_fqi FQI:  14998
nn.learn_nn_feature_fqi FQI:  15998
nn.learn_nn_feature_fqi FQI:  16998
nn.learn_nn_feature_fqi FQI:  17998
nn.learn_nn_feature_fqi FQI:  18998
nn.learn_nn_feature_fqi FQI:  19998
nn.learn_nn_feature_fqi FQI:  20998
nn.learn_nn_feature_fqi FQI:  21998
nn.learn_nn_feature_fqi FQI:  22998
nn.learn_nn_feature_fqi FQI:  23998
nn.learn_nn_feature_fqi FQI:  24998
nn.learn_nn_feature_fqi FQI:  25998
nn.learn_nn_feature_fqi FQI:  26998
nn.learn_nn_feature_fqi FQI:  27998
nn.learn_nn_feature_fqi FQI:  28998
nn.learn_nn_feature_fqi FQI:  29998
nn.learn_nn_feature_fqi FQI:  30998
nn.learn_nn_feature_fqi FQI:  31998
nn.learn_nn_feature_fqi FQI:  32998
nn.learn_nn_feature_fqi FQI:  33998
nn.learn_nn_feature_fqi FQI:  34998
nn.learn_nn_feature_fqi FQI:  35998
nn.learn_nn_feature_fqi FQI:  36998
nn.learn_nn_feature_fqi FQI:  37998
nn.learn_nn_feature_fqi FQI:  38998
nn.learn_nn_feature_fqi FQI:  39998
nn.learn_nn_feature_fqi FQI:  40998
nn.learn_nn_feature_fqi FQI:  41998
nn.learn_nn_feature_fqi FQI:  42998
nn.learn_nn_feature_fqi FQI:  43998
nn.learn_nn_feature_fqi FQI:  44998
nn.learn_nn_feature_fqi FQI:  45998
nn.learn_nn_feature_fqi FQI:  46998
nn.learn_nn_feature_fqi FQI:  47998
nn.learn_nn_feature_fqi FQI:  48998
nn.learn_nn_feature_fqi FQI:  49998
nn.learn_nn_feature_fqi FQI:  50998
nn.learn_nn_feature_fqi FQI:  51998
nn.learn_nn_feature_fqi FQI:  52998
nn.learn_nn_feature_fqi FQI:  53998
nn.learn_nn_feature_fqi FQI:  54998
nn.learn_nn_feature_fqi FQI:  55998
nn.learn_nn_feature_fqi FQI:  56998
nn.learn_nn_feature_fqi FQI:  57998
nn.learn_nn_feature_fqi FQI:  58998
nn.learn_nn_feature_fqi FQI:  59998
nn.learn_nn_feature_fqi FQI:  60998
nn.learn_nn_feature_fqi FQI:  61998
nn.learn_nn_feature_fqi FQI:  62998
nn.learn_nn_feature_fqi FQI:  63998
nn.learn_nn_feature_fqi FQI:  64998
nn.learn_nn_feature_fqi FQI:  65998
nn.learn_nn_feature_fqi FQI:  66998
nn.learn_nn_feature_fqi FQI:  67998
nn.learn_nn_feature_fqi FQI:  68998
nn.learn_nn_feature_fqi FQI:  69998
nn.learn_nn_feature_fqi FQI:  70998
nn.learn_nn_feature_fqi FQI:  71998
nn.learn_nn_feature_fqi FQI:  72998
nn.learn_nn_feature_fqi FQI:  73998
nn.learn_nn_feature_fqi FQI:  74998
nn.learn_nn_feature_fqi FQI:  75998
nn.learn_nn_feature_fqi FQI:  76998
nn.learn_nn_feature_fqi FQI:  77998
nn.learn_nn_feature_fqi FQI:  78998
nn.learn_nn_feature_fqi FQI:  79998
nn.learn_nn_feature_fqi FQI:  80998
nn.learn_nn_feature_fqi FQI:  81998
nn.learn_nn_feature_fqi FQI:  82998
nn.learn_nn_feature_fqi FQI:  83998
nn.learn_nn_feature_fqi FQI:  84998
nn.learn_nn_feature_fqi FQI:  85998
nn.learn_nn_feature_fqi FQI:  86998
nn.learn_nn_feature_fqi FQI:  87998
nn.learn_nn_feature_fqi FQI:  88998
nn.learn_nn_feature_fqi FQI:  89998
nn.learn_nn_feature_fqi FQI:  90998
nn.learn_nn_feature_fqi FQI:  91998
nn.learn_nn_feature_fqi FQI:  92998
nn.learn_nn_feature_fqi FQI:  93998
nn.learn_nn_feature_fqi FQI:  94998
nn.learn_nn_feature_fqi FQI:  95998
nn.learn_nn_feature_fqi FQI:  96998
nn.learn_nn_feature_fqi FQI:  97998
nn.learn_nn_feature_fqi FQI:  98998
nn.learn_nn_feature_fqi FQI:  99998
nn.learn_nn_feature_fqi FQI:  100998
nn.learn_nn_feature_fqi FQI:  101998
nn.learn_nn_feature_fqi FQI:  102998
nn.learn_nn_feature_fqi FQI:  103998
nn.learn_nn_feature_fqi FQI:  104998
nn.learn_nn_feature_fqi FQI:  105998
nn.learn_nn_feature_fqi FQI:  106998
nn.learn_nn_feature_fqi FQI:  107998
nn.learn_nn_feature_fqi FQI:  108998
nn.learn_nn_feature_fqi FQI:  109998
nn.learn_nn_feature_fqi FQI:  110998
nn.learn_nn_feature_fqi FQI:  111998
nn.learn_nn_feature_fqi FQI:  112998
nn.learn_nn_feature_fqi FQI:  113998
nn.learn_nn_feature_fqi FQI:  114998
nn.learn_nn_feature_fqi FQI:  115998
nn.learn_nn_feature_fqi FQI:  116998
nn.learn_nn_feature_fqi FQI:  117998
nn.learn_nn_feature_fqi FQI:  118998
nn.learn_nn_feature_fqi FQI:  119998
nn.learn_nn_feature_fqi FQI:  120998
nn.learn_nn_feature_fqi FQI:  121998
nn.learn_nn_feature_fqi FQI:  122998
nn.learn_nn_feature_fqi FQI:  123998
nn.learn_nn_feature_fqi FQI:  124998
nn.learn_nn_feature_fqi FQI:  125998
nn.learn_nn_feature_fqi FQI:  126998
nn.learn_nn_feature_fqi FQI:  127998
nn.learn_nn_feature_fqi FQI:  128998
nn.learn_nn_feature_fqi FQI:  129998
nn.learn_nn_feature_fqi FQI:  130998
nn.learn_nn_feature_fqi FQI:  131998
nn.learn_nn_feature_fqi FQI:  132998
nn.learn_nn_feature_fqi FQI:  133998
nn.learn_nn_feature_fqi FQI:  134998
nn.learn_nn_feature_fqi FQI:  135998
nn.learn_nn_feature_fqi FQI:  136998
nn.learn_nn_feature_fqi FQI:  137998
nn.learn_nn_feature_fqi FQI:  138998
nn.learn_nn_feature_fqi FQI:  139998
nn.learn_nn_feature_fqi FQI:  140998
nn.learn_nn_feature_fqi FQI:  141998
nn.learn_nn_feature_fqi FQI:  142998
nn.learn_nn_feature_fqi FQI:  143998
nn.learn_nn_feature_fqi FQI:  144998
nn.learn_nn_feature_fqi FQI:  145998
nn.learn_nn_feature_fqi FQI:  146998
nn.learn_nn_feature_fqi FQI:  147998
nn.learn_nn_feature_fqi FQI:  148998
nn.learn_nn_feature_fqi FQI:  149998
nn.learn_nn_feature_fqi FQI:  150998
nn.learn_nn_feature_fqi FQI:  151998
nn.learn_nn_feature_fqi FQI:  152998
nn.learn_nn_feature_fqi FQI:  153998
nn.learn_nn_feature_fqi FQI:  154998
nn.learn_nn_feature_fqi FQI:  155998
0 1001 -1000.0 -98.99572604650622 number episode from 10: 0 avegar over 10 episode: -98.996 avegare return across last 100 episodes: -98.996 state values: tensor(0.8968) 1000
1 1000 -1000.0 -99.99568287525881 number episode from 10: 1 avegar over 10 episode: -99.496 avegare return across last 100 episodes: -99.496 state values: tensor(0.6213) 1000
2 178 -178.0 -83.28660649851152 number episode from 10: 2 avegar over 10 episode: -94.093 avegare return across last 100 episodes: -94.093 state values: tensor(0.7449) 178
3 178 -178.0 -83.28660649851152 number episode from 10: 3 avegar over 10 episode: -91.391 avegare return across last 100 episodes: -91.391 state values: tensor(0.7361) 178
4 1000 -1000.0 -99.99568287525881 number episode from 10: 4 avegar over 10 episode: -93.112 avegare return across last 100 episodes: -93.112 state values: tensor(0.6223) 1000
5 1000 -1000.0 -99.99568287525881 number episode from 10: 5 avegar over 10 episode: -94.259 avegare return across last 100 episodes: -94.259 state values: tensor(0.8859) 1000
6 179 -179.0 -83.4537404335264 number episode from 10: 6 avegar over 10 episode: -92.716 avegare return across last 100 episodes: -92.716 state values: tensor(0.7461) 179
7 187 -187.0 -84.73202677240926 number episode from 10: 7 avegar over 10 episode: -91.718 avegare return across last 100 episodes: -91.718 state values: tensor(0.7456) 187
8 222 -222.0 -89.25977942573611 number episode from 10: 8 avegar over 10 episode: -91.445 avegare return across last 100 episodes: -91.445 state values: tensor(0.7250) 222
9 1000 -1000.0 -99.99568287525881 number episode from 10: 9 avegar over 10 episode: -92.3 avegare return across last 100 episodes: -92.3 state values: tensor(0.6233) 1000
10 242 -242.0 -91.21549908098504 number episode from 10: 10 avegar over 10 episode: -92.201 avegare return across last 100 episodes: -92.201 state values: tensor(0.7445) 242
11 470 -470.0 -99.11173722782941 number episode from 10: 11 avegar over 10 episode: -92.777 avegare return across last 100 episodes: -92.777 state values: tensor(0.6680) 470
12 1000 -1000.0 -99.99568287525881 number episode from 10: 12 avegar over 10 episode: -93.332 avegare return across last 100 episodes: -93.332 state values: tensor(0.6235) 1000
13 982 -982.0 -99.9948267782503 number episode from 10: 13 avegar over 10 episode: -93.808 avegare return across last 100 episodes: -93.808 state values: tensor(0.6469) 982
14 187 -187.0 -84.73202677240926 number episode from 10: 14 avegar over 10 episode: -93.203 avegare return across last 100 episodes: -93.203 state values: tensor(0.7456) 187
15 176 -176.0 -82.94725691104124 number episode from 10: 15 avegar over 10 episode: -92.562 avegare return across last 100 episodes: -92.562 state values: tensor(0.7328) 176
16 1000 -1000.0 -99.99568287525881 number episode from 10: 16 avegar over 10 episode: -92.999 avegare return across last 100 episodes: -92.999 state values: tensor(0.6212) 1000
17 1000 -1000.0 -99.99568287525881 number episode from 10: 17 avegar over 10 episode: -93.388 avegare return across last 100 episodes: -93.388 state values: tensor(0.6222) 1000
18 175 -175.0 -82.77500698084974 number episode from 10: 18 avegar over 10 episode: -92.83 avegare return across last 100 episodes: -92.83 state values: tensor(0.7347) 175
19 184 -184.0 -84.26467178922091 number episode from 10: 19 avegar over 10 episode: -92.401 avegare return across last 100 episodes: -92.401 state values: tensor(0.7449) 184
20 174 -174.0 -82.60101715237347 number episode from 10: 20 avegar over 10 episode: -91.935 avegare return across last 100 episodes: -91.935 state values: tensor(0.7379) 174
21 797 -797.0 -99.96679143615715 number episode from 10: 21 avegar over 10 episode: -92.3 avegare return across last 100 episodes: -92.3 state values: tensor(0.6513) 797
22 1000 -1000.0 -99.99568287525881 number episode from 10: 22 avegar over 10 episode: -92.634 avegare return across last 100 episodes: -92.634 state values: tensor(0.6217) 1000
23 1000 -1000.0 -99.99568287525881 number episode from 10: 23 avegar over 10 episode: -92.941 avegare return across last 100 episodes: -92.941 state values: tensor(0.6238) 1000
24 905 -905.0 -99.9887836614145 number episode from 10: 24 avegar over 10 episode: -93.223 avegare return across last 100 episodes: -93.223 state values: tensor(0.6444) 905
25 1000 -1000.0 -99.99568287525881 number episode from 10: 25 avegar over 10 episode: -93.483 avegare return across last 100 episodes: -93.483 state values: tensor(0.6211) 1000
26 182 -182.0 -83.94518088891023 number episode from 10: 26 avegar over 10 episode: -93.13 avegare return across last 100 episodes: -93.13 state values: tensor(0.7475) 182
27 1000 -1000.0 -99.99568287525881 number episode from 10: 27 avegar over 10 episode: -93.375 avegare return across last 100 episodes: -93.375 state values: tensor(0.6235) 1000
28 1000 -1000.0 -99.99568287525881 number episode from 10: 28 avegar over 10 episode: -93.604 avegare return across last 100 episodes: -93.604 state values: tensor(0.6229) 1000
29 1000 -1000.0 -99.99568287525881 number episode from 10: 29 avegar over 10 episode: -93.817 avegare return across last 100 episodes: -93.817 state values: tensor(0.6227) 1000
30 1000 -1000.0 -99.99568287525881 number episode from 10: 30 avegar over 10 episode: -94.016 avegare return across last 100 episodes: -94.016 state values: tensor(0.6215) 1000
31 1000 -1000.0 -99.99568287525881 number episode from 10: 31 avegar over 10 episode: -94.203 avegare return across last 100 episodes: -94.203 state values: tensor(0.6218) 1000
32 182 -182.0 -83.94518088891023 number episode from 10: 32 avegar over 10 episode: -93.892 avegare return across last 100 episodes: -93.892 state values: tensor(0.7481) 182
33 1000 -1000.0 -99.99568287525881 number episode from 10: 33 avegar over 10 episode: -94.072 avegare return across last 100 episodes: -94.072 state values: tensor(0.6218) 1000
34 184 -184.0 -84.26467178922091 number episode from 10: 34 avegar over 10 episode: -93.791 avegare return across last 100 episodes: -93.791 state values: tensor(0.7465) 184
35 1000 -1000.0 -99.99568287525881 number episode from 10: 35 avegar over 10 episode: -93.964 avegare return across last 100 episodes: -93.964 state values: tensor(0.6214) 1000
36 1000 -1000.0 -99.99568287525881 number episode from 10: 36 avegar over 10 episode: -94.127 avegare return across last 100 episodes: -94.127 state values: tensor(0.6213) 1000
37 1000 -1000.0 -99.99568287525881 number episode from 10: 37 avegar over 10 episode: -94.281 avegare return across last 100 episodes: -94.281 state values: tensor(0.6220) 1000
38 1000 -1000.0 -99.99568287525881 number episode from 10: 38 avegar over 10 episode: -94.428 avegare return across last 100 episodes: -94.428 state values: tensor(0.6223) 1000
39 515 -515.0 -99.4349001165342 number episode from 10: 39 avegar over 10 episode: -94.553 avegare return across last 100 episodes: -94.553 state values: tensor(0.6654) 515
40 1000 -1000.0 -99.99568287525881 number episode from 10: 40 avegar over 10 episode: -94.686 avegare return across last 100 episodes: -94.686 state values: tensor(0.7606) 1000
41 1000 -1000.0 -99.99568287525881 number episode from 10: 41 avegar over 10 episode: -94.812 avegare return across last 100 episodes: -94.812 state values: tensor(0.8615) 1000
42 232 -232.0 -90.28673703099494 number episode from 10: 42 avegar over 10 episode: -94.707 avegare return across last 100 episodes: -94.707 state values: tensor(0.7334) 232
43 1000 -1000.0 -99.99568287525881 number episode from 10: 43 avegar over 10 episode: -94.827 avegare return across last 100 episodes: -94.827 state values: tensor(0.6212) 1000
44 905 -905.0 -99.9887836614145 number episode from 10: 44 avegar over 10 episode: -94.942 avegare return across last 100 episodes: -94.942 state values: tensor(0.6484) 905
45 1000 -1000.0 -99.99568287525881 number episode from 10: 45 avegar over 10 episode: -95.052 avegare return across last 100 episodes: -95.052 state values: tensor(0.6216) 1000
46 190 -190.0 -85.18550084524192 number episode from 10: 46 avegar over 10 episode: -94.842 avegare return across last 100 episodes: -94.842 state values: tensor(0.7438) 190
47 1000 -1000.0 -99.99568287525881 number episode from 10: 47 avegar over 10 episode: -94.949 avegare return across last 100 episodes: -94.949 state values: tensor(0.6224) 1000
48 269 -269.0 -93.3031997252135 number episode from 10: 48 avegar over 10 episode: -94.915 avegare return across last 100 episodes: -94.915 state values: tensor(0.7637) 269
49 1000 -1000.0 -99.99568287525881 number episode from 10: 49 avegar over 10 episode: -95.017 avegare return across last 100 episodes: -95.017 state values: tensor(0.6216) 1000
50 1000 -1000.0 -99.99568287525881 number episode from 10: 50 avegar over 10 episode: -95.115 avegare return across last 100 episodes: -95.115 state values: tensor(0.6233) 1000
51 1000 -1000.0 -99.99568287525881 number episode from 10: 51 avegar over 10 episode: -95.209 avegare return across last 100 episodes: -95.209 state values: tensor(0.6214) 1000
52 1000 -1000.0 -99.99568287525881 number episode from 10: 52 avegar over 10 episode: -95.299 avegare return across last 100 episodes: -95.299 state values: tensor(0.6240) 1000
53 178 -178.0 -83.28660649851152 number episode from 10: 53 avegar over 10 episode: -95.076 avegare return across last 100 episodes: -95.076 state values: tensor(0.7454) 178
54 1000 -1000.0 -99.99568287525881 number episode from 10: 54 avegar over 10 episode: -95.166 avegare return across last 100 episodes: -95.166 state values: tensor(0.6225) 1000
55 260 -260.0 -92.66921309561108 number episode from 10: 55 avegar over 10 episode: -95.121 avegare return across last 100 episodes: -95.121 state values: tensor(0.7094) 260
56 224 -224.0 -89.47350981516395 number episode from 10: 56 avegar over 10 episode: -95.022 avegare return across last 100 episodes: -95.022 state values: tensor(0.7220) 224
57 182 -182.0 -83.94518088891023 number episode from 10: 57 avegar over 10 episode: -94.831 avegare return across last 100 episodes: -94.831 state values: tensor(0.7468) 182
58 1000 -1000.0 -99.99568287525881 number episode from 10: 58 avegar over 10 episode: -94.919 avegare return across last 100 episodes: -94.919 state values: tensor(0.6210) 1000
59 176 -176.0 -82.94725691104124 number episode from 10: 59 avegar over 10 episode: -94.719 avegare return across last 100 episodes: -94.719 state values: tensor(0.7366) 176
60 175 -175.0 -82.77500698084974 number episode from 10: 60 avegar over 10 episode: -94.523 avegare return across last 100 episodes: -94.523 state values: tensor(0.7447) 175
61 179 -179.0 -83.4537404335264 number episode from 10: 61 avegar over 10 episode: -94.345 avegare return across last 100 episodes: -94.345 state values: tensor(0.7451) 179
62 1000 -1000.0 -99.99568287525881 number episode from 10: 62 avegar over 10 episode: -94.435 avegare return across last 100 episodes: -94.435 state values: tensor(0.6224) 1000
63 155 -155.0 -78.94015538032704 number episode from 10: 63 avegar over 10 episode: -94.192 avegare return across last 100 episodes: -94.192 state values: tensor(0.7573) 155
64 1000 -1000.0 -99.99568287525881 number episode from 10: 64 avegar over 10 episode: -94.282 avegare return across last 100 episodes: -94.282 state values: tensor(0.6228) 1000
65 183 -183.0 -84.10572908002112 number episode from 10: 65 avegar over 10 episode: -94.128 avegare return across last 100 episodes: -94.128 state values: tensor(0.7446) 183
66 177 -177.0 -83.11778434193083 number episode from 10: 66 avegar over 10 episode: -93.963 avegare return across last 100 episodes: -93.963 state values: tensor(0.7415) 177
67 221 -221.0 -89.1512923492284 number episode from 10: 67 avegar over 10 episode: -93.892 avegare return across last 100 episodes: -93.892 state values: tensor(0.7206) 221
68 1000 -1000.0 -99.99568287525881 number episode from 10: 68 avegar over 10 episode: -93.981 avegare return across last 100 episodes: -93.981 state values: tensor(0.6218) 1000
69 286 -286.0 -94.3549777909171 number episode from 10: 69 avegar over 10 episode: -93.986 avegare return across last 100 episodes: -93.986 state values: tensor(0.6927) 286
70 189 -189.0 -85.0358594396383 number episode from 10: 70 avegar over 10 episode: -93.86 avegare return across last 100 episodes: -93.86 state values: tensor(0.7509) 189
71 1000 -1000.0 -99.99568287525881 number episode from 10: 71 avegar over 10 episode: -93.945 avegare return across last 100 episodes: -93.945 state values: tensor(0.6213) 1000
72 211 -211.0 -88.0042871806521 number episode from 10: 72 avegar over 10 episode: -93.864 avegare return across last 100 episodes: -93.864 state values: tensor(0.7147) 211
73 183 -183.0 -84.10572908002112 number episode from 10: 73 avegar over 10 episode: -93.732 avegare return across last 100 episodes: -93.732 state values: tensor(0.7424) 183
74 1000 -1000.0 -99.99568287525881 number episode from 10: 74 avegar over 10 episode: -93.816 avegare return across last 100 episodes: -93.816 state values: tensor(0.6231) 1000
75 1000 -1000.0 -99.99568287525881 number episode from 10: 75 avegar over 10 episode: -93.897 avegare return across last 100 episodes: -93.897 state values: tensor(0.6211) 1000
76 260 -260.0 -92.66921309561108 number episode from 10: 76 avegar over 10 episode: -93.881 avegare return across last 100 episodes: -93.881 state values: tensor(0.7096) 260
77 1000 -1000.0 -99.99568287525881 number episode from 10: 77 avegar over 10 episode: -93.959 avegare return across last 100 episodes: -93.959 state values: tensor(0.6223) 1000
78 1000 -1000.0 -99.99568287525881 number episode from 10: 78 avegar over 10 episode: -94.036 avegare return across last 100 episodes: -94.036 state values: tensor(0.6227) 1000
79 222 -222.0 -89.25977942573611 number episode from 10: 79 avegar over 10 episode: -93.976 avegare return across last 100 episodes: -93.976 state values: tensor(0.7217) 222
80 177 -177.0 -83.11778434193083 number episode from 10: 80 avegar over 10 episode: -93.842 avegare return across last 100 episodes: -93.842 state values: tensor(0.7427) 177
81 988 -988.0 -99.99512951441419 number episode from 10: 81 avegar over 10 episode: -93.917 avegare return across last 100 episodes: -93.917 state values: tensor(0.6476) 988
82 178 -178.0 -83.28660649851152 number episode from 10: 82 avegar over 10 episode: -93.789 avegare return across last 100 episodes: -93.789 state values: tensor(0.7448) 178
83 178 -178.0 -83.28660649851152 number episode from 10: 83 avegar over 10 episode: -93.664 avegare return across last 100 episodes: -93.664 state values: tensor(0.7440) 178
84 185 -185.0 -84.4220250713287 number episode from 10: 84 avegar over 10 episode: -93.555 avegare return across last 100 episodes: -93.555 state values: tensor(0.7443) 185
85 722 -722.0 -99.92943156284494 number episode from 10: 85 avegar over 10 episode: -93.629 avegare return across last 100 episodes: -93.629 state values: tensor(0.6502) 722
86 1000 -1000.0 -99.99568287525881 number episode from 10: 86 avegar over 10 episode: -93.703 avegare return across last 100 episodes: -93.703 state values: tensor(0.6239) 1000
87 1000 -1000.0 -99.99568287525881 number episode from 10: 87 avegar over 10 episode: -93.774 avegare return across last 100 episodes: -93.774 state values: tensor(0.6227) 1000
88 177 -177.0 -83.11778434193083 number episode from 10: 88 avegar over 10 episode: -93.654 avegare return across last 100 episodes: -93.654 state values: tensor(0.7441) 177
89 181 -181.0 -83.78301099889923 number episode from 10: 89 avegar over 10 episode: -93.545 avegare return across last 100 episodes: -93.545 state values: tensor(0.7389) 181
90 1000 -1000.0 -99.99568287525881 number episode from 10: 90 avegar over 10 episode: -93.616 avegare return across last 100 episodes: -93.616 state values: tensor(0.6219) 1000
91 183 -183.0 -84.10572908002112 number episode from 10: 91 avegar over 10 episode: -93.512 avegare return across last 100 episodes: -93.512 state values: tensor(0.7432) 183
92 179 -179.0 -83.4537404335264 number episode from 10: 92 avegar over 10 episode: -93.404 avegare return across last 100 episodes: -93.404 state values: tensor(0.7463) 179
93 1000 -1000.0 -99.99568287525881 number episode from 10: 93 avegar over 10 episode: -93.474 avegare return across last 100 episodes: -93.474 state values: tensor(0.8847) 1000
94 1000 -1000.0 -99.99568287525881 number episode from 10: 94 avegar over 10 episode: -93.543 avegare return across last 100 episodes: -93.543 state values: tensor(0.6216) 1000
95 435 -435.0 -98.73727246747016 number episode from 10: 95 avegar over 10 episode: -93.597 avegare return across last 100 episodes: -93.597 state values: tensor(0.6698) 435
96 180 -180.0 -83.61920302919114 number episode from 10: 96 avegar over 10 episode: -93.494 avegare return across last 100 episodes: -93.494 state values: tensor(0.7460) 180
97 176 -176.0 -82.94725691104124 number episode from 10: 97 avegar over 10 episode: -93.386 avegare return across last 100 episodes: -93.386 state values: tensor(0.7435) 176
98 1000 -1000.0 -99.99568287525881 number episode from 10: 98 avegar over 10 episode: -93.453 avegare return across last 100 episodes: -93.453 state values: tensor(0.6227) 1000
99 1000 -1000.0 -99.99568287525881 number episode from 10: 99 avegar over 10 episode: -93.519 avegare return across last 100 episodes: -93.519 state values: tensor(0.7179) 1000
100 1000 -1000.0 -99.99568287525881 number episode from 10: 100 avegar over 10 episode: -93.583 avegare return across last 100 episodes: -93.529 state values: tensor(0.6224) 1000
101 184 -184.0 -84.26467178922091 number episode from 10: 101 avegar over 10 episode: -93.491 avegare return across last 100 episodes: -93.371 state values: tensor(0.7437) 184
102 1000 -1000.0 -99.99568287525881 number episode from 10: 102 avegar over 10 episode: -93.555 avegare return across last 100 episodes: -93.538 state values: tensor(0.6230) 1000
103 178 -178.0 -83.28660649851152 number episode from 10: 103 avegar over 10 episode: -93.456 avegare return across last 100 episodes: -93.538 state values: tensor(0.7448) 178
104 189 -189.0 -85.0358594396383 number episode from 10: 104 avegar over 10 episode: -93.376 avegare return across last 100 episodes: -93.389 state values: tensor(0.7451) 189
105 1000 -1000.0 -99.99568287525881 number episode from 10: 105 avegar over 10 episode: -93.438 avegare return across last 100 episodes: -93.389 state values: tensor(0.6217) 1000
106 249 -249.0 -91.81227109472904 number episode from 10: 106 avegar over 10 episode: -93.423 avegare return across last 100 episodes: -93.472 state values: tensor(0.7523) 249
107 1000 -1000.0 -99.99568287525881 number episode from 10: 107 avegar over 10 episode: -93.484 avegare return across last 100 episodes: -93.625 state values: tensor(0.6221) 1000
108 178 -178.0 -83.28660649851152 number episode from 10: 108 avegar over 10 episode: -93.39 avegare return across last 100 episodes: -93.565 state values: tensor(0.7432) 178
109 178 -178.0 -83.28660649851152 number episode from 10: 109 avegar over 10 episode: -93.298 avegare return across last 100 episodes: -93.398 state values: tensor(0.7453) 178
110 184 -184.0 -84.26467178922091 number episode from 10: 110 avegar over 10 episode: -93.217 avegare return across last 100 episodes: -93.329 state values: tensor(0.7475) 184
111 198 -198.0 -86.32999950434008 number episode from 10: 111 avegar over 10 episode: -93.155 avegare return across last 100 episodes: -93.201 state values: tensor(0.7584) 198
112 177 -177.0 -83.11778434193083 number episode from 10: 112 avegar over 10 episode: -93.067 avegare return across last 100 episodes: -93.032 state values: tensor(0.7445) 177
113 180 -180.0 -83.61920302919114 number episode from 10: 113 avegar over 10 episode: -92.984 avegare return across last 100 episodes: -92.868 state values: tensor(0.7433) 180
114 179 -179.0 -83.4537404335264 number episode from 10: 114 avegar over 10 episode: -92.901 avegare return across last 100 episodes: -92.856 state values: tensor(0.7465) 179
115 1000 -1000.0 -99.99568287525881 number episode from 10: 115 avegar over 10 episode: -92.962 avegare return across last 100 episodes: -93.026 state values: tensor(0.6217) 1000
116 1000 -1000.0 -99.99568287525881 number episode from 10: 116 avegar over 10 episode: -93.022 avegare return across last 100 episodes: -93.026 state values: tensor(0.6215) 1000
117 1000 -1000.0 -99.99568287525881 number episode from 10: 117 avegar over 10 episode: -93.081 avegare return across last 100 episodes: -93.026 state values: tensor(0.6212) 1000
118 1000 -1000.0 -99.99568287525881 number episode from 10: 118 avegar over 10 episode: -93.139 avegare return across last 100 episodes: -93.198 state values: tensor(0.6223) 1000
119 1000 -1000.0 -99.99568287525881 number episode from 10: 119 avegar over 10 episode: -93.197 avegare return across last 100 episodes: -93.356 state values: tensor(0.6215) 1000
120 226 -226.0 -89.68298696984219 number episode from 10: 120 avegar over 10 episode: -93.167 avegare return across last 100 episodes: -93.426 state values: tensor(0.7250) 226
121 179 -179.0 -83.4537404335264 number episode from 10: 121 avegar over 10 episode: -93.088 avegare return across last 100 episodes: -93.261 state values: tensor(0.7460) 179
122 178 -178.0 -83.28660649851152 number episode from 10: 122 avegar over 10 episode: -93.008 avegare return across last 100 episodes: -93.094 state values: tensor(0.7453) 178
123 1000 -1000.0 -99.99568287525881 number episode from 10: 123 avegar over 10 episode: -93.065 avegare return across last 100 episodes: -93.094 state values: tensor(0.6211) 1000
124 213 -213.0 -88.24300186575712 number episode from 10: 124 avegar over 10 episode: -93.026 avegare return across last 100 episodes: -92.977 state values: tensor(0.7161) 213
125 177 -177.0 -83.11778434193083 number episode from 10: 125 avegar over 10 episode: -92.947 avegare return across last 100 episodes: -92.808 state values: tensor(0.7336) 177
126 1000 -1000.0 -99.99568287525881 number episode from 10: 126 avegar over 10 episode: -93.003 avegare return across last 100 episodes: -92.968 state values: tensor(0.6212) 1000
127 182 -182.0 -83.94518088891023 number episode from 10: 127 avegar over 10 episode: -92.932 avegare return across last 100 episodes: -92.808 state values: tensor(0.7483) 182
128 1000 -1000.0 -99.99568287525881 number episode from 10: 128 avegar over 10 episode: -92.987 avegare return across last 100 episodes: -92.808 state values: tensor(0.6213) 1000
129 270 -270.0 -93.37016772796137 number episode from 10: 129 avegar over 10 episode: -92.99 avegare return across last 100 episodes: -92.742 state values: tensor(0.7640) 270
130 1000 -1000.0 -99.99568287525881 number episode from 10: 130 avegar over 10 episode: -93.043 avegare return across last 100 episodes: -92.742 state values: tensor(0.6221) 1000
131 1000 -1000.0 -99.99568287525881 number episode from 10: 131 avegar over 10 episode: -93.096 avegare return across last 100 episodes: -92.742 state values: tensor(0.6234) 1000
132 1000 -1000.0 -99.99568287525881 number episode from 10: 132 avegar over 10 episode: -93.148 avegare return across last 100 episodes: -92.902 state values: tensor(0.6227) 1000
133 1000 -1000.0 -99.99568287525881 number episode from 10: 133 avegar over 10 episode: -93.199 avegare return across last 100 episodes: -92.902 state values: tensor(0.6219) 1000
134 1000 -1000.0 -99.99568287525881 number episode from 10: 134 avegar over 10 episode: -93.249 avegare return across last 100 episodes: -93.06 state values: tensor(0.6266) 1000
135 1000 -1000.0 -99.99568287525881 number episode from 10: 135 avegar over 10 episode: -93.299 avegare return across last 100 episodes: -93.06 state values: tensor(0.6242) 1000
136 183 -183.0 -84.10572908002112 number episode from 10: 136 avegar over 10 episode: -93.232 avegare return across last 100 episodes: -92.901 state values: tensor(0.7380) 183
137 1000 -1000.0 -99.99568287525881 number episode from 10: 137 avegar over 10 episode: -93.281 avegare return across last 100 episodes: -92.901 state values: tensor(0.6211) 1000
138 192 -192.0 -85.48030937842161 number episode from 10: 138 avegar over 10 episode: -93.225 avegare return across last 100 episodes: -92.755 state values: tensor(0.7468) 192
139 727 -727.0 -99.93289011842855 number episode from 10: 139 avegar over 10 episode: -93.273 avegare return across last 100 episodes: -92.76 state values: tensor(0.6526) 727
140 178 -178.0 -83.28660649851152 number episode from 10: 140 avegar over 10 episode: -93.202 avegare return across last 100 episodes: -92.593 state values: tensor(0.7447) 178
141 1000 -1000.0 -99.99568287525881 number episode from 10: 141 avegar over 10 episode: -93.25 avegare return across last 100 episodes: -92.593 state values: tensor(0.6214) 1000
142 989 -989.0 -99.99517821927004 number episode from 10: 142 avegar over 10 episode: -93.297 avegare return across last 100 episodes: -92.69 state values: tensor(0.6459) 989
143 1000 -1000.0 -99.99568287525881 number episode from 10: 143 avegar over 10 episode: -93.343 avegare return across last 100 episodes: -92.69 state values: tensor(0.6213) 1000
144 1000 -1000.0 -99.99568287525881 number episode from 10: 144 avegar over 10 episode: -93.389 avegare return across last 100 episodes: -92.69 state values: tensor(0.6216) 1000
145 176 -176.0 -82.94725691104124 number episode from 10: 145 avegar over 10 episode: -93.318 avegare return across last 100 episodes: -92.52 state values: tensor(0.7433) 176
146 990 -990.0 -99.99522643707735 number episode from 10: 146 avegar over 10 episode: -93.363 avegare return across last 100 episodes: -92.668 state values: tensor(0.6459) 990
147 179 -179.0 -83.4537404335264 number episode from 10: 147 avegar over 10 episode: -93.296 avegare return across last 100 episodes: -92.503 state values: tensor(0.7464) 179
148 1000 -1000.0 -99.99568287525881 number episode from 10: 148 avegar over 10 episode: -93.341 avegare return across last 100 episodes: -92.57 state values: tensor(0.6242) 1000
149 1000 -1000.0 -99.99568287525881 number episode from 10: 149 avegar over 10 episode: -93.385 avegare return across last 100 episodes: -92.57 state values: tensor(0.6217) 1000
150 1000 -1000.0 -99.99568287525881 number episode from 10: 150 avegar over 10 episode: -93.429 avegare return across last 100 episodes: -92.57 state values: tensor(0.6212) 1000
151 175 -175.0 -82.77500698084974 number episode from 10: 151 avegar over 10 episode: -93.359 avegare return across last 100 episodes: -92.397 state values: tensor(0.7418) 175
152 178 -178.0 -83.28660649851152 number episode from 10: 152 avegar over 10 episode: -93.293 avegare return across last 100 episodes: -92.23 state values: tensor(0.7461) 178
153 1000 -1000.0 -99.99568287525881 number episode from 10: 153 avegar over 10 episode: -93.337 avegare return across last 100 episodes: -92.397 state values: tensor(0.6218) 1000
154 186 -186.0 -84.57780482061541 number episode from 10: 154 avegar over 10 episode: -93.28 avegare return across last 100 episodes: -92.243 state values: tensor(0.7416) 186
155 928 -928.0 -99.99109855348831 number episode from 10: 155 avegar over 10 episode: -93.323 avegare return across last 100 episodes: -92.316 state values: tensor(0.6428) 928
156 176 -176.0 -82.94725691104124 number episode from 10: 156 avegar over 10 episode: -93.257 avegare return across last 100 episodes: -92.251 state values: tensor(0.7369) 176
157 904 -904.0 -99.98867036506515 number episode from 10: 157 avegar over 10 episode: -93.3 avegare return across last 100 episodes: -92.412 state values: tensor(0.6448) 904
158 286 -286.0 -94.3549777909171 number episode from 10: 158 avegar over 10 episode: -93.306 avegare return across last 100 episodes: -92.355 state values: tensor(0.6926) 286
159 299 -299.0 -95.04637433623367 number episode from 10: 159 avegar over 10 episode: -93.317 avegare return across last 100 episodes: -92.476 state values: tensor(0.6971) 299
160 1000 -1000.0 -99.99568287525881 number episode from 10: 160 avegar over 10 episode: -93.359 avegare return across last 100 episodes: -92.648 state values: tensor(0.6222) 1000
161 1000 -1000.0 -99.99568287525881 number episode from 10: 161 avegar over 10 episode: -93.4 avegare return across last 100 episodes: -92.814 state values: tensor(0.8610) 1000
162 179 -179.0 -83.4537404335264 number episode from 10: 162 avegar over 10 episode: -93.339 avegare return across last 100 episodes: -92.648 state values: tensor(0.7461) 179
163 1000 -1000.0 -99.99568287525881 number episode from 10: 163 avegar over 10 episode: -93.379 avegare return across last 100 episodes: -92.859 state values: tensor(0.6224) 1000
164 1000 -1000.0 -99.99568287525881 number episode from 10: 164 avegar over 10 episode: -93.419 avegare return across last 100 episodes: -92.859 state values: tensor(0.9044) 1000
165 177 -177.0 -83.11778434193083 number episode from 10: 165 avegar over 10 episode: -93.357 avegare return across last 100 episodes: -92.849 state values: tensor(0.7437) 177
166 231 -231.0 -90.18862326363126 number episode from 10: 166 avegar over 10 episode: -93.338 avegare return across last 100 episodes: -92.92 state values: tensor(0.7321) 231
167 237 -237.0 -90.76278356441406 number episode from 10: 167 avegar over 10 episode: -93.323 avegare return across last 100 episodes: -92.936 state values: tensor(0.7437) 237
168 1000 -1000.0 -99.99568287525881 number episode from 10: 168 avegar over 10 episode: -93.363 avegare return across last 100 episodes: -92.936 state values: tensor(0.6212) 1000
169 177 -177.0 -83.11778434193083 number episode from 10: 169 avegar over 10 episode: -93.302 avegare return across last 100 episodes: -92.824 state values: tensor(0.7437) 177
170 176 -176.0 -82.94725691104124 number episode from 10: 170 avegar over 10 episode: -93.242 avegare return across last 100 episodes: -92.803 state values: tensor(0.7371) 176
171 1000 -1000.0 -99.99568287525881 number episode from 10: 171 avegar over 10 episode: -93.281 avegare return across last 100 episodes: -92.803 state values: tensor(0.6223) 1000
172 703 -703.0 -99.91458349407242 number episode from 10: 172 avegar over 10 episode: -93.319 avegare return across last 100 episodes: -92.922 state values: tensor(0.6545) 703
173 1000 -1000.0 -99.99568287525881 number episode from 10: 173 avegar over 10 episode: -93.358 avegare return across last 100 episodes: -93.081 state values: tensor(0.6237) 1000
174 1000 -1000.0 -99.99568287525881 number episode from 10: 174 avegar over 10 episode: -93.396 avegare return across last 100 episodes: -93.081 state values: tensor(0.6220) 1000
175 1000 -1000.0 -99.99568287525881 number episode from 10: 175 avegar over 10 episode: -93.433 avegare return across last 100 episodes: -93.081 state values: tensor(0.6217) 1000
176 218 -218.0 -88.81921175764214 number episode from 10: 176 avegar over 10 episode: -93.407 avegare return across last 100 episodes: -93.042 state values: tensor(0.7213) 218
177 1000 -1000.0 -99.99568287525881 number episode from 10: 177 avegar over 10 episode: -93.444 avegare return across last 100 episodes: -93.042 state values: tensor(0.6239) 1000
178 1000 -1000.0 -99.99568287525881 number episode from 10: 178 avegar over 10 episode: -93.481 avegare return across last 100 episodes: -93.042 state values: tensor(0.6218) 1000
179 1000 -1000.0 -99.99568287525881 number episode from 10: 179 avegar over 10 episode: -93.517 avegare return across last 100 episodes: -93.15 state values: tensor(0.6228) 1000
180 404 -404.0 -98.27567701466981 number episode from 10: 180 avegar over 10 episode: -93.543 avegare return across last 100 episodes: -93.301 state values: tensor(0.6774) 404
181 179 -179.0 -83.4537404335264 number episode from 10: 181 avegar over 10 episode: -93.488 avegare return across last 100 episodes: -93.136 state values: tensor(0.7406) 179
182 177 -177.0 -83.11778434193083 number episode from 10: 182 avegar over 10 episode: -93.431 avegare return across last 100 episodes: -93.134 state values: tensor(0.7442) 177
183 1000 -1000.0 -99.99568287525881 number episode from 10: 183 avegar over 10 episode: -93.467 avegare return across last 100 episodes: -93.301 state values: tensor(0.9042) 1000
184 360 -360.0 -97.31669490601132 number episode from 10: 184 avegar over 10 episode: -93.488 avegare return across last 100 episodes: -93.43 state values: tensor(0.6771) 360
185 1000 -1000.0 -99.99568287525881 number episode from 10: 185 avegar over 10 episode: -93.523 avegare return across last 100 episodes: -93.431 state values: tensor(0.6223) 1000
186 1000 -1000.0 -99.99568287525881 number episode from 10: 186 avegar over 10 episode: -93.557 avegare return across last 100 episodes: -93.431 state values: tensor(0.6218) 1000
187 1000 -1000.0 -99.99568287525881 number episode from 10: 187 avegar over 10 episode: -93.591 avegare return across last 100 episodes: -93.431 state values: tensor(0.6220) 1000
188 180 -180.0 -83.61920302919114 number episode from 10: 188 avegar over 10 episode: -93.539 avegare return across last 100 episodes: -93.436 state values: tensor(0.7463) 180
189 1000 -1000.0 -99.99568287525881 number episode from 10: 189 avegar over 10 episode: -93.573 avegare return across last 100 episodes: -93.598 state values: tensor(0.6244) 1000
190 1000 -1000.0 -99.99568287525881 number episode from 10: 190 avegar over 10 episode: -93.606 avegare return across last 100 episodes: -93.598 state values: tensor(0.6213) 1000
191 183 -183.0 -84.10572908002112 number episode from 10: 191 avegar over 10 episode: -93.557 avegare return across last 100 episodes: -93.598 state values: tensor(0.7468) 183
192 1000 -1000.0 -99.99568287525881 number episode from 10: 192 avegar over 10 episode: -93.59 avegare return across last 100 episodes: -93.763 state values: tensor(0.8618) 1000
193 250 -250.0 -91.89414838378175 number episode from 10: 193 avegar over 10 episode: -93.581 avegare return across last 100 episodes: -93.682 state values: tensor(0.7008) 250
194 1000 -1000.0 -99.99568287525881 number episode from 10: 194 avegar over 10 episode: -93.614 avegare return across last 100 episodes: -93.682 state values: tensor(0.6227) 1000
195 1000 -1000.0 -99.99568287525881 number episode from 10: 195 avegar over 10 episode: -93.647 avegare return across last 100 episodes: -93.695 state values: tensor(0.6238) 1000
196 1000 -1000.0 -99.99568287525881 number episode from 10: 196 avegar over 10 episode: -93.679 avegare return across last 100 episodes: -93.859 state values: tensor(0.6233) 1000
197 1000 -1000.0 -99.99568287525881 number episode from 10: 197 avegar over 10 episode: -93.711 avegare return across last 100 episodes: -94.029 state values: tensor(0.6223) 1000
198 1000 -1000.0 -99.99568287525881 number episode from 10: 198 avegar over 10 episode: -93.743 avegare return across last 100 episodes: -94.029 state values: tensor(0.6215) 1000
199 177 -177.0 -83.11778434193083 number episode from 10: 199 avegar over 10 episode: -93.689 avegare return across last 100 episodes: -93.86 state values: tensor(0.7430) 177
200 179 -179.0 -83.4537404335264 number episode from 10: 200 avegar over 10 episode: -93.639 avegare return across last 100 episodes: -93.695 state values: tensor(0.7433) 179
load offline data!!!!!
mem_cntr: 50000 ; mem_size: 50000
nn.learn_nn_feature_fqi FQI:  998
nn.learn_nn_feature_fqi FQI:  1998
nn.learn_nn_feature_fqi FQI:  2998
nn.learn_nn_feature_fqi FQI:  3998
nn.learn_nn_feature_fqi FQI:  4998
nn.learn_nn_feature_fqi FQI:  5998
nn.learn_nn_feature_fqi FQI:  6998
nn.learn_nn_feature_fqi FQI:  7998
nn.learn_nn_feature_fqi FQI:  8998
nn.learn_nn_feature_fqi FQI:  9998
nn.learn_nn_feature_fqi FQI:  10998
nn.learn_nn_feature_fqi FQI:  11998
nn.learn_nn_feature_fqi FQI:  12998
nn.learn_nn_feature_fqi FQI:  13998
nn.learn_nn_feature_fqi FQI:  14998
nn.learn_nn_feature_fqi FQI:  15998
nn.learn_nn_feature_fqi FQI:  16998
nn.learn_nn_feature_fqi FQI:  17998
nn.learn_nn_feature_fqi FQI:  18998
nn.learn_nn_feature_fqi FQI:  19998
nn.learn_nn_feature_fqi FQI:  20998
nn.learn_nn_feature_fqi FQI:  21998
nn.learn_nn_feature_fqi FQI:  22998
nn.learn_nn_feature_fqi FQI:  23998
nn.learn_nn_feature_fqi FQI:  24998
nn.learn_nn_feature_fqi FQI:  25998
nn.learn_nn_feature_fqi FQI:  26998
nn.learn_nn_feature_fqi FQI:  27998
nn.learn_nn_feature_fqi FQI:  28998
nn.learn_nn_feature_fqi FQI:  29998
nn.learn_nn_feature_fqi FQI:  30998
nn.learn_nn_feature_fqi FQI:  31998
nn.learn_nn_feature_fqi FQI:  32998
nn.learn_nn_feature_fqi FQI:  33998
nn.learn_nn_feature_fqi FQI:  34998
nn.learn_nn_feature_fqi FQI:  35998
nn.learn_nn_feature_fqi FQI:  36998
nn.learn_nn_feature_fqi FQI:  37998
nn.learn_nn_feature_fqi FQI:  38998
nn.learn_nn_feature_fqi FQI:  39998
nn.learn_nn_feature_fqi FQI:  40998
nn.learn_nn_feature_fqi FQI:  41998
nn.learn_nn_feature_fqi FQI:  42998
nn.learn_nn_feature_fqi FQI:  43998
nn.learn_nn_feature_fqi FQI:  44998
nn.learn_nn_feature_fqi FQI:  45998
nn.learn_nn_feature_fqi FQI:  46998
nn.learn_nn_feature_fqi FQI:  47998
nn.learn_nn_feature_fqi FQI:  48998
nn.learn_nn_feature_fqi FQI:  49998
nn.learn_nn_feature_fqi FQI:  50998
nn.learn_nn_feature_fqi FQI:  51998
nn.learn_nn_feature_fqi FQI:  52998
nn.learn_nn_feature_fqi FQI:  53998
nn.learn_nn_feature_fqi FQI:  54998
nn.learn_nn_feature_fqi FQI:  55998
nn.learn_nn_feature_fqi FQI:  56998
nn.learn_nn_feature_fqi FQI:  57998
nn.learn_nn_feature_fqi FQI:  58998
nn.learn_nn_feature_fqi FQI:  59998
nn.learn_nn_feature_fqi FQI:  60998
nn.learn_nn_feature_fqi FQI:  61998
nn.learn_nn_feature_fqi FQI:  62998
nn.learn_nn_feature_fqi FQI:  63998
nn.learn_nn_feature_fqi FQI:  64998
nn.learn_nn_feature_fqi FQI:  65998
nn.learn_nn_feature_fqi FQI:  66998
nn.learn_nn_feature_fqi FQI:  67998
nn.learn_nn_feature_fqi FQI:  68998
nn.learn_nn_feature_fqi FQI:  69998
nn.learn_nn_feature_fqi FQI:  70998
nn.learn_nn_feature_fqi FQI:  71998
nn.learn_nn_feature_fqi FQI:  72998
nn.learn_nn_feature_fqi FQI:  73998
nn.learn_nn_feature_fqi FQI:  74998
nn.learn_nn_feature_fqi FQI:  75998
nn.learn_nn_feature_fqi FQI:  76998
nn.learn_nn_feature_fqi FQI:  77998
nn.learn_nn_feature_fqi FQI:  78998
nn.learn_nn_feature_fqi FQI:  79998
nn.learn_nn_feature_fqi FQI:  80998
nn.learn_nn_feature_fqi FQI:  81998
nn.learn_nn_feature_fqi FQI:  82998
nn.learn_nn_feature_fqi FQI:  83998
nn.learn_nn_feature_fqi FQI:  84998
nn.learn_nn_feature_fqi FQI:  85998
nn.learn_nn_feature_fqi FQI:  86998
nn.learn_nn_feature_fqi FQI:  87998
nn.learn_nn_feature_fqi FQI:  88998
nn.learn_nn_feature_fqi FQI:  89998
nn.learn_nn_feature_fqi FQI:  90998
nn.learn_nn_feature_fqi FQI:  91998
nn.learn_nn_feature_fqi FQI:  92998
nn.learn_nn_feature_fqi FQI:  93998
nn.learn_nn_feature_fqi FQI:  94998
nn.learn_nn_feature_fqi FQI:  95998
nn.learn_nn_feature_fqi FQI:  96998
nn.learn_nn_feature_fqi FQI:  97998
nn.learn_nn_feature_fqi FQI:  98998
nn.learn_nn_feature_fqi FQI:  99998
nn.learn_nn_feature_fqi FQI:  100998
nn.learn_nn_feature_fqi FQI:  101998
nn.learn_nn_feature_fqi FQI:  102998
nn.learn_nn_feature_fqi FQI:  103998
nn.learn_nn_feature_fqi FQI:  104998
nn.learn_nn_feature_fqi FQI:  105998
nn.learn_nn_feature_fqi FQI:  106998
nn.learn_nn_feature_fqi FQI:  107998
nn.learn_nn_feature_fqi FQI:  108998
nn.learn_nn_feature_fqi FQI:  109998
nn.learn_nn_feature_fqi FQI:  110998
nn.learn_nn_feature_fqi FQI:  111998
nn.learn_nn_feature_fqi FQI:  112998
nn.learn_nn_feature_fqi FQI:  113998
nn.learn_nn_feature_fqi FQI:  114998
nn.learn_nn_feature_fqi FQI:  115998
nn.learn_nn_feature_fqi FQI:  116998
nn.learn_nn_feature_fqi FQI:  117998
nn.learn_nn_feature_fqi FQI:  118998
nn.learn_nn_feature_fqi FQI:  119998
nn.learn_nn_feature_fqi FQI:  120998
nn.learn_nn_feature_fqi FQI:  121998
nn.learn_nn_feature_fqi FQI:  122998
nn.learn_nn_feature_fqi FQI:  123998
nn.learn_nn_feature_fqi FQI:  124998
nn.learn_nn_feature_fqi FQI:  125998
nn.learn_nn_feature_fqi FQI:  126998
nn.learn_nn_feature_fqi FQI:  127998
nn.learn_nn_feature_fqi FQI:  128998
nn.learn_nn_feature_fqi FQI:  129998
nn.learn_nn_feature_fqi FQI:  130998
nn.learn_nn_feature_fqi FQI:  131998
nn.learn_nn_feature_fqi FQI:  132998
nn.learn_nn_feature_fqi FQI:  133998
nn.learn_nn_feature_fqi FQI:  134998
nn.learn_nn_feature_fqi FQI:  135998
nn.learn_nn_feature_fqi FQI:  136998
nn.learn_nn_feature_fqi FQI:  137998
nn.learn_nn_feature_fqi FQI:  138998
nn.learn_nn_feature_fqi FQI:  139998
nn.learn_nn_feature_fqi FQI:  140998
nn.learn_nn_feature_fqi FQI:  141998
nn.learn_nn_feature_fqi FQI:  142998
nn.learn_nn_feature_fqi FQI:  143998
nn.learn_nn_feature_fqi FQI:  144998
nn.learn_nn_feature_fqi FQI:  145998
nn.learn_nn_feature_fqi FQI:  146998
nn.learn_nn_feature_fqi FQI:  147998
nn.learn_nn_feature_fqi FQI:  148998
nn.learn_nn_feature_fqi FQI:  149998
nn.learn_nn_feature_fqi FQI:  150998
nn.learn_nn_feature_fqi FQI:  151998
nn.learn_nn_feature_fqi FQI:  152998
nn.learn_nn_feature_fqi FQI:  153998
nn.learn_nn_feature_fqi FQI:  154998
nn.learn_nn_feature_fqi FQI:  155998
0 1001 -1000.0 -98.99572604650622 number episode from 10: 0 avegar over 10 episode: -98.996 avegare return across last 100 episodes: -98.996 state values: tensor(0.6300) 1000
1 236 -236.0 -90.66947834789299 number episode from 10: 1 avegar over 10 episode: -94.833 avegare return across last 100 episodes: -94.833 state values: tensor(0.7589) 236
2 267 -267.0 -93.16722755352873 number episode from 10: 2 avegar over 10 episode: -94.277 avegare return across last 100 episodes: -94.277 state values: tensor(0.7861) 267
3 212 -212.0 -88.12424430884558 number episode from 10: 3 avegar over 10 episode: -92.739 avegare return across last 100 episodes: -92.739 state values: tensor(0.7206) 212
4 221 -221.0 -89.1512923492284 number episode from 10: 4 avegar over 10 episode: -92.022 avegare return across last 100 episodes: -92.022 state values: tensor(0.7378) 221
5 247 -247.0 -91.64602703267936 number episode from 10: 5 avegar over 10 episode: -91.959 avegare return across last 100 episodes: -91.959 state values: tensor(0.7692) 247
6 215 -215.0 -88.47696612862855 number episode from 10: 6 avegar over 10 episode: -91.462 avegare return across last 100 episodes: -91.462 state values: tensor(0.7304) 215
7 230 -230.0 -90.08951844811239 number episode from 10: 7 avegar over 10 episode: -91.29 avegare return across last 100 episodes: -91.29 state values: tensor(0.7542) 230
8 1000 -1000.0 -99.99568287525881 number episode from 10: 8 avegar over 10 episode: -92.257 avegare return across last 100 episodes: -92.257 state values: tensor(0.6308) 1000
9 1000 -1000.0 -99.99568287525881 number episode from 10: 9 avegar over 10 episode: -93.031 avegare return across last 100 episodes: -93.031 state values: tensor(0.6286) 1000
10 1000 -1000.0 -99.99568287525881 number episode from 10: 10 avegar over 10 episode: -93.664 avegare return across last 100 episodes: -93.664 state values: tensor(0.6375) 1000
11 1000 -1000.0 -99.99568287525881 number episode from 10: 11 avegar over 10 episode: -94.192 avegare return across last 100 episodes: -94.192 state values: tensor(0.6345) 1000
12 158 -158.0 -79.56565382537595 number episode from 10: 12 avegar over 10 episode: -93.067 avegare return across last 100 episodes: -93.067 state values: tensor(0.7733) 158
13 1000 -1000.0 -99.99568287525881 number episode from 10: 13 avegar over 10 episode: -93.562 avegare return across last 100 episodes: -93.562 state values: tensor(0.6327) 1000
14 220 -220.0 -89.04170944366506 number episode from 10: 14 avegar over 10 episode: -93.26 avegare return across last 100 episodes: -93.26 state values: tensor(0.7392) 220
15 214 -214.0 -88.36057184709955 number episode from 10: 15 avegar over 10 episode: -92.954 avegare return across last 100 episodes: -92.954 state values: tensor(0.7133) 214
16 1000 -1000.0 -99.99568287525881 number episode from 10: 16 avegar over 10 episode: -93.368 avegare return across last 100 episodes: -93.368 state values: tensor(0.6332) 1000
17 218 -218.0 -88.81921175764214 number episode from 10: 17 avegar over 10 episode: -93.116 avegare return across last 100 episodes: -93.116 state values: tensor(0.7395) 218
18 237 -237.0 -90.76278356441406 number episode from 10: 18 avegar over 10 episode: -92.992 avegare return across last 100 episodes: -92.992 state values: tensor(0.7602) 237
19 219 -219.0 -88.93101964006571 number episode from 10: 19 avegar over 10 episode: -92.789 avegare return across last 100 episodes: -92.789 state values: tensor(0.7395) 219
20 1000 -1000.0 -99.99568287525881 number episode from 10: 20 avegar over 10 episode: -93.132 avegare return across last 100 episodes: -93.132 state values: tensor(0.6311) 1000
21 1000 -1000.0 -99.99568287525881 number episode from 10: 21 avegar over 10 episode: -93.444 avegare return across last 100 episodes: -93.444 state values: tensor(0.6321) 1000
22 153 -153.0 -78.51255522939195 number episode from 10: 22 avegar over 10 episode: -92.795 avegare return across last 100 episodes: -92.795 state values: tensor(0.7683) 153
23 215 -215.0 -88.47696612862855 number episode from 10: 23 avegar over 10 episode: -92.615 avegare return across last 100 episodes: -92.615 state values: tensor(0.7276) 215
24 221 -221.0 -89.1512923492284 number episode from 10: 24 avegar over 10 episode: -92.476 avegare return across last 100 episodes: -92.476 state values: tensor(0.7360) 221
25 746 -746.0 -99.94455592149627 number episode from 10: 25 avegar over 10 episode: -92.764 avegare return across last 100 episodes: -92.764 state values: tensor(0.6585) 746
26 237 -237.0 -90.76278356441406 number episode from 10: 26 avegar over 10 episode: -92.689 avegare return across last 100 episodes: -92.689 state values: tensor(0.7601) 237
27 1000 -1000.0 -99.99568287525881 number episode from 10: 27 avegar over 10 episode: -92.95 avegare return across last 100 episodes: -92.95 state values: tensor(0.6298) 1000
28 222 -222.0 -89.25977942573611 number episode from 10: 28 avegar over 10 episode: -92.823 avegare return across last 100 episodes: -92.823 state values: tensor(0.7404) 222
29 236 -236.0 -90.66947834789299 number episode from 10: 29 avegar over 10 episode: -92.751 avegare return across last 100 episodes: -92.751 state values: tensor(0.7598) 236
30 1000 -1000.0 -99.99568287525881 number episode from 10: 30 avegar over 10 episode: -92.985 avegare return across last 100 episodes: -92.985 state values: tensor(0.6300) 1000
31 250 -250.0 -91.89414838378175 number episode from 10: 31 avegar over 10 episode: -92.951 avegare return across last 100 episodes: -92.951 state values: tensor(0.7727) 250
32 249 -249.0 -91.81227109472904 number episode from 10: 32 avegar over 10 episode: -92.916 avegare return across last 100 episodes: -92.916 state values: tensor(0.7727) 249
33 1000 -1000.0 -99.99568287525881 number episode from 10: 33 avegar over 10 episode: -93.125 avegare return across last 100 episodes: -93.125 state values: tensor(0.6301) 1000
34 215 -215.0 -88.47696612862855 number episode from 10: 34 avegar over 10 episode: -92.992 avegare return across last 100 episodes: -92.992 state values: tensor(0.7102) 215
35 1000 -1000.0 -99.99568287525881 number episode from 10: 35 avegar over 10 episode: -93.186 avegare return across last 100 episodes: -93.186 state values: tensor(0.6287) 1000
36 212 -212.0 -88.12424430884558 number episode from 10: 36 avegar over 10 episode: -93.05 avegare return across last 100 episodes: -93.05 state values: tensor(0.7142) 212
37 223 -223.0 -89.36718163147874 number episode from 10: 37 avegar over 10 episode: -92.953 avegare return across last 100 episodes: -92.953 state values: tensor(0.7405) 223
38 1000 -1000.0 -99.99568287525881 number episode from 10: 38 avegar over 10 episode: -93.133 avegare return across last 100 episodes: -93.133 state values: tensor(0.6343) 1000
39 222 -222.0 -89.25977942573611 number episode from 10: 39 avegar over 10 episode: -93.036 avegare return across last 100 episodes: -93.036 state values: tensor(0.7386) 222
40 1000 -1000.0 -99.99568287525881 number episode from 10: 40 avegar over 10 episode: -93.206 avegare return across last 100 episodes: -93.206 state values: tensor(0.6312) 1000
41 1000 -1000.0 -99.99568287525881 number episode from 10: 41 avegar over 10 episode: -93.368 avegare return across last 100 episodes: -93.368 state values: tensor(0.6294) 1000
42 1000 -1000.0 -99.99568287525881 number episode from 10: 42 avegar over 10 episode: -93.522 avegare return across last 100 episodes: -93.522 state values: tensor(0.6313) 1000
43 233 -233.0 -90.383869660685 number episode from 10: 43 avegar over 10 episode: -93.451 avegare return across last 100 episodes: -93.451 state values: tensor(0.7547) 233
44 1000 -1000.0 -99.99568287525881 number episode from 10: 44 avegar over 10 episode: -93.596 avegare return across last 100 episodes: -93.596 state values: tensor(0.6277) 1000
45 1000 -1000.0 -99.99568287525881 number episode from 10: 45 avegar over 10 episode: -93.735 avegare return across last 100 episodes: -93.735 state values: tensor(0.6285) 1000
46 211 -211.0 -88.0042871806521 number episode from 10: 46 avegar over 10 episode: -93.613 avegare return across last 100 episodes: -93.613 state values: tensor(0.7115) 211
47 364 -364.0 -97.42242783310179 number episode from 10: 47 avegar over 10 episode: -93.693 avegare return across last 100 episodes: -93.693 state values: tensor(0.6803) 364
48 218 -218.0 -88.81921175764214 number episode from 10: 48 avegar over 10 episode: -93.593 avegare return across last 100 episodes: -93.593 state values: tensor(0.7325) 218
49 269 -269.0 -93.3031997252135 number episode from 10: 49 avegar over 10 episode: -93.587 avegare return across last 100 episodes: -93.587 state values: tensor(0.7894) 269
50 231 -231.0 -90.18862326363126 number episode from 10: 50 avegar over 10 episode: -93.521 avegare return across last 100 episodes: -93.521 state values: tensor(0.7521) 231
51 216 -216.0 -88.59219646734226 number episode from 10: 51 avegar over 10 episode: -93.426 avegare return across last 100 episodes: -93.426 state values: tensor(0.7320) 216
52 1000 -1000.0 -99.99568287525881 number episode from 10: 52 avegar over 10 episode: -93.55 avegare return across last 100 episodes: -93.55 state values: tensor(0.6363) 1000
53 1000 -1000.0 -99.99568287525881 number episode from 10: 53 avegar over 10 episode: -93.669 avegare return across last 100 episodes: -93.669 state values: tensor(0.6303) 1000
54 1000 -1000.0 -99.99568287525881 number episode from 10: 54 avegar over 10 episode: -93.784 avegare return across last 100 episodes: -93.784 state values: tensor(0.6290) 1000
55 1000 -1000.0 -99.99568287525881 number episode from 10: 55 avegar over 10 episode: -93.895 avegare return across last 100 episodes: -93.895 state values: tensor(0.6276) 1000
56 223 -223.0 -89.36718163147874 number episode from 10: 56 avegar over 10 episode: -93.816 avegare return across last 100 episodes: -93.816 state values: tensor(0.7388) 223
57 1000 -1000.0 -99.99568287525881 number episode from 10: 57 avegar over 10 episode: -93.922 avegare return across last 100 episodes: -93.922 state values: tensor(0.6340) 1000
58 1000 -1000.0 -99.99568287525881 number episode from 10: 58 avegar over 10 episode: -94.025 avegare return across last 100 episodes: -94.025 state values: tensor(0.6334) 1000
59 1000 -1000.0 -99.99568287525881 number episode from 10: 59 avegar over 10 episode: -94.125 avegare return across last 100 episodes: -94.125 state values: tensor(0.6324) 1000
60 236 -236.0 -90.66947834789299 number episode from 10: 60 avegar over 10 episode: -94.068 avegare return across last 100 episodes: -94.068 state values: tensor(0.7571) 236
61 214 -214.0 -88.36057184709955 number episode from 10: 61 avegar over 10 episode: -93.976 avegare return across last 100 episodes: -93.976 state values: tensor(0.7096) 214
62 236 -236.0 -90.66947834789299 number episode from 10: 62 avegar over 10 episode: -93.924 avegare return across last 100 episodes: -93.924 state values: tensor(0.7586) 236
63 1000 -1000.0 -99.99568287525881 number episode from 10: 63 avegar over 10 episode: -94.018 avegare return across last 100 episodes: -94.018 state values: tensor(0.6351) 1000
64 211 -211.0 -88.0042871806521 number episode from 10: 64 avegar over 10 episode: -93.926 avegare return across last 100 episodes: -93.926 state values: tensor(0.7116) 211
65 217 -217.0 -88.70627450266883 number episode from 10: 65 avegar over 10 episode: -93.847 avegare return across last 100 episodes: -93.847 state values: tensor(0.7282) 217
66 1000 -1000.0 -99.99568287525881 number episode from 10: 66 avegar over 10 episode: -93.939 avegare return across last 100 episodes: -93.939 state values: tensor(0.6334) 1000
67 213 -213.0 -88.24300186575712 number episode from 10: 67 avegar over 10 episode: -93.855 avegare return across last 100 episodes: -93.855 state values: tensor(0.7191) 213
68 217 -217.0 -88.70627450266883 number episode from 10: 68 avegar over 10 episode: -93.78 avegare return across last 100 episodes: -93.78 state values: tensor(0.7244) 217
69 222 -222.0 -89.25977942573611 number episode from 10: 69 avegar over 10 episode: -93.716 avegare return across last 100 episodes: -93.716 state values: tensor(0.7408) 222
70 1000 -1000.0 -99.99568287525881 number episode from 10: 70 avegar over 10 episode: -93.804 avegare return across last 100 episodes: -93.804 state values: tensor(0.6288) 1000
71 1000 -1000.0 -99.99568287525881 number episode from 10: 71 avegar over 10 episode: -93.89 avegare return across last 100 episodes: -93.89 state values: tensor(0.6335) 1000
72 276 -276.0 -93.7581445220175 number episode from 10: 72 avegar over 10 episode: -93.888 avegare return across last 100 episodes: -93.888 state values: tensor(0.7913) 276
73 220 -220.0 -89.04170944366506 number episode from 10: 73 avegar over 10 episode: -93.823 avegare return across last 100 episodes: -93.823 state values: tensor(0.7375) 220
74 214 -214.0 -88.36057184709955 number episode from 10: 74 avegar over 10 episode: -93.75 avegare return across last 100 episodes: -93.75 state values: tensor(0.7187) 214
75 1000 -1000.0 -99.99568287525881 number episode from 10: 75 avegar over 10 episode: -93.832 avegare return across last 100 episodes: -93.832 state values: tensor(0.6282) 1000
76 229 -229.0 -89.9894125738509 number episode from 10: 76 avegar over 10 episode: -93.782 avegare return across last 100 episodes: -93.782 state values: tensor(0.7509) 229
77 231 -231.0 -90.18862326363126 number episode from 10: 77 avegar over 10 episode: -93.736 avegare return across last 100 episodes: -93.736 state values: tensor(0.7234) 231
78 1000 -1000.0 -99.99568287525881 number episode from 10: 78 avegar over 10 episode: -93.815 avegare return across last 100 episodes: -93.815 state values: tensor(0.6286) 1000
79 226 -226.0 -89.68298696984219 number episode from 10: 79 avegar over 10 episode: -93.764 avegare return across last 100 episodes: -93.764 state values: tensor(0.7442) 226
80 1000 -1000.0 -99.99568287525881 number episode from 10: 80 avegar over 10 episode: -93.841 avegare return across last 100 episodes: -93.841 state values: tensor(0.6281) 1000
81 1000 -1000.0 -99.99568287525881 number episode from 10: 81 avegar over 10 episode: -93.916 avegare return across last 100 episodes: -93.916 state values: tensor(0.6365) 1000
82 222 -222.0 -89.25977942573611 number episode from 10: 82 avegar over 10 episode: -93.86 avegare return across last 100 episodes: -93.86 state values: tensor(0.7388) 222
83 523 -523.0 -99.47855708071009 number episode from 10: 83 avegar over 10 episode: -93.927 avegare return across last 100 episodes: -93.927 state values: tensor(0.6665) 523
84 216 -216.0 -88.59219646734226 number episode from 10: 84 avegar over 10 episode: -93.864 avegare return across last 100 episodes: -93.864 state values: tensor(0.7253) 216
85 216 -216.0 -88.59219646734226 number episode from 10: 85 avegar over 10 episode: -93.803 avegare return across last 100 episodes: -93.803 state values: tensor(0.7183) 216
86 217 -217.0 -88.70627450266883 number episode from 10: 86 avegar over 10 episode: -93.744 avegare return across last 100 episodes: -93.744 state values: tensor(0.7276) 217
87 223 -223.0 -89.36718163147874 number episode from 10: 87 avegar over 10 episode: -93.694 avegare return across last 100 episodes: -93.694 state values: tensor(0.7408) 223
88 1000 -1000.0 -99.99568287525881 number episode from 10: 88 avegar over 10 episode: -93.765 avegare return across last 100 episodes: -93.765 state values: tensor(0.6270) 1000
89 1000 -1000.0 -99.99568287525881 number episode from 10: 89 avegar over 10 episode: -93.834 avegare return across last 100 episodes: -93.834 state values: tensor(0.6334) 1000
90 1000 -1000.0 -99.99568287525881 number episode from 10: 90 avegar over 10 episode: -93.902 avegare return across last 100 episodes: -93.902 state values: tensor(0.6281) 1000
91 1000 -1000.0 -99.99568287525881 number episode from 10: 91 avegar over 10 episode: -93.968 avegare return across last 100 episodes: -93.968 state values: tensor(0.6656) 1000
92 1000 -1000.0 -99.99568287525881 number episode from 10: 92 avegar over 10 episode: -94.033 avegare return across last 100 episodes: -94.033 state values: tensor(0.6318) 1000
93 1000 -1000.0 -99.99568287525881 number episode from 10: 93 avegar over 10 episode: -94.096 avegare return across last 100 episodes: -94.096 state values: tensor(0.6269) 1000
94 269 -269.0 -93.3031997252135 number episode from 10: 94 avegar over 10 episode: -94.088 avegare return across last 100 episodes: -94.088 state values: tensor(0.7894) 269
95 1000 -1000.0 -99.99568287525881 number episode from 10: 95 avegar over 10 episode: -94.15 avegare return across last 100 episodes: -94.15 state values: tensor(0.6323) 1000
96 237 -237.0 -90.76278356441406 number episode from 10: 96 avegar over 10 episode: -94.115 avegare return across last 100 episodes: -94.115 state values: tensor(0.7601) 237
97 222 -222.0 -89.25977942573611 number episode from 10: 97 avegar over 10 episode: -94.065 avegare return across last 100 episodes: -94.065 state values: tensor(0.7379) 222
98 216 -216.0 -88.59219646734226 number episode from 10: 98 avegar over 10 episode: -94.01 avegare return across last 100 episodes: -94.01 state values: tensor(0.7184) 216
99 1000 -1000.0 -99.99568287525881 number episode from 10: 99 avegar over 10 episode: -94.07 avegare return across last 100 episodes: -94.07 state values: tensor(0.6275) 1000
100 213 -213.0 -88.24300186575712 number episode from 10: 100 avegar over 10 episode: -94.012 avegare return across last 100 episodes: -93.962 state values: tensor(0.7172) 213
101 311 -311.0 -95.60918115149273 number episode from 10: 101 avegar over 10 episode: -94.028 avegare return across last 100 episodes: -94.012 state values: tensor(0.7064) 311
102 235 -235.0 -90.57523065443736 number episode from 10: 102 avegar over 10 episode: -93.994 avegare return across last 100 episodes: -93.986 state values: tensor(0.7558) 235
103 214 -214.0 -88.36057184709955 number episode from 10: 103 avegar over 10 episode: -93.94 avegare return across last 100 episodes: -93.988 state values: tensor(0.7116) 214
104 1000 -1000.0 -99.99568287525881 number episode from 10: 104 avegar over 10 episode: -93.998 avegare return across last 100 episodes: -94.096 state values: tensor(0.6297) 1000
105 527 -527.0 -99.49910401228738 number episode from 10: 105 avegar over 10 episode: -94.05 avegare return across last 100 episodes: -94.175 state values: tensor(0.6671) 527
106 214 -214.0 -88.36057184709955 number episode from 10: 106 avegar over 10 episode: -93.996 avegare return across last 100 episodes: -94.174 state values: tensor(0.7112) 214
107 218 -218.0 -88.81921175764214 number episode from 10: 107 avegar over 10 episode: -93.948 avegare return across last 100 episodes: -94.161 state values: tensor(0.7357) 218
108 222 -222.0 -89.25977942573611 number episode from 10: 108 avegar over 10 episode: -93.905 avegare return across last 100 episodes: -94.054 state values: tensor(0.7239) 222
109 1000 -1000.0 -99.99568287525881 number episode from 10: 109 avegar over 10 episode: -93.961 avegare return across last 100 episodes: -94.054 state values: tensor(0.6304) 1000
110 214 -214.0 -88.36057184709955 number episode from 10: 110 avegar over 10 episode: -93.91 avegare return across last 100 episodes: -93.937 state values: tensor(0.7209) 214
111 1000 -1000.0 -99.99568287525881 number episode from 10: 111 avegar over 10 episode: -93.965 avegare return across last 100 episodes: -93.937 state values: tensor(0.6334) 1000
112 1000 -1000.0 -99.99568287525881 number episode from 10: 112 avegar over 10 episode: -94.018 avegare return across last 100 episodes: -94.142 state values: tensor(0.6281) 1000
113 1000 -1000.0 -99.99568287525881 number episode from 10: 113 avegar over 10 episode: -94.071 avegare return across last 100 episodes: -94.142 state values: tensor(0.6321) 1000
114 225 -225.0 -89.57877471701231 number episode from 10: 114 avegar over 10 episode: -94.031 avegare return across last 100 episodes: -94.147 state values: tensor(0.7390) 225
115 370 -370.0 -97.57326697121681 number episode from 10: 115 avegar over 10 episode: -94.062 avegare return across last 100 episodes: -94.239 state values: tensor(0.6802) 370
116 253 -253.0 -92.13490028263506 number episode from 10: 116 avegar over 10 episode: -94.046 avegare return across last 100 episodes: -94.161 state values: tensor(0.7773) 253
117 1000 -1000.0 -99.99568287525881 number episode from 10: 117 avegar over 10 episode: -94.096 avegare return across last 100 episodes: -94.272 state values: tensor(0.6346) 1000
118 1000 -1000.0 -99.99568287525881 number episode from 10: 118 avegar over 10 episode: -94.146 avegare return across last 100 episodes: -94.365 state values: tensor(0.6302) 1000
119 1000 -1000.0 -99.99568287525881 number episode from 10: 119 avegar over 10 episode: -94.194 avegare return across last 100 episodes: -94.475 state values: tensor(0.6377) 1000
120 1000 -1000.0 -99.99568287525881 number episode from 10: 120 avegar over 10 episode: -94.242 avegare return across last 100 episodes: -94.475 state values: tensor(0.6362) 1000
121 831 -831.0 -99.97640354778837 number episode from 10: 121 avegar over 10 episode: -94.289 avegare return across last 100 episodes: -94.475 state values: tensor(0.6574) 831
122 311 -311.0 -95.60918115149273 number episode from 10: 122 avegar over 10 episode: -94.3 avegare return across last 100 episodes: -94.646 state values: tensor(0.7012) 311
123 220 -220.0 -89.04170944366506 number episode from 10: 123 avegar over 10 episode: -94.258 avegare return across last 100 episodes: -94.652 state values: tensor(0.7338) 220
124 1000 -1000.0 -99.99568287525881 number episode from 10: 124 avegar over 10 episode: -94.303 avegare return across last 100 episodes: -94.76 state values: tensor(0.6295) 1000
125 1000 -1000.0 -99.99568287525881 number episode from 10: 125 avegar over 10 episode: -94.349 avegare return across last 100 episodes: -94.761 state values: tensor(0.6368) 1000
126 217 -217.0 -88.70627450266883 number episode from 10: 126 avegar over 10 episode: -94.304 avegare return across last 100 episodes: -94.74 state values: tensor(0.7279) 217
127 216 -216.0 -88.59219646734226 number episode from 10: 127 avegar over 10 episode: -94.26 avegare return across last 100 episodes: -94.626 state values: tensor(0.7225) 216
128 227 -227.0 -89.78615710014377 number episode from 10: 128 avegar over 10 episode: -94.225 avegare return across last 100 episodes: -94.631 state values: tensor(0.7439) 227
129 1000 -1000.0 -99.99568287525881 number episode from 10: 129 avegar over 10 episode: -94.269 avegare return across last 100 episodes: -94.725 state values: tensor(0.6299) 1000
130 212 -212.0 -88.12424430884558 number episode from 10: 130 avegar over 10 episode: -94.222 avegare return across last 100 episodes: -94.606 state values: tensor(0.7141) 212
131 1000 -1000.0 -99.99568287525881 number episode from 10: 131 avegar over 10 episode: -94.266 avegare return across last 100 episodes: -94.687 state values: tensor(0.6292) 1000
132 1000 -1000.0 -99.99568287525881 number episode from 10: 132 avegar over 10 episode: -94.309 avegare return across last 100 episodes: -94.769 state values: tensor(0.6312) 1000
133 671 -671.0 -99.88218093417017 number episode from 10: 133 avegar over 10 episode: -94.351 avegare return across last 100 episodes: -94.768 state values: tensor(0.6592) 671
134 219 -219.0 -88.93101964006571 number episode from 10: 134 avegar over 10 episode: -94.311 avegare return across last 100 episodes: -94.772 state values: tensor(0.7360) 219
135 1000 -1000.0 -99.99568287525881 number episode from 10: 135 avegar over 10 episode: -94.352 avegare return across last 100 episodes: -94.772 state values: tensor(0.6331) 1000
136 217 -217.0 -88.70627450266883 number episode from 10: 136 avegar over 10 episode: -94.311 avegare return across last 100 episodes: -94.778 state values: tensor(0.7280) 217
137 211 -211.0 -88.0042871806521 number episode from 10: 137 avegar over 10 episode: -94.266 avegare return across last 100 episodes: -94.764 state values: tensor(0.7142) 211
138 257 -257.0 -92.44481659324711 number episode from 10: 138 avegar over 10 episode: -94.252 avegare return across last 100 episodes: -94.689 state values: tensor(0.7792) 257
139 1000 -1000.0 -99.99568287525881 number episode from 10: 139 avegar over 10 episode: -94.293 avegare return across last 100 episodes: -94.796 state values: tensor(0.6321) 1000
140 1000 -1000.0 -99.99568287525881 number episode from 10: 140 avegar over 10 episode: -94.334 avegare return across last 100 episodes: -94.796 state values: tensor(0.6276) 1000
141 253 -253.0 -92.13490028263506 number episode from 10: 141 avegar over 10 episode: -94.318 avegare return across last 100 episodes: -94.718 state values: tensor(0.7748) 253
142 234 -234.0 -90.48003096407814 number episode from 10: 142 avegar over 10 episode: -94.292 avegare return across last 100 episodes: -94.622 state values: tensor(0.7543) 234
143 212 -212.0 -88.12424430884558 number episode from 10: 143 avegar over 10 episode: -94.249 avegare return across last 100 episodes: -94.6 state values: tensor(0.7151) 212
144 1000 -1000.0 -99.99568287525881 number episode from 10: 144 avegar over 10 episode: -94.288 avegare return across last 100 episodes: -94.6 state values: tensor(0.6288) 1000
145 1000 -1000.0 -99.99568287525881 number episode from 10: 145 avegar over 10 episode: -94.327 avegare return across last 100 episodes: -94.6 state values: tensor(0.6355) 1000
146 214 -214.0 -88.36057184709955 number episode from 10: 146 avegar over 10 episode: -94.287 avegare return across last 100 episodes: -94.603 state values: tensor(0.7220) 214
147 1000 -1000.0 -99.99568287525881 number episode from 10: 147 avegar over 10 episode: -94.325 avegare return across last 100 episodes: -94.629 state values: tensor(0.6340) 1000
148 1000 -1000.0 -99.99568287525881 number episode from 10: 148 avegar over 10 episode: -94.363 avegare return across last 100 episodes: -94.741 state values: tensor(0.6329) 1000
149 1000 -1000.0 -99.99568287525881 number episode from 10: 149 avegar over 10 episode: -94.401 avegare return across last 100 episodes: -94.808 state values: tensor(0.6339) 1000
150 1000 -1000.0 -99.99568287525881 number episode from 10: 150 avegar over 10 episode: -94.438 avegare return across last 100 episodes: -94.906 state values: tensor(0.6298) 1000
151 1000 -1000.0 -99.99568287525881 number episode from 10: 151 avegar over 10 episode: -94.475 avegare return across last 100 episodes: -95.02 state values: tensor(0.6294) 1000
152 216 -216.0 -88.59219646734226 number episode from 10: 152 avegar over 10 episode: -94.436 avegare return across last 100 episodes: -94.906 state values: tensor(0.7259) 216
153 596 -596.0 -99.74963363721328 number episode from 10: 153 avegar over 10 episode: -94.471 avegare return across last 100 episodes: -94.903 state values: tensor(0.6632) 596
154 893 -893.0 -99.98734597245127 number episode from 10: 154 avegar over 10 episode: -94.506 avegare return across last 100 episodes: -94.903 state values: tensor(0.6526) 893
155 235 -235.0 -90.57523065443736 number episode from 10: 155 avegar over 10 episode: -94.481 avegare return across last 100 episodes: -94.809 state values: tensor(0.7555) 235
156 219 -219.0 -88.93101964006571 number episode from 10: 156 avegar over 10 episode: -94.446 avegare return across last 100 episodes: -94.805 state values: tensor(0.7322) 219
157 212 -212.0 -88.12424430884558 number episode from 10: 157 avegar over 10 episode: -94.406 avegare return across last 100 episodes: -94.686 state values: tensor(0.7097) 212
158 221 -221.0 -89.1512923492284 number episode from 10: 158 avegar over 10 episode: -94.373 avegare return across last 100 episodes: -94.578 state values: tensor(0.7377) 221
159 222 -222.0 -89.25977942573611 number episode from 10: 159 avegar over 10 episode: -94.341 avegare return across last 100 episodes: -94.47 state values: tensor(0.7395) 222
160 288 -288.0 -94.46731373287786 number episode from 10: 160 avegar over 10 episode: -94.342 avegare return across last 100 episodes: -94.508 state values: tensor(0.6932) 288
161 232 -232.0 -90.28673703099494 number episode from 10: 161 avegar over 10 episode: -94.316 avegare return across last 100 episodes: -94.528 state values: tensor(0.7582) 232
162 1000 -1000.0 -99.99568287525881 number episode from 10: 162 avegar over 10 episode: -94.351 avegare return across last 100 episodes: -94.621 state values: tensor(0.6297) 1000
163 214 -214.0 -88.36057184709955 number episode from 10: 163 avegar over 10 episode: -94.315 avegare return across last 100 episodes: -94.504 state values: tensor(0.7189) 214
164 227 -227.0 -89.78615710014377 number episode from 10: 164 avegar over 10 episode: -94.287 avegare return across last 100 episodes: -94.522 state values: tensor(0.7443) 227
165 1000 -1000.0 -99.99568287525881 number episode from 10: 165 avegar over 10 episode: -94.322 avegare return across last 100 episodes: -94.635 state values: tensor(0.6297) 1000
166 216 -216.0 -88.59219646734226 number episode from 10: 166 avegar over 10 episode: -94.287 avegare return across last 100 episodes: -94.521 state values: tensor(0.7135) 216
167 220 -220.0 -89.04170944366506 number episode from 10: 167 avegar over 10 episode: -94.256 avegare return across last 100 episodes: -94.529 state values: tensor(0.7351) 220
168 1000 -1000.0 -99.99568287525881 number episode from 10: 168 avegar over 10 episode: -94.29 avegare return across last 100 episodes: -94.642 state values: tensor(0.6300) 1000
169 1000 -1000.0 -99.99568287525881 number episode from 10: 169 avegar over 10 episode: -94.324 avegare return across last 100 episodes: -94.749 state values: tensor(0.6340) 1000
170 1000 -1000.0 -99.99568287525881 number episode from 10: 170 avegar over 10 episode: -94.357 avegare return across last 100 episodes: -94.749 state values: tensor(0.6314) 1000
171 221 -221.0 -89.1512923492284 number episode from 10: 171 avegar over 10 episode: -94.327 avegare return across last 100 episodes: -94.641 state values: tensor(0.7364) 221
172 156 -156.0 -79.15075382652377 number episode from 10: 172 avegar over 10 episode: -94.239 avegare return across last 100 episodes: -94.495 state values: tensor(0.7709) 156
173 215 -215.0 -88.47696612862855 number episode from 10: 173 avegar over 10 episode: -94.206 avegare return across last 100 episodes: -94.489 state values: tensor(0.7187) 215
174 208 -208.0 -87.6370965863637 number episode from 10: 174 avegar over 10 episode: -94.168 avegare return across last 100 episodes: -94.482 state values: tensor(0.7176) 208
175 1000 -1000.0 -99.99568287525881 number episode from 10: 175 avegar over 10 episode: -94.201 avegare return across last 100 episodes: -94.482 state values: tensor(0.6284) 1000
176 1000 -1000.0 -99.99568287525881 number episode from 10: 176 avegar over 10 episode: -94.234 avegare return across last 100 episodes: -94.582 state values: tensor(0.6311) 1000
177 211 -211.0 -88.0042871806521 number episode from 10: 177 avegar over 10 episode: -94.199 avegare return across last 100 episodes: -94.56 state values: tensor(0.7111) 211
178 326 -326.0 -96.22363956562485 number episode from 10: 178 avegar over 10 episode: -94.21 avegare return across last 100 episodes: -94.522 state values: tensor(0.7373) 326
179 219 -219.0 -88.93101964006571 number episode from 10: 179 avegar over 10 episode: -94.181 avegare return across last 100 episodes: -94.515 state values: tensor(0.7317) 219
180 212 -212.0 -88.12424430884558 number episode from 10: 180 avegar over 10 episode: -94.148 avegare return across last 100 episodes: -94.396 state values: tensor(0.7150) 212
181 929 -929.0 -99.99118756795343 number episode from 10: 181 avegar over 10 episode: -94.18 avegare return across last 100 episodes: -94.396 state values: tensor(0.6681) 929
182 1000 -1000.0 -99.99568287525881 number episode from 10: 182 avegar over 10 episode: -94.212 avegare return across last 100 episodes: -94.504 state values: tensor(0.6309) 1000
183 212 -212.0 -88.12424430884558 number episode from 10: 183 avegar over 10 episode: -94.178 avegare return across last 100 episodes: -94.39 state values: tensor(0.7124) 212
184 214 -214.0 -88.36057184709955 number episode from 10: 184 avegar over 10 episode: -94.147 avegare return across last 100 episodes: -94.388 state values: tensor(0.7186) 214
185 1000 -1000.0 -99.99568287525881 number episode from 10: 185 avegar over 10 episode: -94.178 avegare return across last 100 episodes: -94.502 state values: tensor(0.6316) 1000
186 214 -214.0 -88.36057184709955 number episode from 10: 186 avegar over 10 episode: -94.147 avegare return across last 100 episodes: -94.498 state values: tensor(0.7196) 214
187 218 -218.0 -88.81921175764214 number episode from 10: 187 avegar over 10 episode: -94.119 avegare return across last 100 episodes: -94.493 state values: tensor(0.7300) 218
188 215 -215.0 -88.47696612862855 number episode from 10: 188 avegar over 10 episode: -94.089 avegare return across last 100 episodes: -94.378 state values: tensor(0.7234) 215
189 211 -211.0 -88.0042871806521 number episode from 10: 189 avegar over 10 episode: -94.057 avegare return across last 100 episodes: -94.258 state values: tensor(0.7117) 211
190 1000 -1000.0 -99.99568287525881 number episode from 10: 190 avegar over 10 episode: -94.088 avegare return across last 100 episodes: -94.258 state values: tensor(0.6279) 1000
191 286 -286.0 -94.3549777909171 number episode from 10: 191 avegar over 10 episode: -94.09 avegare return across last 100 episodes: -94.201 state values: tensor(0.6923) 286
192 234 -234.0 -90.48003096407814 number episode from 10: 192 avegar over 10 episode: -94.071 avegare return across last 100 episodes: -94.106 state values: tensor(0.7561) 234
193 210 -210.0 -87.88311836429506 number episode from 10: 193 avegar over 10 episode: -94.039 avegare return across last 100 episodes: -93.985 state values: tensor(0.7186) 210
194 244 -244.0 -91.39031064927343 number episode from 10: 194 avegar over 10 episode: -94.025 avegare return across last 100 episodes: -93.966 state values: tensor(0.7697) 244
195 228 -228.0 -89.88829552914233 number episode from 10: 195 avegar over 10 episode: -94.004 avegare return across last 100 episodes: -93.865 state values: tensor(0.7455) 228
196 634 -634.0 -99.82911128864384 number episode from 10: 196 avegar over 10 episode: -94.034 avegare return across last 100 episodes: -93.955 state values: tensor(0.6950) 634
197 216 -216.0 -88.59219646734226 number episode from 10: 197 avegar over 10 episode: -94.006 avegare return across last 100 episodes: -93.949 state values: tensor(0.7299) 216
198 222 -222.0 -89.25977942573611 number episode from 10: 198 avegar over 10 episode: -93.983 avegare return across last 100 episodes: -93.955 state values: tensor(0.7401) 222
199 232 -232.0 -90.28673703099494 number episode from 10: 199 avegar over 10 episode: -93.964 avegare return across last 100 episodes: -93.858 state values: tensor(0.7513) 232
200 1000 -1000.0 -99.99568287525881 number episode from 10: 200 avegar over 10 episode: -93.994 avegare return across last 100 episodes: -93.976 state values: tensor(0.6275) 1000
load offline data!!!!!
mem_cntr: 50000 ; mem_size: 50000
nn.learn_nn_feature_fqi FQI:  998
nn.learn_nn_feature_fqi FQI:  1998
nn.learn_nn_feature_fqi FQI:  2998
nn.learn_nn_feature_fqi FQI:  3998
nn.learn_nn_feature_fqi FQI:  4998
nn.learn_nn_feature_fqi FQI:  5998
nn.learn_nn_feature_fqi FQI:  6998
nn.learn_nn_feature_fqi FQI:  7998
nn.learn_nn_feature_fqi FQI:  8998
nn.learn_nn_feature_fqi FQI:  9998
nn.learn_nn_feature_fqi FQI:  10998
nn.learn_nn_feature_fqi FQI:  11998
nn.learn_nn_feature_fqi FQI:  12998
nn.learn_nn_feature_fqi FQI:  13998
nn.learn_nn_feature_fqi FQI:  14998
nn.learn_nn_feature_fqi FQI:  15998
nn.learn_nn_feature_fqi FQI:  16998
nn.learn_nn_feature_fqi FQI:  17998
nn.learn_nn_feature_fqi FQI:  18998
nn.learn_nn_feature_fqi FQI:  19998
nn.learn_nn_feature_fqi FQI:  20998
nn.learn_nn_feature_fqi FQI:  21998
nn.learn_nn_feature_fqi FQI:  22998
nn.learn_nn_feature_fqi FQI:  23998
nn.learn_nn_feature_fqi FQI:  24998
nn.learn_nn_feature_fqi FQI:  25998
nn.learn_nn_feature_fqi FQI:  26998
nn.learn_nn_feature_fqi FQI:  27998
nn.learn_nn_feature_fqi FQI:  28998
nn.learn_nn_feature_fqi FQI:  29998
nn.learn_nn_feature_fqi FQI:  30998
nn.learn_nn_feature_fqi FQI:  31998
nn.learn_nn_feature_fqi FQI:  32998
nn.learn_nn_feature_fqi FQI:  33998
nn.learn_nn_feature_fqi FQI:  34998
nn.learn_nn_feature_fqi FQI:  35998
nn.learn_nn_feature_fqi FQI:  36998
nn.learn_nn_feature_fqi FQI:  37998
nn.learn_nn_feature_fqi FQI:  38998
nn.learn_nn_feature_fqi FQI:  39998
nn.learn_nn_feature_fqi FQI:  40998
nn.learn_nn_feature_fqi FQI:  41998
nn.learn_nn_feature_fqi FQI:  42998
nn.learn_nn_feature_fqi FQI:  43998
nn.learn_nn_feature_fqi FQI:  44998
nn.learn_nn_feature_fqi FQI:  45998
nn.learn_nn_feature_fqi FQI:  46998
nn.learn_nn_feature_fqi FQI:  47998
nn.learn_nn_feature_fqi FQI:  48998
nn.learn_nn_feature_fqi FQI:  49998
nn.learn_nn_feature_fqi FQI:  50998
nn.learn_nn_feature_fqi FQI:  51998
nn.learn_nn_feature_fqi FQI:  52998
nn.learn_nn_feature_fqi FQI:  53998
nn.learn_nn_feature_fqi FQI:  54998
nn.learn_nn_feature_fqi FQI:  55998
nn.learn_nn_feature_fqi FQI:  56998
nn.learn_nn_feature_fqi FQI:  57998
nn.learn_nn_feature_fqi FQI:  58998
nn.learn_nn_feature_fqi FQI:  59998
nn.learn_nn_feature_fqi FQI:  60998
nn.learn_nn_feature_fqi FQI:  61998
nn.learn_nn_feature_fqi FQI:  62998
nn.learn_nn_feature_fqi FQI:  63998
nn.learn_nn_feature_fqi FQI:  64998
nn.learn_nn_feature_fqi FQI:  65998
nn.learn_nn_feature_fqi FQI:  66998
nn.learn_nn_feature_fqi FQI:  67998
nn.learn_nn_feature_fqi FQI:  68998
nn.learn_nn_feature_fqi FQI:  69998
nn.learn_nn_feature_fqi FQI:  70998
nn.learn_nn_feature_fqi FQI:  71998
nn.learn_nn_feature_fqi FQI:  72998
nn.learn_nn_feature_fqi FQI:  73998
nn.learn_nn_feature_fqi FQI:  74998
nn.learn_nn_feature_fqi FQI:  75998
nn.learn_nn_feature_fqi FQI:  76998
nn.learn_nn_feature_fqi FQI:  77998
nn.learn_nn_feature_fqi FQI:  78998
nn.learn_nn_feature_fqi FQI:  79998
nn.learn_nn_feature_fqi FQI:  80998
nn.learn_nn_feature_fqi FQI:  81998
nn.learn_nn_feature_fqi FQI:  82998
nn.learn_nn_feature_fqi FQI:  83998
nn.learn_nn_feature_fqi FQI:  84998
nn.learn_nn_feature_fqi FQI:  85998
nn.learn_nn_feature_fqi FQI:  86998
nn.learn_nn_feature_fqi FQI:  87998
nn.learn_nn_feature_fqi FQI:  88998
nn.learn_nn_feature_fqi FQI:  89998
nn.learn_nn_feature_fqi FQI:  90998
nn.learn_nn_feature_fqi FQI:  91998
nn.learn_nn_feature_fqi FQI:  92998
nn.learn_nn_feature_fqi FQI:  93998
nn.learn_nn_feature_fqi FQI:  94998
nn.learn_nn_feature_fqi FQI:  95998
nn.learn_nn_feature_fqi FQI:  96998
nn.learn_nn_feature_fqi FQI:  97998
nn.learn_nn_feature_fqi FQI:  98998
nn.learn_nn_feature_fqi FQI:  99998
nn.learn_nn_feature_fqi FQI:  100998
nn.learn_nn_feature_fqi FQI:  101998
nn.learn_nn_feature_fqi FQI:  102998
nn.learn_nn_feature_fqi FQI:  103998
nn.learn_nn_feature_fqi FQI:  104998
nn.learn_nn_feature_fqi FQI:  105998
nn.learn_nn_feature_fqi FQI:  106998
nn.learn_nn_feature_fqi FQI:  107998
nn.learn_nn_feature_fqi FQI:  108998
nn.learn_nn_feature_fqi FQI:  109998
nn.learn_nn_feature_fqi FQI:  110998
nn.learn_nn_feature_fqi FQI:  111998
nn.learn_nn_feature_fqi FQI:  112998
nn.learn_nn_feature_fqi FQI:  113998
nn.learn_nn_feature_fqi FQI:  114998
nn.learn_nn_feature_fqi FQI:  115998
nn.learn_nn_feature_fqi FQI:  116998
nn.learn_nn_feature_fqi FQI:  117998
nn.learn_nn_feature_fqi FQI:  118998
nn.learn_nn_feature_fqi FQI:  119998
nn.learn_nn_feature_fqi FQI:  120998
nn.learn_nn_feature_fqi FQI:  121998
nn.learn_nn_feature_fqi FQI:  122998
nn.learn_nn_feature_fqi FQI:  123998
nn.learn_nn_feature_fqi FQI:  124998
nn.learn_nn_feature_fqi FQI:  125998
nn.learn_nn_feature_fqi FQI:  126998
nn.learn_nn_feature_fqi FQI:  127998
nn.learn_nn_feature_fqi FQI:  128998
nn.learn_nn_feature_fqi FQI:  129998
nn.learn_nn_feature_fqi FQI:  130998
nn.learn_nn_feature_fqi FQI:  131998
nn.learn_nn_feature_fqi FQI:  132998
nn.learn_nn_feature_fqi FQI:  133998
nn.learn_nn_feature_fqi FQI:  134998
nn.learn_nn_feature_fqi FQI:  135998
nn.learn_nn_feature_fqi FQI:  136998
nn.learn_nn_feature_fqi FQI:  137998
nn.learn_nn_feature_fqi FQI:  138998
nn.learn_nn_feature_fqi FQI:  139998
nn.learn_nn_feature_fqi FQI:  140998
nn.learn_nn_feature_fqi FQI:  141998
nn.learn_nn_feature_fqi FQI:  142998
nn.learn_nn_feature_fqi FQI:  143998
nn.learn_nn_feature_fqi FQI:  144998
nn.learn_nn_feature_fqi FQI:  145998
nn.learn_nn_feature_fqi FQI:  146998
nn.learn_nn_feature_fqi FQI:  147998
nn.learn_nn_feature_fqi FQI:  148998
nn.learn_nn_feature_fqi FQI:  149998
nn.learn_nn_feature_fqi FQI:  150998
nn.learn_nn_feature_fqi FQI:  151998
nn.learn_nn_feature_fqi FQI:  152998
nn.learn_nn_feature_fqi FQI:  153998
nn.learn_nn_feature_fqi FQI:  154998
nn.learn_nn_feature_fqi FQI:  155998
0 348 -347.0 -95.9727539586799 number episode from 10: 0 avegar over 10 episode: -95.973 avegare return across last 100 episodes: -95.973 state values: tensor(0.8474) 347
1 335 -335.0 -96.55022961048348 number episode from 10: 1 avegar over 10 episode: -96.261 avegare return across last 100 episodes: -96.261 state values: tensor(0.8395) 335
2 388 -388.0 -97.97485789211497 number episode from 10: 2 avegar over 10 episode: -96.833 avegare return across last 100 episodes: -96.833 state values: tensor(0.8377) 388
3 427 -427.0 -98.63155264922688 number episode from 10: 3 avegar over 10 episode: -97.282 avegare return across last 100 episodes: -97.282 state values: tensor(0.8282) 427
4 416 -416.0 -98.47158619185093 number episode from 10: 4 avegar over 10 episode: -97.52 avegare return across last 100 episodes: -97.52 state values: tensor(0.8337) 416
5 1000 -1000.0 -99.99568287525881 number episode from 10: 5 avegar over 10 episode: -97.933 avegare return across last 100 episodes: -97.933 state values: tensor(0.7679) 1000
6 550 -550.0 -99.6024817895315 number episode from 10: 6 avegar over 10 episode: -98.171 avegare return across last 100 episodes: -98.171 state values: tensor(0.8188) 550
7 401 -401.0 -98.22289522577042 number episode from 10: 7 avegar over 10 episode: -98.178 avegare return across last 100 episodes: -98.178 state values: tensor(0.8415) 401
8 324 -324.0 -96.14696415225472 number episode from 10: 8 avegar over 10 episode: -97.952 avegare return across last 100 episodes: -97.952 state values: tensor(0.8413) 324
9 412 -412.0 -98.40889011380645 number episode from 10: 9 avegar over 10 episode: -97.998 avegare return across last 100 episodes: -97.998 state values: tensor(0.8351) 412
10 347 -347.0 -96.94217571583829 number episode from 10: 10 avegar over 10 episode: -97.902 avegare return across last 100 episodes: -97.902 state values: tensor(0.8438) 347
11 394 -394.0 -98.09336890571012 number episode from 10: 11 avegar over 10 episode: -97.918 avegare return across last 100 episodes: -97.918 state values: tensor(0.8387) 394
12 415 -415.0 -98.45614766853629 number episode from 10: 12 avegar over 10 episode: -97.959 avegare return across last 100 episodes: -97.959 state values: tensor(0.8369) 415
13 351 -351.0 -97.06266619335314 number episode from 10: 13 avegar over 10 episode: -97.895 avegare return across last 100 episodes: -97.895 state values: tensor(0.8475) 351
14 1000 -1000.0 -99.99568287525881 number episode from 10: 14 avegar over 10 episode: -98.035 avegare return across last 100 episodes: -98.035 state values: tensor(0.7678) 1000
15 423 -423.0 -98.57541845216168 number episode from 10: 15 avegar over 10 episode: -98.069 avegare return across last 100 episodes: -98.069 state values: tensor(0.8365) 423
16 1000 -1000.0 -99.99568287525881 number episode from 10: 16 avegar over 10 episode: -98.182 avegare return across last 100 episodes: -98.182 state values: tensor(0.7681) 1000
17 352 -352.0 -97.0920395314196 number episode from 10: 17 avegar over 10 episode: -98.122 avegare return across last 100 episodes: -98.122 state values: tensor(0.8477) 352
18 1000 -1000.0 -99.99568287525881 number episode from 10: 18 avegar over 10 episode: -98.22 avegare return across last 100 episodes: -98.22 state values: tensor(0.7727) 1000
19 336 -336.0 -96.58472731437865 number episode from 10: 19 avegar over 10 episode: -98.139 avegare return across last 100 episodes: -98.139 state values: tensor(0.8415) 336
20 401 -401.0 -98.22289522577042 number episode from 10: 20 avegar over 10 episode: -98.143 avegare return across last 100 episodes: -98.143 state values: tensor(0.8405) 401
21 655 -655.0 -99.86162664805052 number episode from 10: 21 avegar over 10 episode: -98.221 avegare return across last 100 episodes: -98.221 state values: tensor(0.8093) 655
22 357 -357.0 -97.23455852887751 number episode from 10: 22 avegar over 10 episode: -98.178 avegare return across last 100 episodes: -98.178 state values: tensor(0.8483) 357
23 1000 -1000.0 -99.99568287525881 number episode from 10: 23 avegar over 10 episode: -98.254 avegare return across last 100 episodes: -98.254 state values: tensor(0.7678) 1000
24 354 -354.0 -97.14990794474436 number episode from 10: 24 avegar over 10 episode: -98.209 avegare return across last 100 episodes: -98.209 state values: tensor(0.8477) 354
25 428 -428.0 -98.6452371227346 number episode from 10: 25 avegar over 10 episode: -98.226 avegare return across last 100 episodes: -98.226 state values: tensor(0.8422) 428
26 317 -317.0 -95.86613121451465 number episode from 10: 26 avegar over 10 episode: -98.139 avegare return across last 100 episodes: -98.139 state values: tensor(0.8318) 317
27 1000 -1000.0 -99.99568287525881 number episode from 10: 27 avegar over 10 episode: -98.205 avegare return across last 100 episodes: -98.205 state values: tensor(0.7680) 1000
28 419 -419.0 -98.51698161036676 number episode from 10: 28 avegar over 10 episode: -98.216 avegare return across last 100 episodes: -98.216 state values: tensor(0.8341) 419
29 348 -348.0 -96.9727539586799 number episode from 10: 29 avegar over 10 episode: -98.174 avegare return across last 100 episodes: -98.174 state values: tensor(0.8470) 348
30 1000 -1000.0 -99.99568287525881 number episode from 10: 30 avegar over 10 episode: -98.233 avegare return across last 100 episodes: -98.233 state values: tensor(0.7790) 1000
31 339 -339.0 -96.68616432841428 number episode from 10: 31 avegar over 10 episode: -98.185 avegare return across last 100 episodes: -98.185 state values: tensor(0.8431) 339
32 768 -768.0 -99.95555433066257 number episode from 10: 32 avegar over 10 episode: -98.238 avegare return across last 100 episodes: -98.238 state values: tensor(0.8036) 768
33 435 -435.0 -98.73727246747016 number episode from 10: 33 avegar over 10 episode: -98.253 avegare return across last 100 episodes: -98.253 state values: tensor(0.8456) 435
34 424 -424.0 -98.58966426764006 number episode from 10: 34 avegar over 10 episode: -98.263 avegare return across last 100 episodes: -98.263 state values: tensor(0.8366) 424
35 335 -335.0 -96.55022961048348 number episode from 10: 35 avegar over 10 episode: -98.215 avegare return across last 100 episodes: -98.215 state values: tensor(0.8404) 335
36 395 -395.0 -98.11243521665303 number episode from 10: 36 avegar over 10 episode: -98.212 avegare return across last 100 episodes: -98.212 state values: tensor(0.8356) 395
37 423 -423.0 -98.57541845216168 number episode from 10: 37 avegar over 10 episode: -98.222 avegare return across last 100 episodes: -98.222 state values: tensor(0.8363) 423
38 325 -325.0 -96.18549451073217 number episode from 10: 38 avegar over 10 episode: -98.17 avegare return across last 100 episodes: -98.17 state values: tensor(0.8384) 325
39 1000 -1000.0 -99.99568287525881 number episode from 10: 39 avegar over 10 episode: -98.215 avegare return across last 100 episodes: -98.215 state values: tensor(0.7672) 1000
40 331 -331.0 -96.40871880207318 number episode from 10: 40 avegar over 10 episode: -98.171 avegare return across last 100 episodes: -98.171 state values: tensor(0.8400) 331
41 406 -406.0 -98.30999104207788 number episode from 10: 41 avegar over 10 episode: -98.175 avegare return across last 100 episodes: -98.175 state values: tensor(0.8350) 406
42 1000 -1000.0 -99.99568287525881 number episode from 10: 42 avegar over 10 episode: -98.217 avegare return across last 100 episodes: -98.217 state values: tensor(0.7681) 1000
43 336 -336.0 -96.58472731437865 number episode from 10: 43 avegar over 10 episode: -98.18 avegare return across last 100 episodes: -98.18 state values: tensor(0.8406) 336
44 584 -584.0 -99.71754215265206 number episode from 10: 44 avegar over 10 episode: -98.214 avegare return across last 100 episodes: -98.214 state values: tensor(0.8129) 584
45 1000 -1000.0 -99.99568287525881 number episode from 10: 45 avegar over 10 episode: -98.253 avegare return across last 100 episodes: -98.253 state values: tensor(0.7681) 1000
46 401 -401.0 -98.22289522577042 number episode from 10: 46 avegar over 10 episode: -98.252 avegare return across last 100 episodes: -98.252 state values: tensor(0.8315) 401
47 387 -387.0 -97.95440191122724 number episode from 10: 47 avegar over 10 episode: -98.246 avegare return across last 100 episodes: -98.246 state values: tensor(0.8373) 387
48 346 -346.0 -96.91128860185685 number episode from 10: 48 avegar over 10 episode: -98.219 avegare return across last 100 episodes: -98.219 state values: tensor(0.8454) 346
49 350 -350.0 -97.03299615490216 number episode from 10: 49 avegar over 10 episode: -98.195 avegare return across last 100 episodes: -98.195 state values: tensor(0.8481) 350
50 324 -324.0 -96.14696415225472 number episode from 10: 50 avegar over 10 episode: -98.155 avegare return across last 100 episodes: -98.155 state values: tensor(0.8391) 324
51 319 -319.0 -95.9483952033458 number episode from 10: 51 avegar over 10 episode: -98.112 avegare return across last 100 episodes: -98.112 state values: tensor(0.8353) 319
52 413 -413.0 -98.42480121266838 number episode from 10: 52 avegar over 10 episode: -98.118 avegare return across last 100 episodes: -98.118 state values: tensor(0.8385) 413
53 1000 -1000.0 -99.99568287525881 number episode from 10: 53 avegar over 10 episode: -98.153 avegare return across last 100 episodes: -98.153 state values: tensor(0.7680) 1000
54 351 -351.0 -97.06266619335314 number episode from 10: 54 avegar over 10 episode: -98.133 avegare return across last 100 episodes: -98.133 state values: tensor(0.8492) 351
55 337 -337.0 -96.61888004123486 number episode from 10: 55 avegar over 10 episode: -98.106 avegare return across last 100 episodes: -98.106 state values: tensor(0.8411) 337
56 352 -352.0 -97.0920395314196 number episode from 10: 56 avegar over 10 episode: -98.088 avegare return across last 100 episodes: -98.088 state values: tensor(0.8427) 352
57 418 -418.0 -98.50200162663309 number episode from 10: 57 avegar over 10 episode: -98.096 avegare return across last 100 episodes: -98.096 state values: tensor(0.8402) 418
58 337 -337.0 -96.61888004123486 number episode from 10: 58 avegar over 10 episode: -98.071 avegare return across last 100 episodes: -98.071 state values: tensor(0.8403) 337
59 345 -345.0 -96.88008949682511 number episode from 10: 59 avegar over 10 episode: -98.051 avegare return across last 100 episodes: -98.051 state values: tensor(0.8463) 345
60 354 -354.0 -97.14990794474436 number episode from 10: 60 avegar over 10 episode: -98.036 avegare return across last 100 episodes: -98.036 state values: tensor(0.8454) 354
61 796 -796.0 -99.96645599611834 number episode from 10: 61 avegar over 10 episode: -98.067 avegare return across last 100 episodes: -98.067 state values: tensor(0.8034) 796
62 400 -400.0 -98.20494467249537 number episode from 10: 62 avegar over 10 episode: -98.069 avegare return across last 100 episodes: -98.069 state values: tensor(0.8413) 400
63 1000 -1000.0 -99.99568287525881 number episode from 10: 63 avegar over 10 episode: -98.099 avegare return across last 100 episodes: -98.099 state values: tensor(0.7687) 1000
64 408 -408.0 -98.34362222034054 number episode from 10: 64 avegar over 10 episode: -98.103 avegare return across last 100 episodes: -98.103 state values: tensor(0.8343) 408
65 337 -337.0 -96.61888004123486 number episode from 10: 65 avegar over 10 episode: -98.081 avegare return across last 100 episodes: -98.081 state values: tensor(0.8403) 337
66 398 -398.0 -98.16849777828321 number episode from 10: 66 avegar over 10 episode: -98.082 avegare return across last 100 episodes: -98.082 state values: tensor(0.8300) 398
67 350 -350.0 -97.03299615490216 number episode from 10: 67 avegar over 10 episode: -98.066 avegare return across last 100 episodes: -98.066 state values: tensor(0.8501) 350
68 349 -349.0 -97.0030264190931 number episode from 10: 68 avegar over 10 episode: -98.051 avegare return across last 100 episodes: -98.051 state values: tensor(0.8469) 349
69 334 -334.0 -96.51538344493281 number episode from 10: 69 avegar over 10 episode: -98.029 avegare return across last 100 episodes: -98.029 state values: tensor(0.8404) 334
70 1000 -1000.0 -99.99568287525881 number episode from 10: 70 avegar over 10 episode: -98.057 avegare return across last 100 episodes: -98.057 state values: tensor(0.7865) 1000
71 409 -409.0 -98.36018599813713 number episode from 10: 71 avegar over 10 episode: -98.061 avegare return across last 100 episodes: -98.061 state values: tensor(0.8365) 409
72 334 -334.0 -96.51538344493281 number episode from 10: 72 avegar over 10 episode: -98.04 avegare return across last 100 episodes: -98.04 state values: tensor(0.8386) 334
73 328 -328.0 -96.29878913826892 number episode from 10: 73 avegar over 10 episode: -98.016 avegare return across last 100 episodes: -98.016 state values: tensor(0.8403) 328
74 329 -329.0 -96.33580124688622 number episode from 10: 74 avegar over 10 episode: -97.994 avegare return across last 100 episodes: -97.994 state values: tensor(0.8397) 329
75 340 -340.0 -96.71930268513013 number episode from 10: 75 avegar over 10 episode: -97.977 avegare return across last 100 episodes: -97.977 state values: tensor(0.8441) 340
76 413 -413.0 -98.42480121266838 number episode from 10: 76 avegar over 10 episode: -97.983 avegare return across last 100 episodes: -97.983 state values: tensor(0.8361) 413
77 408 -408.0 -98.34362222034054 number episode from 10: 77 avegar over 10 episode: -97.988 avegare return across last 100 episodes: -97.988 state values: tensor(0.8347) 408
78 334 -334.0 -96.51538344493281 number episode from 10: 78 avegar over 10 episode: -97.969 avegare return across last 100 episodes: -97.969 state values: tensor(0.8393) 334
79 340 -340.0 -96.71930268513013 number episode from 10: 79 avegar over 10 episode: -97.953 avegare return across last 100 episodes: -97.953 state values: tensor(0.8426) 340
80 460 -460.0 -99.01782355409692 number episode from 10: 80 avegar over 10 episode: -97.966 avegare return across last 100 episodes: -97.966 state values: tensor(0.8282) 460
81 337 -337.0 -96.61888004123486 number episode from 10: 81 avegar over 10 episode: -97.95 avegare return across last 100 episodes: -97.95 state values: tensor(0.8374) 337
82 327 -327.0 -96.2614031699686 number episode from 10: 82 avegar over 10 episode: -97.93 avegare return across last 100 episodes: -97.93 state values: tensor(0.8406) 327
83 337 -337.0 -96.61888004123486 number episode from 10: 83 avegar over 10 episode: -97.914 avegare return across last 100 episodes: -97.914 state values: tensor(0.8378) 337
84 353 -353.0 -97.1211191361054 number episode from 10: 84 avegar over 10 episode: -97.905 avegare return across last 100 episodes: -97.905 state values: tensor(0.8483) 353
85 1000 -1000.0 -99.99568287525881 number episode from 10: 85 avegar over 10 episode: -97.929 avegare return across last 100 episodes: -97.929 state values: tensor(0.7764) 1000
86 497 -497.0 -99.32283934720998 number episode from 10: 86 avegar over 10 episode: -97.945 avegare return across last 100 episodes: -97.945 state values: tensor(0.8233) 497
87 1000 -1000.0 -99.99568287525881 number episode from 10: 87 avegar over 10 episode: -97.968 avegare return across last 100 episodes: -97.968 state values: tensor(0.7714) 1000
88 849 -849.0 -99.980308435908 number episode from 10: 88 avegar over 10 episode: -97.991 avegare return across last 100 episodes: -97.991 state values: tensor(0.7991) 849
89 427 -427.0 -98.63155264922688 number episode from 10: 89 avegar over 10 episode: -97.998 avegare return across last 100 episodes: -97.998 state values: tensor(0.8379) 427
90 403 -403.0 -98.25825961077759 number episode from 10: 90 avegar over 10 episode: -98.001 avegare return across last 100 episodes: -98.001 state values: tensor(0.8373) 403
91 1000 -1000.0 -99.99568287525881 number episode from 10: 91 avegar over 10 episode: -98.023 avegare return across last 100 episodes: -98.023 state values: tensor(0.7678) 1000
92 415 -415.0 -98.45614766853629 number episode from 10: 92 avegar over 10 episode: -98.027 avegare return across last 100 episodes: -98.027 state values: tensor(0.8345) 415
93 724 -724.0 -99.93083587474433 number episode from 10: 93 avegar over 10 episode: -98.048 avegare return across last 100 episodes: -98.048 state values: tensor(0.8036) 724
94 425 -425.0 -98.60376762496365 number episode from 10: 94 avegar over 10 episode: -98.053 avegare return across last 100 episodes: -98.053 state values: tensor(0.8383) 425
95 351 -351.0 -97.06266619335314 number episode from 10: 95 avegar over 10 episode: -98.043 avegare return across last 100 episodes: -98.043 state values: tensor(0.8458) 351
96 1000 -1000.0 -99.99568287525881 number episode from 10: 96 avegar over 10 episode: -98.063 avegare return across last 100 episodes: -98.063 state values: tensor(0.7680) 1000
97 1000 -1000.0 -99.99568287525881 number episode from 10: 97 avegar over 10 episode: -98.083 avegare return across last 100 episodes: -98.083 state values: tensor(0.7678) 1000
98 310 -310.0 -95.56482944595226 number episode from 10: 98 avegar over 10 episode: -98.058 avegare return across last 100 episodes: -98.058 state values: tensor(0.8279) 310
99 332 -332.0 -96.44463161405245 number episode from 10: 99 avegar over 10 episode: -98.041 avegare return across last 100 episodes: -98.041 state values: tensor(0.8372) 332
100 415 -415.0 -98.45614766853629 number episode from 10: 100 avegar over 10 episode: -98.046 avegare return across last 100 episodes: -98.066 state values: tensor(0.8346) 415
101 335 -335.0 -96.55022961048348 number episode from 10: 101 avegar over 10 episode: -98.031 avegare return across last 100 episodes: -98.066 state values: tensor(0.8399) 335
102 790 -790.0 -99.96437099188657 number episode from 10: 102 avegar over 10 episode: -98.05 avegare return across last 100 episodes: -98.086 state values: tensor(0.8039) 790
103 349 -349.0 -97.0030264190931 number episode from 10: 103 avegar over 10 episode: -98.04 avegare return across last 100 episodes: -98.07 state values: tensor(0.8455) 349
104 348 -348.0 -96.9727539586799 number episode from 10: 104 avegar over 10 episode: -98.029 avegare return across last 100 episodes: -98.055 state values: tensor(0.8477) 348
105 901 -901.0 -99.98832356321624 number episode from 10: 105 avegar over 10 episode: -98.048 avegare return across last 100 episodes: -98.055 state values: tensor(0.7967) 901
106 405 -405.0 -98.29292024452312 number episode from 10: 106 avegar over 10 episode: -98.05 avegare return across last 100 episodes: -98.042 state values: tensor(0.8309) 405
107 338 -338.0 -96.6526912408225 number episode from 10: 107 avegar over 10 episode: -98.037 avegare return across last 100 episodes: -98.026 state values: tensor(0.8427) 338
108 960 -960.0 -99.99354662631742 number episode from 10: 108 avegar over 10 episode: -98.055 avegare return across last 100 episodes: -98.064 state values: tensor(0.7965) 960
109 1000 -1000.0 -99.99568287525881 number episode from 10: 109 avegar over 10 episode: -98.073 avegare return across last 100 episodes: -98.08 state values: tensor(0.7680) 1000
110 413 -413.0 -98.42480121266838 number episode from 10: 110 avegar over 10 episode: -98.076 avegare return across last 100 episodes: -98.095 state values: tensor(0.8356) 413
111 353 -353.0 -97.1211191361054 number episode from 10: 111 avegar over 10 episode: -98.067 avegare return across last 100 episodes: -98.085 state values: tensor(0.8479) 353
112 331 -331.0 -96.40871880207318 number episode from 10: 112 avegar over 10 episode: -98.053 avegare return across last 100 episodes: -98.065 state values: tensor(0.8408) 331
113 1000 -1000.0 -99.99568287525881 number episode from 10: 113 avegar over 10 episode: -98.07 avegare return across last 100 episodes: -98.094 state values: tensor(0.7681) 1000
114 427 -427.0 -98.63155264922688 number episode from 10: 114 avegar over 10 episode: -98.075 avegare return across last 100 episodes: -98.081 state values: tensor(0.8351) 427
115 324 -324.0 -96.14696415225472 number episode from 10: 115 avegar over 10 episode: -98.058 avegare return across last 100 episodes: -98.056 state values: tensor(0.8389) 324
116 1000 -1000.0 -99.99568287525881 number episode from 10: 116 avegar over 10 episode: -98.075 avegare return across last 100 episodes: -98.056 state values: tensor(0.7681) 1000
117 347 -347.0 -96.94217571583829 number episode from 10: 117 avegar over 10 episode: -98.065 avegare return across last 100 episodes: -98.055 state values: tensor(0.8464) 347
118 545 -545.0 -99.58199540519871 number episode from 10: 118 avegar over 10 episode: -98.078 avegare return across last 100 episodes: -98.051 state values: tensor(0.8517) 545
119 1000 -1000.0 -99.99568287525881 number episode from 10: 119 avegar over 10 episode: -98.094 avegare return across last 100 episodes: -98.085 state values: tensor(0.7681) 1000
120 1000 -1000.0 -99.99568287525881 number episode from 10: 120 avegar over 10 episode: -98.11 avegare return across last 100 episodes: -98.103 state values: tensor(0.7679) 1000
121 355 -355.0 -97.17840886529692 number episode from 10: 121 avegar over 10 episode: -98.102 avegare return across last 100 episodes: -98.076 state values: tensor(0.8327) 355
122 431 -431.0 -98.68547493495227 number episode from 10: 122 avegar over 10 episode: -98.107 avegare return across last 100 episodes: -98.09 state values: tensor(0.8424) 431
123 351 -351.0 -97.06266619335314 number episode from 10: 123 avegar over 10 episode: -98.098 avegare return across last 100 episodes: -98.061 state values: tensor(0.8469) 351
124 352 -352.0 -97.0920395314196 number episode from 10: 124 avegar over 10 episode: -98.09 avegare return across last 100 episodes: -98.06 state values: tensor(0.8481) 352
125 416 -416.0 -98.47158619185093 number episode from 10: 125 avegar over 10 episode: -98.093 avegare return across last 100 episodes: -98.059 state values: tensor(0.8381) 416
126 330 -330.0 -96.37244323441736 number episode from 10: 126 avegar over 10 episode: -98.08 avegare return across last 100 episodes: -98.064 state values: tensor(0.8396) 330
127 353 -353.0 -97.1211191361054 number episode from 10: 127 avegar over 10 episode: -98.072 avegare return across last 100 episodes: -98.035 state values: tensor(0.8455) 353
128 328 -328.0 -96.29878913826892 number episode from 10: 128 avegar over 10 episode: -98.058 avegare return across last 100 episodes: -98.013 state values: tensor(0.8400) 328
129 354 -354.0 -97.14990794474436 number episode from 10: 129 avegar over 10 episode: -98.051 avegare return across last 100 episodes: -98.015 state values: tensor(0.8478) 354
130 328 -328.0 -96.29878913826892 number episode from 10: 130 avegar over 10 episode: -98.038 avegare return across last 100 episodes: -97.978 state values: tensor(0.8377) 328
131 350 -350.0 -97.03299615490216 number episode from 10: 131 avegar over 10 episode: -98.03 avegare return across last 100 episodes: -97.981 state values: tensor(0.8482) 350
132 694 -694.0 -99.90649710647186 number episode from 10: 132 avegar over 10 episode: -98.045 avegare return across last 100 episodes: -97.981 state values: tensor(0.8072) 694
133 414 -414.0 -98.4405532005417 number episode from 10: 133 avegar over 10 episode: -98.047 avegare return across last 100 episodes: -97.978 state values: tensor(0.8346) 414
134 350 -350.0 -97.03299615490216 number episode from 10: 134 avegar over 10 episode: -98.04 avegare return across last 100 episodes: -97.962 state values: tensor(0.8444) 350
135 350 -350.0 -97.03299615490216 number episode from 10: 135 avegar over 10 episode: -98.033 avegare return across last 100 episodes: -97.967 state values: tensor(0.8474) 350
136 345 -345.0 -96.88008949682511 number episode from 10: 136 avegar over 10 episode: -98.024 avegare return across last 100 episodes: -97.954 state values: tensor(0.8446) 345
137 941 -941.0 -99.9921887935509 number episode from 10: 137 avegar over 10 episode: -98.038 avegare return across last 100 episodes: -97.969 state values: tensor(0.7967) 941
138 384 -384.0 -97.89178584253641 number episode from 10: 138 avegar over 10 episode: -98.037 avegare return across last 100 episodes: -97.986 state values: tensor(0.8350) 384
139 393 -393.0 -98.0741100057678 number episode from 10: 139 avegar over 10 episode: -98.038 avegare return across last 100 episodes: -97.966 state values: tensor(0.8364) 393
140 328 -328.0 -96.29878913826892 number episode from 10: 140 avegar over 10 episode: -98.025 avegare return across last 100 episodes: -97.965 state values: tensor(0.8410) 328
141 1000 -1000.0 -99.99568287525881 number episode from 10: 141 avegar over 10 episode: -98.039 avegare return across last 100 episodes: -97.982 state values: tensor(0.7677) 1000
142 307 -307.0 -95.42906820057762 number episode from 10: 142 avegar over 10 episode: -98.021 avegare return across last 100 episodes: -97.937 state values: tensor(0.8268) 307
143 416 -416.0 -98.47158619185093 number episode from 10: 143 avegar over 10 episode: -98.024 avegare return across last 100 episodes: -97.955 state values: tensor(0.8355) 416
144 1000 -1000.0 -99.99568287525881 number episode from 10: 144 avegar over 10 episode: -98.038 avegare return across last 100 episodes: -97.958 state values: tensor(0.7678) 1000
145 1000 -1000.0 -99.99568287525881 number episode from 10: 145 avegar over 10 episode: -98.051 avegare return across last 100 episodes: -97.958 state values: tensor(0.7678) 1000
146 426 -426.0 -98.61772994871401 number episode from 10: 146 avegar over 10 episode: -98.055 avegare return across last 100 episodes: -97.962 state values: tensor(0.8330) 426
147 333 -333.0 -96.48018529791193 number episode from 10: 147 avegar over 10 episode: -98.044 avegare return across last 100 episodes: -97.947 state values: tensor(0.8379) 333
148 346 -346.0 -96.91128860185685 number episode from 10: 148 avegar over 10 episode: -98.037 avegare return across last 100 episodes: -97.947 state values: tensor(0.8457) 346
149 1000 -1000.0 -99.99568287525881 number episode from 10: 149 avegar over 10 episode: -98.05 avegare return across last 100 episodes: -97.977 state values: tensor(0.7676) 1000
150 358 -358.0 -97.26221294358874 number episode from 10: 150 avegar over 10 episode: -98.045 avegare return across last 100 episodes: -97.988 state values: tensor(0.8493) 358
151 325 -325.0 -96.18549451073217 number episode from 10: 151 avegar over 10 episode: -98.032 avegare return across last 100 episodes: -97.991 state values: tensor(0.8385) 325
152 348 -348.0 -96.9727539586799 number episode from 10: 152 avegar over 10 episode: -98.025 avegare return across last 100 episodes: -97.976 state values: tensor(0.8475) 348
153 308 -308.0 -95.47477751857184 number episode from 10: 153 avegar over 10 episode: -98.009 avegare return across last 100 episodes: -97.931 state values: tensor(0.8272) 308
154 412 -412.0 -98.40889011380645 number episode from 10: 154 avegar over 10 episode: -98.011 avegare return across last 100 episodes: -97.944 state values: tensor(0.8362) 412
155 655 -655.0 -99.86162664805052 number episode from 10: 155 avegar over 10 episode: -98.023 avegare return across last 100 episodes: -97.977 state values: tensor(0.8075) 655
156 1000 -1000.0 -99.99568287525881 number episode from 10: 156 avegar over 10 episode: -98.036 avegare return across last 100 episodes: -98.006 state values: tensor(0.7691) 1000
157 1000 -1000.0 -99.99568287525881 number episode from 10: 157 avegar over 10 episode: -98.048 avegare return across last 100 episodes: -98.021 state values: tensor(0.7942) 1000
158 416 -416.0 -98.47158619185093 number episode from 10: 158 avegar over 10 episode: -98.051 avegare return across last 100 episodes: -98.039 state values: tensor(0.8351) 416
159 395 -395.0 -98.11243521665303 number episode from 10: 159 avegar over 10 episode: -98.051 avegare return across last 100 episodes: -98.052 state values: tensor(0.8335) 395
160 418 -418.0 -98.50200162663309 number episode from 10: 160 avegar over 10 episode: -98.054 avegare return across last 100 episodes: -98.065 state values: tensor(0.8347) 418
161 350 -350.0 -97.03299615490216 number episode from 10: 161 avegar over 10 episode: -98.048 avegare return across last 100 episodes: -98.036 state values: tensor(0.8474) 350
162 354 -354.0 -97.14990794474436 number episode from 10: 162 avegar over 10 episode: -98.042 avegare return across last 100 episodes: -98.025 state values: tensor(0.8476) 354
163 1000 -1000.0 -99.99568287525881 number episode from 10: 163 avegar over 10 episode: -98.054 avegare return across last 100 episodes: -98.025 state values: tensor(0.7822) 1000
164 335 -335.0 -96.55022961048348 number episode from 10: 164 avegar over 10 episode: -98.045 avegare return across last 100 episodes: -98.007 state values: tensor(0.8402) 335
165 1000 -1000.0 -99.99568287525881 number episode from 10: 165 avegar over 10 episode: -98.057 avegare return across last 100 episodes: -98.041 state values: tensor(0.7679) 1000
166 331 -331.0 -96.40871880207318 number episode from 10: 166 avegar over 10 episode: -98.047 avegare return across last 100 episodes: -98.023 state values: tensor(0.8395) 331
167 1000 -1000.0 -99.99568287525881 number episode from 10: 167 avegar over 10 episode: -98.059 avegare return across last 100 episodes: -98.053 state values: tensor(0.7678) 1000
168 345 -345.0 -96.88008949682511 number episode from 10: 168 avegar over 10 episode: -98.052 avegare return across last 100 episodes: -98.052 state values: tensor(0.8461) 345
169 1000 -1000.0 -99.99568287525881 number episode from 10: 169 avegar over 10 episode: -98.063 avegare return across last 100 episodes: -98.087 state values: tensor(0.7680) 1000
170 1000 -1000.0 -99.99568287525881 number episode from 10: 170 avegar over 10 episode: -98.074 avegare return across last 100 episodes: -98.087 state values: tensor(0.7677) 1000
171 347 -347.0 -96.94217571583829 number episode from 10: 171 avegar over 10 episode: -98.068 avegare return across last 100 episodes: -98.072 state values: tensor(0.8466) 347
172 387 -387.0 -97.95440191122724 number episode from 10: 172 avegar over 10 episode: -98.067 avegare return across last 100 episodes: -98.087 state values: tensor(0.8379) 387
173 1000 -1000.0 -99.99568287525881 number episode from 10: 173 avegar over 10 episode: -98.078 avegare return across last 100 episodes: -98.124 state values: tensor(0.7679) 1000
174 413 -413.0 -98.42480121266838 number episode from 10: 174 avegar over 10 episode: -98.08 avegare return across last 100 episodes: -98.145 state values: tensor(0.8367) 413
175 427 -427.0 -98.63155264922688 number episode from 10: 175 avegar over 10 episode: -98.083 avegare return across last 100 episodes: -98.164 state values: tensor(0.8333) 427
176 329 -329.0 -96.33580124688622 number episode from 10: 176 avegar over 10 episode: -98.073 avegare return across last 100 episodes: -98.143 state values: tensor(0.8414) 329
177 344 -344.0 -96.84857524931829 number episode from 10: 177 avegar over 10 episode: -98.066 avegare return across last 100 episodes: -98.128 state values: tensor(0.8436) 344
178 336 -336.0 -96.58472731437865 number episode from 10: 178 avegar over 10 episode: -98.058 avegare return across last 100 episodes: -98.129 state values: tensor(0.8409) 336
179 319 -319.0 -95.9483952033458 number episode from 10: 179 avegar over 10 episode: -98.046 avegare return across last 100 episodes: -98.121 state values: tensor(0.8368) 319
180 338 -338.0 -96.6526912408225 number episode from 10: 180 avegar over 10 episode: -98.039 avegare return across last 100 episodes: -98.097 state values: tensor(0.8429) 338
181 1000 -1000.0 -99.99568287525881 number episode from 10: 181 avegar over 10 episode: -98.05 avegare return across last 100 episodes: -98.131 state values: tensor(0.7680) 1000
182 1000 -1000.0 -99.99568287525881 number episode from 10: 182 avegar over 10 episode: -98.06 avegare return across last 100 episodes: -98.168 state values: tensor(0.7681) 1000
183 1000 -1000.0 -99.99568287525881 number episode from 10: 183 avegar over 10 episode: -98.071 avegare return across last 100 episodes: -98.202 state values: tensor(0.7678) 1000
184 1000 -1000.0 -99.99568287525881 number episode from 10: 184 avegar over 10 episode: -98.081 avegare return across last 100 episodes: -98.231 state values: tensor(0.7680) 1000
185 400 -400.0 -98.20494467249537 number episode from 10: 185 avegar over 10 episode: -98.082 avegare return across last 100 episodes: -98.213 state values: tensor(0.8352) 400
186 387 -387.0 -97.95440191122724 number episode from 10: 186 avegar over 10 episode: -98.081 avegare return across last 100 episodes: -98.199 state values: tensor(0.8403) 387
187 431 -431.0 -98.68547493495227 number episode from 10: 187 avegar over 10 episode: -98.084 avegare return across last 100 episodes: -98.186 state values: tensor(0.8301) 431
188 356 -356.0 -97.20662477664395 number episode from 10: 188 avegar over 10 episode: -98.08 avegare return across last 100 episodes: -98.159 state values: tensor(0.8458) 356
189 353 -353.0 -97.1211191361054 number episode from 10: 189 avegar over 10 episode: -98.075 avegare return across last 100 episodes: -98.143 state values: tensor(0.8451) 353
190 386 -386.0 -97.93373930426993 number episode from 10: 190 avegar over 10 episode: -98.074 avegare return across last 100 episodes: -98.14 state values: tensor(0.8392) 386
191 736 -736.0 -99.93869396570786 number episode from 10: 191 avegar over 10 episode: -98.084 avegare return across last 100 episodes: -98.14 state values: tensor(0.8035) 736
192 472 -472.0 -99.1294136569956 number episode from 10: 192 avegar over 10 episode: -98.089 avegare return across last 100 episodes: -98.146 state values: tensor(0.8206) 472
193 417 -417.0 -98.48687032993242 number episode from 10: 193 avegar over 10 episode: -98.091 avegare return across last 100 episodes: -98.132 state values: tensor(0.8361) 417
194 402 -402.0 -98.24066627351272 number episode from 10: 194 avegar over 10 episode: -98.092 avegare return across last 100 episodes: -98.128 state values: tensor(0.8350) 402
195 1000 -1000.0 -99.99568287525881 number episode from 10: 195 avegar over 10 episode: -98.102 avegare return across last 100 episodes: -98.158 state values: tensor(0.7680) 1000
196 367 -367.0 -97.49898430403083 number episode from 10: 196 avegar over 10 episode: -98.098 avegare return across last 100 episodes: -98.133 state values: tensor(0.8399) 367
197 367 -367.0 -97.49898430403083 number episode from 10: 197 avegar over 10 episode: -98.095 avegare return across last 100 episodes: -98.108 state values: tensor(0.8391) 367
198 321 -321.0 -96.0290221387992 number episode from 10: 198 avegar over 10 episode: -98.085 avegare return across last 100 episodes: -98.112 state values: tensor(0.8400) 321
199 419 -419.0 -98.51698161036676 number episode from 10: 199 avegar over 10 episode: -98.087 avegare return across last 100 episodes: -98.133 state values: tensor(0.8353) 419
200 417 -417.0 -98.48687032993242 number episode from 10: 200 avegar over 10 episode: -98.089 avegare return across last 100 episodes: -98.133 state values: tensor(0.8356) 417
load offline data!!!!!
mem_cntr: 50000 ; mem_size: 50000
nn.learn_nn_feature_fqi FQI:  998
nn.learn_nn_feature_fqi FQI:  1998
nn.learn_nn_feature_fqi FQI:  2998
nn.learn_nn_feature_fqi FQI:  3998
nn.learn_nn_feature_fqi FQI:  4998
nn.learn_nn_feature_fqi FQI:  5998
nn.learn_nn_feature_fqi FQI:  6998
nn.learn_nn_feature_fqi FQI:  7998
nn.learn_nn_feature_fqi FQI:  8998
nn.learn_nn_feature_fqi FQI:  9998
nn.learn_nn_feature_fqi FQI:  10998
nn.learn_nn_feature_fqi FQI:  11998
nn.learn_nn_feature_fqi FQI:  12998
nn.learn_nn_feature_fqi FQI:  13998
nn.learn_nn_feature_fqi FQI:  14998
nn.learn_nn_feature_fqi FQI:  15998
nn.learn_nn_feature_fqi FQI:  16998
nn.learn_nn_feature_fqi FQI:  17998
nn.learn_nn_feature_fqi FQI:  18998
nn.learn_nn_feature_fqi FQI:  19998
nn.learn_nn_feature_fqi FQI:  20998
nn.learn_nn_feature_fqi FQI:  21998
nn.learn_nn_feature_fqi FQI:  22998
nn.learn_nn_feature_fqi FQI:  23998
nn.learn_nn_feature_fqi FQI:  24998
nn.learn_nn_feature_fqi FQI:  25998
nn.learn_nn_feature_fqi FQI:  26998
nn.learn_nn_feature_fqi FQI:  27998
nn.learn_nn_feature_fqi FQI:  28998
nn.learn_nn_feature_fqi FQI:  29998
nn.learn_nn_feature_fqi FQI:  30998
nn.learn_nn_feature_fqi FQI:  31998
nn.learn_nn_feature_fqi FQI:  32998
nn.learn_nn_feature_fqi FQI:  33998
nn.learn_nn_feature_fqi FQI:  34998
nn.learn_nn_feature_fqi FQI:  35998
nn.learn_nn_feature_fqi FQI:  36998
nn.learn_nn_feature_fqi FQI:  37998
nn.learn_nn_feature_fqi FQI:  38998
nn.learn_nn_feature_fqi FQI:  39998
nn.learn_nn_feature_fqi FQI:  40998
nn.learn_nn_feature_fqi FQI:  41998
nn.learn_nn_feature_fqi FQI:  42998
nn.learn_nn_feature_fqi FQI:  43998
nn.learn_nn_feature_fqi FQI:  44998
nn.learn_nn_feature_fqi FQI:  45998
nn.learn_nn_feature_fqi FQI:  46998
nn.learn_nn_feature_fqi FQI:  47998
nn.learn_nn_feature_fqi FQI:  48998
nn.learn_nn_feature_fqi FQI:  49998
nn.learn_nn_feature_fqi FQI:  50998
nn.learn_nn_feature_fqi FQI:  51998
nn.learn_nn_feature_fqi FQI:  52998
nn.learn_nn_feature_fqi FQI:  53998
nn.learn_nn_feature_fqi FQI:  54998
nn.learn_nn_feature_fqi FQI:  55998
nn.learn_nn_feature_fqi FQI:  56998
nn.learn_nn_feature_fqi FQI:  57998
nn.learn_nn_feature_fqi FQI:  58998
nn.learn_nn_feature_fqi FQI:  59998
nn.learn_nn_feature_fqi FQI:  60998
nn.learn_nn_feature_fqi FQI:  61998
nn.learn_nn_feature_fqi FQI:  62998
nn.learn_nn_feature_fqi FQI:  63998
nn.learn_nn_feature_fqi FQI:  64998
nn.learn_nn_feature_fqi FQI:  65998
nn.learn_nn_feature_fqi FQI:  66998
nn.learn_nn_feature_fqi FQI:  67998
nn.learn_nn_feature_fqi FQI:  68998
nn.learn_nn_feature_fqi FQI:  69998
nn.learn_nn_feature_fqi FQI:  70998
nn.learn_nn_feature_fqi FQI:  71998
nn.learn_nn_feature_fqi FQI:  72998
nn.learn_nn_feature_fqi FQI:  73998
nn.learn_nn_feature_fqi FQI:  74998
nn.learn_nn_feature_fqi FQI:  75998
nn.learn_nn_feature_fqi FQI:  76998
nn.learn_nn_feature_fqi FQI:  77998
nn.learn_nn_feature_fqi FQI:  78998
nn.learn_nn_feature_fqi FQI:  79998
nn.learn_nn_feature_fqi FQI:  80998
nn.learn_nn_feature_fqi FQI:  81998
nn.learn_nn_feature_fqi FQI:  82998
nn.learn_nn_feature_fqi FQI:  83998
nn.learn_nn_feature_fqi FQI:  84998
nn.learn_nn_feature_fqi FQI:  85998
nn.learn_nn_feature_fqi FQI:  86998
nn.learn_nn_feature_fqi FQI:  87998
nn.learn_nn_feature_fqi FQI:  88998
nn.learn_nn_feature_fqi FQI:  89998
nn.learn_nn_feature_fqi FQI:  90998
nn.learn_nn_feature_fqi FQI:  91998
nn.learn_nn_feature_fqi FQI:  92998
nn.learn_nn_feature_fqi FQI:  93998
nn.learn_nn_feature_fqi FQI:  94998
nn.learn_nn_feature_fqi FQI:  95998
nn.learn_nn_feature_fqi FQI:  96998
nn.learn_nn_feature_fqi FQI:  97998
nn.learn_nn_feature_fqi FQI:  98998
nn.learn_nn_feature_fqi FQI:  99998
nn.learn_nn_feature_fqi FQI:  100998
nn.learn_nn_feature_fqi FQI:  101998
nn.learn_nn_feature_fqi FQI:  102998
nn.learn_nn_feature_fqi FQI:  103998
nn.learn_nn_feature_fqi FQI:  104998
nn.learn_nn_feature_fqi FQI:  105998
nn.learn_nn_feature_fqi FQI:  106998
nn.learn_nn_feature_fqi FQI:  107998
nn.learn_nn_feature_fqi FQI:  108998
nn.learn_nn_feature_fqi FQI:  109998
nn.learn_nn_feature_fqi FQI:  110998
nn.learn_nn_feature_fqi FQI:  111998
nn.learn_nn_feature_fqi FQI:  112998
nn.learn_nn_feature_fqi FQI:  113998
nn.learn_nn_feature_fqi FQI:  114998
nn.learn_nn_feature_fqi FQI:  115998
nn.learn_nn_feature_fqi FQI:  116998
nn.learn_nn_feature_fqi FQI:  117998
nn.learn_nn_feature_fqi FQI:  118998
nn.learn_nn_feature_fqi FQI:  119998
nn.learn_nn_feature_fqi FQI:  120998
nn.learn_nn_feature_fqi FQI:  121998
nn.learn_nn_feature_fqi FQI:  122998
nn.learn_nn_feature_fqi FQI:  123998
nn.learn_nn_feature_fqi FQI:  124998
nn.learn_nn_feature_fqi FQI:  125998
nn.learn_nn_feature_fqi FQI:  126998
nn.learn_nn_feature_fqi FQI:  127998
nn.learn_nn_feature_fqi FQI:  128998
nn.learn_nn_feature_fqi FQI:  129998
nn.learn_nn_feature_fqi FQI:  130998
nn.learn_nn_feature_fqi FQI:  131998
nn.learn_nn_feature_fqi FQI:  132998
nn.learn_nn_feature_fqi FQI:  133998
nn.learn_nn_feature_fqi FQI:  134998
nn.learn_nn_feature_fqi FQI:  135998
nn.learn_nn_feature_fqi FQI:  136998
nn.learn_nn_feature_fqi FQI:  137998
nn.learn_nn_feature_fqi FQI:  138998
nn.learn_nn_feature_fqi FQI:  139998
nn.learn_nn_feature_fqi FQI:  140998
nn.learn_nn_feature_fqi FQI:  141998
nn.learn_nn_feature_fqi FQI:  142998
nn.learn_nn_feature_fqi FQI:  143998
nn.learn_nn_feature_fqi FQI:  144998
nn.learn_nn_feature_fqi FQI:  145998
nn.learn_nn_feature_fqi FQI:  146998
nn.learn_nn_feature_fqi FQI:  147998
nn.learn_nn_feature_fqi FQI:  148998
nn.learn_nn_feature_fqi FQI:  149998
nn.learn_nn_feature_fqi FQI:  150998
nn.learn_nn_feature_fqi FQI:  151998
nn.learn_nn_feature_fqi FQI:  152998
nn.learn_nn_feature_fqi FQI:  153998
nn.learn_nn_feature_fqi FQI:  154998
nn.learn_nn_feature_fqi FQI:  155998
0 1001 -1000.0 -98.99572604650622 number episode from 10: 0 avegar over 10 episode: -98.996 avegare return across last 100 episodes: -98.996 state values: tensor(0.8477) 1000
1 1000 -1000.0 -99.99568287525881 number episode from 10: 1 avegar over 10 episode: -99.496 avegare return across last 100 episodes: -99.496 state values: tensor(0.8508) 1000
2 1000 -1000.0 -99.99568287525881 number episode from 10: 2 avegar over 10 episode: -99.662 avegare return across last 100 episodes: -99.662 state values: tensor(0.8510) 1000
3 1000 -1000.0 -99.99568287525881 number episode from 10: 3 avegar over 10 episode: -99.746 avegare return across last 100 episodes: -99.746 state values: tensor(0.8457) 1000
4 1000 -1000.0 -99.99568287525881 number episode from 10: 4 avegar over 10 episode: -99.796 avegare return across last 100 episodes: -99.796 state values: tensor(0.8491) 1000
5 1000 -1000.0 -99.99568287525881 number episode from 10: 5 avegar over 10 episode: -99.829 avegare return across last 100 episodes: -99.829 state values: tensor(0.8504) 1000
6 1000 -1000.0 -99.99568287525881 number episode from 10: 6 avegar over 10 episode: -99.853 avegare return across last 100 episodes: -99.853 state values: tensor(0.8463) 1000
7 1000 -1000.0 -99.99568287525881 number episode from 10: 7 avegar over 10 episode: -99.871 avegare return across last 100 episodes: -99.871 state values: tensor(0.8501) 1000
8 1000 -1000.0 -99.99568287525881 number episode from 10: 8 avegar over 10 episode: -99.885 avegare return across last 100 episodes: -99.885 state values: tensor(0.8511) 1000
9 1000 -1000.0 -99.99568287525881 number episode from 10: 9 avegar over 10 episode: -99.896 avegare return across last 100 episodes: -99.896 state values: tensor(0.8488) 1000
10 1000 -1000.0 -99.99568287525881 number episode from 10: 10 avegar over 10 episode: -99.905 avegare return across last 100 episodes: -99.905 state values: tensor(0.8488) 1000
11 1000 -1000.0 -99.99568287525881 number episode from 10: 11 avegar over 10 episode: -99.912 avegare return across last 100 episodes: -99.912 state values: tensor(0.8490) 1000
12 1000 -1000.0 -99.99568287525881 number episode from 10: 12 avegar over 10 episode: -99.919 avegare return across last 100 episodes: -99.919 state values: tensor(0.8453) 1000
13 1000 -1000.0 -99.99568287525881 number episode from 10: 13 avegar over 10 episode: -99.924 avegare return across last 100 episodes: -99.924 state values: tensor(0.8486) 1000
14 1000 -1000.0 -99.99568287525881 number episode from 10: 14 avegar over 10 episode: -99.929 avegare return across last 100 episodes: -99.929 state values: tensor(0.8510) 1000
15 1000 -1000.0 -99.99568287525881 number episode from 10: 15 avegar over 10 episode: -99.933 avegare return across last 100 episodes: -99.933 state values: tensor(0.8478) 1000
16 1000 -1000.0 -99.99568287525881 number episode from 10: 16 avegar over 10 episode: -99.937 avegare return across last 100 episodes: -99.937 state values: tensor(0.8480) 1000
17 1000 -1000.0 -99.99568287525881 number episode from 10: 17 avegar over 10 episode: -99.94 avegare return across last 100 episodes: -99.94 state values: tensor(0.8502) 1000
18 1000 -1000.0 -99.99568287525881 number episode from 10: 18 avegar over 10 episode: -99.943 avegare return across last 100 episodes: -99.943 state values: tensor(0.8453) 1000
19 1000 -1000.0 -99.99568287525881 number episode from 10: 19 avegar over 10 episode: -99.946 avegare return across last 100 episodes: -99.946 state values: tensor(0.8497) 1000
20 1000 -1000.0 -99.99568287525881 number episode from 10: 20 avegar over 10 episode: -99.948 avegare return across last 100 episodes: -99.948 state values: tensor(0.8451) 1000
21 1000 -1000.0 -99.99568287525881 number episode from 10: 21 avegar over 10 episode: -99.95 avegare return across last 100 episodes: -99.95 state values: tensor(0.8461) 1000
22 1000 -1000.0 -99.99568287525881 number episode from 10: 22 avegar over 10 episode: -99.952 avegare return across last 100 episodes: -99.952 state values: tensor(0.8483) 1000
23 1000 -1000.0 -99.99568287525881 number episode from 10: 23 avegar over 10 episode: -99.954 avegare return across last 100 episodes: -99.954 state values: tensor(0.8504) 1000
24 1000 -1000.0 -99.99568287525881 number episode from 10: 24 avegar over 10 episode: -99.956 avegare return across last 100 episodes: -99.956 state values: tensor(0.8492) 1000
25 1000 -1000.0 -99.99568287525881 number episode from 10: 25 avegar over 10 episode: -99.957 avegare return across last 100 episodes: -99.957 state values: tensor(0.8499) 1000
26 1000 -1000.0 -99.99568287525881 number episode from 10: 26 avegar over 10 episode: -99.959 avegare return across last 100 episodes: -99.959 state values: tensor(0.8511) 1000
27 1000 -1000.0 -99.99568287525881 number episode from 10: 27 avegar over 10 episode: -99.96 avegare return across last 100 episodes: -99.96 state values: tensor(0.8508) 1000
28 1000 -1000.0 -99.99568287525881 number episode from 10: 28 avegar over 10 episode: -99.961 avegare return across last 100 episodes: -99.961 state values: tensor(0.8462) 1000
29 1000 -1000.0 -99.99568287525881 number episode from 10: 29 avegar over 10 episode: -99.962 avegare return across last 100 episodes: -99.962 state values: tensor(0.8491) 1000
30 1000 -1000.0 -99.99568287525881 number episode from 10: 30 avegar over 10 episode: -99.963 avegare return across last 100 episodes: -99.963 state values: tensor(0.8503) 1000
31 1000 -1000.0 -99.99568287525881 number episode from 10: 31 avegar over 10 episode: -99.964 avegare return across last 100 episodes: -99.964 state values: tensor(0.8504) 1000
32 1000 -1000.0 -99.99568287525881 number episode from 10: 32 avegar over 10 episode: -99.965 avegare return across last 100 episodes: -99.965 state values: tensor(0.8477) 1000
33 1000 -1000.0 -99.99568287525881 number episode from 10: 33 avegar over 10 episode: -99.966 avegare return across last 100 episodes: -99.966 state values: tensor(0.8514) 1000
34 1000 -1000.0 -99.99568287525881 number episode from 10: 34 avegar over 10 episode: -99.967 avegare return across last 100 episodes: -99.967 state values: tensor(0.8491) 1000
35 1000 -1000.0 -99.99568287525881 number episode from 10: 35 avegar over 10 episode: -99.968 avegare return across last 100 episodes: -99.968 state values: tensor(0.8520) 1000
36 1000 -1000.0 -99.99568287525881 number episode from 10: 36 avegar over 10 episode: -99.969 avegare return across last 100 episodes: -99.969 state values: tensor(0.8502) 1000
37 1000 -1000.0 -99.99568287525881 number episode from 10: 37 avegar over 10 episode: -99.969 avegare return across last 100 episodes: -99.969 state values: tensor(0.8511) 1000
38 1000 -1000.0 -99.99568287525881 number episode from 10: 38 avegar over 10 episode: -99.97 avegare return across last 100 episodes: -99.97 state values: tensor(0.8507) 1000
39 1000 -1000.0 -99.99568287525881 number episode from 10: 39 avegar over 10 episode: -99.971 avegare return across last 100 episodes: -99.971 state values: tensor(0.8513) 1000
40 1000 -1000.0 -99.99568287525881 number episode from 10: 40 avegar over 10 episode: -99.971 avegare return across last 100 episodes: -99.971 state values: tensor(0.8515) 1000
41 1000 -1000.0 -99.99568287525881 number episode from 10: 41 avegar over 10 episode: -99.972 avegare return across last 100 episodes: -99.972 state values: tensor(0.8497) 1000
42 1000 -1000.0 -99.99568287525881 number episode from 10: 42 avegar over 10 episode: -99.972 avegare return across last 100 episodes: -99.972 state values: tensor(0.8449) 1000
43 1000 -1000.0 -99.99568287525881 number episode from 10: 43 avegar over 10 episode: -99.973 avegare return across last 100 episodes: -99.973 state values: tensor(0.8475) 1000
44 1000 -1000.0 -99.99568287525881 number episode from 10: 44 avegar over 10 episode: -99.973 avegare return across last 100 episodes: -99.973 state values: tensor(0.8498) 1000
45 1000 -1000.0 -99.99568287525881 number episode from 10: 45 avegar over 10 episode: -99.974 avegare return across last 100 episodes: -99.974 state values: tensor(0.8508) 1000
46 1000 -1000.0 -99.99568287525881 number episode from 10: 46 avegar over 10 episode: -99.974 avegare return across last 100 episodes: -99.974 state values: tensor(0.8506) 1000
47 1000 -1000.0 -99.99568287525881 number episode from 10: 47 avegar over 10 episode: -99.975 avegare return across last 100 episodes: -99.975 state values: tensor(0.8474) 1000
48 1000 -1000.0 -99.99568287525881 number episode from 10: 48 avegar over 10 episode: -99.975 avegare return across last 100 episodes: -99.975 state values: tensor(0.8490) 1000
49 1000 -1000.0 -99.99568287525881 number episode from 10: 49 avegar over 10 episode: -99.976 avegare return across last 100 episodes: -99.976 state values: tensor(0.8494) 1000
50 1000 -1000.0 -99.99568287525881 number episode from 10: 50 avegar over 10 episode: -99.976 avegare return across last 100 episodes: -99.976 state values: tensor(0.8508) 1000
51 1000 -1000.0 -99.99568287525881 number episode from 10: 51 avegar over 10 episode: -99.976 avegare return across last 100 episodes: -99.976 state values: tensor(0.8469) 1000
52 1000 -1000.0 -99.99568287525881 number episode from 10: 52 avegar over 10 episode: -99.977 avegare return across last 100 episodes: -99.977 state values: tensor(0.8467) 1000
53 1000 -1000.0 -99.99568287525881 number episode from 10: 53 avegar over 10 episode: -99.977 avegare return across last 100 episodes: -99.977 state values: tensor(0.8470) 1000
54 1000 -1000.0 -99.99568287525881 number episode from 10: 54 avegar over 10 episode: -99.978 avegare return across last 100 episodes: -99.978 state values: tensor(0.8478) 1000
55 1000 -1000.0 -99.99568287525881 number episode from 10: 55 avegar over 10 episode: -99.978 avegare return across last 100 episodes: -99.978 state values: tensor(0.8511) 1000
56 1000 -1000.0 -99.99568287525881 number episode from 10: 56 avegar over 10 episode: -99.978 avegare return across last 100 episodes: -99.978 state values: tensor(0.8473) 1000
57 1000 -1000.0 -99.99568287525881 number episode from 10: 57 avegar over 10 episode: -99.978 avegare return across last 100 episodes: -99.978 state values: tensor(0.8511) 1000
58 1000 -1000.0 -99.99568287525881 number episode from 10: 58 avegar over 10 episode: -99.979 avegare return across last 100 episodes: -99.979 state values: tensor(0.8483) 1000
59 1000 -1000.0 -99.99568287525881 number episode from 10: 59 avegar over 10 episode: -99.979 avegare return across last 100 episodes: -99.979 state values: tensor(0.8459) 1000
60 1000 -1000.0 -99.99568287525881 number episode from 10: 60 avegar over 10 episode: -99.979 avegare return across last 100 episodes: -99.979 state values: tensor(0.8514) 1000
61 1000 -1000.0 -99.99568287525881 number episode from 10: 61 avegar over 10 episode: -99.98 avegare return across last 100 episodes: -99.98 state values: tensor(0.8501) 1000
62 1000 -1000.0 -99.99568287525881 number episode from 10: 62 avegar over 10 episode: -99.98 avegare return across last 100 episodes: -99.98 state values: tensor(0.8502) 1000
63 1000 -1000.0 -99.99568287525881 number episode from 10: 63 avegar over 10 episode: -99.98 avegare return across last 100 episodes: -99.98 state values: tensor(0.8446) 1000
64 1000 -1000.0 -99.99568287525881 number episode from 10: 64 avegar over 10 episode: -99.98 avegare return across last 100 episodes: -99.98 state values: tensor(0.8474) 1000
65 1000 -1000.0 -99.99568287525881 number episode from 10: 65 avegar over 10 episode: -99.981 avegare return across last 100 episodes: -99.981 state values: tensor(0.8469) 1000
66 1000 -1000.0 -99.99568287525881 number episode from 10: 66 avegar over 10 episode: -99.981 avegare return across last 100 episodes: -99.981 state values: tensor(0.8472) 1000
67 1000 -1000.0 -99.99568287525881 number episode from 10: 67 avegar over 10 episode: -99.981 avegare return across last 100 episodes: -99.981 state values: tensor(0.8486) 1000
68 1000 -1000.0 -99.99568287525881 number episode from 10: 68 avegar over 10 episode: -99.981 avegare return across last 100 episodes: -99.981 state values: tensor(0.8447) 1000
69 1000 -1000.0 -99.99568287525881 number episode from 10: 69 avegar over 10 episode: -99.981 avegare return across last 100 episodes: -99.981 state values: tensor(0.8503) 1000
70 1000 -1000.0 -99.99568287525881 number episode from 10: 70 avegar over 10 episode: -99.982 avegare return across last 100 episodes: -99.982 state values: tensor(0.8445) 1000
71 1000 -1000.0 -99.99568287525881 number episode from 10: 71 avegar over 10 episode: -99.982 avegare return across last 100 episodes: -99.982 state values: tensor(0.8519) 1000
72 1000 -1000.0 -99.99568287525881 number episode from 10: 72 avegar over 10 episode: -99.982 avegare return across last 100 episodes: -99.982 state values: tensor(0.8513) 1000
73 1000 -1000.0 -99.99568287525881 number episode from 10: 73 avegar over 10 episode: -99.982 avegare return across last 100 episodes: -99.982 state values: tensor(0.8509) 1000
74 1000 -1000.0 -99.99568287525881 number episode from 10: 74 avegar over 10 episode: -99.982 avegare return across last 100 episodes: -99.982 state values: tensor(0.8464) 1000
75 1000 -1000.0 -99.99568287525881 number episode from 10: 75 avegar over 10 episode: -99.983 avegare return across last 100 episodes: -99.983 state values: tensor(0.8464) 1000
76 1000 -1000.0 -99.99568287525881 number episode from 10: 76 avegar over 10 episode: -99.983 avegare return across last 100 episodes: -99.983 state values: tensor(0.8489) 1000
77 1000 -1000.0 -99.99568287525881 number episode from 10: 77 avegar over 10 episode: -99.983 avegare return across last 100 episodes: -99.983 state values: tensor(0.8457) 1000
78 1000 -1000.0 -99.99568287525881 number episode from 10: 78 avegar over 10 episode: -99.983 avegare return across last 100 episodes: -99.983 state values: tensor(0.8519) 1000
79 1000 -1000.0 -99.99568287525881 number episode from 10: 79 avegar over 10 episode: -99.983 avegare return across last 100 episodes: -99.983 state values: tensor(0.8488) 1000
80 1000 -1000.0 -99.99568287525881 number episode from 10: 80 avegar over 10 episode: -99.983 avegare return across last 100 episodes: -99.983 state values: tensor(0.8502) 1000
81 1000 -1000.0 -99.99568287525881 number episode from 10: 81 avegar over 10 episode: -99.983 avegare return across last 100 episodes: -99.983 state values: tensor(0.8469) 1000
82 1000 -1000.0 -99.99568287525881 number episode from 10: 82 avegar over 10 episode: -99.984 avegare return across last 100 episodes: -99.984 state values: tensor(0.8491) 1000
83 1000 -1000.0 -99.99568287525881 number episode from 10: 83 avegar over 10 episode: -99.984 avegare return across last 100 episodes: -99.984 state values: tensor(0.8472) 1000
84 1000 -1000.0 -99.99568287525881 number episode from 10: 84 avegar over 10 episode: -99.984 avegare return across last 100 episodes: -99.984 state values: tensor(0.8501) 1000
85 1000 -1000.0 -99.99568287525881 number episode from 10: 85 avegar over 10 episode: -99.984 avegare return across last 100 episodes: -99.984 state values: tensor(0.8457) 1000
86 1000 -1000.0 -99.99568287525881 number episode from 10: 86 avegar over 10 episode: -99.984 avegare return across last 100 episodes: -99.984 state values: tensor(0.8464) 1000
87 1000 -1000.0 -99.99568287525881 number episode from 10: 87 avegar over 10 episode: -99.984 avegare return across last 100 episodes: -99.984 state values: tensor(0.8453) 1000
88 1000 -1000.0 -99.99568287525881 number episode from 10: 88 avegar over 10 episode: -99.984 avegare return across last 100 episodes: -99.984 state values: tensor(0.8502) 1000
89 1000 -1000.0 -99.99568287525881 number episode from 10: 89 avegar over 10 episode: -99.985 avegare return across last 100 episodes: -99.985 state values: tensor(0.8507) 1000
90 1000 -1000.0 -99.99568287525881 number episode from 10: 90 avegar over 10 episode: -99.985 avegare return across last 100 episodes: -99.985 state values: tensor(0.8519) 1000
91 1000 -1000.0 -99.99568287525881 number episode from 10: 91 avegar over 10 episode: -99.985 avegare return across last 100 episodes: -99.985 state values: tensor(0.8510) 1000
92 1000 -1000.0 -99.99568287525881 number episode from 10: 92 avegar over 10 episode: -99.985 avegare return across last 100 episodes: -99.985 state values: tensor(0.8516) 1000
93 1000 -1000.0 -99.99568287525881 number episode from 10: 93 avegar over 10 episode: -99.985 avegare return across last 100 episodes: -99.985 state values: tensor(0.8466) 1000
94 1000 -1000.0 -99.99568287525881 number episode from 10: 94 avegar over 10 episode: -99.985 avegare return across last 100 episodes: -99.985 state values: tensor(0.8490) 1000
95 1000 -1000.0 -99.99568287525881 number episode from 10: 95 avegar over 10 episode: -99.985 avegare return across last 100 episodes: -99.985 state values: tensor(0.8499) 1000
96 1000 -1000.0 -99.99568287525881 number episode from 10: 96 avegar over 10 episode: -99.985 avegare return across last 100 episodes: -99.985 state values: tensor(0.8501) 1000
97 1000 -1000.0 -99.99568287525881 number episode from 10: 97 avegar over 10 episode: -99.985 avegare return across last 100 episodes: -99.985 state values: tensor(0.8495) 1000
98 1000 -1000.0 -99.99568287525881 number episode from 10: 98 avegar over 10 episode: -99.986 avegare return across last 100 episodes: -99.986 state values: tensor(0.8496) 1000
99 1000 -1000.0 -99.99568287525881 number episode from 10: 99 avegar over 10 episode: -99.986 avegare return across last 100 episodes: -99.986 state values: tensor(0.8492) 1000
100 1000 -1000.0 -99.99568287525881 number episode from 10: 100 avegar over 10 episode: -99.986 avegare return across last 100 episodes: -99.996 state values: tensor(0.8502) 1000
101 1000 -1000.0 -99.99568287525881 number episode from 10: 101 avegar over 10 episode: -99.986 avegare return across last 100 episodes: -99.996 state values: tensor(0.8470) 1000
102 1000 -1000.0 -99.99568287525881 number episode from 10: 102 avegar over 10 episode: -99.986 avegare return across last 100 episodes: -99.996 state values: tensor(0.8460) 1000
103 1000 -1000.0 -99.99568287525881 number episode from 10: 103 avegar over 10 episode: -99.986 avegare return across last 100 episodes: -99.996 state values: tensor(0.8454) 1000
104 1000 -1000.0 -99.99568287525881 number episode from 10: 104 avegar over 10 episode: -99.986 avegare return across last 100 episodes: -99.996 state values: tensor(0.8512) 1000
105 1000 -1000.0 -99.99568287525881 number episode from 10: 105 avegar over 10 episode: -99.986 avegare return across last 100 episodes: -99.996 state values: tensor(0.8466) 1000
106 1000 -1000.0 -99.99568287525881 number episode from 10: 106 avegar over 10 episode: -99.986 avegare return across last 100 episodes: -99.996 state values: tensor(0.8504) 1000
107 1000 -1000.0 -99.99568287525881 number episode from 10: 107 avegar over 10 episode: -99.986 avegare return across last 100 episodes: -99.996 state values: tensor(0.8453) 1000
108 1000 -1000.0 -99.99568287525881 number episode from 10: 108 avegar over 10 episode: -99.987 avegare return across last 100 episodes: -99.996 state values: tensor(0.8510) 1000
109 1000 -1000.0 -99.99568287525881 number episode from 10: 109 avegar over 10 episode: -99.987 avegare return across last 100 episodes: -99.996 state values: tensor(0.8507) 1000
110 1000 -1000.0 -99.99568287525881 number episode from 10: 110 avegar over 10 episode: -99.987 avegare return across last 100 episodes: -99.996 state values: tensor(0.8498) 1000
111 1000 -1000.0 -99.99568287525881 number episode from 10: 111 avegar over 10 episode: -99.987 avegare return across last 100 episodes: -99.996 state values: tensor(0.8457) 1000
112 1000 -1000.0 -99.99568287525881 number episode from 10: 112 avegar over 10 episode: -99.987 avegare return across last 100 episodes: -99.996 state values: tensor(0.8506) 1000
113 1000 -1000.0 -99.99568287525881 number episode from 10: 113 avegar over 10 episode: -99.987 avegare return across last 100 episodes: -99.996 state values: tensor(0.8508) 1000
114 1000 -1000.0 -99.99568287525881 number episode from 10: 114 avegar over 10 episode: -99.987 avegare return across last 100 episodes: -99.996 state values: tensor(0.8472) 1000
115 1000 -1000.0 -99.99568287525881 number episode from 10: 115 avegar over 10 episode: -99.987 avegare return across last 100 episodes: -99.996 state values: tensor(0.8461) 1000
116 1000 -1000.0 -99.99568287525881 number episode from 10: 116 avegar over 10 episode: -99.987 avegare return across last 100 episodes: -99.996 state values: tensor(0.8503) 1000
117 1000 -1000.0 -99.99568287525881 number episode from 10: 117 avegar over 10 episode: -99.987 avegare return across last 100 episodes: -99.996 state values: tensor(0.8461) 1000
118 1000 -1000.0 -99.99568287525881 number episode from 10: 118 avegar over 10 episode: -99.987 avegare return across last 100 episodes: -99.996 state values: tensor(0.8462) 1000
119 1000 -1000.0 -99.99568287525881 number episode from 10: 119 avegar over 10 episode: -99.987 avegare return across last 100 episodes: -99.996 state values: tensor(0.8502) 1000
120 1000 -1000.0 -99.99568287525881 number episode from 10: 120 avegar over 10 episode: -99.987 avegare return across last 100 episodes: -99.996 state values: tensor(0.8457) 1000
121 1000 -1000.0 -99.99568287525881 number episode from 10: 121 avegar over 10 episode: -99.987 avegare return across last 100 episodes: -99.996 state values: tensor(0.8491) 1000
122 1000 -1000.0 -99.99568287525881 number episode from 10: 122 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.8496) 1000
123 1000 -1000.0 -99.99568287525881 number episode from 10: 123 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.8502) 1000
124 1000 -1000.0 -99.99568287525881 number episode from 10: 124 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.8489) 1000
125 1000 -1000.0 -99.99568287525881 number episode from 10: 125 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.8482) 1000
126 1000 -1000.0 -99.99568287525881 number episode from 10: 126 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.8501) 1000
127 1000 -1000.0 -99.99568287525881 number episode from 10: 127 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.8514) 1000
128 1000 -1000.0 -99.99568287525881 number episode from 10: 128 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.8465) 1000
129 1000 -1000.0 -99.99568287525881 number episode from 10: 129 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.8482) 1000
130 1000 -1000.0 -99.99568287525881 number episode from 10: 130 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.8461) 1000
131 1000 -1000.0 -99.99568287525881 number episode from 10: 131 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.8500) 1000
132 1000 -1000.0 -99.99568287525881 number episode from 10: 132 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.8500) 1000
133 1000 -1000.0 -99.99568287525881 number episode from 10: 133 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.8503) 1000
134 1000 -1000.0 -99.99568287525881 number episode from 10: 134 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.8507) 1000
135 1000 -1000.0 -99.99568287525881 number episode from 10: 135 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.8500) 1000
136 1000 -1000.0 -99.99568287525881 number episode from 10: 136 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.8506) 1000
137 1000 -1000.0 -99.99568287525881 number episode from 10: 137 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.8484) 1000
138 1000 -1000.0 -99.99568287525881 number episode from 10: 138 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.8497) 1000
139 1000 -1000.0 -99.99568287525881 number episode from 10: 139 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.8489) 1000
140 1000 -1000.0 -99.99568287525881 number episode from 10: 140 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.8468) 1000
141 1000 -1000.0 -99.99568287525881 number episode from 10: 141 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.8449) 1000
142 1000 -1000.0 -99.99568287525881 number episode from 10: 142 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.8458) 1000
143 1000 -1000.0 -99.99568287525881 number episode from 10: 143 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.8503) 1000
144 1000 -1000.0 -99.99568287525881 number episode from 10: 144 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.8461) 1000
145 1000 -1000.0 -99.99568287525881 number episode from 10: 145 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.8510) 1000
146 1000 -1000.0 -99.99568287525881 number episode from 10: 146 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.8488) 1000
147 1000 -1000.0 -99.99568287525881 number episode from 10: 147 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.8506) 1000
148 1000 -1000.0 -99.99568287525881 number episode from 10: 148 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.8484) 1000
149 1000 -1000.0 -99.99568287525881 number episode from 10: 149 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.8487) 1000
150 1000 -1000.0 -99.99568287525881 number episode from 10: 150 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.8490) 1000
151 1000 -1000.0 -99.99568287525881 number episode from 10: 151 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.8494) 1000
152 1000 -1000.0 -99.99568287525881 number episode from 10: 152 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.8483) 1000
153 1000 -1000.0 -99.99568287525881 number episode from 10: 153 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.8446) 1000
154 1000 -1000.0 -99.99568287525881 number episode from 10: 154 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.8485) 1000
155 1000 -1000.0 -99.99568287525881 number episode from 10: 155 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.8510) 1000
156 1000 -1000.0 -99.99568287525881 number episode from 10: 156 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.8507) 1000
157 1000 -1000.0 -99.99568287525881 number episode from 10: 157 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.8462) 1000
158 1000 -1000.0 -99.99568287525881 number episode from 10: 158 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.8509) 1000
159 1000 -1000.0 -99.99568287525881 number episode from 10: 159 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.8474) 1000
160 1000 -1000.0 -99.99568287525881 number episode from 10: 160 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.8507) 1000
161 1000 -1000.0 -99.99568287525881 number episode from 10: 161 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.8468) 1000
162 1000 -1000.0 -99.99568287525881 number episode from 10: 162 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.8473) 1000
163 1000 -1000.0 -99.99568287525881 number episode from 10: 163 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.8485) 1000
164 1000 -1000.0 -99.99568287525881 number episode from 10: 164 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.8473) 1000
165 1000 -1000.0 -99.99568287525881 number episode from 10: 165 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.8450) 1000
166 1000 -1000.0 -99.99568287525881 number episode from 10: 166 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.8461) 1000
167 1000 -1000.0 -99.99568287525881 number episode from 10: 167 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.8454) 1000
168 1000 -1000.0 -99.99568287525881 number episode from 10: 168 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.8456) 1000
169 1000 -1000.0 -99.99568287525881 number episode from 10: 169 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.8474) 1000
170 1000 -1000.0 -99.99568287525881 number episode from 10: 170 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.8503) 1000
171 1000 -1000.0 -99.99568287525881 number episode from 10: 171 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.8455) 1000
172 1000 -1000.0 -99.99568287525881 number episode from 10: 172 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.8481) 1000
173 1000 -1000.0 -99.99568287525881 number episode from 10: 173 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.8475) 1000
174 1000 -1000.0 -99.99568287525881 number episode from 10: 174 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.8498) 1000
175 1000 -1000.0 -99.99568287525881 number episode from 10: 175 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.8503) 1000
176 1000 -1000.0 -99.99568287525881 number episode from 10: 176 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.8508) 1000
177 1000 -1000.0 -99.99568287525881 number episode from 10: 177 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.8510) 1000
178 1000 -1000.0 -99.99568287525881 number episode from 10: 178 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.8453) 1000
179 1000 -1000.0 -99.99568287525881 number episode from 10: 179 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.8471) 1000
180 1000 -1000.0 -99.99568287525881 number episode from 10: 180 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.8507) 1000
181 1000 -1000.0 -99.99568287525881 number episode from 10: 181 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.8503) 1000
182 1000 -1000.0 -99.99568287525881 number episode from 10: 182 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.8496) 1000
183 1000 -1000.0 -99.99568287525881 number episode from 10: 183 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.8514) 1000
184 1000 -1000.0 -99.99568287525881 number episode from 10: 184 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.8488) 1000
185 1000 -1000.0 -99.99568287525881 number episode from 10: 185 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.8497) 1000
186 1000 -1000.0 -99.99568287525881 number episode from 10: 186 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.8495) 1000
187 1000 -1000.0 -99.99568287525881 number episode from 10: 187 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.8457) 1000
188 1000 -1000.0 -99.99568287525881 number episode from 10: 188 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.8512) 1000
189 1000 -1000.0 -99.99568287525881 number episode from 10: 189 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.8474) 1000
190 1000 -1000.0 -99.99568287525881 number episode from 10: 190 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.8494) 1000
191 1000 -1000.0 -99.99568287525881 number episode from 10: 191 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.8492) 1000
192 1000 -1000.0 -99.99568287525881 number episode from 10: 192 avegar over 10 episode: -99.991 avegare return across last 100 episodes: -99.996 state values: tensor(0.8516) 1000
193 1000 -1000.0 -99.99568287525881 number episode from 10: 193 avegar over 10 episode: -99.991 avegare return across last 100 episodes: -99.996 state values: tensor(0.8468) 1000
194 1000 -1000.0 -99.99568287525881 number episode from 10: 194 avegar over 10 episode: -99.991 avegare return across last 100 episodes: -99.996 state values: tensor(0.8490) 1000
195 1000 -1000.0 -99.99568287525881 number episode from 10: 195 avegar over 10 episode: -99.991 avegare return across last 100 episodes: -99.996 state values: tensor(0.8472) 1000
196 1000 -1000.0 -99.99568287525881 number episode from 10: 196 avegar over 10 episode: -99.991 avegare return across last 100 episodes: -99.996 state values: tensor(0.8491) 1000
197 1000 -1000.0 -99.99568287525881 number episode from 10: 197 avegar over 10 episode: -99.991 avegare return across last 100 episodes: -99.996 state values: tensor(0.8465) 1000
198 1000 -1000.0 -99.99568287525881 number episode from 10: 198 avegar over 10 episode: -99.991 avegare return across last 100 episodes: -99.996 state values: tensor(0.8474) 1000
199 1000 -1000.0 -99.99568287525881 number episode from 10: 199 avegar over 10 episode: -99.991 avegare return across last 100 episodes: -99.996 state values: tensor(0.8510) 1000
200 1000 -1000.0 -99.99568287525881 number episode from 10: 200 avegar over 10 episode: -99.991 avegare return across last 100 episodes: -99.996 state values: tensor(0.8469) 1000
load offline data!!!!!
mem_cntr: 50000 ; mem_size: 50000
nn.learn_nn_feature_fqi FQI:  998
nn.learn_nn_feature_fqi FQI:  1998
nn.learn_nn_feature_fqi FQI:  2998
nn.learn_nn_feature_fqi FQI:  3998
nn.learn_nn_feature_fqi FQI:  4998
nn.learn_nn_feature_fqi FQI:  5998
nn.learn_nn_feature_fqi FQI:  6998
nn.learn_nn_feature_fqi FQI:  7998
nn.learn_nn_feature_fqi FQI:  8998
nn.learn_nn_feature_fqi FQI:  9998
nn.learn_nn_feature_fqi FQI:  10998
nn.learn_nn_feature_fqi FQI:  11998
nn.learn_nn_feature_fqi FQI:  12998
nn.learn_nn_feature_fqi FQI:  13998
nn.learn_nn_feature_fqi FQI:  14998
nn.learn_nn_feature_fqi FQI:  15998
nn.learn_nn_feature_fqi FQI:  16998
nn.learn_nn_feature_fqi FQI:  17998
nn.learn_nn_feature_fqi FQI:  18998
nn.learn_nn_feature_fqi FQI:  19998
nn.learn_nn_feature_fqi FQI:  20998
nn.learn_nn_feature_fqi FQI:  21998
nn.learn_nn_feature_fqi FQI:  22998
nn.learn_nn_feature_fqi FQI:  23998
nn.learn_nn_feature_fqi FQI:  24998
nn.learn_nn_feature_fqi FQI:  25998
nn.learn_nn_feature_fqi FQI:  26998
nn.learn_nn_feature_fqi FQI:  27998
nn.learn_nn_feature_fqi FQI:  28998
nn.learn_nn_feature_fqi FQI:  29998
nn.learn_nn_feature_fqi FQI:  30998
nn.learn_nn_feature_fqi FQI:  31998
nn.learn_nn_feature_fqi FQI:  32998
nn.learn_nn_feature_fqi FQI:  33998
nn.learn_nn_feature_fqi FQI:  34998
nn.learn_nn_feature_fqi FQI:  35998
nn.learn_nn_feature_fqi FQI:  36998
nn.learn_nn_feature_fqi FQI:  37998
nn.learn_nn_feature_fqi FQI:  38998
nn.learn_nn_feature_fqi FQI:  39998
nn.learn_nn_feature_fqi FQI:  40998
nn.learn_nn_feature_fqi FQI:  41998
nn.learn_nn_feature_fqi FQI:  42998
nn.learn_nn_feature_fqi FQI:  43998
nn.learn_nn_feature_fqi FQI:  44998
nn.learn_nn_feature_fqi FQI:  45998
nn.learn_nn_feature_fqi FQI:  46998
nn.learn_nn_feature_fqi FQI:  47998
nn.learn_nn_feature_fqi FQI:  48998
nn.learn_nn_feature_fqi FQI:  49998
nn.learn_nn_feature_fqi FQI:  50998
nn.learn_nn_feature_fqi FQI:  51998
nn.learn_nn_feature_fqi FQI:  52998
nn.learn_nn_feature_fqi FQI:  53998
nn.learn_nn_feature_fqi FQI:  54998
nn.learn_nn_feature_fqi FQI:  55998
nn.learn_nn_feature_fqi FQI:  56998
nn.learn_nn_feature_fqi FQI:  57998
nn.learn_nn_feature_fqi FQI:  58998
nn.learn_nn_feature_fqi FQI:  59998
nn.learn_nn_feature_fqi FQI:  60998
nn.learn_nn_feature_fqi FQI:  61998
nn.learn_nn_feature_fqi FQI:  62998
nn.learn_nn_feature_fqi FQI:  63998
nn.learn_nn_feature_fqi FQI:  64998
nn.learn_nn_feature_fqi FQI:  65998
nn.learn_nn_feature_fqi FQI:  66998
nn.learn_nn_feature_fqi FQI:  67998
nn.learn_nn_feature_fqi FQI:  68998
nn.learn_nn_feature_fqi FQI:  69998
nn.learn_nn_feature_fqi FQI:  70998
nn.learn_nn_feature_fqi FQI:  71998
nn.learn_nn_feature_fqi FQI:  72998
nn.learn_nn_feature_fqi FQI:  73998
nn.learn_nn_feature_fqi FQI:  74998
nn.learn_nn_feature_fqi FQI:  75998
nn.learn_nn_feature_fqi FQI:  76998
nn.learn_nn_feature_fqi FQI:  77998
nn.learn_nn_feature_fqi FQI:  78998
nn.learn_nn_feature_fqi FQI:  79998
nn.learn_nn_feature_fqi FQI:  80998
nn.learn_nn_feature_fqi FQI:  81998
nn.learn_nn_feature_fqi FQI:  82998
nn.learn_nn_feature_fqi FQI:  83998
nn.learn_nn_feature_fqi FQI:  84998
nn.learn_nn_feature_fqi FQI:  85998
nn.learn_nn_feature_fqi FQI:  86998
nn.learn_nn_feature_fqi FQI:  87998
nn.learn_nn_feature_fqi FQI:  88998
nn.learn_nn_feature_fqi FQI:  89998
nn.learn_nn_feature_fqi FQI:  90998
nn.learn_nn_feature_fqi FQI:  91998
nn.learn_nn_feature_fqi FQI:  92998
nn.learn_nn_feature_fqi FQI:  93998
nn.learn_nn_feature_fqi FQI:  94998
nn.learn_nn_feature_fqi FQI:  95998
nn.learn_nn_feature_fqi FQI:  96998
nn.learn_nn_feature_fqi FQI:  97998
nn.learn_nn_feature_fqi FQI:  98998
nn.learn_nn_feature_fqi FQI:  99998
nn.learn_nn_feature_fqi FQI:  100998
nn.learn_nn_feature_fqi FQI:  101998
nn.learn_nn_feature_fqi FQI:  102998
nn.learn_nn_feature_fqi FQI:  103998
nn.learn_nn_feature_fqi FQI:  104998
nn.learn_nn_feature_fqi FQI:  105998
nn.learn_nn_feature_fqi FQI:  106998
nn.learn_nn_feature_fqi FQI:  107998
nn.learn_nn_feature_fqi FQI:  108998
nn.learn_nn_feature_fqi FQI:  109998
nn.learn_nn_feature_fqi FQI:  110998
nn.learn_nn_feature_fqi FQI:  111998
nn.learn_nn_feature_fqi FQI:  112998
nn.learn_nn_feature_fqi FQI:  113998
nn.learn_nn_feature_fqi FQI:  114998
nn.learn_nn_feature_fqi FQI:  115998
nn.learn_nn_feature_fqi FQI:  116998
nn.learn_nn_feature_fqi FQI:  117998
nn.learn_nn_feature_fqi FQI:  118998
nn.learn_nn_feature_fqi FQI:  119998
nn.learn_nn_feature_fqi FQI:  120998
nn.learn_nn_feature_fqi FQI:  121998
nn.learn_nn_feature_fqi FQI:  122998
nn.learn_nn_feature_fqi FQI:  123998
nn.learn_nn_feature_fqi FQI:  124998
nn.learn_nn_feature_fqi FQI:  125998
nn.learn_nn_feature_fqi FQI:  126998
nn.learn_nn_feature_fqi FQI:  127998
nn.learn_nn_feature_fqi FQI:  128998
nn.learn_nn_feature_fqi FQI:  129998
nn.learn_nn_feature_fqi FQI:  130998
nn.learn_nn_feature_fqi FQI:  131998
nn.learn_nn_feature_fqi FQI:  132998
nn.learn_nn_feature_fqi FQI:  133998
nn.learn_nn_feature_fqi FQI:  134998
nn.learn_nn_feature_fqi FQI:  135998
nn.learn_nn_feature_fqi FQI:  136998
nn.learn_nn_feature_fqi FQI:  137998
nn.learn_nn_feature_fqi FQI:  138998
nn.learn_nn_feature_fqi FQI:  139998
nn.learn_nn_feature_fqi FQI:  140998
nn.learn_nn_feature_fqi FQI:  141998
nn.learn_nn_feature_fqi FQI:  142998
nn.learn_nn_feature_fqi FQI:  143998
nn.learn_nn_feature_fqi FQI:  144998
nn.learn_nn_feature_fqi FQI:  145998
nn.learn_nn_feature_fqi FQI:  146998
nn.learn_nn_feature_fqi FQI:  147998
nn.learn_nn_feature_fqi FQI:  148998
nn.learn_nn_feature_fqi FQI:  149998
nn.learn_nn_feature_fqi FQI:  150998
nn.learn_nn_feature_fqi FQI:  151998
nn.learn_nn_feature_fqi FQI:  152998
nn.learn_nn_feature_fqi FQI:  153998
nn.learn_nn_feature_fqi FQI:  154998
nn.learn_nn_feature_fqi FQI:  155998
0 1001 -1000.0 -98.99572604650622 number episode from 10: 0 avegar over 10 episode: -98.996 avegare return across last 100 episodes: -98.996 state values: tensor(0.6841) 1000
1 1000 -1000.0 -99.99568287525881 number episode from 10: 1 avegar over 10 episode: -99.496 avegare return across last 100 episodes: -99.496 state values: tensor(0.6858) 1000
2 562 -562.0 -99.64764587200904 number episode from 10: 2 avegar over 10 episode: -99.546 avegare return across last 100 episodes: -99.546 state values: tensor(0.8478) 562
3 1000 -1000.0 -99.99568287525881 number episode from 10: 3 avegar over 10 episode: -99.659 avegare return across last 100 episodes: -99.659 state values: tensor(0.6855) 1000
4 1000 -1000.0 -99.99568287525881 number episode from 10: 4 avegar over 10 episode: -99.726 avegare return across last 100 episodes: -99.726 state values: tensor(0.6853) 1000
5 1000 -1000.0 -99.99568287525881 number episode from 10: 5 avegar over 10 episode: -99.771 avegare return across last 100 episodes: -99.771 state values: tensor(0.6888) 1000
6 1000 -1000.0 -99.99568287525881 number episode from 10: 6 avegar over 10 episode: -99.803 avegare return across last 100 episodes: -99.803 state values: tensor(0.6864) 1000
7 1000 -1000.0 -99.99568287525881 number episode from 10: 7 avegar over 10 episode: -99.827 avegare return across last 100 episodes: -99.827 state values: tensor(0.6871) 1000
8 1000 -1000.0 -99.99568287525881 number episode from 10: 8 avegar over 10 episode: -99.846 avegare return across last 100 episodes: -99.846 state values: tensor(0.6918) 1000
9 1000 -1000.0 -99.99568287525881 number episode from 10: 9 avegar over 10 episode: -99.861 avegare return across last 100 episodes: -99.861 state values: tensor(0.6873) 1000
10 1000 -1000.0 -99.99568287525881 number episode from 10: 10 avegar over 10 episode: -99.873 avegare return across last 100 episodes: -99.873 state values: tensor(0.6843) 1000
11 393 -393.0 -98.0741100057678 number episode from 10: 11 avegar over 10 episode: -99.723 avegare return across last 100 episodes: -99.723 state values: tensor(0.8528) 393
12 1000 -1000.0 -99.99568287525881 number episode from 10: 12 avegar over 10 episode: -99.744 avegare return across last 100 episodes: -99.744 state values: tensor(0.6896) 1000
13 1000 -1000.0 -99.99568287525881 number episode from 10: 13 avegar over 10 episode: -99.762 avegare return across last 100 episodes: -99.762 state values: tensor(0.6879) 1000
14 1000 -1000.0 -99.99568287525881 number episode from 10: 14 avegar over 10 episode: -99.778 avegare return across last 100 episodes: -99.778 state values: tensor(0.8674) 1000
15 1000 -1000.0 -99.99568287525881 number episode from 10: 15 avegar over 10 episode: -99.791 avegare return across last 100 episodes: -99.791 state values: tensor(0.6899) 1000
16 1000 -1000.0 -99.99568287525881 number episode from 10: 16 avegar over 10 episode: -99.803 avegare return across last 100 episodes: -99.803 state values: tensor(0.6866) 1000
17 1000 -1000.0 -99.99568287525881 number episode from 10: 17 avegar over 10 episode: -99.814 avegare return across last 100 episodes: -99.814 state values: tensor(0.6878) 1000
18 1000 -1000.0 -99.99568287525881 number episode from 10: 18 avegar over 10 episode: -99.824 avegare return across last 100 episodes: -99.824 state values: tensor(0.6867) 1000
19 1000 -1000.0 -99.99568287525881 number episode from 10: 19 avegar over 10 episode: -99.832 avegare return across last 100 episodes: -99.832 state values: tensor(0.6866) 1000
20 1000 -1000.0 -99.99568287525881 number episode from 10: 20 avegar over 10 episode: -99.84 avegare return across last 100 episodes: -99.84 state values: tensor(0.6976) 1000
21 1000 -1000.0 -99.99568287525881 number episode from 10: 21 avegar over 10 episode: -99.847 avegare return across last 100 episodes: -99.847 state values: tensor(0.6878) 1000
22 1000 -1000.0 -99.99568287525881 number episode from 10: 22 avegar over 10 episode: -99.854 avegare return across last 100 episodes: -99.854 state values: tensor(0.6854) 1000
23 1000 -1000.0 -99.99568287525881 number episode from 10: 23 avegar over 10 episode: -99.859 avegare return across last 100 episodes: -99.859 state values: tensor(0.6865) 1000
24 303 -303.0 -95.24156695235246 number episode from 10: 24 avegar over 10 episode: -99.675 avegare return across last 100 episodes: -99.675 state values: tensor(0.8055) 303
25 1000 -1000.0 -99.99568287525881 number episode from 10: 25 avegar over 10 episode: -99.687 avegare return across last 100 episodes: -99.687 state values: tensor(0.6846) 1000
26 1000 -1000.0 -99.99568287525881 number episode from 10: 26 avegar over 10 episode: -99.699 avegare return across last 100 episodes: -99.699 state values: tensor(0.6852) 1000
27 1000 -1000.0 -99.99568287525881 number episode from 10: 27 avegar over 10 episode: -99.709 avegare return across last 100 episodes: -99.709 state values: tensor(0.6883) 1000
28 1000 -1000.0 -99.99568287525881 number episode from 10: 28 avegar over 10 episode: -99.719 avegare return across last 100 episodes: -99.719 state values: tensor(0.6860) 1000
29 1000 -1000.0 -99.99568287525881 number episode from 10: 29 avegar over 10 episode: -99.728 avegare return across last 100 episodes: -99.728 state values: tensor(0.6859) 1000
30 1000 -1000.0 -99.99568287525881 number episode from 10: 30 avegar over 10 episode: -99.737 avegare return across last 100 episodes: -99.737 state values: tensor(0.6883) 1000
31 1000 -1000.0 -99.99568287525881 number episode from 10: 31 avegar over 10 episode: -99.745 avegare return across last 100 episodes: -99.745 state values: tensor(0.8586) 1000
32 1000 -1000.0 -99.99568287525881 number episode from 10: 32 avegar over 10 episode: -99.753 avegare return across last 100 episodes: -99.753 state values: tensor(0.6921) 1000
33 1000 -1000.0 -99.99568287525881 number episode from 10: 33 avegar over 10 episode: -99.76 avegare return across last 100 episodes: -99.76 state values: tensor(0.6866) 1000
34 1000 -1000.0 -99.99568287525881 number episode from 10: 34 avegar over 10 episode: -99.766 avegare return across last 100 episodes: -99.766 state values: tensor(0.6903) 1000
35 1000 -1000.0 -99.99568287525881 number episode from 10: 35 avegar over 10 episode: -99.773 avegare return across last 100 episodes: -99.773 state values: tensor(0.6846) 1000
36 1000 -1000.0 -99.99568287525881 number episode from 10: 36 avegar over 10 episode: -99.779 avegare return across last 100 episodes: -99.779 state values: tensor(0.6911) 1000
37 1000 -1000.0 -99.99568287525881 number episode from 10: 37 avegar over 10 episode: -99.785 avegare return across last 100 episodes: -99.785 state values: tensor(0.6850) 1000
38 420 -420.0 -98.53181179426309 number episode from 10: 38 avegar over 10 episode: -99.752 avegare return across last 100 episodes: -99.752 state values: tensor(0.8181) 420
39 1000 -1000.0 -99.99568287525881 number episode from 10: 39 avegar over 10 episode: -99.758 avegare return across last 100 episodes: -99.758 state values: tensor(0.8399) 1000
40 1000 -1000.0 -99.99568287525881 number episode from 10: 40 avegar over 10 episode: -99.764 avegare return across last 100 episodes: -99.764 state values: tensor(0.6852) 1000
41 1000 -1000.0 -99.99568287525881 number episode from 10: 41 avegar over 10 episode: -99.77 avegare return across last 100 episodes: -99.77 state values: tensor(0.6867) 1000
42 1000 -1000.0 -99.99568287525881 number episode from 10: 42 avegar over 10 episode: -99.775 avegare return across last 100 episodes: -99.775 state values: tensor(0.6861) 1000
43 1000 -1000.0 -99.99568287525881 number episode from 10: 43 avegar over 10 episode: -99.78 avegare return across last 100 episodes: -99.78 state values: tensor(0.6859) 1000
44 1000 -1000.0 -99.99568287525881 number episode from 10: 44 avegar over 10 episode: -99.785 avegare return across last 100 episodes: -99.785 state values: tensor(0.6844) 1000
45 450 -450.0 -98.91398063601214 number episode from 10: 45 avegar over 10 episode: -99.766 avegare return across last 100 episodes: -99.766 state values: tensor(0.8305) 450
46 1000 -1000.0 -99.99568287525881 number episode from 10: 46 avegar over 10 episode: -99.771 avegare return across last 100 episodes: -99.771 state values: tensor(0.6873) 1000
47 1000 -1000.0 -99.99568287525881 number episode from 10: 47 avegar over 10 episode: -99.775 avegare return across last 100 episodes: -99.775 state values: tensor(0.6842) 1000
48 1000 -1000.0 -99.99568287525881 number episode from 10: 48 avegar over 10 episode: -99.78 avegare return across last 100 episodes: -99.78 state values: tensor(0.6871) 1000
49 1000 -1000.0 -99.99568287525881 number episode from 10: 49 avegar over 10 episode: -99.784 avegare return across last 100 episodes: -99.784 state values: tensor(0.6846) 1000
50 1000 -1000.0 -99.99568287525881 number episode from 10: 50 avegar over 10 episode: -99.788 avegare return across last 100 episodes: -99.788 state values: tensor(0.6895) 1000
51 1000 -1000.0 -99.99568287525881 number episode from 10: 51 avegar over 10 episode: -99.792 avegare return across last 100 episodes: -99.792 state values: tensor(0.6857) 1000
52 1000 -1000.0 -99.99568287525881 number episode from 10: 52 avegar over 10 episode: -99.796 avegare return across last 100 episodes: -99.796 state values: tensor(0.6933) 1000
53 1000 -1000.0 -99.99568287525881 number episode from 10: 53 avegar over 10 episode: -99.8 avegare return across last 100 episodes: -99.8 state values: tensor(0.6843) 1000
54 1000 -1000.0 -99.99568287525881 number episode from 10: 54 avegar over 10 episode: -99.804 avegare return across last 100 episodes: -99.804 state values: tensor(0.6872) 1000
55 1000 -1000.0 -99.99568287525881 number episode from 10: 55 avegar over 10 episode: -99.807 avegare return across last 100 episodes: -99.807 state values: tensor(0.6854) 1000
56 1000 -1000.0 -99.99568287525881 number episode from 10: 56 avegar over 10 episode: -99.81 avegare return across last 100 episodes: -99.81 state values: tensor(0.6856) 1000
57 1000 -1000.0 -99.99568287525881 number episode from 10: 57 avegar over 10 episode: -99.813 avegare return across last 100 episodes: -99.813 state values: tensor(0.6861) 1000
58 1000 -1000.0 -99.99568287525881 number episode from 10: 58 avegar over 10 episode: -99.817 avegare return across last 100 episodes: -99.817 state values: tensor(0.6867) 1000
59 1000 -1000.0 -99.99568287525881 number episode from 10: 59 avegar over 10 episode: -99.82 avegare return across last 100 episodes: -99.82 state values: tensor(0.6866) 1000
60 1000 -1000.0 -99.99568287525881 number episode from 10: 60 avegar over 10 episode: -99.822 avegare return across last 100 episodes: -99.822 state values: tensor(0.6865) 1000
61 1000 -1000.0 -99.99568287525881 number episode from 10: 61 avegar over 10 episode: -99.825 avegare return across last 100 episodes: -99.825 state values: tensor(0.6870) 1000
62 1000 -1000.0 -99.99568287525881 number episode from 10: 62 avegar over 10 episode: -99.828 avegare return across last 100 episodes: -99.828 state values: tensor(0.6848) 1000
63 1000 -1000.0 -99.99568287525881 number episode from 10: 63 avegar over 10 episode: -99.831 avegare return across last 100 episodes: -99.831 state values: tensor(0.6844) 1000
64 1000 -1000.0 -99.99568287525881 number episode from 10: 64 avegar over 10 episode: -99.833 avegare return across last 100 episodes: -99.833 state values: tensor(0.6877) 1000
65 1000 -1000.0 -99.99568287525881 number episode from 10: 65 avegar over 10 episode: -99.836 avegare return across last 100 episodes: -99.836 state values: tensor(0.6852) 1000
66 1000 -1000.0 -99.99568287525881 number episode from 10: 66 avegar over 10 episode: -99.838 avegare return across last 100 episodes: -99.838 state values: tensor(0.6857) 1000
67 1000 -1000.0 -99.99568287525881 number episode from 10: 67 avegar over 10 episode: -99.84 avegare return across last 100 episodes: -99.84 state values: tensor(0.6876) 1000
68 1000 -1000.0 -99.99568287525881 number episode from 10: 68 avegar over 10 episode: -99.843 avegare return across last 100 episodes: -99.843 state values: tensor(0.6896) 1000
69 1000 -1000.0 -99.99568287525881 number episode from 10: 69 avegar over 10 episode: -99.845 avegare return across last 100 episodes: -99.845 state values: tensor(0.6847) 1000
70 1000 -1000.0 -99.99568287525881 number episode from 10: 70 avegar over 10 episode: -99.847 avegare return across last 100 episodes: -99.847 state values: tensor(0.6851) 1000
71 304 -304.0 -95.28915128282893 number episode from 10: 71 avegar over 10 episode: -99.784 avegare return across last 100 episodes: -99.784 state values: tensor(0.8001) 304
72 1000 -1000.0 -99.99568287525881 number episode from 10: 72 avegar over 10 episode: -99.786 avegare return across last 100 episodes: -99.786 state values: tensor(0.6845) 1000
73 1000 -1000.0 -99.99568287525881 number episode from 10: 73 avegar over 10 episode: -99.789 avegare return across last 100 episodes: -99.789 state values: tensor(0.6848) 1000
74 1000 -1000.0 -99.99568287525881 number episode from 10: 74 avegar over 10 episode: -99.792 avegare return across last 100 episodes: -99.792 state values: tensor(0.6856) 1000
75 1000 -1000.0 -99.99568287525881 number episode from 10: 75 avegar over 10 episode: -99.795 avegare return across last 100 episodes: -99.795 state values: tensor(0.6906) 1000
76 1000 -1000.0 -99.99568287525881 number episode from 10: 76 avegar over 10 episode: -99.797 avegare return across last 100 episodes: -99.797 state values: tensor(0.6844) 1000
77 554 -554.0 -99.61814559312161 number episode from 10: 77 avegar over 10 episode: -99.795 avegare return across last 100 episodes: -99.795 state values: tensor(0.8430) 554
78 1000 -1000.0 -99.99568287525881 number episode from 10: 78 avegar over 10 episode: -99.798 avegare return across last 100 episodes: -99.798 state values: tensor(0.6848) 1000
79 1000 -1000.0 -99.99568287525881 number episode from 10: 79 avegar over 10 episode: -99.8 avegare return across last 100 episodes: -99.8 state values: tensor(0.6856) 1000
80 1000 -1000.0 -99.99568287525881 number episode from 10: 80 avegar over 10 episode: -99.802 avegare return across last 100 episodes: -99.802 state values: tensor(0.6885) 1000
81 1000 -1000.0 -99.99568287525881 number episode from 10: 81 avegar over 10 episode: -99.805 avegare return across last 100 episodes: -99.805 state values: tensor(0.6861) 1000
82 1000 -1000.0 -99.99568287525881 number episode from 10: 82 avegar over 10 episode: -99.807 avegare return across last 100 episodes: -99.807 state values: tensor(0.6859) 1000
83 1000 -1000.0 -99.99568287525881 number episode from 10: 83 avegar over 10 episode: -99.809 avegare return across last 100 episodes: -99.809 state values: tensor(0.6860) 1000
84 1000 -1000.0 -99.99568287525881 number episode from 10: 84 avegar over 10 episode: -99.812 avegare return across last 100 episodes: -99.812 state values: tensor(0.6883) 1000
85 1000 -1000.0 -99.99568287525881 number episode from 10: 85 avegar over 10 episode: -99.814 avegare return across last 100 episodes: -99.814 state values: tensor(0.6857) 1000
86 649 -649.0 -99.85302573608426 number episode from 10: 86 avegar over 10 episode: -99.814 avegare return across last 100 episodes: -99.814 state values: tensor(0.8367) 649
87 1000 -1000.0 -99.99568287525881 number episode from 10: 87 avegar over 10 episode: -99.816 avegare return across last 100 episodes: -99.816 state values: tensor(0.6862) 1000
88 1000 -1000.0 -99.99568287525881 number episode from 10: 88 avegar over 10 episode: -99.818 avegare return across last 100 episodes: -99.818 state values: tensor(0.6867) 1000
89 1000 -1000.0 -99.99568287525881 number episode from 10: 89 avegar over 10 episode: -99.82 avegare return across last 100 episodes: -99.82 state values: tensor(0.6849) 1000
90 1000 -1000.0 -99.99568287525881 number episode from 10: 90 avegar over 10 episode: -99.822 avegare return across last 100 episodes: -99.822 state values: tensor(0.6847) 1000
91 1000 -1000.0 -99.99568287525881 number episode from 10: 91 avegar over 10 episode: -99.824 avegare return across last 100 episodes: -99.824 state values: tensor(0.6850) 1000
92 1000 -1000.0 -99.99568287525881 number episode from 10: 92 avegar over 10 episode: -99.826 avegare return across last 100 episodes: -99.826 state values: tensor(0.6847) 1000
93 1000 -1000.0 -99.99568287525881 number episode from 10: 93 avegar over 10 episode: -99.828 avegare return across last 100 episodes: -99.828 state values: tensor(0.6844) 1000
94 1000 -1000.0 -99.99568287525881 number episode from 10: 94 avegar over 10 episode: -99.829 avegare return across last 100 episodes: -99.829 state values: tensor(0.6907) 1000
95 1000 -1000.0 -99.99568287525881 number episode from 10: 95 avegar over 10 episode: -99.831 avegare return across last 100 episodes: -99.831 state values: tensor(0.6848) 1000
96 1000 -1000.0 -99.99568287525881 number episode from 10: 96 avegar over 10 episode: -99.833 avegare return across last 100 episodes: -99.833 state values: tensor(0.6867) 1000
97 1000 -1000.0 -99.99568287525881 number episode from 10: 97 avegar over 10 episode: -99.834 avegare return across last 100 episodes: -99.834 state values: tensor(0.6848) 1000
98 1000 -1000.0 -99.99568287525881 number episode from 10: 98 avegar over 10 episode: -99.836 avegare return across last 100 episodes: -99.836 state values: tensor(0.6886) 1000
99 1000 -1000.0 -99.99568287525881 number episode from 10: 99 avegar over 10 episode: -99.838 avegare return across last 100 episodes: -99.838 state values: tensor(0.6878) 1000
100 653 -653.0 -99.85881710850987 number episode from 10: 100 avegar over 10 episode: -99.838 avegare return across last 100 episodes: -99.846 state values: tensor(0.8373) 653
101 1000 -1000.0 -99.99568287525881 number episode from 10: 101 avegar over 10 episode: -99.839 avegare return across last 100 episodes: -99.846 state values: tensor(0.6867) 1000
102 1000 -1000.0 -99.99568287525881 number episode from 10: 102 avegar over 10 episode: -99.841 avegare return across last 100 episodes: -99.85 state values: tensor(0.6851) 1000
103 1000 -1000.0 -99.99568287525881 number episode from 10: 103 avegar over 10 episode: -99.842 avegare return across last 100 episodes: -99.85 state values: tensor(0.6895) 1000
104 1000 -1000.0 -99.99568287525881 number episode from 10: 104 avegar over 10 episode: -99.844 avegare return across last 100 episodes: -99.85 state values: tensor(0.6847) 1000
105 1000 -1000.0 -99.99568287525881 number episode from 10: 105 avegar over 10 episode: -99.845 avegare return across last 100 episodes: -99.85 state values: tensor(0.6917) 1000
106 1000 -1000.0 -99.99568287525881 number episode from 10: 106 avegar over 10 episode: -99.847 avegare return across last 100 episodes: -99.85 state values: tensor(0.6881) 1000
107 1000 -1000.0 -99.99568287525881 number episode from 10: 107 avegar over 10 episode: -99.848 avegare return across last 100 episodes: -99.85 state values: tensor(0.6883) 1000
108 1000 -1000.0 -99.99568287525881 number episode from 10: 108 avegar over 10 episode: -99.85 avegare return across last 100 episodes: -99.85 state values: tensor(0.6857) 1000
109 1000 -1000.0 -99.99568287525881 number episode from 10: 109 avegar over 10 episode: -99.851 avegare return across last 100 episodes: -99.85 state values: tensor(0.7812) 1000
110 1000 -1000.0 -99.99568287525881 number episode from 10: 110 avegar over 10 episode: -99.852 avegare return across last 100 episodes: -99.85 state values: tensor(0.6903) 1000
111 1000 -1000.0 -99.99568287525881 number episode from 10: 111 avegar over 10 episode: -99.853 avegare return across last 100 episodes: -99.869 state values: tensor(0.6849) 1000
112 1000 -1000.0 -99.99568287525881 number episode from 10: 112 avegar over 10 episode: -99.855 avegare return across last 100 episodes: -99.869 state values: tensor(0.6845) 1000
113 1000 -1000.0 -99.99568287525881 number episode from 10: 113 avegar over 10 episode: -99.856 avegare return across last 100 episodes: -99.869 state values: tensor(0.6869) 1000
114 1000 -1000.0 -99.99568287525881 number episode from 10: 114 avegar over 10 episode: -99.857 avegare return across last 100 episodes: -99.869 state values: tensor(0.6868) 1000
115 1000 -1000.0 -99.99568287525881 number episode from 10: 115 avegar over 10 episode: -99.858 avegare return across last 100 episodes: -99.869 state values: tensor(0.6853) 1000
116 1000 -1000.0 -99.99568287525881 number episode from 10: 116 avegar over 10 episode: -99.86 avegare return across last 100 episodes: -99.869 state values: tensor(0.6883) 1000
117 1000 -1000.0 -99.99568287525881 number episode from 10: 117 avegar over 10 episode: -99.861 avegare return across last 100 episodes: -99.869 state values: tensor(0.6859) 1000
118 1000 -1000.0 -99.99568287525881 number episode from 10: 118 avegar over 10 episode: -99.862 avegare return across last 100 episodes: -99.869 state values: tensor(0.6849) 1000
119 1000 -1000.0 -99.99568287525881 number episode from 10: 119 avegar over 10 episode: -99.863 avegare return across last 100 episodes: -99.869 state values: tensor(0.6862) 1000
120 1000 -1000.0 -99.99568287525881 number episode from 10: 120 avegar over 10 episode: -99.864 avegare return across last 100 episodes: -99.869 state values: tensor(0.6880) 1000
121 438 -438.0 -98.77477673791384 number episode from 10: 121 avegar over 10 episode: -99.855 avegare return across last 100 episodes: -99.857 state values: tensor(0.7599) 438
122 1000 -1000.0 -99.99568287525881 number episode from 10: 122 avegar over 10 episode: -99.856 avegare return across last 100 episodes: -99.857 state values: tensor(0.6874) 1000
123 1000 -1000.0 -99.99568287525881 number episode from 10: 123 avegar over 10 episode: -99.857 avegare return across last 100 episodes: -99.857 state values: tensor(0.6845) 1000
124 1000 -1000.0 -99.99568287525881 number episode from 10: 124 avegar over 10 episode: -99.858 avegare return across last 100 episodes: -99.904 state values: tensor(0.8578) 1000
125 1000 -1000.0 -99.99568287525881 number episode from 10: 125 avegar over 10 episode: -99.86 avegare return across last 100 episodes: -99.904 state values: tensor(0.6854) 1000
126 424 -424.0 -98.58966426764006 number episode from 10: 126 avegar over 10 episode: -99.85 avegare return across last 100 episodes: -99.89 state values: tensor(0.8262) 424
127 1000 -1000.0 -99.99568287525881 number episode from 10: 127 avegar over 10 episode: -99.851 avegare return across last 100 episodes: -99.89 state values: tensor(0.6850) 1000
128 1000 -1000.0 -99.99568287525881 number episode from 10: 128 avegar over 10 episode: -99.852 avegare return across last 100 episodes: -99.89 state values: tensor(0.6872) 1000
129 1000 -1000.0 -99.99568287525881 number episode from 10: 129 avegar over 10 episode: -99.853 avegare return across last 100 episodes: -99.89 state values: tensor(0.6888) 1000
130 1000 -1000.0 -99.99568287525881 number episode from 10: 130 avegar over 10 episode: -99.854 avegare return across last 100 episodes: -99.89 state values: tensor(0.6851) 1000
131 1000 -1000.0 -99.99568287525881 number episode from 10: 131 avegar over 10 episode: -99.855 avegare return across last 100 episodes: -99.89 state values: tensor(0.6843) 1000
132 1000 -1000.0 -99.99568287525881 number episode from 10: 132 avegar over 10 episode: -99.856 avegare return across last 100 episodes: -99.89 state values: tensor(0.6843) 1000
133 1000 -1000.0 -99.99568287525881 number episode from 10: 133 avegar over 10 episode: -99.857 avegare return across last 100 episodes: -99.89 state values: tensor(0.6846) 1000
134 1000 -1000.0 -99.99568287525881 number episode from 10: 134 avegar over 10 episode: -99.858 avegare return across last 100 episodes: -99.89 state values: tensor(0.6866) 1000
135 1000 -1000.0 -99.99568287525881 number episode from 10: 135 avegar over 10 episode: -99.859 avegare return across last 100 episodes: -99.89 state values: tensor(0.6852) 1000
136 1000 -1000.0 -99.99568287525881 number episode from 10: 136 avegar over 10 episode: -99.86 avegare return across last 100 episodes: -99.89 state values: tensor(0.6850) 1000
137 1000 -1000.0 -99.99568287525881 number episode from 10: 137 avegar over 10 episode: -99.861 avegare return across last 100 episodes: -99.89 state values: tensor(0.6846) 1000
138 1000 -1000.0 -99.99568287525881 number episode from 10: 138 avegar over 10 episode: -99.862 avegare return across last 100 episodes: -99.905 state values: tensor(0.6849) 1000
139 1000 -1000.0 -99.99568287525881 number episode from 10: 139 avegar over 10 episode: -99.863 avegare return across last 100 episodes: -99.905 state values: tensor(0.6860) 1000
140 525 -525.0 -99.48893379480397 number episode from 10: 140 avegar over 10 episode: -99.86 avegare return across last 100 episodes: -99.9 state values: tensor(0.7508) 525
141 1000 -1000.0 -99.99568287525881 number episode from 10: 141 avegar over 10 episode: -99.861 avegare return across last 100 episodes: -99.9 state values: tensor(0.6879) 1000
142 1000 -1000.0 -99.99568287525881 number episode from 10: 142 avegar over 10 episode: -99.862 avegare return across last 100 episodes: -99.9 state values: tensor(0.6858) 1000
143 1000 -1000.0 -99.99568287525881 number episode from 10: 143 avegar over 10 episode: -99.863 avegare return across last 100 episodes: -99.9 state values: tensor(0.6870) 1000
144 1000 -1000.0 -99.99568287525881 number episode from 10: 144 avegar over 10 episode: -99.864 avegare return across last 100 episodes: -99.9 state values: tensor(0.6883) 1000
145 1000 -1000.0 -99.99568287525881 number episode from 10: 145 avegar over 10 episode: -99.865 avegare return across last 100 episodes: -99.911 state values: tensor(0.6861) 1000
146 1000 -1000.0 -99.99568287525881 number episode from 10: 146 avegar over 10 episode: -99.866 avegare return across last 100 episodes: -99.911 state values: tensor(0.6882) 1000
147 1000 -1000.0 -99.99568287525881 number episode from 10: 147 avegar over 10 episode: -99.867 avegare return across last 100 episodes: -99.911 state values: tensor(0.6872) 1000
148 1000 -1000.0 -99.99568287525881 number episode from 10: 148 avegar over 10 episode: -99.868 avegare return across last 100 episodes: -99.911 state values: tensor(0.6864) 1000
149 1000 -1000.0 -99.99568287525881 number episode from 10: 149 avegar over 10 episode: -99.869 avegare return across last 100 episodes: -99.911 state values: tensor(0.6882) 1000
150 905 -905.0 -99.9887836614145 number episode from 10: 150 avegar over 10 episode: -99.869 avegare return across last 100 episodes: -99.911 state values: tensor(0.8519) 905
151 665 -665.0 -99.874857620838 number episode from 10: 151 avegar over 10 episode: -99.869 avegare return across last 100 episodes: -99.909 state values: tensor(0.7394) 665
152 1000 -1000.0 -99.99568287525881 number episode from 10: 152 avegar over 10 episode: -99.87 avegare return across last 100 episodes: -99.909 state values: tensor(0.6865) 1000
153 1000 -1000.0 -99.99568287525881 number episode from 10: 153 avegar over 10 episode: -99.871 avegare return across last 100 episodes: -99.909 state values: tensor(0.6856) 1000
154 1000 -1000.0 -99.99568287525881 number episode from 10: 154 avegar over 10 episode: -99.872 avegare return across last 100 episodes: -99.909 state values: tensor(0.6896) 1000
155 1000 -1000.0 -99.99568287525881 number episode from 10: 155 avegar over 10 episode: -99.873 avegare return across last 100 episodes: -99.909 state values: tensor(0.6852) 1000
156 1000 -1000.0 -99.99568287525881 number episode from 10: 156 avegar over 10 episode: -99.873 avegare return across last 100 episodes: -99.909 state values: tensor(0.6847) 1000
157 1000 -1000.0 -99.99568287525881 number episode from 10: 157 avegar over 10 episode: -99.874 avegare return across last 100 episodes: -99.909 state values: tensor(0.6875) 1000
158 1000 -1000.0 -99.99568287525881 number episode from 10: 158 avegar over 10 episode: -99.875 avegare return across last 100 episodes: -99.909 state values: tensor(0.6878) 1000
159 1000 -1000.0 -99.99568287525881 number episode from 10: 159 avegar over 10 episode: -99.876 avegare return across last 100 episodes: -99.909 state values: tensor(0.6881) 1000
160 953 -953.0 -99.99307626477363 number episode from 10: 160 avegar over 10 episode: -99.876 avegare return across last 100 episodes: -99.909 state values: tensor(0.7241) 953
161 1000 -1000.0 -99.99568287525881 number episode from 10: 161 avegar over 10 episode: -99.877 avegare return across last 100 episodes: -99.909 state values: tensor(0.6863) 1000
162 1000 -1000.0 -99.99568287525881 number episode from 10: 162 avegar over 10 episode: -99.878 avegare return across last 100 episodes: -99.909 state values: tensor(0.6853) 1000
163 1000 -1000.0 -99.99568287525881 number episode from 10: 163 avegar over 10 episode: -99.879 avegare return across last 100 episodes: -99.909 state values: tensor(0.6870) 1000
164 1000 -1000.0 -99.99568287525881 number episode from 10: 164 avegar over 10 episode: -99.879 avegare return across last 100 episodes: -99.909 state values: tensor(0.6853) 1000
165 1000 -1000.0 -99.99568287525881 number episode from 10: 165 avegar over 10 episode: -99.88 avegare return across last 100 episodes: -99.909 state values: tensor(0.6870) 1000
166 1000 -1000.0 -99.99568287525881 number episode from 10: 166 avegar over 10 episode: -99.881 avegare return across last 100 episodes: -99.909 state values: tensor(0.6877) 1000
167 1000 -1000.0 -99.99568287525881 number episode from 10: 167 avegar over 10 episode: -99.881 avegare return across last 100 episodes: -99.909 state values: tensor(0.6863) 1000
168 1000 -1000.0 -99.99568287525881 number episode from 10: 168 avegar over 10 episode: -99.882 avegare return across last 100 episodes: -99.909 state values: tensor(0.6878) 1000
169 1000 -1000.0 -99.99568287525881 number episode from 10: 169 avegar over 10 episode: -99.883 avegare return across last 100 episodes: -99.909 state values: tensor(0.6892) 1000
170 1000 -1000.0 -99.99568287525881 number episode from 10: 170 avegar over 10 episode: -99.883 avegare return across last 100 episodes: -99.909 state values: tensor(0.6865) 1000
171 1000 -1000.0 -99.99568287525881 number episode from 10: 171 avegar over 10 episode: -99.884 avegare return across last 100 episodes: -99.956 state values: tensor(0.6872) 1000
172 1000 -1000.0 -99.99568287525881 number episode from 10: 172 avegar over 10 episode: -99.885 avegare return across last 100 episodes: -99.956 state values: tensor(0.6891) 1000
173 1000 -1000.0 -99.99568287525881 number episode from 10: 173 avegar over 10 episode: -99.885 avegare return across last 100 episodes: -99.956 state values: tensor(0.6873) 1000
174 1000 -1000.0 -99.99568287525881 number episode from 10: 174 avegar over 10 episode: -99.886 avegare return across last 100 episodes: -99.956 state values: tensor(0.6854) 1000
175 1000 -1000.0 -99.99568287525881 number episode from 10: 175 avegar over 10 episode: -99.887 avegare return across last 100 episodes: -99.956 state values: tensor(0.6872) 1000
176 1000 -1000.0 -99.99568287525881 number episode from 10: 176 avegar over 10 episode: -99.887 avegare return across last 100 episodes: -99.956 state values: tensor(0.7778) 1000
177 1000 -1000.0 -99.99568287525881 number episode from 10: 177 avegar over 10 episode: -99.888 avegare return across last 100 episodes: -99.96 state values: tensor(0.6847) 1000
178 335 -335.0 -96.55022961048348 number episode from 10: 178 avegar over 10 episode: -99.869 avegare return across last 100 episodes: -99.926 state values: tensor(0.8177) 335
179 1000 -1000.0 -99.99568287525881 number episode from 10: 179 avegar over 10 episode: -99.87 avegare return across last 100 episodes: -99.926 state values: tensor(0.6847) 1000
180 1000 -1000.0 -99.99568287525881 number episode from 10: 180 avegar over 10 episode: -99.871 avegare return across last 100 episodes: -99.926 state values: tensor(0.6883) 1000
181 445 -445.0 -98.85801185395994 number episode from 10: 181 avegar over 10 episode: -99.865 avegare return across last 100 episodes: -99.914 state values: tensor(0.7579) 445
182 1000 -1000.0 -99.99568287525881 number episode from 10: 182 avegar over 10 episode: -99.866 avegare return across last 100 episodes: -99.914 state values: tensor(0.6893) 1000
183 1000 -1000.0 -99.99568287525881 number episode from 10: 183 avegar over 10 episode: -99.866 avegare return across last 100 episodes: -99.914 state values: tensor(0.6880) 1000
184 1000 -1000.0 -99.99568287525881 number episode from 10: 184 avegar over 10 episode: -99.867 avegare return across last 100 episodes: -99.914 state values: tensor(0.6874) 1000
185 1000 -1000.0 -99.99568287525881 number episode from 10: 185 avegar over 10 episode: -99.868 avegare return across last 100 episodes: -99.914 state values: tensor(0.6853) 1000
186 319 -319.0 -95.9483952033458 number episode from 10: 186 avegar over 10 episode: -99.847 avegare return across last 100 episodes: -99.875 state values: tensor(0.8115) 319
187 814 -814.0 -99.97200706714662 number episode from 10: 187 avegar over 10 episode: -99.848 avegare return across last 100 episodes: -99.875 state values: tensor(0.8595) 814
188 1000 -1000.0 -99.99568287525881 number episode from 10: 188 avegar over 10 episode: -99.848 avegare return across last 100 episodes: -99.875 state values: tensor(0.6847) 1000
189 1000 -1000.0 -99.99568287525881 number episode from 10: 189 avegar over 10 episode: -99.849 avegare return across last 100 episodes: -99.875 state values: tensor(0.6883) 1000
190 1000 -1000.0 -99.99568287525881 number episode from 10: 190 avegar over 10 episode: -99.85 avegare return across last 100 episodes: -99.875 state values: tensor(0.6888) 1000
191 1000 -1000.0 -99.99568287525881 number episode from 10: 191 avegar over 10 episode: -99.851 avegare return across last 100 episodes: -99.875 state values: tensor(0.6881) 1000
192 1000 -1000.0 -99.99568287525881 number episode from 10: 192 avegar over 10 episode: -99.851 avegare return across last 100 episodes: -99.875 state values: tensor(0.6856) 1000
193 1000 -1000.0 -99.99568287525881 number episode from 10: 193 avegar over 10 episode: -99.852 avegare return across last 100 episodes: -99.875 state values: tensor(0.6881) 1000
194 1000 -1000.0 -99.99568287525881 number episode from 10: 194 avegar over 10 episode: -99.853 avegare return across last 100 episodes: -99.875 state values: tensor(0.6875) 1000
195 1000 -1000.0 -99.99568287525881 number episode from 10: 195 avegar over 10 episode: -99.854 avegare return across last 100 episodes: -99.875 state values: tensor(0.6900) 1000
196 1000 -1000.0 -99.99568287525881 number episode from 10: 196 avegar over 10 episode: -99.854 avegare return across last 100 episodes: -99.875 state values: tensor(0.6847) 1000
197 1000 -1000.0 -99.99568287525881 number episode from 10: 197 avegar over 10 episode: -99.855 avegare return across last 100 episodes: -99.875 state values: tensor(0.6868) 1000
198 414 -414.0 -98.4405532005417 number episode from 10: 198 avegar over 10 episode: -99.848 avegare return across last 100 episodes: -99.86 state values: tensor(0.8110) 414
199 1000 -1000.0 -99.99568287525881 number episode from 10: 199 avegar over 10 episode: -99.849 avegare return across last 100 episodes: -99.86 state values: tensor(0.6868) 1000
200 1000 -1000.0 -99.99568287525881 number episode from 10: 200 avegar over 10 episode: -99.849 avegare return across last 100 episodes: -99.861 state values: tensor(0.6894) 1000
load offline data!!!!!
mem_cntr: 50000 ; mem_size: 50000
nn.learn_nn_feature_fqi FQI:  998
nn.learn_nn_feature_fqi FQI:  1998
nn.learn_nn_feature_fqi FQI:  2998
nn.learn_nn_feature_fqi FQI:  3998
nn.learn_nn_feature_fqi FQI:  4998
nn.learn_nn_feature_fqi FQI:  5998
nn.learn_nn_feature_fqi FQI:  6998
nn.learn_nn_feature_fqi FQI:  7998
nn.learn_nn_feature_fqi FQI:  8998
nn.learn_nn_feature_fqi FQI:  9998
nn.learn_nn_feature_fqi FQI:  10998
nn.learn_nn_feature_fqi FQI:  11998
nn.learn_nn_feature_fqi FQI:  12998
nn.learn_nn_feature_fqi FQI:  13998
nn.learn_nn_feature_fqi FQI:  14998
nn.learn_nn_feature_fqi FQI:  15998
nn.learn_nn_feature_fqi FQI:  16998
nn.learn_nn_feature_fqi FQI:  17998
nn.learn_nn_feature_fqi FQI:  18998
nn.learn_nn_feature_fqi FQI:  19998
nn.learn_nn_feature_fqi FQI:  20998
nn.learn_nn_feature_fqi FQI:  21998
nn.learn_nn_feature_fqi FQI:  22998
nn.learn_nn_feature_fqi FQI:  23998
nn.learn_nn_feature_fqi FQI:  24998
nn.learn_nn_feature_fqi FQI:  25998
nn.learn_nn_feature_fqi FQI:  26998
nn.learn_nn_feature_fqi FQI:  27998
nn.learn_nn_feature_fqi FQI:  28998
nn.learn_nn_feature_fqi FQI:  29998
nn.learn_nn_feature_fqi FQI:  30998
nn.learn_nn_feature_fqi FQI:  31998
nn.learn_nn_feature_fqi FQI:  32998
nn.learn_nn_feature_fqi FQI:  33998
nn.learn_nn_feature_fqi FQI:  34998
nn.learn_nn_feature_fqi FQI:  35998
nn.learn_nn_feature_fqi FQI:  36998
nn.learn_nn_feature_fqi FQI:  37998
nn.learn_nn_feature_fqi FQI:  38998
nn.learn_nn_feature_fqi FQI:  39998
nn.learn_nn_feature_fqi FQI:  40998
nn.learn_nn_feature_fqi FQI:  41998
nn.learn_nn_feature_fqi FQI:  42998
nn.learn_nn_feature_fqi FQI:  43998
nn.learn_nn_feature_fqi FQI:  44998
nn.learn_nn_feature_fqi FQI:  45998
nn.learn_nn_feature_fqi FQI:  46998
nn.learn_nn_feature_fqi FQI:  47998
nn.learn_nn_feature_fqi FQI:  48998
nn.learn_nn_feature_fqi FQI:  49998
nn.learn_nn_feature_fqi FQI:  50998
nn.learn_nn_feature_fqi FQI:  51998
nn.learn_nn_feature_fqi FQI:  52998
nn.learn_nn_feature_fqi FQI:  53998
nn.learn_nn_feature_fqi FQI:  54998
nn.learn_nn_feature_fqi FQI:  55998
nn.learn_nn_feature_fqi FQI:  56998
nn.learn_nn_feature_fqi FQI:  57998
nn.learn_nn_feature_fqi FQI:  58998
nn.learn_nn_feature_fqi FQI:  59998
nn.learn_nn_feature_fqi FQI:  60998
nn.learn_nn_feature_fqi FQI:  61998
nn.learn_nn_feature_fqi FQI:  62998
nn.learn_nn_feature_fqi FQI:  63998
nn.learn_nn_feature_fqi FQI:  64998
nn.learn_nn_feature_fqi FQI:  65998
nn.learn_nn_feature_fqi FQI:  66998
nn.learn_nn_feature_fqi FQI:  67998
nn.learn_nn_feature_fqi FQI:  68998
nn.learn_nn_feature_fqi FQI:  69998
nn.learn_nn_feature_fqi FQI:  70998
nn.learn_nn_feature_fqi FQI:  71998
nn.learn_nn_feature_fqi FQI:  72998
nn.learn_nn_feature_fqi FQI:  73998
nn.learn_nn_feature_fqi FQI:  74998
nn.learn_nn_feature_fqi FQI:  75998
nn.learn_nn_feature_fqi FQI:  76998
nn.learn_nn_feature_fqi FQI:  77998
nn.learn_nn_feature_fqi FQI:  78998
nn.learn_nn_feature_fqi FQI:  79998
nn.learn_nn_feature_fqi FQI:  80998
nn.learn_nn_feature_fqi FQI:  81998
nn.learn_nn_feature_fqi FQI:  82998
nn.learn_nn_feature_fqi FQI:  83998
nn.learn_nn_feature_fqi FQI:  84998
nn.learn_nn_feature_fqi FQI:  85998
nn.learn_nn_feature_fqi FQI:  86998
nn.learn_nn_feature_fqi FQI:  87998
nn.learn_nn_feature_fqi FQI:  88998
nn.learn_nn_feature_fqi FQI:  89998
nn.learn_nn_feature_fqi FQI:  90998
nn.learn_nn_feature_fqi FQI:  91998
nn.learn_nn_feature_fqi FQI:  92998
nn.learn_nn_feature_fqi FQI:  93998
nn.learn_nn_feature_fqi FQI:  94998
nn.learn_nn_feature_fqi FQI:  95998
nn.learn_nn_feature_fqi FQI:  96998
nn.learn_nn_feature_fqi FQI:  97998
nn.learn_nn_feature_fqi FQI:  98998
nn.learn_nn_feature_fqi FQI:  99998
nn.learn_nn_feature_fqi FQI:  100998
nn.learn_nn_feature_fqi FQI:  101998
nn.learn_nn_feature_fqi FQI:  102998
nn.learn_nn_feature_fqi FQI:  103998
nn.learn_nn_feature_fqi FQI:  104998
nn.learn_nn_feature_fqi FQI:  105998
nn.learn_nn_feature_fqi FQI:  106998
nn.learn_nn_feature_fqi FQI:  107998
nn.learn_nn_feature_fqi FQI:  108998
nn.learn_nn_feature_fqi FQI:  109998
nn.learn_nn_feature_fqi FQI:  110998
nn.learn_nn_feature_fqi FQI:  111998
nn.learn_nn_feature_fqi FQI:  112998
nn.learn_nn_feature_fqi FQI:  113998
nn.learn_nn_feature_fqi FQI:  114998
nn.learn_nn_feature_fqi FQI:  115998
nn.learn_nn_feature_fqi FQI:  116998
nn.learn_nn_feature_fqi FQI:  117998
nn.learn_nn_feature_fqi FQI:  118998
nn.learn_nn_feature_fqi FQI:  119998
nn.learn_nn_feature_fqi FQI:  120998
nn.learn_nn_feature_fqi FQI:  121998
nn.learn_nn_feature_fqi FQI:  122998
nn.learn_nn_feature_fqi FQI:  123998
nn.learn_nn_feature_fqi FQI:  124998
nn.learn_nn_feature_fqi FQI:  125998
nn.learn_nn_feature_fqi FQI:  126998
nn.learn_nn_feature_fqi FQI:  127998
nn.learn_nn_feature_fqi FQI:  128998
nn.learn_nn_feature_fqi FQI:  129998
nn.learn_nn_feature_fqi FQI:  130998
nn.learn_nn_feature_fqi FQI:  131998
nn.learn_nn_feature_fqi FQI:  132998
nn.learn_nn_feature_fqi FQI:  133998
nn.learn_nn_feature_fqi FQI:  134998
nn.learn_nn_feature_fqi FQI:  135998
nn.learn_nn_feature_fqi FQI:  136998
nn.learn_nn_feature_fqi FQI:  137998
nn.learn_nn_feature_fqi FQI:  138998
nn.learn_nn_feature_fqi FQI:  139998
nn.learn_nn_feature_fqi FQI:  140998
nn.learn_nn_feature_fqi FQI:  141998
nn.learn_nn_feature_fqi FQI:  142998
nn.learn_nn_feature_fqi FQI:  143998
nn.learn_nn_feature_fqi FQI:  144998
nn.learn_nn_feature_fqi FQI:  145998
nn.learn_nn_feature_fqi FQI:  146998
nn.learn_nn_feature_fqi FQI:  147998
nn.learn_nn_feature_fqi FQI:  148998
nn.learn_nn_feature_fqi FQI:  149998
nn.learn_nn_feature_fqi FQI:  150998
nn.learn_nn_feature_fqi FQI:  151998
nn.learn_nn_feature_fqi FQI:  152998
nn.learn_nn_feature_fqi FQI:  153998
nn.learn_nn_feature_fqi FQI:  154998
nn.learn_nn_feature_fqi FQI:  155998
0 1001 -1000.0 -98.99572604650622 number episode from 10: 0 avegar over 10 episode: -98.996 avegare return across last 100 episodes: -98.996 state values: tensor(0.9564) 1000
1 1000 -1000.0 -99.99568287525881 number episode from 10: 1 avegar over 10 episode: -99.496 avegare return across last 100 episodes: -99.496 state values: tensor(0.9506) 1000
2 1000 -1000.0 -99.99568287525881 number episode from 10: 2 avegar over 10 episode: -99.662 avegare return across last 100 episodes: -99.662 state values: tensor(0.9575) 1000
3 1000 -1000.0 -99.99568287525881 number episode from 10: 3 avegar over 10 episode: -99.746 avegare return across last 100 episodes: -99.746 state values: tensor(0.9584) 1000
4 1000 -1000.0 -99.99568287525881 number episode from 10: 4 avegar over 10 episode: -99.796 avegare return across last 100 episodes: -99.796 state values: tensor(0.9524) 1000
5 1000 -1000.0 -99.99568287525881 number episode from 10: 5 avegar over 10 episode: -99.829 avegare return across last 100 episodes: -99.829 state values: tensor(0.9466) 1000
6 1000 -1000.0 -99.99568287525881 number episode from 10: 6 avegar over 10 episode: -99.853 avegare return across last 100 episodes: -99.853 state values: tensor(0.9534) 1000
7 1000 -1000.0 -99.99568287525881 number episode from 10: 7 avegar over 10 episode: -99.871 avegare return across last 100 episodes: -99.871 state values: tensor(0.9537) 1000
8 1000 -1000.0 -99.99568287525881 number episode from 10: 8 avegar over 10 episode: -99.885 avegare return across last 100 episodes: -99.885 state values: tensor(0.9486) 1000
9 1000 -1000.0 -99.99568287525881 number episode from 10: 9 avegar over 10 episode: -99.896 avegare return across last 100 episodes: -99.896 state values: tensor(0.9459) 1000
10 1000 -1000.0 -99.99568287525881 number episode from 10: 10 avegar over 10 episode: -99.905 avegare return across last 100 episodes: -99.905 state values: tensor(0.9569) 1000
11 1000 -1000.0 -99.99568287525881 number episode from 10: 11 avegar over 10 episode: -99.912 avegare return across last 100 episodes: -99.912 state values: tensor(0.9409) 1000
12 1000 -1000.0 -99.99568287525881 number episode from 10: 12 avegar over 10 episode: -99.919 avegare return across last 100 episodes: -99.919 state values: tensor(0.9469) 1000
13 1000 -1000.0 -99.99568287525881 number episode from 10: 13 avegar over 10 episode: -99.924 avegare return across last 100 episodes: -99.924 state values: tensor(0.9587) 1000
14 1000 -1000.0 -99.99568287525881 number episode from 10: 14 avegar over 10 episode: -99.929 avegare return across last 100 episodes: -99.929 state values: tensor(0.9479) 1000
15 1000 -1000.0 -99.99568287525881 number episode from 10: 15 avegar over 10 episode: -99.933 avegare return across last 100 episodes: -99.933 state values: tensor(0.9517) 1000
16 1000 -1000.0 -99.99568287525881 number episode from 10: 16 avegar over 10 episode: -99.937 avegare return across last 100 episodes: -99.937 state values: tensor(0.9482) 1000
17 1000 -1000.0 -99.99568287525881 number episode from 10: 17 avegar over 10 episode: -99.94 avegare return across last 100 episodes: -99.94 state values: tensor(0.9521) 1000
18 1000 -1000.0 -99.99568287525881 number episode from 10: 18 avegar over 10 episode: -99.943 avegare return across last 100 episodes: -99.943 state values: tensor(0.9555) 1000
19 1000 -1000.0 -99.99568287525881 number episode from 10: 19 avegar over 10 episode: -99.946 avegare return across last 100 episodes: -99.946 state values: tensor(0.9585) 1000
20 1000 -1000.0 -99.99568287525881 number episode from 10: 20 avegar over 10 episode: -99.948 avegare return across last 100 episodes: -99.948 state values: tensor(0.9589) 1000
21 1000 -1000.0 -99.99568287525881 number episode from 10: 21 avegar over 10 episode: -99.95 avegare return across last 100 episodes: -99.95 state values: tensor(0.7352) 1000
22 1000 -1000.0 -99.99568287525881 number episode from 10: 22 avegar over 10 episode: -99.952 avegare return across last 100 episodes: -99.952 state values: tensor(0.9552) 1000
23 1000 -1000.0 -99.99568287525881 number episode from 10: 23 avegar over 10 episode: -99.954 avegare return across last 100 episodes: -99.954 state values: tensor(0.9579) 1000
24 1000 -1000.0 -99.99568287525881 number episode from 10: 24 avegar over 10 episode: -99.956 avegare return across last 100 episodes: -99.956 state values: tensor(0.9574) 1000
25 1000 -1000.0 -99.99568287525881 number episode from 10: 25 avegar over 10 episode: -99.957 avegare return across last 100 episodes: -99.957 state values: tensor(0.9470) 1000
26 1000 -1000.0 -99.99568287525881 number episode from 10: 26 avegar over 10 episode: -99.959 avegare return across last 100 episodes: -99.959 state values: tensor(0.9506) 1000
27 1000 -1000.0 -99.99568287525881 number episode from 10: 27 avegar over 10 episode: -99.96 avegare return across last 100 episodes: -99.96 state values: tensor(0.8925) 1000
28 1000 -1000.0 -99.99568287525881 number episode from 10: 28 avegar over 10 episode: -99.961 avegare return across last 100 episodes: -99.961 state values: tensor(0.9484) 1000
29 1000 -1000.0 -99.99568287525881 number episode from 10: 29 avegar over 10 episode: -99.962 avegare return across last 100 episodes: -99.962 state values: tensor(0.9480) 1000
30 1000 -1000.0 -99.99568287525881 number episode from 10: 30 avegar over 10 episode: -99.963 avegare return across last 100 episodes: -99.963 state values: tensor(0.9503) 1000
31 1000 -1000.0 -99.99568287525881 number episode from 10: 31 avegar over 10 episode: -99.964 avegare return across last 100 episodes: -99.964 state values: tensor(0.9559) 1000
32 1000 -1000.0 -99.99568287525881 number episode from 10: 32 avegar over 10 episode: -99.965 avegare return across last 100 episodes: -99.965 state values: tensor(0.9472) 1000
33 1000 -1000.0 -99.99568287525881 number episode from 10: 33 avegar over 10 episode: -99.966 avegare return across last 100 episodes: -99.966 state values: tensor(0.9573) 1000
34 1000 -1000.0 -99.99568287525881 number episode from 10: 34 avegar over 10 episode: -99.967 avegare return across last 100 episodes: -99.967 state values: tensor(0.9496) 1000
35 1000 -1000.0 -99.99568287525881 number episode from 10: 35 avegar over 10 episode: -99.968 avegare return across last 100 episodes: -99.968 state values: tensor(0.9534) 1000
36 1000 -1000.0 -99.99568287525881 number episode from 10: 36 avegar over 10 episode: -99.969 avegare return across last 100 episodes: -99.969 state values: tensor(0.9500) 1000
37 1000 -1000.0 -99.99568287525881 number episode from 10: 37 avegar over 10 episode: -99.969 avegare return across last 100 episodes: -99.969 state values: tensor(0.9445) 1000
38 1000 -1000.0 -99.99568287525881 number episode from 10: 38 avegar over 10 episode: -99.97 avegare return across last 100 episodes: -99.97 state values: tensor(0.9578) 1000
39 1000 -1000.0 -99.99568287525881 number episode from 10: 39 avegar over 10 episode: -99.971 avegare return across last 100 episodes: -99.971 state values: tensor(0.9524) 1000
40 1000 -1000.0 -99.99568287525881 number episode from 10: 40 avegar over 10 episode: -99.971 avegare return across last 100 episodes: -99.971 state values: tensor(0.9554) 1000
41 1000 -1000.0 -99.99568287525881 number episode from 10: 41 avegar over 10 episode: -99.972 avegare return across last 100 episodes: -99.972 state values: tensor(0.9586) 1000
42 1000 -1000.0 -99.99568287525881 number episode from 10: 42 avegar over 10 episode: -99.972 avegare return across last 100 episodes: -99.972 state values: tensor(0.9504) 1000
43 1000 -1000.0 -99.99568287525881 number episode from 10: 43 avegar over 10 episode: -99.973 avegare return across last 100 episodes: -99.973 state values: tensor(0.9480) 1000
44 1000 -1000.0 -99.99568287525881 number episode from 10: 44 avegar over 10 episode: -99.973 avegare return across last 100 episodes: -99.973 state values: tensor(0.9483) 1000
45 1000 -1000.0 -99.99568287525881 number episode from 10: 45 avegar over 10 episode: -99.974 avegare return across last 100 episodes: -99.974 state values: tensor(0.7356) 1000
46 1000 -1000.0 -99.99568287525881 number episode from 10: 46 avegar over 10 episode: -99.974 avegare return across last 100 episodes: -99.974 state values: tensor(0.8379) 1000
47 1000 -1000.0 -99.99568287525881 number episode from 10: 47 avegar over 10 episode: -99.975 avegare return across last 100 episodes: -99.975 state values: tensor(0.7653) 1000
48 1000 -1000.0 -99.99568287525881 number episode from 10: 48 avegar over 10 episode: -99.975 avegare return across last 100 episodes: -99.975 state values: tensor(0.9581) 1000
49 1000 -1000.0 -99.99568287525881 number episode from 10: 49 avegar over 10 episode: -99.976 avegare return across last 100 episodes: -99.976 state values: tensor(0.9475) 1000
50 1000 -1000.0 -99.99568287525881 number episode from 10: 50 avegar over 10 episode: -99.976 avegare return across last 100 episodes: -99.976 state values: tensor(0.9469) 1000
51 1000 -1000.0 -99.99568287525881 number episode from 10: 51 avegar over 10 episode: -99.976 avegare return across last 100 episodes: -99.976 state values: tensor(0.9461) 1000
52 1000 -1000.0 -99.99568287525881 number episode from 10: 52 avegar over 10 episode: -99.977 avegare return across last 100 episodes: -99.977 state values: tensor(0.9449) 1000
53 1000 -1000.0 -99.99568287525881 number episode from 10: 53 avegar over 10 episode: -99.977 avegare return across last 100 episodes: -99.977 state values: tensor(0.9481) 1000
54 1000 -1000.0 -99.99568287525881 number episode from 10: 54 avegar over 10 episode: -99.978 avegare return across last 100 episodes: -99.978 state values: tensor(0.9569) 1000
55 1000 -1000.0 -99.99568287525881 number episode from 10: 55 avegar over 10 episode: -99.978 avegare return across last 100 episodes: -99.978 state values: tensor(0.9468) 1000
56 1000 -1000.0 -99.99568287525881 number episode from 10: 56 avegar over 10 episode: -99.978 avegare return across last 100 episodes: -99.978 state values: tensor(0.9254) 1000
57 1000 -1000.0 -99.99568287525881 number episode from 10: 57 avegar over 10 episode: -99.978 avegare return across last 100 episodes: -99.978 state values: tensor(0.9462) 1000
58 1000 -1000.0 -99.99568287525881 number episode from 10: 58 avegar over 10 episode: -99.979 avegare return across last 100 episodes: -99.979 state values: tensor(0.9495) 1000
59 1000 -1000.0 -99.99568287525881 number episode from 10: 59 avegar over 10 episode: -99.979 avegare return across last 100 episodes: -99.979 state values: tensor(0.9491) 1000
60 1000 -1000.0 -99.99568287525881 number episode from 10: 60 avegar over 10 episode: -99.979 avegare return across last 100 episodes: -99.979 state values: tensor(0.9425) 1000
61 1000 -1000.0 -99.99568287525881 number episode from 10: 61 avegar over 10 episode: -99.98 avegare return across last 100 episodes: -99.98 state values: tensor(0.9581) 1000
62 1000 -1000.0 -99.99568287525881 number episode from 10: 62 avegar over 10 episode: -99.98 avegare return across last 100 episodes: -99.98 state values: tensor(0.9507) 1000
63 1000 -1000.0 -99.99568287525881 number episode from 10: 63 avegar over 10 episode: -99.98 avegare return across last 100 episodes: -99.98 state values: tensor(0.9530) 1000
64 1000 -1000.0 -99.99568287525881 number episode from 10: 64 avegar over 10 episode: -99.98 avegare return across last 100 episodes: -99.98 state values: tensor(0.9308) 1000
65 1000 -1000.0 -99.99568287525881 number episode from 10: 65 avegar over 10 episode: -99.981 avegare return across last 100 episodes: -99.981 state values: tensor(0.9472) 1000
66 1000 -1000.0 -99.99568287525881 number episode from 10: 66 avegar over 10 episode: -99.981 avegare return across last 100 episodes: -99.981 state values: tensor(0.7377) 1000
67 1000 -1000.0 -99.99568287525881 number episode from 10: 67 avegar over 10 episode: -99.981 avegare return across last 100 episodes: -99.981 state values: tensor(0.9522) 1000
68 1000 -1000.0 -99.99568287525881 number episode from 10: 68 avegar over 10 episode: -99.981 avegare return across last 100 episodes: -99.981 state values: tensor(0.8374) 1000
69 1000 -1000.0 -99.99568287525881 number episode from 10: 69 avegar over 10 episode: -99.981 avegare return across last 100 episodes: -99.981 state values: tensor(0.8007) 1000
70 1000 -1000.0 -99.99568287525881 number episode from 10: 70 avegar over 10 episode: -99.982 avegare return across last 100 episodes: -99.982 state values: tensor(0.9503) 1000
71 1000 -1000.0 -99.99568287525881 number episode from 10: 71 avegar over 10 episode: -99.982 avegare return across last 100 episodes: -99.982 state values: tensor(0.9468) 1000
72 1000 -1000.0 -99.99568287525881 number episode from 10: 72 avegar over 10 episode: -99.982 avegare return across last 100 episodes: -99.982 state values: tensor(0.9461) 1000
73 1000 -1000.0 -99.99568287525881 number episode from 10: 73 avegar over 10 episode: -99.982 avegare return across last 100 episodes: -99.982 state values: tensor(0.9455) 1000
74 1000 -1000.0 -99.99568287525881 number episode from 10: 74 avegar over 10 episode: -99.982 avegare return across last 100 episodes: -99.982 state values: tensor(0.9497) 1000
75 1000 -1000.0 -99.99568287525881 number episode from 10: 75 avegar over 10 episode: -99.983 avegare return across last 100 episodes: -99.983 state values: tensor(0.9511) 1000
76 1000 -1000.0 -99.99568287525881 number episode from 10: 76 avegar over 10 episode: -99.983 avegare return across last 100 episodes: -99.983 state values: tensor(0.9507) 1000
77 1000 -1000.0 -99.99568287525881 number episode from 10: 77 avegar over 10 episode: -99.983 avegare return across last 100 episodes: -99.983 state values: tensor(0.9591) 1000
78 1000 -1000.0 -99.99568287525881 number episode from 10: 78 avegar over 10 episode: -99.983 avegare return across last 100 episodes: -99.983 state values: tensor(0.9569) 1000
79 1000 -1000.0 -99.99568287525881 number episode from 10: 79 avegar over 10 episode: -99.983 avegare return across last 100 episodes: -99.983 state values: tensor(0.9581) 1000
80 1000 -1000.0 -99.99568287525881 number episode from 10: 80 avegar over 10 episode: -99.983 avegare return across last 100 episodes: -99.983 state values: tensor(0.9510) 1000
81 1000 -1000.0 -99.99568287525881 number episode from 10: 81 avegar over 10 episode: -99.983 avegare return across last 100 episodes: -99.983 state values: tensor(0.7370) 1000
82 1000 -1000.0 -99.99568287525881 number episode from 10: 82 avegar over 10 episode: -99.984 avegare return across last 100 episodes: -99.984 state values: tensor(0.9514) 1000
83 1000 -1000.0 -99.99568287525881 number episode from 10: 83 avegar over 10 episode: -99.984 avegare return across last 100 episodes: -99.984 state values: tensor(0.9546) 1000
84 1000 -1000.0 -99.99568287525881 number episode from 10: 84 avegar over 10 episode: -99.984 avegare return across last 100 episodes: -99.984 state values: tensor(0.9573) 1000
85 1000 -1000.0 -99.99568287525881 number episode from 10: 85 avegar over 10 episode: -99.984 avegare return across last 100 episodes: -99.984 state values: tensor(0.9584) 1000
86 1000 -1000.0 -99.99568287525881 number episode from 10: 86 avegar over 10 episode: -99.984 avegare return across last 100 episodes: -99.984 state values: tensor(0.9494) 1000
87 1000 -1000.0 -99.99568287525881 number episode from 10: 87 avegar over 10 episode: -99.984 avegare return across last 100 episodes: -99.984 state values: tensor(0.7363) 1000
88 1000 -1000.0 -99.99568287525881 number episode from 10: 88 avegar over 10 episode: -99.984 avegare return across last 100 episodes: -99.984 state values: tensor(0.9488) 1000
89 1000 -1000.0 -99.99568287525881 number episode from 10: 89 avegar over 10 episode: -99.985 avegare return across last 100 episodes: -99.985 state values: tensor(0.9489) 1000
90 1000 -1000.0 -99.99568287525881 number episode from 10: 90 avegar over 10 episode: -99.985 avegare return across last 100 episodes: -99.985 state values: tensor(0.9485) 1000
91 1000 -1000.0 -99.99568287525881 number episode from 10: 91 avegar over 10 episode: -99.985 avegare return across last 100 episodes: -99.985 state values: tensor(0.9536) 1000
92 1000 -1000.0 -99.99568287525881 number episode from 10: 92 avegar over 10 episode: -99.985 avegare return across last 100 episodes: -99.985 state values: tensor(0.9480) 1000
93 1000 -1000.0 -99.99568287525881 number episode from 10: 93 avegar over 10 episode: -99.985 avegare return across last 100 episodes: -99.985 state values: tensor(0.8922) 1000
94 1000 -1000.0 -99.99568287525881 number episode from 10: 94 avegar over 10 episode: -99.985 avegare return across last 100 episodes: -99.985 state values: tensor(0.9518) 1000
95 1000 -1000.0 -99.99568287525881 number episode from 10: 95 avegar over 10 episode: -99.985 avegare return across last 100 episodes: -99.985 state values: tensor(0.9483) 1000
96 1000 -1000.0 -99.99568287525881 number episode from 10: 96 avegar over 10 episode: -99.985 avegare return across last 100 episodes: -99.985 state values: tensor(0.9480) 1000
97 1000 -1000.0 -99.99568287525881 number episode from 10: 97 avegar over 10 episode: -99.985 avegare return across last 100 episodes: -99.985 state values: tensor(0.9498) 1000
98 1000 -1000.0 -99.99568287525881 number episode from 10: 98 avegar over 10 episode: -99.986 avegare return across last 100 episodes: -99.986 state values: tensor(0.9472) 1000
99 1000 -1000.0 -99.99568287525881 number episode from 10: 99 avegar over 10 episode: -99.986 avegare return across last 100 episodes: -99.986 state values: tensor(0.9580) 1000
100 1000 -1000.0 -99.99568287525881 number episode from 10: 100 avegar over 10 episode: -99.986 avegare return across last 100 episodes: -99.996 state values: tensor(0.9477) 1000
101 1000 -1000.0 -99.99568287525881 number episode from 10: 101 avegar over 10 episode: -99.986 avegare return across last 100 episodes: -99.996 state values: tensor(0.9488) 1000
102 1000 -1000.0 -99.99568287525881 number episode from 10: 102 avegar over 10 episode: -99.986 avegare return across last 100 episodes: -99.996 state values: tensor(0.9472) 1000
103 1000 -1000.0 -99.99568287525881 number episode from 10: 103 avegar over 10 episode: -99.986 avegare return across last 100 episodes: -99.996 state values: tensor(0.9413) 1000
104 1000 -1000.0 -99.99568287525881 number episode from 10: 104 avegar over 10 episode: -99.986 avegare return across last 100 episodes: -99.996 state values: tensor(0.9536) 1000
105 1000 -1000.0 -99.99568287525881 number episode from 10: 105 avegar over 10 episode: -99.986 avegare return across last 100 episodes: -99.996 state values: tensor(0.9470) 1000
106 1000 -1000.0 -99.99568287525881 number episode from 10: 106 avegar over 10 episode: -99.986 avegare return across last 100 episodes: -99.996 state values: tensor(0.9481) 1000
107 1000 -1000.0 -99.99568287525881 number episode from 10: 107 avegar over 10 episode: -99.986 avegare return across last 100 episodes: -99.996 state values: tensor(0.9501) 1000
108 1000 -1000.0 -99.99568287525881 number episode from 10: 108 avegar over 10 episode: -99.987 avegare return across last 100 episodes: -99.996 state values: tensor(0.9480) 1000
109 1000 -1000.0 -99.99568287525881 number episode from 10: 109 avegar over 10 episode: -99.987 avegare return across last 100 episodes: -99.996 state values: tensor(0.9590) 1000
110 1000 -1000.0 -99.99568287525881 number episode from 10: 110 avegar over 10 episode: -99.987 avegare return across last 100 episodes: -99.996 state values: tensor(0.9488) 1000
111 1000 -1000.0 -99.99568287525881 number episode from 10: 111 avegar over 10 episode: -99.987 avegare return across last 100 episodes: -99.996 state values: tensor(0.9567) 1000
112 1000 -1000.0 -99.99568287525881 number episode from 10: 112 avegar over 10 episode: -99.987 avegare return across last 100 episodes: -99.996 state values: tensor(0.9537) 1000
113 1000 -1000.0 -99.99568287525881 number episode from 10: 113 avegar over 10 episode: -99.987 avegare return across last 100 episodes: -99.996 state values: tensor(0.9491) 1000
114 1000 -1000.0 -99.99568287525881 number episode from 10: 114 avegar over 10 episode: -99.987 avegare return across last 100 episodes: -99.996 state values: tensor(0.9507) 1000
115 1000 -1000.0 -99.99568287525881 number episode from 10: 115 avegar over 10 episode: -99.987 avegare return across last 100 episodes: -99.996 state values: tensor(0.7361) 1000
116 1000 -1000.0 -99.99568287525881 number episode from 10: 116 avegar over 10 episode: -99.987 avegare return across last 100 episodes: -99.996 state values: tensor(0.9494) 1000
117 1000 -1000.0 -99.99568287525881 number episode from 10: 117 avegar over 10 episode: -99.987 avegare return across last 100 episodes: -99.996 state values: tensor(0.9582) 1000
118 1000 -1000.0 -99.99568287525881 number episode from 10: 118 avegar over 10 episode: -99.987 avegare return across last 100 episodes: -99.996 state values: tensor(0.9478) 1000
119 1000 -1000.0 -99.99568287525881 number episode from 10: 119 avegar over 10 episode: -99.987 avegare return across last 100 episodes: -99.996 state values: tensor(0.9387) 1000
120 1000 -1000.0 -99.99568287525881 number episode from 10: 120 avegar over 10 episode: -99.987 avegare return across last 100 episodes: -99.996 state values: tensor(0.9351) 1000
121 1000 -1000.0 -99.99568287525881 number episode from 10: 121 avegar over 10 episode: -99.987 avegare return across last 100 episodes: -99.996 state values: tensor(0.9580) 1000
122 1000 -1000.0 -99.99568287525881 number episode from 10: 122 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.9563) 1000
123 1000 -1000.0 -99.99568287525881 number episode from 10: 123 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.9574) 1000
124 1000 -1000.0 -99.99568287525881 number episode from 10: 124 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.9478) 1000
125 1000 -1000.0 -99.99568287525881 number episode from 10: 125 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.9435) 1000
126 1000 -1000.0 -99.99568287525881 number episode from 10: 126 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.9508) 1000
127 1000 -1000.0 -99.99568287525881 number episode from 10: 127 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.9472) 1000
128 1000 -1000.0 -99.99568287525881 number episode from 10: 128 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.9506) 1000
129 1000 -1000.0 -99.99568287525881 number episode from 10: 129 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.9585) 1000
130 1000 -1000.0 -99.99568287525881 number episode from 10: 130 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.9550) 1000
131 1000 -1000.0 -99.99568287525881 number episode from 10: 131 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.9499) 1000
132 1000 -1000.0 -99.99568287525881 number episode from 10: 132 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.9579) 1000
133 1000 -1000.0 -99.99568287525881 number episode from 10: 133 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.9499) 1000
134 1000 -1000.0 -99.99568287525881 number episode from 10: 134 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.9484) 1000
135 1000 -1000.0 -99.99568287525881 number episode from 10: 135 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.9538) 1000
136 1000 -1000.0 -99.99568287525881 number episode from 10: 136 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.9482) 1000
137 1000 -1000.0 -99.99568287525881 number episode from 10: 137 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.9536) 1000
138 1000 -1000.0 -99.99568287525881 number episode from 10: 138 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.9512) 1000
139 1000 -1000.0 -99.99568287525881 number episode from 10: 139 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.9534) 1000
140 1000 -1000.0 -99.99568287525881 number episode from 10: 140 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.9489) 1000
141 1000 -1000.0 -99.99568287525881 number episode from 10: 141 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.9581) 1000
142 1000 -1000.0 -99.99568287525881 number episode from 10: 142 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.9538) 1000
143 1000 -1000.0 -99.99568287525881 number episode from 10: 143 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.9507) 1000
144 1000 -1000.0 -99.99568287525881 number episode from 10: 144 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.9490) 1000
145 1000 -1000.0 -99.99568287525881 number episode from 10: 145 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.9531) 1000
146 1000 -1000.0 -99.99568287525881 number episode from 10: 146 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.7372) 1000
147 1000 -1000.0 -99.99568287525881 number episode from 10: 147 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.9582) 1000
148 1000 -1000.0 -99.99568287525881 number episode from 10: 148 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.7363) 1000
149 1000 -1000.0 -99.99568287525881 number episode from 10: 149 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.9523) 1000
150 1000 -1000.0 -99.99568287525881 number episode from 10: 150 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.9551) 1000
151 1000 -1000.0 -99.99568287525881 number episode from 10: 151 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.9584) 1000
152 1000 -1000.0 -99.99568287525881 number episode from 10: 152 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.9570) 1000
153 1000 -1000.0 -99.99568287525881 number episode from 10: 153 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.9571) 1000
154 1000 -1000.0 -99.99568287525881 number episode from 10: 154 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.9533) 1000
155 1000 -1000.0 -99.99568287525881 number episode from 10: 155 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.9585) 1000
156 1000 -1000.0 -99.99568287525881 number episode from 10: 156 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.9561) 1000
157 1000 -1000.0 -99.99568287525881 number episode from 10: 157 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.9580) 1000
158 1000 -1000.0 -99.99568287525881 number episode from 10: 158 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.9511) 1000
159 1000 -1000.0 -99.99568287525881 number episode from 10: 159 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.9544) 1000
160 1000 -1000.0 -99.99568287525881 number episode from 10: 160 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.9476) 1000
161 1000 -1000.0 -99.99568287525881 number episode from 10: 161 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.9464) 1000
162 1000 -1000.0 -99.99568287525881 number episode from 10: 162 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.9475) 1000
163 1000 -1000.0 -99.99568287525881 number episode from 10: 163 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.9491) 1000
164 1000 -1000.0 -99.99568287525881 number episode from 10: 164 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.9512) 1000
165 1000 -1000.0 -99.99568287525881 number episode from 10: 165 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.9467) 1000
166 1000 -1000.0 -99.99568287525881 number episode from 10: 166 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.9459) 1000
167 1000 -1000.0 -99.99568287525881 number episode from 10: 167 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.9582) 1000
168 1000 -1000.0 -99.99568287525881 number episode from 10: 168 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.9478) 1000
169 1000 -1000.0 -99.99568287525881 number episode from 10: 169 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.8863) 1000
170 1000 -1000.0 -99.99568287525881 number episode from 10: 170 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.9493) 1000
171 1000 -1000.0 -99.99568287525881 number episode from 10: 171 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.9475) 1000
172 1000 -1000.0 -99.99568287525881 number episode from 10: 172 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.9497) 1000
173 1000 -1000.0 -99.99568287525881 number episode from 10: 173 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.9534) 1000
174 1000 -1000.0 -99.99568287525881 number episode from 10: 174 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.9503) 1000
175 1000 -1000.0 -99.99568287525881 number episode from 10: 175 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.9511) 1000
176 1000 -1000.0 -99.99568287525881 number episode from 10: 176 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.9530) 1000
177 1000 -1000.0 -99.99568287525881 number episode from 10: 177 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.9480) 1000
178 1000 -1000.0 -99.99568287525881 number episode from 10: 178 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.9583) 1000
179 1000 -1000.0 -99.99568287525881 number episode from 10: 179 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.8854) 1000
180 1000 -1000.0 -99.99568287525881 number episode from 10: 180 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.9456) 1000
181 1000 -1000.0 -99.99568287525881 number episode from 10: 181 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.9573) 1000
182 1000 -1000.0 -99.99568287525881 number episode from 10: 182 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.9580) 1000
183 1000 -1000.0 -99.99568287525881 number episode from 10: 183 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.7357) 1000
184 1000 -1000.0 -99.99568287525881 number episode from 10: 184 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.9532) 1000
185 1000 -1000.0 -99.99568287525881 number episode from 10: 185 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.9588) 1000
186 1000 -1000.0 -99.99568287525881 number episode from 10: 186 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.8871) 1000
187 1000 -1000.0 -99.99568287525881 number episode from 10: 187 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.9586) 1000
188 1000 -1000.0 -99.99568287525881 number episode from 10: 188 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.9551) 1000
189 1000 -1000.0 -99.99568287525881 number episode from 10: 189 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.9489) 1000
190 1000 -1000.0 -99.99568287525881 number episode from 10: 190 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.9454) 1000
191 1000 -1000.0 -99.99568287525881 number episode from 10: 191 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.9483) 1000
192 1000 -1000.0 -99.99568287525881 number episode from 10: 192 avegar over 10 episode: -99.991 avegare return across last 100 episodes: -99.996 state values: tensor(0.9479) 1000
193 1000 -1000.0 -99.99568287525881 number episode from 10: 193 avegar over 10 episode: -99.991 avegare return across last 100 episodes: -99.996 state values: tensor(0.7362) 1000
194 1000 -1000.0 -99.99568287525881 number episode from 10: 194 avegar over 10 episode: -99.991 avegare return across last 100 episodes: -99.996 state values: tensor(0.9565) 1000
195 1000 -1000.0 -99.99568287525881 number episode from 10: 195 avegar over 10 episode: -99.991 avegare return across last 100 episodes: -99.996 state values: tensor(0.9489) 1000
196 1000 -1000.0 -99.99568287525881 number episode from 10: 196 avegar over 10 episode: -99.991 avegare return across last 100 episodes: -99.996 state values: tensor(0.9512) 1000
197 1000 -1000.0 -99.99568287525881 number episode from 10: 197 avegar over 10 episode: -99.991 avegare return across last 100 episodes: -99.996 state values: tensor(0.9546) 1000
198 1000 -1000.0 -99.99568287525881 number episode from 10: 198 avegar over 10 episode: -99.991 avegare return across last 100 episodes: -99.996 state values: tensor(0.9583) 1000
199 1000 -1000.0 -99.99568287525881 number episode from 10: 199 avegar over 10 episode: -99.991 avegare return across last 100 episodes: -99.996 state values: tensor(0.9545) 1000
200 1000 -1000.0 -99.99568287525881 number episode from 10: 200 avegar over 10 episode: -99.991 avegare return across last 100 episodes: -99.996 state values: tensor(0.9573) 1000
load offline data!!!!!
mem_cntr: 50000 ; mem_size: 50000
nn.learn_nn_feature_fqi FQI:  998
nn.learn_nn_feature_fqi FQI:  1998
nn.learn_nn_feature_fqi FQI:  2998
nn.learn_nn_feature_fqi FQI:  3998
nn.learn_nn_feature_fqi FQI:  4998
nn.learn_nn_feature_fqi FQI:  5998
nn.learn_nn_feature_fqi FQI:  6998
nn.learn_nn_feature_fqi FQI:  7998
nn.learn_nn_feature_fqi FQI:  8998
nn.learn_nn_feature_fqi FQI:  9998
nn.learn_nn_feature_fqi FQI:  10998
nn.learn_nn_feature_fqi FQI:  11998
nn.learn_nn_feature_fqi FQI:  12998
nn.learn_nn_feature_fqi FQI:  13998
nn.learn_nn_feature_fqi FQI:  14998
nn.learn_nn_feature_fqi FQI:  15998
nn.learn_nn_feature_fqi FQI:  16998
nn.learn_nn_feature_fqi FQI:  17998
nn.learn_nn_feature_fqi FQI:  18998
nn.learn_nn_feature_fqi FQI:  19998
nn.learn_nn_feature_fqi FQI:  20998
nn.learn_nn_feature_fqi FQI:  21998
nn.learn_nn_feature_fqi FQI:  22998
nn.learn_nn_feature_fqi FQI:  23998
nn.learn_nn_feature_fqi FQI:  24998
nn.learn_nn_feature_fqi FQI:  25998
nn.learn_nn_feature_fqi FQI:  26998
nn.learn_nn_feature_fqi FQI:  27998
nn.learn_nn_feature_fqi FQI:  28998
nn.learn_nn_feature_fqi FQI:  29998
nn.learn_nn_feature_fqi FQI:  30998
nn.learn_nn_feature_fqi FQI:  31998
nn.learn_nn_feature_fqi FQI:  32998
nn.learn_nn_feature_fqi FQI:  33998
nn.learn_nn_feature_fqi FQI:  34998
nn.learn_nn_feature_fqi FQI:  35998
nn.learn_nn_feature_fqi FQI:  36998
nn.learn_nn_feature_fqi FQI:  37998
nn.learn_nn_feature_fqi FQI:  38998
nn.learn_nn_feature_fqi FQI:  39998
nn.learn_nn_feature_fqi FQI:  40998
nn.learn_nn_feature_fqi FQI:  41998
nn.learn_nn_feature_fqi FQI:  42998
nn.learn_nn_feature_fqi FQI:  43998
nn.learn_nn_feature_fqi FQI:  44998
nn.learn_nn_feature_fqi FQI:  45998
nn.learn_nn_feature_fqi FQI:  46998
nn.learn_nn_feature_fqi FQI:  47998
nn.learn_nn_feature_fqi FQI:  48998
nn.learn_nn_feature_fqi FQI:  49998
nn.learn_nn_feature_fqi FQI:  50998
nn.learn_nn_feature_fqi FQI:  51998
nn.learn_nn_feature_fqi FQI:  52998
nn.learn_nn_feature_fqi FQI:  53998
nn.learn_nn_feature_fqi FQI:  54998
nn.learn_nn_feature_fqi FQI:  55998
nn.learn_nn_feature_fqi FQI:  56998
nn.learn_nn_feature_fqi FQI:  57998
nn.learn_nn_feature_fqi FQI:  58998
nn.learn_nn_feature_fqi FQI:  59998
nn.learn_nn_feature_fqi FQI:  60998
nn.learn_nn_feature_fqi FQI:  61998
nn.learn_nn_feature_fqi FQI:  62998
nn.learn_nn_feature_fqi FQI:  63998
nn.learn_nn_feature_fqi FQI:  64998
nn.learn_nn_feature_fqi FQI:  65998
nn.learn_nn_feature_fqi FQI:  66998
nn.learn_nn_feature_fqi FQI:  67998
nn.learn_nn_feature_fqi FQI:  68998
nn.learn_nn_feature_fqi FQI:  69998
nn.learn_nn_feature_fqi FQI:  70998
nn.learn_nn_feature_fqi FQI:  71998
nn.learn_nn_feature_fqi FQI:  72998
nn.learn_nn_feature_fqi FQI:  73998
nn.learn_nn_feature_fqi FQI:  74998
nn.learn_nn_feature_fqi FQI:  75998
nn.learn_nn_feature_fqi FQI:  76998
nn.learn_nn_feature_fqi FQI:  77998
nn.learn_nn_feature_fqi FQI:  78998
nn.learn_nn_feature_fqi FQI:  79998
nn.learn_nn_feature_fqi FQI:  80998
nn.learn_nn_feature_fqi FQI:  81998
nn.learn_nn_feature_fqi FQI:  82998
nn.learn_nn_feature_fqi FQI:  83998
nn.learn_nn_feature_fqi FQI:  84998
nn.learn_nn_feature_fqi FQI:  85998
nn.learn_nn_feature_fqi FQI:  86998
nn.learn_nn_feature_fqi FQI:  87998
nn.learn_nn_feature_fqi FQI:  88998
nn.learn_nn_feature_fqi FQI:  89998
nn.learn_nn_feature_fqi FQI:  90998
nn.learn_nn_feature_fqi FQI:  91998
nn.learn_nn_feature_fqi FQI:  92998
nn.learn_nn_feature_fqi FQI:  93998
nn.learn_nn_feature_fqi FQI:  94998
nn.learn_nn_feature_fqi FQI:  95998
nn.learn_nn_feature_fqi FQI:  96998
nn.learn_nn_feature_fqi FQI:  97998
nn.learn_nn_feature_fqi FQI:  98998
nn.learn_nn_feature_fqi FQI:  99998
nn.learn_nn_feature_fqi FQI:  100998
nn.learn_nn_feature_fqi FQI:  101998
nn.learn_nn_feature_fqi FQI:  102998
nn.learn_nn_feature_fqi FQI:  103998
nn.learn_nn_feature_fqi FQI:  104998
nn.learn_nn_feature_fqi FQI:  105998
nn.learn_nn_feature_fqi FQI:  106998
nn.learn_nn_feature_fqi FQI:  107998
nn.learn_nn_feature_fqi FQI:  108998
nn.learn_nn_feature_fqi FQI:  109998
nn.learn_nn_feature_fqi FQI:  110998
nn.learn_nn_feature_fqi FQI:  111998
nn.learn_nn_feature_fqi FQI:  112998
nn.learn_nn_feature_fqi FQI:  113998
nn.learn_nn_feature_fqi FQI:  114998
nn.learn_nn_feature_fqi FQI:  115998
nn.learn_nn_feature_fqi FQI:  116998
nn.learn_nn_feature_fqi FQI:  117998
nn.learn_nn_feature_fqi FQI:  118998
nn.learn_nn_feature_fqi FQI:  119998
nn.learn_nn_feature_fqi FQI:  120998
nn.learn_nn_feature_fqi FQI:  121998
nn.learn_nn_feature_fqi FQI:  122998
nn.learn_nn_feature_fqi FQI:  123998
nn.learn_nn_feature_fqi FQI:  124998
nn.learn_nn_feature_fqi FQI:  125998
nn.learn_nn_feature_fqi FQI:  126998
nn.learn_nn_feature_fqi FQI:  127998
nn.learn_nn_feature_fqi FQI:  128998
nn.learn_nn_feature_fqi FQI:  129998
nn.learn_nn_feature_fqi FQI:  130998
nn.learn_nn_feature_fqi FQI:  131998
nn.learn_nn_feature_fqi FQI:  132998
nn.learn_nn_feature_fqi FQI:  133998
nn.learn_nn_feature_fqi FQI:  134998
nn.learn_nn_feature_fqi FQI:  135998
nn.learn_nn_feature_fqi FQI:  136998
nn.learn_nn_feature_fqi FQI:  137998
nn.learn_nn_feature_fqi FQI:  138998
nn.learn_nn_feature_fqi FQI:  139998
nn.learn_nn_feature_fqi FQI:  140998
nn.learn_nn_feature_fqi FQI:  141998
nn.learn_nn_feature_fqi FQI:  142998
nn.learn_nn_feature_fqi FQI:  143998
nn.learn_nn_feature_fqi FQI:  144998
nn.learn_nn_feature_fqi FQI:  145998
nn.learn_nn_feature_fqi FQI:  146998
nn.learn_nn_feature_fqi FQI:  147998
nn.learn_nn_feature_fqi FQI:  148998
nn.learn_nn_feature_fqi FQI:  149998
nn.learn_nn_feature_fqi FQI:  150998
nn.learn_nn_feature_fqi FQI:  151998
nn.learn_nn_feature_fqi FQI:  152998
nn.learn_nn_feature_fqi FQI:  153998
nn.learn_nn_feature_fqi FQI:  154998
nn.learn_nn_feature_fqi FQI:  155998
0 1001 -1000.0 -98.99572604650622 number episode from 10: 0 avegar over 10 episode: -98.996 avegare return across last 100 episodes: -98.996 state values: tensor(0.6627) 1000
1 1000 -1000.0 -99.99568287525881 number episode from 10: 1 avegar over 10 episode: -99.496 avegare return across last 100 episodes: -99.496 state values: tensor(0.6629) 1000
2 1000 -1000.0 -99.99568287525881 number episode from 10: 2 avegar over 10 episode: -99.662 avegare return across last 100 episodes: -99.662 state values: tensor(0.6627) 1000
3 214 -214.0 -88.36057184709955 number episode from 10: 3 avegar over 10 episode: -96.837 avegare return across last 100 episodes: -96.837 state values: tensor(0.7427) 214
4 1000 -1000.0 -99.99568287525881 number episode from 10: 4 avegar over 10 episode: -97.469 avegare return across last 100 episodes: -97.469 state values: tensor(0.6626) 1000
5 1000 -1000.0 -99.99568287525881 number episode from 10: 5 avegar over 10 episode: -97.89 avegare return across last 100 episodes: -97.89 state values: tensor(0.6626) 1000
6 1000 -1000.0 -99.99568287525881 number episode from 10: 6 avegar over 10 episode: -98.191 avegare return across last 100 episodes: -98.191 state values: tensor(0.6629) 1000
7 1000 -1000.0 -99.99568287525881 number episode from 10: 7 avegar over 10 episode: -98.416 avegare return across last 100 episodes: -98.416 state values: tensor(0.6628) 1000
8 1000 -1000.0 -99.99568287525881 number episode from 10: 8 avegar over 10 episode: -98.592 avegare return across last 100 episodes: -98.592 state values: tensor(0.6628) 1000
9 1000 -1000.0 -99.99568287525881 number episode from 10: 9 avegar over 10 episode: -98.732 avegare return across last 100 episodes: -98.732 state values: tensor(0.6630) 1000
10 1000 -1000.0 -99.99568287525881 number episode from 10: 10 avegar over 10 episode: -98.847 avegare return across last 100 episodes: -98.847 state values: tensor(0.6629) 1000
11 1000 -1000.0 -99.99568287525881 number episode from 10: 11 avegar over 10 episode: -98.943 avegare return across last 100 episodes: -98.943 state values: tensor(0.6631) 1000
12 191 -191.0 -85.3336458367895 number episode from 10: 12 avegar over 10 episode: -97.896 avegare return across last 100 episodes: -97.896 state values: tensor(0.7582) 191
13 1000 -1000.0 -99.99568287525881 number episode from 10: 13 avegar over 10 episode: -98.046 avegare return across last 100 episodes: -98.046 state values: tensor(0.6626) 1000
14 1000 -1000.0 -99.99568287525881 number episode from 10: 14 avegar over 10 episode: -98.176 avegare return across last 100 episodes: -98.176 state values: tensor(0.6630) 1000
15 1000 -1000.0 -99.99568287525881 number episode from 10: 15 avegar over 10 episode: -98.29 avegare return across last 100 episodes: -98.29 state values: tensor(0.6622) 1000
16 1000 -1000.0 -99.99568287525881 number episode from 10: 16 avegar over 10 episode: -98.39 avegare return across last 100 episodes: -98.39 state values: tensor(0.6627) 1000
17 1000 -1000.0 -99.99568287525881 number episode from 10: 17 avegar over 10 episode: -98.479 avegare return across last 100 episodes: -98.479 state values: tensor(0.6626) 1000
18 1000 -1000.0 -99.99568287525881 number episode from 10: 18 avegar over 10 episode: -98.559 avegare return across last 100 episodes: -98.559 state values: tensor(0.6629) 1000
19 1000 -1000.0 -99.99568287525881 number episode from 10: 19 avegar over 10 episode: -98.631 avegare return across last 100 episodes: -98.631 state values: tensor(0.6629) 1000
20 1000 -1000.0 -99.99568287525881 number episode from 10: 20 avegar over 10 episode: -98.696 avegare return across last 100 episodes: -98.696 state values: tensor(0.6630) 1000
21 219 -219.0 -88.93101964006571 number episode from 10: 21 avegar over 10 episode: -98.252 avegare return across last 100 episodes: -98.252 state values: tensor(0.7442) 219
22 1000 -1000.0 -99.99568287525881 number episode from 10: 22 avegar over 10 episode: -98.328 avegare return across last 100 episodes: -98.328 state values: tensor(0.6628) 1000
23 1000 -1000.0 -99.99568287525881 number episode from 10: 23 avegar over 10 episode: -98.397 avegare return across last 100 episodes: -98.397 state values: tensor(0.6626) 1000
24 1000 -1000.0 -99.99568287525881 number episode from 10: 24 avegar over 10 episode: -98.461 avegare return across last 100 episodes: -98.461 state values: tensor(0.6630) 1000
25 194 -194.0 -85.76925122179102 number episode from 10: 25 avegar over 10 episode: -97.973 avegare return across last 100 episodes: -97.973 state values: tensor(0.7585) 194
26 1000 -1000.0 -99.99568287525881 number episode from 10: 26 avegar over 10 episode: -98.048 avegare return across last 100 episodes: -98.048 state values: tensor(0.6628) 1000
27 1000 -1000.0 -99.99568287525881 number episode from 10: 27 avegar over 10 episode: -98.118 avegare return across last 100 episodes: -98.118 state values: tensor(0.6628) 1000
28 1000 -1000.0 -99.99568287525881 number episode from 10: 28 avegar over 10 episode: -98.182 avegare return across last 100 episodes: -98.182 state values: tensor(0.6628) 1000
29 1000 -1000.0 -99.99568287525881 number episode from 10: 29 avegar over 10 episode: -98.243 avegare return across last 100 episodes: -98.243 state values: tensor(0.6630) 1000
30 1000 -1000.0 -99.99568287525881 number episode from 10: 30 avegar over 10 episode: -98.299 avegare return across last 100 episodes: -98.299 state values: tensor(0.6627) 1000
31 1000 -1000.0 -99.99568287525881 number episode from 10: 31 avegar over 10 episode: -98.352 avegare return across last 100 episodes: -98.352 state values: tensor(0.6628) 1000
32 1000 -1000.0 -99.99568287525881 number episode from 10: 32 avegar over 10 episode: -98.402 avegare return across last 100 episodes: -98.402 state values: tensor(0.6630) 1000
33 195 -195.0 -85.91155870957311 number episode from 10: 33 avegar over 10 episode: -98.035 avegare return across last 100 episodes: -98.035 state values: tensor(0.7589) 195
34 1000 -1000.0 -99.99568287525881 number episode from 10: 34 avegar over 10 episode: -98.091 avegare return across last 100 episodes: -98.091 state values: tensor(0.6626) 1000
35 1000 -1000.0 -99.99568287525881 number episode from 10: 35 avegar over 10 episode: -98.144 avegare return across last 100 episodes: -98.144 state values: tensor(0.6628) 1000
36 1000 -1000.0 -99.99568287525881 number episode from 10: 36 avegar over 10 episode: -98.194 avegare return across last 100 episodes: -98.194 state values: tensor(0.6630) 1000
37 1000 -1000.0 -99.99568287525881 number episode from 10: 37 avegar over 10 episode: -98.241 avegare return across last 100 episodes: -98.241 state values: tensor(0.6630) 1000
38 191 -191.0 -85.3336458367895 number episode from 10: 38 avegar over 10 episode: -97.91 avegare return across last 100 episodes: -97.91 state values: tensor(0.7572) 191
39 191 -191.0 -85.3336458367895 number episode from 10: 39 avegar over 10 episode: -97.596 avegare return across last 100 episodes: -97.596 state values: tensor(0.7578) 191
40 1000 -1000.0 -99.99568287525881 number episode from 10: 40 avegar over 10 episode: -97.654 avegare return across last 100 episodes: -97.654 state values: tensor(0.6626) 1000
41 1000 -1000.0 -99.99568287525881 number episode from 10: 41 avegar over 10 episode: -97.71 avegare return across last 100 episodes: -97.71 state values: tensor(0.6629) 1000
42 1000 -1000.0 -99.99568287525881 number episode from 10: 42 avegar over 10 episode: -97.763 avegare return across last 100 episodes: -97.763 state values: tensor(0.6625) 1000
43 196 -196.0 -86.05244312247738 number episode from 10: 43 avegar over 10 episode: -97.497 avegare return across last 100 episodes: -97.497 state values: tensor(0.7593) 196
44 1000 -1000.0 -99.99568287525881 number episode from 10: 44 avegar over 10 episode: -97.553 avegare return across last 100 episodes: -97.553 state values: tensor(0.6628) 1000
45 1000 -1000.0 -99.99568287525881 number episode from 10: 45 avegar over 10 episode: -97.606 avegare return across last 100 episodes: -97.606 state values: tensor(0.6630) 1000
46 218 -218.0 -88.81921175764214 number episode from 10: 46 avegar over 10 episode: -97.419 avegare return across last 100 episodes: -97.419 state values: tensor(0.7439) 218
47 1000 -1000.0 -99.99568287525881 number episode from 10: 47 avegar over 10 episode: -97.472 avegare return across last 100 episodes: -97.472 state values: tensor(0.6630) 1000
48 1000 -1000.0 -99.99568287525881 number episode from 10: 48 avegar over 10 episode: -97.524 avegare return across last 100 episodes: -97.524 state values: tensor(0.6630) 1000
49 1000 -1000.0 -99.99568287525881 number episode from 10: 49 avegar over 10 episode: -97.573 avegare return across last 100 episodes: -97.573 state values: tensor(0.6630) 1000
50 188 -188.0 -84.88470650468516 number episode from 10: 50 avegar over 10 episode: -97.325 avegare return across last 100 episodes: -97.325 state values: tensor(0.7552) 188
51 1000 -1000.0 -99.99568287525881 number episode from 10: 51 avegar over 10 episode: -97.376 avegare return across last 100 episodes: -97.376 state values: tensor(0.6627) 1000
52 1000 -1000.0 -99.99568287525881 number episode from 10: 52 avegar over 10 episode: -97.425 avegare return across last 100 episodes: -97.425 state values: tensor(0.6630) 1000
53 1000 -1000.0 -99.99568287525881 number episode from 10: 53 avegar over 10 episode: -97.473 avegare return across last 100 episodes: -97.473 state values: tensor(0.6631) 1000
54 1000 -1000.0 -99.99568287525881 number episode from 10: 54 avegar over 10 episode: -97.519 avegare return across last 100 episodes: -97.519 state values: tensor(0.6630) 1000
55 188 -188.0 -84.88470650468516 number episode from 10: 55 avegar over 10 episode: -97.293 avegare return across last 100 episodes: -97.293 state values: tensor(0.7555) 188
56 1000 -1000.0 -99.99568287525881 number episode from 10: 56 avegar over 10 episode: -97.341 avegare return across last 100 episodes: -97.341 state values: tensor(0.6630) 1000
57 1000 -1000.0 -99.99568287525881 number episode from 10: 57 avegar over 10 episode: -97.386 avegare return across last 100 episodes: -97.386 state values: tensor(0.6631) 1000
58 1000 -1000.0 -99.99568287525881 number episode from 10: 58 avegar over 10 episode: -97.431 avegare return across last 100 episodes: -97.431 state values: tensor(0.6628) 1000
59 1000 -1000.0 -99.99568287525881 number episode from 10: 59 avegar over 10 episode: -97.473 avegare return across last 100 episodes: -97.473 state values: tensor(0.6626) 1000
60 1000 -1000.0 -99.99568287525881 number episode from 10: 60 avegar over 10 episode: -97.515 avegare return across last 100 episodes: -97.515 state values: tensor(0.6626) 1000
61 1000 -1000.0 -99.99568287525881 number episode from 10: 61 avegar over 10 episode: -97.555 avegare return across last 100 episodes: -97.555 state values: tensor(0.6629) 1000
62 1000 -1000.0 -99.99568287525881 number episode from 10: 62 avegar over 10 episode: -97.593 avegare return across last 100 episodes: -97.593 state values: tensor(0.6631) 1000
63 1000 -1000.0 -99.99568287525881 number episode from 10: 63 avegar over 10 episode: -97.631 avegare return across last 100 episodes: -97.631 state values: tensor(0.6630) 1000
64 1000 -1000.0 -99.99568287525881 number episode from 10: 64 avegar over 10 episode: -97.667 avegare return across last 100 episodes: -97.667 state values: tensor(0.6630) 1000
65 1000 -1000.0 -99.99568287525881 number episode from 10: 65 avegar over 10 episode: -97.703 avegare return across last 100 episodes: -97.703 state values: tensor(0.6626) 1000
66 1000 -1000.0 -99.99568287525881 number episode from 10: 66 avegar over 10 episode: -97.737 avegare return across last 100 episodes: -97.737 state values: tensor(0.6628) 1000
67 1000 -1000.0 -99.99568287525881 number episode from 10: 67 avegar over 10 episode: -97.77 avegare return across last 100 episodes: -97.77 state values: tensor(0.6629) 1000
68 1000 -1000.0 -99.99568287525881 number episode from 10: 68 avegar over 10 episode: -97.802 avegare return across last 100 episodes: -97.802 state values: tensor(0.6630) 1000
69 219 -219.0 -88.93101964006571 number episode from 10: 69 avegar over 10 episode: -97.676 avegare return across last 100 episodes: -97.676 state values: tensor(0.7442) 219
70 1000 -1000.0 -99.99568287525881 number episode from 10: 70 avegar over 10 episode: -97.708 avegare return across last 100 episodes: -97.708 state values: tensor(0.6628) 1000
71 1000 -1000.0 -99.99568287525881 number episode from 10: 71 avegar over 10 episode: -97.74 avegare return across last 100 episodes: -97.74 state values: tensor(0.6626) 1000
72 1000 -1000.0 -99.99568287525881 number episode from 10: 72 avegar over 10 episode: -97.771 avegare return across last 100 episodes: -97.771 state values: tensor(0.6626) 1000
73 1000 -1000.0 -99.99568287525881 number episode from 10: 73 avegar over 10 episode: -97.801 avegare return across last 100 episodes: -97.801 state values: tensor(0.6626) 1000
74 190 -190.0 -85.18550084524192 number episode from 10: 74 avegar over 10 episode: -97.633 avegare return across last 100 episodes: -97.633 state values: tensor(0.7597) 190
75 241 -241.0 -91.12676674846973 number episode from 10: 75 avegar over 10 episode: -97.547 avegare return across last 100 episodes: -97.547 state values: tensor(0.7335) 241
76 1000 -1000.0 -99.99568287525881 number episode from 10: 76 avegar over 10 episode: -97.579 avegare return across last 100 episodes: -97.579 state values: tensor(0.6630) 1000
77 195 -195.0 -85.91155870957311 number episode from 10: 77 avegar over 10 episode: -97.429 avegare return across last 100 episodes: -97.429 state values: tensor(0.7642) 195
78 187 -187.0 -84.73202677240926 number episode from 10: 78 avegar over 10 episode: -97.269 avegare return across last 100 episodes: -97.269 state values: tensor(0.7568) 187
79 1000 -1000.0 -99.99568287525881 number episode from 10: 79 avegar over 10 episode: -97.303 avegare return across last 100 episodes: -97.303 state values: tensor(0.6632) 1000
80 1000 -1000.0 -99.99568287525881 number episode from 10: 80 avegar over 10 episode: -97.336 avegare return across last 100 episodes: -97.336 state values: tensor(0.6629) 1000
81 1000 -1000.0 -99.99568287525881 number episode from 10: 81 avegar over 10 episode: -97.368 avegare return across last 100 episodes: -97.368 state values: tensor(0.6627) 1000
82 172 -172.0 -82.24774732412354 number episode from 10: 82 avegar over 10 episode: -97.186 avegare return across last 100 episodes: -97.186 state values: tensor(0.7411) 172
83 1000 -1000.0 -99.99568287525881 number episode from 10: 83 avegar over 10 episode: -97.22 avegare return across last 100 episodes: -97.22 state values: tensor(0.6629) 1000
84 191 -191.0 -85.3336458367895 number episode from 10: 84 avegar over 10 episode: -97.08 avegare return across last 100 episodes: -97.08 state values: tensor(0.7449) 191
85 1000 -1000.0 -99.99568287525881 number episode from 10: 85 avegar over 10 episode: -97.114 avegare return across last 100 episodes: -97.114 state values: tensor(0.6628) 1000
86 1000 -1000.0 -99.99568287525881 number episode from 10: 86 avegar over 10 episode: -97.147 avegare return across last 100 episodes: -97.147 state values: tensor(0.6627) 1000
87 248 -248.0 -91.72956676235256 number episode from 10: 87 avegar over 10 episode: -97.085 avegare return across last 100 episodes: -97.085 state values: tensor(0.7374) 248
88 1000 -1000.0 -99.99568287525881 number episode from 10: 88 avegar over 10 episode: -97.118 avegare return across last 100 episodes: -97.118 state values: tensor(0.6626) 1000
89 1000 -1000.0 -99.99568287525881 number episode from 10: 89 avegar over 10 episode: -97.15 avegare return across last 100 episodes: -97.15 state values: tensor(0.6629) 1000
90 1000 -1000.0 -99.99568287525881 number episode from 10: 90 avegar over 10 episode: -97.181 avegare return across last 100 episodes: -97.181 state values: tensor(0.6624) 1000
91 218 -218.0 -88.81921175764214 number episode from 10: 91 avegar over 10 episode: -97.09 avegare return across last 100 episodes: -97.09 state values: tensor(0.7435) 218
92 1000 -1000.0 -99.99568287525881 number episode from 10: 92 avegar over 10 episode: -97.122 avegare return across last 100 episodes: -97.122 state values: tensor(0.6628) 1000
93 1000 -1000.0 -99.99568287525881 number episode from 10: 93 avegar over 10 episode: -97.152 avegare return across last 100 episodes: -97.152 state values: tensor(0.6628) 1000
94 192 -192.0 -85.48030937842161 number episode from 10: 94 avegar over 10 episode: -97.029 avegare return across last 100 episodes: -97.029 state values: tensor(0.7576) 192
95 1000 -1000.0 -99.99568287525881 number episode from 10: 95 avegar over 10 episode: -97.06 avegare return across last 100 episodes: -97.06 state values: tensor(0.6630) 1000
96 1000 -1000.0 -99.99568287525881 number episode from 10: 96 avegar over 10 episode: -97.091 avegare return across last 100 episodes: -97.091 state values: tensor(0.6630) 1000
97 1000 -1000.0 -99.99568287525881 number episode from 10: 97 avegar over 10 episode: -97.12 avegare return across last 100 episodes: -97.12 state values: tensor(0.6628) 1000
98 189 -189.0 -85.0358594396383 number episode from 10: 98 avegar over 10 episode: -96.998 avegare return across last 100 episodes: -96.998 state values: tensor(0.7575) 189
99 1000 -1000.0 -99.99568287525881 number episode from 10: 99 avegar over 10 episode: -97.028 avegare return across last 100 episodes: -97.028 state values: tensor(0.6629) 1000
100 1000 -1000.0 -99.99568287525881 number episode from 10: 100 avegar over 10 episode: -97.057 avegare return across last 100 episodes: -97.038 state values: tensor(0.6625) 1000
101 1000 -1000.0 -99.99568287525881 number episode from 10: 101 avegar over 10 episode: -97.086 avegare return across last 100 episodes: -97.038 state values: tensor(0.6625) 1000
102 186 -186.0 -84.57780482061541 number episode from 10: 102 avegar over 10 episode: -96.965 avegare return across last 100 episodes: -96.884 state values: tensor(0.7555) 186
103 1000 -1000.0 -99.99568287525881 number episode from 10: 103 avegar over 10 episode: -96.994 avegare return across last 100 episodes: -97.0 state values: tensor(0.6625) 1000
104 1000 -1000.0 -99.99568287525881 number episode from 10: 104 avegar over 10 episode: -97.023 avegare return across last 100 episodes: -97.0 state values: tensor(0.6626) 1000
105 186 -186.0 -84.57780482061541 number episode from 10: 105 avegar over 10 episode: -96.905 avegare return across last 100 episodes: -96.846 state values: tensor(0.7557) 186
106 1000 -1000.0 -99.99568287525881 number episode from 10: 106 avegar over 10 episode: -96.934 avegare return across last 100 episodes: -96.846 state values: tensor(0.6628) 1000
107 1000 -1000.0 -99.99568287525881 number episode from 10: 107 avegar over 10 episode: -96.962 avegare return across last 100 episodes: -96.846 state values: tensor(0.6625) 1000
108 1000 -1000.0 -99.99568287525881 number episode from 10: 108 avegar over 10 episode: -96.99 avegare return across last 100 episodes: -96.846 state values: tensor(0.6628) 1000
109 1000 -1000.0 -99.99568287525881 number episode from 10: 109 avegar over 10 episode: -97.018 avegare return across last 100 episodes: -96.846 state values: tensor(0.6631) 1000
110 1000 -1000.0 -99.99568287525881 number episode from 10: 110 avegar over 10 episode: -97.044 avegare return across last 100 episodes: -96.846 state values: tensor(0.6629) 1000
111 1000 -1000.0 -99.99568287525881 number episode from 10: 111 avegar over 10 episode: -97.071 avegare return across last 100 episodes: -96.846 state values: tensor(0.6630) 1000
112 1000 -1000.0 -99.99568287525881 number episode from 10: 112 avegar over 10 episode: -97.097 avegare return across last 100 episodes: -96.993 state values: tensor(0.6628) 1000
113 255 -255.0 -92.29141576701062 number episode from 10: 113 avegar over 10 episode: -97.054 avegare return across last 100 episodes: -96.916 state values: tensor(0.7436) 255
114 1000 -1000.0 -99.99568287525881 number episode from 10: 114 avegar over 10 episode: -97.08 avegare return across last 100 episodes: -96.916 state values: tensor(0.6630) 1000
115 1000 -1000.0 -99.99568287525881 number episode from 10: 115 avegar over 10 episode: -97.105 avegare return across last 100 episodes: -96.916 state values: tensor(0.6629) 1000
116 1000 -1000.0 -99.99568287525881 number episode from 10: 116 avegar over 10 episode: -97.13 avegare return across last 100 episodes: -96.916 state values: tensor(0.6629) 1000
117 190 -190.0 -85.18550084524192 number episode from 10: 117 avegar over 10 episode: -97.029 avegare return across last 100 episodes: -96.768 state values: tensor(0.7571) 190
118 1000 -1000.0 -99.99568287525881 number episode from 10: 118 avegar over 10 episode: -97.054 avegare return across last 100 episodes: -96.768 state values: tensor(0.6629) 1000
119 1000 -1000.0 -99.99568287525881 number episode from 10: 119 avegar over 10 episode: -97.078 avegare return across last 100 episodes: -96.768 state values: tensor(0.6627) 1000
120 1000 -1000.0 -99.99568287525881 number episode from 10: 120 avegar over 10 episode: -97.102 avegare return across last 100 episodes: -96.768 state values: tensor(0.6629) 1000
121 177 -177.0 -83.11778434193083 number episode from 10: 121 avegar over 10 episode: -96.988 avegare return across last 100 episodes: -96.709 state values: tensor(0.7421) 177
122 1000 -1000.0 -99.99568287525881 number episode from 10: 122 avegar over 10 episode: -97.012 avegare return across last 100 episodes: -96.709 state values: tensor(0.6631) 1000
123 1000 -1000.0 -99.99568287525881 number episode from 10: 123 avegar over 10 episode: -97.036 avegare return across last 100 episodes: -96.709 state values: tensor(0.6631) 1000
124 1000 -1000.0 -99.99568287525881 number episode from 10: 124 avegar over 10 episode: -97.06 avegare return across last 100 episodes: -96.709 state values: tensor(0.6628) 1000
125 1000 -1000.0 -99.99568287525881 number episode from 10: 125 avegar over 10 episode: -97.083 avegare return across last 100 episodes: -96.852 state values: tensor(0.6627) 1000
126 1000 -1000.0 -99.99568287525881 number episode from 10: 126 avegar over 10 episode: -97.106 avegare return across last 100 episodes: -96.852 state values: tensor(0.6627) 1000
127 1000 -1000.0 -99.99568287525881 number episode from 10: 127 avegar over 10 episode: -97.129 avegare return across last 100 episodes: -96.852 state values: tensor(0.6629) 1000
128 244 -244.0 -91.39031064927343 number episode from 10: 128 avegar over 10 episode: -97.084 avegare return across last 100 episodes: -96.766 state values: tensor(0.7364) 244
129 196 -196.0 -86.05244312247738 number episode from 10: 129 avegar over 10 episode: -96.999 avegare return across last 100 episodes: -96.626 state values: tensor(0.7592) 196
130 1000 -1000.0 -99.99568287525881 number episode from 10: 130 avegar over 10 episode: -97.022 avegare return across last 100 episodes: -96.626 state values: tensor(0.6627) 1000
131 1000 -1000.0 -99.99568287525881 number episode from 10: 131 avegar over 10 episode: -97.045 avegare return across last 100 episodes: -96.626 state values: tensor(0.6630) 1000
132 188 -188.0 -84.88470650468516 number episode from 10: 132 avegar over 10 episode: -96.953 avegare return across last 100 episodes: -96.475 state values: tensor(0.7559) 188
133 1000 -1000.0 -99.99568287525881 number episode from 10: 133 avegar over 10 episode: -96.976 avegare return across last 100 episodes: -96.616 state values: tensor(0.6625) 1000
134 1000 -1000.0 -99.99568287525881 number episode from 10: 134 avegar over 10 episode: -96.998 avegare return across last 100 episodes: -96.616 state values: tensor(0.6625) 1000
135 246 -246.0 -91.56164346735288 number episode from 10: 135 avegar over 10 episode: -96.958 avegare return across last 100 episodes: -96.532 state values: tensor(0.7365) 246
136 1000 -1000.0 -99.99568287525881 number episode from 10: 136 avegar over 10 episode: -96.981 avegare return across last 100 episodes: -96.532 state values: tensor(0.6628) 1000
137 1000 -1000.0 -99.99568287525881 number episode from 10: 137 avegar over 10 episode: -97.002 avegare return across last 100 episodes: -96.532 state values: tensor(0.6629) 1000
138 218 -218.0 -88.81921175764214 number episode from 10: 138 avegar over 10 episode: -96.943 avegare return across last 100 episodes: -96.566 state values: tensor(0.7436) 218
139 1000 -1000.0 -99.99568287525881 number episode from 10: 139 avegar over 10 episode: -96.965 avegare return across last 100 episodes: -96.713 state values: tensor(0.6630) 1000
140 1000 -1000.0 -99.99568287525881 number episode from 10: 140 avegar over 10 episode: -96.987 avegare return across last 100 episodes: -96.713 state values: tensor(0.6628) 1000
141 195 -195.0 -85.91155870957311 number episode from 10: 141 avegar over 10 episode: -96.909 avegare return across last 100 episodes: -96.572 state values: tensor(0.7594) 195
142 1000 -1000.0 -99.99568287525881 number episode from 10: 142 avegar over 10 episode: -96.93 avegare return across last 100 episodes: -96.572 state values: tensor(0.6630) 1000
143 1000 -1000.0 -99.99568287525881 number episode from 10: 143 avegar over 10 episode: -96.952 avegare return across last 100 episodes: -96.712 state values: tensor(0.6629) 1000
144 218 -218.0 -88.81921175764214 number episode from 10: 144 avegar over 10 episode: -96.896 avegare return across last 100 episodes: -96.6 state values: tensor(0.7434) 218
145 1000 -1000.0 -99.99568287525881 number episode from 10: 145 avegar over 10 episode: -96.917 avegare return across last 100 episodes: -96.6 state values: tensor(0.6627) 1000
146 188 -188.0 -84.88470650468516 number episode from 10: 146 avegar over 10 episode: -96.835 avegare return across last 100 episodes: -96.561 state values: tensor(0.7555) 188
147 1000 -1000.0 -99.99568287525881 number episode from 10: 147 avegar over 10 episode: -96.856 avegare return across last 100 episodes: -96.561 state values: tensor(0.6630) 1000
148 312 -312.0 -95.65308933997781 number episode from 10: 148 avegar over 10 episode: -96.848 avegare return across last 100 episodes: -96.517 state values: tensor(0.7909) 312
149 1000 -1000.0 -99.99568287525881 number episode from 10: 149 avegar over 10 episode: -96.869 avegare return across last 100 episodes: -96.517 state values: tensor(0.6628) 1000
150 1000 -1000.0 -99.99568287525881 number episode from 10: 150 avegar over 10 episode: -96.89 avegare return across last 100 episodes: -96.668 state values: tensor(0.6626) 1000
151 1000 -1000.0 -99.99568287525881 number episode from 10: 151 avegar over 10 episode: -96.91 avegare return across last 100 episodes: -96.668 state values: tensor(0.6630) 1000
152 177 -177.0 -83.11778434193083 number episode from 10: 152 avegar over 10 episode: -96.82 avegare return across last 100 episodes: -96.499 state values: tensor(0.7464) 177
153 185 -185.0 -84.4220250713287 number episode from 10: 153 avegar over 10 episode: -96.74 avegare return across last 100 episodes: -96.344 state values: tensor(0.7535) 185
154 274 -274.0 -93.63140957251046 number episode from 10: 154 avegar over 10 episode: -96.72 avegare return across last 100 episodes: -96.28 state values: tensor(0.7288) 274
155 1000 -1000.0 -99.99568287525881 number episode from 10: 155 avegar over 10 episode: -96.741 avegare return across last 100 episodes: -96.431 state values: tensor(0.6627) 1000
156 243 -243.0 -91.30334409017519 number episode from 10: 156 avegar over 10 episode: -96.706 avegare return across last 100 episodes: -96.344 state values: tensor(0.7367) 243
157 1000 -1000.0 -99.99568287525881 number episode from 10: 157 avegar over 10 episode: -96.727 avegare return across last 100 episodes: -96.344 state values: tensor(0.6630) 1000
158 1000 -1000.0 -99.99568287525881 number episode from 10: 158 avegar over 10 episode: -96.747 avegare return across last 100 episodes: -96.344 state values: tensor(0.6628) 1000
159 1000 -1000.0 -99.99568287525881 number episode from 10: 159 avegar over 10 episode: -96.768 avegare return across last 100 episodes: -96.344 state values: tensor(0.6626) 1000
160 1000 -1000.0 -99.99568287525881 number episode from 10: 160 avegar over 10 episode: -96.788 avegare return across last 100 episodes: -96.344 state values: tensor(0.6624) 1000
161 1000 -1000.0 -99.99568287525881 number episode from 10: 161 avegar over 10 episode: -96.808 avegare return across last 100 episodes: -96.344 state values: tensor(0.6626) 1000
162 1000 -1000.0 -99.99568287525881 number episode from 10: 162 avegar over 10 episode: -96.827 avegare return across last 100 episodes: -96.344 state values: tensor(0.6629) 1000
163 1000 -1000.0 -99.99568287525881 number episode from 10: 163 avegar over 10 episode: -96.846 avegare return across last 100 episodes: -96.344 state values: tensor(0.6627) 1000
164 242 -242.0 -91.21549908098504 number episode from 10: 164 avegar over 10 episode: -96.812 avegare return across last 100 episodes: -96.256 state values: tensor(0.7354) 242
165 1000 -1000.0 -99.99568287525881 number episode from 10: 165 avegar over 10 episode: -96.831 avegare return across last 100 episodes: -96.256 state values: tensor(0.6628) 1000
166 1000 -1000.0 -99.99568287525881 number episode from 10: 166 avegar over 10 episode: -96.85 avegare return across last 100 episodes: -96.256 state values: tensor(0.6627) 1000
167 1000 -1000.0 -99.99568287525881 number episode from 10: 167 avegar over 10 episode: -96.869 avegare return across last 100 episodes: -96.256 state values: tensor(0.6630) 1000
168 1000 -1000.0 -99.99568287525881 number episode from 10: 168 avegar over 10 episode: -96.888 avegare return across last 100 episodes: -96.256 state values: tensor(0.6630) 1000
169 230 -230.0 -90.08951844811239 number episode from 10: 169 avegar over 10 episode: -96.848 avegare return across last 100 episodes: -96.268 state values: tensor(0.7232) 230
170 1000 -1000.0 -99.99568287525881 number episode from 10: 170 avegar over 10 episode: -96.866 avegare return across last 100 episodes: -96.268 state values: tensor(0.6630) 1000
171 1000 -1000.0 -99.99568287525881 number episode from 10: 171 avegar over 10 episode: -96.884 avegare return across last 100 episodes: -96.268 state values: tensor(0.6625) 1000
172 1000 -1000.0 -99.99568287525881 number episode from 10: 172 avegar over 10 episode: -96.902 avegare return across last 100 episodes: -96.268 state values: tensor(0.6628) 1000
173 1000 -1000.0 -99.99568287525881 number episode from 10: 173 avegar over 10 episode: -96.92 avegare return across last 100 episodes: -96.268 state values: tensor(0.6628) 1000
174 1000 -1000.0 -99.99568287525881 number episode from 10: 174 avegar over 10 episode: -96.938 avegare return across last 100 episodes: -96.416 state values: tensor(0.6628) 1000
175 1000 -1000.0 -99.99568287525881 number episode from 10: 175 avegar over 10 episode: -96.955 avegare return across last 100 episodes: -96.505 state values: tensor(0.6628) 1000
176 1000 -1000.0 -99.99568287525881 number episode from 10: 176 avegar over 10 episode: -96.972 avegare return across last 100 episodes: -96.505 state values: tensor(0.6626) 1000
177 1000 -1000.0 -99.99568287525881 number episode from 10: 177 avegar over 10 episode: -96.989 avegare return across last 100 episodes: -96.646 state values: tensor(0.6629) 1000
178 1000 -1000.0 -99.99568287525881 number episode from 10: 178 avegar over 10 episode: -97.006 avegare return across last 100 episodes: -96.798 state values: tensor(0.6628) 1000
179 1000 -1000.0 -99.99568287525881 number episode from 10: 179 avegar over 10 episode: -97.023 avegare return across last 100 episodes: -96.798 state values: tensor(0.6625) 1000
180 1000 -1000.0 -99.99568287525881 number episode from 10: 180 avegar over 10 episode: -97.039 avegare return across last 100 episodes: -96.798 state values: tensor(0.6627) 1000
181 1000 -1000.0 -99.99568287525881 number episode from 10: 181 avegar over 10 episode: -97.055 avegare return across last 100 episodes: -96.798 state values: tensor(0.6626) 1000
182 1000 -1000.0 -99.99568287525881 number episode from 10: 182 avegar over 10 episode: -97.071 avegare return across last 100 episodes: -96.976 state values: tensor(0.6631) 1000
183 1000 -1000.0 -99.99568287525881 number episode from 10: 183 avegar over 10 episode: -97.087 avegare return across last 100 episodes: -96.976 state values: tensor(0.6630) 1000
184 1000 -1000.0 -99.99568287525881 number episode from 10: 184 avegar over 10 episode: -97.103 avegare return across last 100 episodes: -97.122 state values: tensor(0.6630) 1000
185 1000 -1000.0 -99.99568287525881 number episode from 10: 185 avegar over 10 episode: -97.118 avegare return across last 100 episodes: -97.122 state values: tensor(0.6629) 1000
186 1000 -1000.0 -99.99568287525881 number episode from 10: 186 avegar over 10 episode: -97.134 avegare return across last 100 episodes: -97.122 state values: tensor(0.6626) 1000
187 189 -189.0 -85.0358594396383 number episode from 10: 187 avegar over 10 episode: -97.069 avegare return across last 100 episodes: -97.055 state values: tensor(0.7553) 189
188 1000 -1000.0 -99.99568287525881 number episode from 10: 188 avegar over 10 episode: -97.085 avegare return across last 100 episodes: -97.055 state values: tensor(0.6630) 1000
189 1000 -1000.0 -99.99568287525881 number episode from 10: 189 avegar over 10 episode: -97.1 avegare return across last 100 episodes: -97.055 state values: tensor(0.6628) 1000
190 192 -192.0 -85.48030937842161 number episode from 10: 190 avegar over 10 episode: -97.039 avegare return across last 100 episodes: -96.91 state values: tensor(0.7579) 192
191 196 -196.0 -86.05244312247738 number episode from 10: 191 avegar over 10 episode: -96.982 avegare return across last 100 episodes: -96.883 state values: tensor(0.7593) 196
192 1000 -1000.0 -99.99568287525881 number episode from 10: 192 avegar over 10 episode: -96.998 avegare return across last 100 episodes: -96.883 state values: tensor(0.6631) 1000
193 188 -188.0 -84.88470650468516 number episode from 10: 193 avegar over 10 episode: -96.935 avegare return across last 100 episodes: -96.732 state values: tensor(0.7545) 188
194 1000 -1000.0 -99.99568287525881 number episode from 10: 194 avegar over 10 episode: -96.951 avegare return across last 100 episodes: -96.877 state values: tensor(0.6629) 1000
195 245 -245.0 -91.47640754278069 number episode from 10: 195 avegar over 10 episode: -96.923 avegare return across last 100 episodes: -96.792 state values: tensor(0.7372) 245
196 1000 -1000.0 -99.99568287525881 number episode from 10: 196 avegar over 10 episode: -96.939 avegare return across last 100 episodes: -96.792 state values: tensor(0.6629) 1000
197 1000 -1000.0 -99.99568287525881 number episode from 10: 197 avegar over 10 episode: -96.954 avegare return across last 100 episodes: -96.792 state values: tensor(0.6629) 1000
198 188 -188.0 -84.88470650468516 number episode from 10: 198 avegar over 10 episode: -96.894 avegare return across last 100 episodes: -96.79 state values: tensor(0.7559) 188
199 192 -192.0 -85.48030937842161 number episode from 10: 199 avegar over 10 episode: -96.836 avegare return across last 100 episodes: -96.645 state values: tensor(0.7583) 192
200 1000 -1000.0 -99.99568287525881 number episode from 10: 200 avegar over 10 episode: -96.852 avegare return across last 100 episodes: -96.645 state values: tensor(0.6626) 1000
load offline data!!!!!
mem_cntr: 50000 ; mem_size: 50000
nn.learn_nn_feature_fqi FQI:  998
nn.learn_nn_feature_fqi FQI:  1998
nn.learn_nn_feature_fqi FQI:  2998
nn.learn_nn_feature_fqi FQI:  3998
nn.learn_nn_feature_fqi FQI:  4998
nn.learn_nn_feature_fqi FQI:  5998
nn.learn_nn_feature_fqi FQI:  6998
nn.learn_nn_feature_fqi FQI:  7998
nn.learn_nn_feature_fqi FQI:  8998
nn.learn_nn_feature_fqi FQI:  9998
nn.learn_nn_feature_fqi FQI:  10998
nn.learn_nn_feature_fqi FQI:  11998
nn.learn_nn_feature_fqi FQI:  12998
nn.learn_nn_feature_fqi FQI:  13998
nn.learn_nn_feature_fqi FQI:  14998
nn.learn_nn_feature_fqi FQI:  15998
nn.learn_nn_feature_fqi FQI:  16998
nn.learn_nn_feature_fqi FQI:  17998
nn.learn_nn_feature_fqi FQI:  18998
nn.learn_nn_feature_fqi FQI:  19998
nn.learn_nn_feature_fqi FQI:  20998
nn.learn_nn_feature_fqi FQI:  21998
nn.learn_nn_feature_fqi FQI:  22998
nn.learn_nn_feature_fqi FQI:  23998
nn.learn_nn_feature_fqi FQI:  24998
nn.learn_nn_feature_fqi FQI:  25998
nn.learn_nn_feature_fqi FQI:  26998
nn.learn_nn_feature_fqi FQI:  27998
nn.learn_nn_feature_fqi FQI:  28998
nn.learn_nn_feature_fqi FQI:  29998
nn.learn_nn_feature_fqi FQI:  30998
nn.learn_nn_feature_fqi FQI:  31998
nn.learn_nn_feature_fqi FQI:  32998
nn.learn_nn_feature_fqi FQI:  33998
nn.learn_nn_feature_fqi FQI:  34998
nn.learn_nn_feature_fqi FQI:  35998
nn.learn_nn_feature_fqi FQI:  36998
nn.learn_nn_feature_fqi FQI:  37998
nn.learn_nn_feature_fqi FQI:  38998
nn.learn_nn_feature_fqi FQI:  39998
nn.learn_nn_feature_fqi FQI:  40998
nn.learn_nn_feature_fqi FQI:  41998
nn.learn_nn_feature_fqi FQI:  42998
nn.learn_nn_feature_fqi FQI:  43998
nn.learn_nn_feature_fqi FQI:  44998
nn.learn_nn_feature_fqi FQI:  45998
nn.learn_nn_feature_fqi FQI:  46998
nn.learn_nn_feature_fqi FQI:  47998
nn.learn_nn_feature_fqi FQI:  48998
nn.learn_nn_feature_fqi FQI:  49998
nn.learn_nn_feature_fqi FQI:  50998
nn.learn_nn_feature_fqi FQI:  51998
nn.learn_nn_feature_fqi FQI:  52998
nn.learn_nn_feature_fqi FQI:  53998
nn.learn_nn_feature_fqi FQI:  54998
nn.learn_nn_feature_fqi FQI:  55998
nn.learn_nn_feature_fqi FQI:  56998
nn.learn_nn_feature_fqi FQI:  57998
nn.learn_nn_feature_fqi FQI:  58998
nn.learn_nn_feature_fqi FQI:  59998
nn.learn_nn_feature_fqi FQI:  60998
nn.learn_nn_feature_fqi FQI:  61998
nn.learn_nn_feature_fqi FQI:  62998
nn.learn_nn_feature_fqi FQI:  63998
nn.learn_nn_feature_fqi FQI:  64998
nn.learn_nn_feature_fqi FQI:  65998
nn.learn_nn_feature_fqi FQI:  66998
nn.learn_nn_feature_fqi FQI:  67998
nn.learn_nn_feature_fqi FQI:  68998
nn.learn_nn_feature_fqi FQI:  69998
nn.learn_nn_feature_fqi FQI:  70998
nn.learn_nn_feature_fqi FQI:  71998
nn.learn_nn_feature_fqi FQI:  72998
nn.learn_nn_feature_fqi FQI:  73998
nn.learn_nn_feature_fqi FQI:  74998
nn.learn_nn_feature_fqi FQI:  75998
nn.learn_nn_feature_fqi FQI:  76998
nn.learn_nn_feature_fqi FQI:  77998
nn.learn_nn_feature_fqi FQI:  78998
nn.learn_nn_feature_fqi FQI:  79998
nn.learn_nn_feature_fqi FQI:  80998
nn.learn_nn_feature_fqi FQI:  81998
nn.learn_nn_feature_fqi FQI:  82998
nn.learn_nn_feature_fqi FQI:  83998
nn.learn_nn_feature_fqi FQI:  84998
nn.learn_nn_feature_fqi FQI:  85998
nn.learn_nn_feature_fqi FQI:  86998
nn.learn_nn_feature_fqi FQI:  87998
nn.learn_nn_feature_fqi FQI:  88998
nn.learn_nn_feature_fqi FQI:  89998
nn.learn_nn_feature_fqi FQI:  90998
nn.learn_nn_feature_fqi FQI:  91998
nn.learn_nn_feature_fqi FQI:  92998
nn.learn_nn_feature_fqi FQI:  93998
nn.learn_nn_feature_fqi FQI:  94998
nn.learn_nn_feature_fqi FQI:  95998
nn.learn_nn_feature_fqi FQI:  96998
nn.learn_nn_feature_fqi FQI:  97998
nn.learn_nn_feature_fqi FQI:  98998
nn.learn_nn_feature_fqi FQI:  99998
nn.learn_nn_feature_fqi FQI:  100998
nn.learn_nn_feature_fqi FQI:  101998
nn.learn_nn_feature_fqi FQI:  102998
nn.learn_nn_feature_fqi FQI:  103998
nn.learn_nn_feature_fqi FQI:  104998
nn.learn_nn_feature_fqi FQI:  105998
nn.learn_nn_feature_fqi FQI:  106998
nn.learn_nn_feature_fqi FQI:  107998
nn.learn_nn_feature_fqi FQI:  108998
nn.learn_nn_feature_fqi FQI:  109998
nn.learn_nn_feature_fqi FQI:  110998
nn.learn_nn_feature_fqi FQI:  111998
nn.learn_nn_feature_fqi FQI:  112998
nn.learn_nn_feature_fqi FQI:  113998
nn.learn_nn_feature_fqi FQI:  114998
nn.learn_nn_feature_fqi FQI:  115998
nn.learn_nn_feature_fqi FQI:  116998
nn.learn_nn_feature_fqi FQI:  117998
nn.learn_nn_feature_fqi FQI:  118998
nn.learn_nn_feature_fqi FQI:  119998
nn.learn_nn_feature_fqi FQI:  120998
nn.learn_nn_feature_fqi FQI:  121998
nn.learn_nn_feature_fqi FQI:  122998
nn.learn_nn_feature_fqi FQI:  123998
nn.learn_nn_feature_fqi FQI:  124998
nn.learn_nn_feature_fqi FQI:  125998
nn.learn_nn_feature_fqi FQI:  126998
nn.learn_nn_feature_fqi FQI:  127998
nn.learn_nn_feature_fqi FQI:  128998
nn.learn_nn_feature_fqi FQI:  129998
nn.learn_nn_feature_fqi FQI:  130998
nn.learn_nn_feature_fqi FQI:  131998
nn.learn_nn_feature_fqi FQI:  132998
nn.learn_nn_feature_fqi FQI:  133998
nn.learn_nn_feature_fqi FQI:  134998
nn.learn_nn_feature_fqi FQI:  135998
nn.learn_nn_feature_fqi FQI:  136998
nn.learn_nn_feature_fqi FQI:  137998
nn.learn_nn_feature_fqi FQI:  138998
nn.learn_nn_feature_fqi FQI:  139998
nn.learn_nn_feature_fqi FQI:  140998
nn.learn_nn_feature_fqi FQI:  141998
nn.learn_nn_feature_fqi FQI:  142998
nn.learn_nn_feature_fqi FQI:  143998
nn.learn_nn_feature_fqi FQI:  144998
nn.learn_nn_feature_fqi FQI:  145998
nn.learn_nn_feature_fqi FQI:  146998
nn.learn_nn_feature_fqi FQI:  147998
nn.learn_nn_feature_fqi FQI:  148998
nn.learn_nn_feature_fqi FQI:  149998
nn.learn_nn_feature_fqi FQI:  150998
nn.learn_nn_feature_fqi FQI:  151998
nn.learn_nn_feature_fqi FQI:  152998
nn.learn_nn_feature_fqi FQI:  153998
nn.learn_nn_feature_fqi FQI:  154998
nn.learn_nn_feature_fqi FQI:  155998
0 1001 -1000.0 -98.99572604650622 number episode from 10: 0 avegar over 10 episode: -98.996 avegare return across last 100 episodes: -98.996 state values: tensor(0.6099) 1000
1 1000 -1000.0 -99.99568287525881 number episode from 10: 1 avegar over 10 episode: -99.496 avegare return across last 100 episodes: -99.496 state values: tensor(0.6125) 1000
2 1000 -1000.0 -99.99568287525881 number episode from 10: 2 avegar over 10 episode: -99.662 avegare return across last 100 episodes: -99.662 state values: tensor(0.6207) 1000
3 1000 -1000.0 -99.99568287525881 number episode from 10: 3 avegar over 10 episode: -99.746 avegare return across last 100 episodes: -99.746 state values: tensor(0.6171) 1000
4 1000 -1000.0 -99.99568287525881 number episode from 10: 4 avegar over 10 episode: -99.796 avegare return across last 100 episodes: -99.796 state values: tensor(0.6100) 1000
5 1000 -1000.0 -99.99568287525881 number episode from 10: 5 avegar over 10 episode: -99.829 avegare return across last 100 episodes: -99.829 state values: tensor(0.6099) 1000
6 1000 -1000.0 -99.99568287525881 number episode from 10: 6 avegar over 10 episode: -99.853 avegare return across last 100 episodes: -99.853 state values: tensor(0.6108) 1000
7 1000 -1000.0 -99.99568287525881 number episode from 10: 7 avegar over 10 episode: -99.871 avegare return across last 100 episodes: -99.871 state values: tensor(0.6192) 1000
8 1000 -1000.0 -99.99568287525881 number episode from 10: 8 avegar over 10 episode: -99.885 avegare return across last 100 episodes: -99.885 state values: tensor(0.6110) 1000
9 1000 -1000.0 -99.99568287525881 number episode from 10: 9 avegar over 10 episode: -99.896 avegare return across last 100 episodes: -99.896 state values: tensor(0.6116) 1000
10 1000 -1000.0 -99.99568287525881 number episode from 10: 10 avegar over 10 episode: -99.905 avegare return across last 100 episodes: -99.905 state values: tensor(0.6102) 1000
11 1000 -1000.0 -99.99568287525881 number episode from 10: 11 avegar over 10 episode: -99.912 avegare return across last 100 episodes: -99.912 state values: tensor(0.6133) 1000
12 1000 -1000.0 -99.99568287525881 number episode from 10: 12 avegar over 10 episode: -99.919 avegare return across last 100 episodes: -99.919 state values: tensor(0.6109) 1000
13 1000 -1000.0 -99.99568287525881 number episode from 10: 13 avegar over 10 episode: -99.924 avegare return across last 100 episodes: -99.924 state values: tensor(0.6137) 1000
14 1000 -1000.0 -99.99568287525881 number episode from 10: 14 avegar over 10 episode: -99.929 avegare return across last 100 episodes: -99.929 state values: tensor(0.6116) 1000
15 1000 -1000.0 -99.99568287525881 number episode from 10: 15 avegar over 10 episode: -99.933 avegare return across last 100 episodes: -99.933 state values: tensor(0.6121) 1000
16 1000 -1000.0 -99.99568287525881 number episode from 10: 16 avegar over 10 episode: -99.937 avegare return across last 100 episodes: -99.937 state values: tensor(0.6142) 1000
17 1000 -1000.0 -99.99568287525881 number episode from 10: 17 avegar over 10 episode: -99.94 avegare return across last 100 episodes: -99.94 state values: tensor(0.6107) 1000
18 1000 -1000.0 -99.99568287525881 number episode from 10: 18 avegar over 10 episode: -99.943 avegare return across last 100 episodes: -99.943 state values: tensor(0.6205) 1000
19 1000 -1000.0 -99.99568287525881 number episode from 10: 19 avegar over 10 episode: -99.946 avegare return across last 100 episodes: -99.946 state values: tensor(0.6214) 1000
20 1000 -1000.0 -99.99568287525881 number episode from 10: 20 avegar over 10 episode: -99.948 avegare return across last 100 episodes: -99.948 state values: tensor(0.6131) 1000
21 1000 -1000.0 -99.99568287525881 number episode from 10: 21 avegar over 10 episode: -99.95 avegare return across last 100 episodes: -99.95 state values: tensor(0.6103) 1000
22 1000 -1000.0 -99.99568287525881 number episode from 10: 22 avegar over 10 episode: -99.952 avegare return across last 100 episodes: -99.952 state values: tensor(0.6101) 1000
23 1000 -1000.0 -99.99568287525881 number episode from 10: 23 avegar over 10 episode: -99.954 avegare return across last 100 episodes: -99.954 state values: tensor(0.6147) 1000
24 1000 -1000.0 -99.99568287525881 number episode from 10: 24 avegar over 10 episode: -99.956 avegare return across last 100 episodes: -99.956 state values: tensor(0.6159) 1000
25 1000 -1000.0 -99.99568287525881 number episode from 10: 25 avegar over 10 episode: -99.957 avegare return across last 100 episodes: -99.957 state values: tensor(0.6164) 1000
26 1000 -1000.0 -99.99568287525881 number episode from 10: 26 avegar over 10 episode: -99.959 avegare return across last 100 episodes: -99.959 state values: tensor(0.6107) 1000
27 1000 -1000.0 -99.99568287525881 number episode from 10: 27 avegar over 10 episode: -99.96 avegare return across last 100 episodes: -99.96 state values: tensor(0.6131) 1000
28 1000 -1000.0 -99.99568287525881 number episode from 10: 28 avegar over 10 episode: -99.961 avegare return across last 100 episodes: -99.961 state values: tensor(0.6110) 1000
29 1000 -1000.0 -99.99568287525881 number episode from 10: 29 avegar over 10 episode: -99.962 avegare return across last 100 episodes: -99.962 state values: tensor(0.6234) 1000
30 1000 -1000.0 -99.99568287525881 number episode from 10: 30 avegar over 10 episode: -99.963 avegare return across last 100 episodes: -99.963 state values: tensor(0.6100) 1000
31 1000 -1000.0 -99.99568287525881 number episode from 10: 31 avegar over 10 episode: -99.964 avegare return across last 100 episodes: -99.964 state values: tensor(0.6172) 1000
32 1000 -1000.0 -99.99568287525881 number episode from 10: 32 avegar over 10 episode: -99.965 avegare return across last 100 episodes: -99.965 state values: tensor(0.6116) 1000
33 1000 -1000.0 -99.99568287525881 number episode from 10: 33 avegar over 10 episode: -99.966 avegare return across last 100 episodes: -99.966 state values: tensor(0.6102) 1000
34 1000 -1000.0 -99.99568287525881 number episode from 10: 34 avegar over 10 episode: -99.967 avegare return across last 100 episodes: -99.967 state values: tensor(0.6100) 1000
35 1000 -1000.0 -99.99568287525881 number episode from 10: 35 avegar over 10 episode: -99.968 avegare return across last 100 episodes: -99.968 state values: tensor(0.6128) 1000
36 1000 -1000.0 -99.99568287525881 number episode from 10: 36 avegar over 10 episode: -99.969 avegare return across last 100 episodes: -99.969 state values: tensor(0.6212) 1000
37 1000 -1000.0 -99.99568287525881 number episode from 10: 37 avegar over 10 episode: -99.969 avegare return across last 100 episodes: -99.969 state values: tensor(0.6100) 1000
38 1000 -1000.0 -99.99568287525881 number episode from 10: 38 avegar over 10 episode: -99.97 avegare return across last 100 episodes: -99.97 state values: tensor(0.6100) 1000
39 1000 -1000.0 -99.99568287525881 number episode from 10: 39 avegar over 10 episode: -99.971 avegare return across last 100 episodes: -99.971 state values: tensor(0.6102) 1000
40 1000 -1000.0 -99.99568287525881 number episode from 10: 40 avegar over 10 episode: -99.971 avegare return across last 100 episodes: -99.971 state values: tensor(0.6155) 1000
41 1000 -1000.0 -99.99568287525881 number episode from 10: 41 avegar over 10 episode: -99.972 avegare return across last 100 episodes: -99.972 state values: tensor(0.6100) 1000
42 1000 -1000.0 -99.99568287525881 number episode from 10: 42 avegar over 10 episode: -99.972 avegare return across last 100 episodes: -99.972 state values: tensor(0.6106) 1000
43 1000 -1000.0 -99.99568287525881 number episode from 10: 43 avegar over 10 episode: -99.973 avegare return across last 100 episodes: -99.973 state values: tensor(0.6099) 1000
44 1000 -1000.0 -99.99568287525881 number episode from 10: 44 avegar over 10 episode: -99.973 avegare return across last 100 episodes: -99.973 state values: tensor(0.6098) 1000
45 1000 -1000.0 -99.99568287525881 number episode from 10: 45 avegar over 10 episode: -99.974 avegare return across last 100 episodes: -99.974 state values: tensor(0.6125) 1000
46 1000 -1000.0 -99.99568287525881 number episode from 10: 46 avegar over 10 episode: -99.974 avegare return across last 100 episodes: -99.974 state values: tensor(0.6098) 1000
47 1000 -1000.0 -99.99568287525881 number episode from 10: 47 avegar over 10 episode: -99.975 avegare return across last 100 episodes: -99.975 state values: tensor(0.6100) 1000
48 1000 -1000.0 -99.99568287525881 number episode from 10: 48 avegar over 10 episode: -99.975 avegare return across last 100 episodes: -99.975 state values: tensor(0.6108) 1000
49 1000 -1000.0 -99.99568287525881 number episode from 10: 49 avegar over 10 episode: -99.976 avegare return across last 100 episodes: -99.976 state values: tensor(0.6103) 1000
50 1000 -1000.0 -99.99568287525881 number episode from 10: 50 avegar over 10 episode: -99.976 avegare return across last 100 episodes: -99.976 state values: tensor(0.6098) 1000
51 1000 -1000.0 -99.99568287525881 number episode from 10: 51 avegar over 10 episode: -99.976 avegare return across last 100 episodes: -99.976 state values: tensor(0.6133) 1000
52 1000 -1000.0 -99.99568287525881 number episode from 10: 52 avegar over 10 episode: -99.977 avegare return across last 100 episodes: -99.977 state values: tensor(0.6102) 1000
53 1000 -1000.0 -99.99568287525881 number episode from 10: 53 avegar over 10 episode: -99.977 avegare return across last 100 episodes: -99.977 state values: tensor(0.6102) 1000
54 1000 -1000.0 -99.99568287525881 number episode from 10: 54 avegar over 10 episode: -99.978 avegare return across last 100 episodes: -99.978 state values: tensor(0.6136) 1000
55 1000 -1000.0 -99.99568287525881 number episode from 10: 55 avegar over 10 episode: -99.978 avegare return across last 100 episodes: -99.978 state values: tensor(0.6100) 1000
56 1000 -1000.0 -99.99568287525881 number episode from 10: 56 avegar over 10 episode: -99.978 avegare return across last 100 episodes: -99.978 state values: tensor(0.6105) 1000
57 1000 -1000.0 -99.99568287525881 number episode from 10: 57 avegar over 10 episode: -99.978 avegare return across last 100 episodes: -99.978 state values: tensor(0.6204) 1000
58 1000 -1000.0 -99.99568287525881 number episode from 10: 58 avegar over 10 episode: -99.979 avegare return across last 100 episodes: -99.979 state values: tensor(0.6199) 1000
59 1000 -1000.0 -99.99568287525881 number episode from 10: 59 avegar over 10 episode: -99.979 avegare return across last 100 episodes: -99.979 state values: tensor(0.6217) 1000
60 1000 -1000.0 -99.99568287525881 number episode from 10: 60 avegar over 10 episode: -99.979 avegare return across last 100 episodes: -99.979 state values: tensor(0.6101) 1000
61 1000 -1000.0 -99.99568287525881 number episode from 10: 61 avegar over 10 episode: -99.98 avegare return across last 100 episodes: -99.98 state values: tensor(0.6109) 1000
62 1000 -1000.0 -99.99568287525881 number episode from 10: 62 avegar over 10 episode: -99.98 avegare return across last 100 episodes: -99.98 state values: tensor(0.6099) 1000
63 1000 -1000.0 -99.99568287525881 number episode from 10: 63 avegar over 10 episode: -99.98 avegare return across last 100 episodes: -99.98 state values: tensor(0.6136) 1000
64 1000 -1000.0 -99.99568287525881 number episode from 10: 64 avegar over 10 episode: -99.98 avegare return across last 100 episodes: -99.98 state values: tensor(0.6111) 1000
65 1000 -1000.0 -99.99568287525881 number episode from 10: 65 avegar over 10 episode: -99.981 avegare return across last 100 episodes: -99.981 state values: tensor(0.6161) 1000
66 1000 -1000.0 -99.99568287525881 number episode from 10: 66 avegar over 10 episode: -99.981 avegare return across last 100 episodes: -99.981 state values: tensor(0.6209) 1000
67 1000 -1000.0 -99.99568287525881 number episode from 10: 67 avegar over 10 episode: -99.981 avegare return across last 100 episodes: -99.981 state values: tensor(0.6104) 1000
68 1000 -1000.0 -99.99568287525881 number episode from 10: 68 avegar over 10 episode: -99.981 avegare return across last 100 episodes: -99.981 state values: tensor(0.6126) 1000
69 1000 -1000.0 -99.99568287525881 number episode from 10: 69 avegar over 10 episode: -99.981 avegare return across last 100 episodes: -99.981 state values: tensor(0.6103) 1000
70 1000 -1000.0 -99.99568287525881 number episode from 10: 70 avegar over 10 episode: -99.982 avegare return across last 100 episodes: -99.982 state values: tensor(0.6102) 1000
71 1000 -1000.0 -99.99568287525881 number episode from 10: 71 avegar over 10 episode: -99.982 avegare return across last 100 episodes: -99.982 state values: tensor(0.6159) 1000
72 1000 -1000.0 -99.99568287525881 number episode from 10: 72 avegar over 10 episode: -99.982 avegare return across last 100 episodes: -99.982 state values: tensor(0.6099) 1000
73 1000 -1000.0 -99.99568287525881 number episode from 10: 73 avegar over 10 episode: -99.982 avegare return across last 100 episodes: -99.982 state values: tensor(0.6100) 1000
74 1000 -1000.0 -99.99568287525881 number episode from 10: 74 avegar over 10 episode: -99.982 avegare return across last 100 episodes: -99.982 state values: tensor(0.6109) 1000
75 1000 -1000.0 -99.99568287525881 number episode from 10: 75 avegar over 10 episode: -99.983 avegare return across last 100 episodes: -99.983 state values: tensor(0.6128) 1000
76 1000 -1000.0 -99.99568287525881 number episode from 10: 76 avegar over 10 episode: -99.983 avegare return across last 100 episodes: -99.983 state values: tensor(0.6111) 1000
77 1000 -1000.0 -99.99568287525881 number episode from 10: 77 avegar over 10 episode: -99.983 avegare return across last 100 episodes: -99.983 state values: tensor(0.6135) 1000
78 1000 -1000.0 -99.99568287525881 number episode from 10: 78 avegar over 10 episode: -99.983 avegare return across last 100 episodes: -99.983 state values: tensor(0.6129) 1000
79 1000 -1000.0 -99.99568287525881 number episode from 10: 79 avegar over 10 episode: -99.983 avegare return across last 100 episodes: -99.983 state values: tensor(0.6146) 1000
80 1000 -1000.0 -99.99568287525881 number episode from 10: 80 avegar over 10 episode: -99.983 avegare return across last 100 episodes: -99.983 state values: tensor(0.6099) 1000
81 1000 -1000.0 -99.99568287525881 number episode from 10: 81 avegar over 10 episode: -99.983 avegare return across last 100 episodes: -99.983 state values: tensor(0.6100) 1000
82 1000 -1000.0 -99.99568287525881 number episode from 10: 82 avegar over 10 episode: -99.984 avegare return across last 100 episodes: -99.984 state values: tensor(0.6175) 1000
83 1000 -1000.0 -99.99568287525881 number episode from 10: 83 avegar over 10 episode: -99.984 avegare return across last 100 episodes: -99.984 state values: tensor(0.6169) 1000
84 1000 -1000.0 -99.99568287525881 number episode from 10: 84 avegar over 10 episode: -99.984 avegare return across last 100 episodes: -99.984 state values: tensor(0.6128) 1000
85 1000 -1000.0 -99.99568287525881 number episode from 10: 85 avegar over 10 episode: -99.984 avegare return across last 100 episodes: -99.984 state values: tensor(0.6123) 1000
86 1000 -1000.0 -99.99568287525881 number episode from 10: 86 avegar over 10 episode: -99.984 avegare return across last 100 episodes: -99.984 state values: tensor(0.6099) 1000
87 1000 -1000.0 -99.99568287525881 number episode from 10: 87 avegar over 10 episode: -99.984 avegare return across last 100 episodes: -99.984 state values: tensor(0.6102) 1000
88 1000 -1000.0 -99.99568287525881 number episode from 10: 88 avegar over 10 episode: -99.984 avegare return across last 100 episodes: -99.984 state values: tensor(0.6100) 1000
89 1000 -1000.0 -99.99568287525881 number episode from 10: 89 avegar over 10 episode: -99.985 avegare return across last 100 episodes: -99.985 state values: tensor(0.6103) 1000
90 1000 -1000.0 -99.99568287525881 number episode from 10: 90 avegar over 10 episode: -99.985 avegare return across last 100 episodes: -99.985 state values: tensor(0.6126) 1000
91 1000 -1000.0 -99.99568287525881 number episode from 10: 91 avegar over 10 episode: -99.985 avegare return across last 100 episodes: -99.985 state values: tensor(0.6153) 1000
92 1000 -1000.0 -99.99568287525881 number episode from 10: 92 avegar over 10 episode: -99.985 avegare return across last 100 episodes: -99.985 state values: tensor(0.6131) 1000
93 1000 -1000.0 -99.99568287525881 number episode from 10: 93 avegar over 10 episode: -99.985 avegare return across last 100 episodes: -99.985 state values: tensor(0.6099) 1000
94 1000 -1000.0 -99.99568287525881 number episode from 10: 94 avegar over 10 episode: -99.985 avegare return across last 100 episodes: -99.985 state values: tensor(0.6184) 1000
95 1000 -1000.0 -99.99568287525881 number episode from 10: 95 avegar over 10 episode: -99.985 avegare return across last 100 episodes: -99.985 state values: tensor(0.6105) 1000
96 1000 -1000.0 -99.99568287525881 number episode from 10: 96 avegar over 10 episode: -99.985 avegare return across last 100 episodes: -99.985 state values: tensor(0.6102) 1000
97 1000 -1000.0 -99.99568287525881 number episode from 10: 97 avegar over 10 episode: -99.985 avegare return across last 100 episodes: -99.985 state values: tensor(0.6100) 1000
98 1000 -1000.0 -99.99568287525881 number episode from 10: 98 avegar over 10 episode: -99.986 avegare return across last 100 episodes: -99.986 state values: tensor(0.6102) 1000
99 1000 -1000.0 -99.99568287525881 number episode from 10: 99 avegar over 10 episode: -99.986 avegare return across last 100 episodes: -99.986 state values: tensor(0.6183) 1000
100 1000 -1000.0 -99.99568287525881 number episode from 10: 100 avegar over 10 episode: -99.986 avegare return across last 100 episodes: -99.996 state values: tensor(0.6105) 1000
101 1000 -1000.0 -99.99568287525881 number episode from 10: 101 avegar over 10 episode: -99.986 avegare return across last 100 episodes: -99.996 state values: tensor(0.6118) 1000
102 1000 -1000.0 -99.99568287525881 number episode from 10: 102 avegar over 10 episode: -99.986 avegare return across last 100 episodes: -99.996 state values: tensor(0.6099) 1000
103 1000 -1000.0 -99.99568287525881 number episode from 10: 103 avegar over 10 episode: -99.986 avegare return across last 100 episodes: -99.996 state values: tensor(0.6118) 1000
104 1000 -1000.0 -99.99568287525881 number episode from 10: 104 avegar over 10 episode: -99.986 avegare return across last 100 episodes: -99.996 state values: tensor(0.6103) 1000
105 1000 -1000.0 -99.99568287525881 number episode from 10: 105 avegar over 10 episode: -99.986 avegare return across last 100 episodes: -99.996 state values: tensor(0.6100) 1000
106 1000 -1000.0 -99.99568287525881 number episode from 10: 106 avegar over 10 episode: -99.986 avegare return across last 100 episodes: -99.996 state values: tensor(0.6115) 1000
107 1000 -1000.0 -99.99568287525881 number episode from 10: 107 avegar over 10 episode: -99.986 avegare return across last 100 episodes: -99.996 state values: tensor(0.6098) 1000
108 1000 -1000.0 -99.99568287525881 number episode from 10: 108 avegar over 10 episode: -99.987 avegare return across last 100 episodes: -99.996 state values: tensor(0.6109) 1000
109 1000 -1000.0 -99.99568287525881 number episode from 10: 109 avegar over 10 episode: -99.987 avegare return across last 100 episodes: -99.996 state values: tensor(0.6098) 1000
110 1000 -1000.0 -99.99568287525881 number episode from 10: 110 avegar over 10 episode: -99.987 avegare return across last 100 episodes: -99.996 state values: tensor(0.6109) 1000
111 1000 -1000.0 -99.99568287525881 number episode from 10: 111 avegar over 10 episode: -99.987 avegare return across last 100 episodes: -99.996 state values: tensor(0.6146) 1000
112 1000 -1000.0 -99.99568287525881 number episode from 10: 112 avegar over 10 episode: -99.987 avegare return across last 100 episodes: -99.996 state values: tensor(0.6128) 1000
113 1000 -1000.0 -99.99568287525881 number episode from 10: 113 avegar over 10 episode: -99.987 avegare return across last 100 episodes: -99.996 state values: tensor(0.6146) 1000
114 1000 -1000.0 -99.99568287525881 number episode from 10: 114 avegar over 10 episode: -99.987 avegare return across last 100 episodes: -99.996 state values: tensor(0.6114) 1000
115 1000 -1000.0 -99.99568287525881 number episode from 10: 115 avegar over 10 episode: -99.987 avegare return across last 100 episodes: -99.996 state values: tensor(0.6101) 1000
116 1000 -1000.0 -99.99568287525881 number episode from 10: 116 avegar over 10 episode: -99.987 avegare return across last 100 episodes: -99.996 state values: tensor(0.6099) 1000
117 1000 -1000.0 -99.99568287525881 number episode from 10: 117 avegar over 10 episode: -99.987 avegare return across last 100 episodes: -99.996 state values: tensor(0.6099) 1000
118 1000 -1000.0 -99.99568287525881 number episode from 10: 118 avegar over 10 episode: -99.987 avegare return across last 100 episodes: -99.996 state values: tensor(0.6098) 1000
119 1000 -1000.0 -99.99568287525881 number episode from 10: 119 avegar over 10 episode: -99.987 avegare return across last 100 episodes: -99.996 state values: tensor(0.6103) 1000
120 1000 -1000.0 -99.99568287525881 number episode from 10: 120 avegar over 10 episode: -99.987 avegare return across last 100 episodes: -99.996 state values: tensor(0.6105) 1000
121 1000 -1000.0 -99.99568287525881 number episode from 10: 121 avegar over 10 episode: -99.987 avegare return across last 100 episodes: -99.996 state values: tensor(0.6118) 1000
122 1000 -1000.0 -99.99568287525881 number episode from 10: 122 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.6160) 1000
123 1000 -1000.0 -99.99568287525881 number episode from 10: 123 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.6098) 1000
124 1000 -1000.0 -99.99568287525881 number episode from 10: 124 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.6124) 1000
125 1000 -1000.0 -99.99568287525881 number episode from 10: 125 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.6099) 1000
126 1000 -1000.0 -99.99568287525881 number episode from 10: 126 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.6160) 1000
127 1000 -1000.0 -99.99568287525881 number episode from 10: 127 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.6105) 1000
128 1000 -1000.0 -99.99568287525881 number episode from 10: 128 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.6105) 1000
129 1000 -1000.0 -99.99568287525881 number episode from 10: 129 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.6162) 1000
130 1000 -1000.0 -99.99568287525881 number episode from 10: 130 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.6106) 1000
131 1000 -1000.0 -99.99568287525881 number episode from 10: 131 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.6138) 1000
132 1000 -1000.0 -99.99568287525881 number episode from 10: 132 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.6101) 1000
133 1000 -1000.0 -99.99568287525881 number episode from 10: 133 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.6099) 1000
134 1000 -1000.0 -99.99568287525881 number episode from 10: 134 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.6170) 1000
135 1000 -1000.0 -99.99568287525881 number episode from 10: 135 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.6139) 1000
136 1000 -1000.0 -99.99568287525881 number episode from 10: 136 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.6101) 1000
137 1000 -1000.0 -99.99568287525881 number episode from 10: 137 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.6133) 1000
138 1000 -1000.0 -99.99568287525881 number episode from 10: 138 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.6142) 1000
139 1000 -1000.0 -99.99568287525881 number episode from 10: 139 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.6197) 1000
140 1000 -1000.0 -99.99568287525881 number episode from 10: 140 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.6120) 1000
141 1000 -1000.0 -99.99568287525881 number episode from 10: 141 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.6099) 1000
142 1000 -1000.0 -99.99568287525881 number episode from 10: 142 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.6249) 1000
143 1000 -1000.0 -99.99568287525881 number episode from 10: 143 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.6128) 1000
144 1000 -1000.0 -99.99568287525881 number episode from 10: 144 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.6203) 1000
145 1000 -1000.0 -99.99568287525881 number episode from 10: 145 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.6159) 1000
146 1000 -1000.0 -99.99568287525881 number episode from 10: 146 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.6180) 1000
147 1000 -1000.0 -99.99568287525881 number episode from 10: 147 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.6100) 1000
148 1000 -1000.0 -99.99568287525881 number episode from 10: 148 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.6101) 1000
149 1000 -1000.0 -99.99568287525881 number episode from 10: 149 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.6128) 1000
150 1000 -1000.0 -99.99568287525881 number episode from 10: 150 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.6120) 1000
151 1000 -1000.0 -99.99568287525881 number episode from 10: 151 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.6104) 1000
152 1000 -1000.0 -99.99568287525881 number episode from 10: 152 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.6178) 1000
153 1000 -1000.0 -99.99568287525881 number episode from 10: 153 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.6098) 1000
154 1000 -1000.0 -99.99568287525881 number episode from 10: 154 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.6133) 1000
155 1000 -1000.0 -99.99568287525881 number episode from 10: 155 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.6152) 1000
156 1000 -1000.0 -99.99568287525881 number episode from 10: 156 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.6177) 1000
157 1000 -1000.0 -99.99568287525881 number episode from 10: 157 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.6108) 1000
158 1000 -1000.0 -99.99568287525881 number episode from 10: 158 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.6116) 1000
159 1000 -1000.0 -99.99568287525881 number episode from 10: 159 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.6124) 1000
160 1000 -1000.0 -99.99568287525881 number episode from 10: 160 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.6120) 1000
161 1000 -1000.0 -99.99568287525881 number episode from 10: 161 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.6111) 1000
162 1000 -1000.0 -99.99568287525881 number episode from 10: 162 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.6146) 1000
163 1000 -1000.0 -99.99568287525881 number episode from 10: 163 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.6184) 1000
164 1000 -1000.0 -99.99568287525881 number episode from 10: 164 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.6100) 1000
165 1000 -1000.0 -99.99568287525881 number episode from 10: 165 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.6124) 1000
166 1000 -1000.0 -99.99568287525881 number episode from 10: 166 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.6157) 1000
167 1000 -1000.0 -99.99568287525881 number episode from 10: 167 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.6148) 1000
168 1000 -1000.0 -99.99568287525881 number episode from 10: 168 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.6215) 1000
169 1000 -1000.0 -99.99568287525881 number episode from 10: 169 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.6199) 1000
170 1000 -1000.0 -99.99568287525881 number episode from 10: 170 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.6102) 1000
171 1000 -1000.0 -99.99568287525881 number episode from 10: 171 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.6131) 1000
172 1000 -1000.0 -99.99568287525881 number episode from 10: 172 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.6195) 1000
173 1000 -1000.0 -99.99568287525881 number episode from 10: 173 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.6202) 1000
174 1000 -1000.0 -99.99568287525881 number episode from 10: 174 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.6118) 1000
175 1000 -1000.0 -99.99568287525881 number episode from 10: 175 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.6161) 1000
176 1000 -1000.0 -99.99568287525881 number episode from 10: 176 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.6101) 1000
177 1000 -1000.0 -99.99568287525881 number episode from 10: 177 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.6195) 1000
178 1000 -1000.0 -99.99568287525881 number episode from 10: 178 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.6106) 1000
179 1000 -1000.0 -99.99568287525881 number episode from 10: 179 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.6198) 1000
180 1000 -1000.0 -99.99568287525881 number episode from 10: 180 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.6134) 1000
181 1000 -1000.0 -99.99568287525881 number episode from 10: 181 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.6113) 1000
182 1000 -1000.0 -99.99568287525881 number episode from 10: 182 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.6105) 1000
183 1000 -1000.0 -99.99568287525881 number episode from 10: 183 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.6101) 1000
184 1000 -1000.0 -99.99568287525881 number episode from 10: 184 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.6151) 1000
185 1000 -1000.0 -99.99568287525881 number episode from 10: 185 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.6099) 1000
186 1000 -1000.0 -99.99568287525881 number episode from 10: 186 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.6098) 1000
187 1000 -1000.0 -99.99568287525881 number episode from 10: 187 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.6221) 1000
188 1000 -1000.0 -99.99568287525881 number episode from 10: 188 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.6097) 1000
189 1000 -1000.0 -99.99568287525881 number episode from 10: 189 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.6102) 1000
190 1000 -1000.0 -99.99568287525881 number episode from 10: 190 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.6101) 1000
191 1000 -1000.0 -99.99568287525881 number episode from 10: 191 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.6100) 1000
192 1000 -1000.0 -99.99568287525881 number episode from 10: 192 avegar over 10 episode: -99.991 avegare return across last 100 episodes: -99.996 state values: tensor(0.6137) 1000
193 1000 -1000.0 -99.99568287525881 number episode from 10: 193 avegar over 10 episode: -99.991 avegare return across last 100 episodes: -99.996 state values: tensor(0.6214) 1000
194 1000 -1000.0 -99.99568287525881 number episode from 10: 194 avegar over 10 episode: -99.991 avegare return across last 100 episodes: -99.996 state values: tensor(0.6206) 1000
195 1000 -1000.0 -99.99568287525881 number episode from 10: 195 avegar over 10 episode: -99.991 avegare return across last 100 episodes: -99.996 state values: tensor(0.6161) 1000
196 1000 -1000.0 -99.99568287525881 number episode from 10: 196 avegar over 10 episode: -99.991 avegare return across last 100 episodes: -99.996 state values: tensor(0.6102) 1000
197 1000 -1000.0 -99.99568287525881 number episode from 10: 197 avegar over 10 episode: -99.991 avegare return across last 100 episodes: -99.996 state values: tensor(0.6113) 1000
198 1000 -1000.0 -99.99568287525881 number episode from 10: 198 avegar over 10 episode: -99.991 avegare return across last 100 episodes: -99.996 state values: tensor(0.6118) 1000
199 1000 -1000.0 -99.99568287525881 number episode from 10: 199 avegar over 10 episode: -99.991 avegare return across last 100 episodes: -99.996 state values: tensor(0.6153) 1000
200 1000 -1000.0 -99.99568287525881 number episode from 10: 200 avegar over 10 episode: -99.991 avegare return across last 100 episodes: -99.996 state values: tensor(0.6138) 1000
