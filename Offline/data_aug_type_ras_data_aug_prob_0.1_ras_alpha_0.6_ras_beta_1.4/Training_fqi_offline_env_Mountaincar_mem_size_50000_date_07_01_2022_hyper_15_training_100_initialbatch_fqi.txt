Start! Seed: 0
0 1001 -1000.0 -98.99572604650622 number episode from 10: 0 avegar over 10 episode: -98.996 avegare return across last 100 episodes: -98.996 state values: tensor(0.7043) 1000
1 1000 -1000.0 -99.99568287525881 number episode from 10: 1 avegar over 10 episode: -99.496 avegare return across last 100 episodes: -99.496 state values: tensor(0.6887) 1000
2 1000 -1000.0 -99.99568287525881 number episode from 10: 2 avegar over 10 episode: -99.662 avegare return across last 100 episodes: -99.662 state values: tensor(0.6922) 1000
3 1000 -1000.0 -99.99568287525881 number episode from 10: 3 avegar over 10 episode: -99.746 avegare return across last 100 episodes: -99.746 state values: tensor(0.6926) 1000
4 1000 -1000.0 -99.99568287525881 number episode from 10: 4 avegar over 10 episode: -99.796 avegare return across last 100 episodes: -99.796 state values: tensor(0.6922) 1000
5 1000 -1000.0 -99.99568287525881 number episode from 10: 5 avegar over 10 episode: -99.829 avegare return across last 100 episodes: -99.829 state values: tensor(0.7025) 1000
6 1000 -1000.0 -99.99568287525881 number episode from 10: 6 avegar over 10 episode: -99.853 avegare return across last 100 episodes: -99.853 state values: tensor(0.6927) 1000
7 1000 -1000.0 -99.99568287525881 number episode from 10: 7 avegar over 10 episode: -99.871 avegare return across last 100 episodes: -99.871 state values: tensor(0.6957) 1000
8 1000 -1000.0 -99.99568287525881 number episode from 10: 8 avegar over 10 episode: -99.885 avegare return across last 100 episodes: -99.885 state values: tensor(0.7001) 1000
9 1000 -1000.0 -99.99568287525881 number episode from 10: 9 avegar over 10 episode: -99.896 avegare return across last 100 episodes: -99.896 state values: tensor(0.7033) 1000
10 1000 -1000.0 -99.99568287525881 number episode from 10: 10 avegar over 10 episode: -99.905 avegare return across last 100 episodes: -99.905 state values: tensor(0.6893) 1000
11 1000 -1000.0 -99.99568287525881 number episode from 10: 11 avegar over 10 episode: -99.912 avegare return across last 100 episodes: -99.912 state values: tensor(0.6938) 1000
12 1000 -1000.0 -99.99568287525881 number episode from 10: 12 avegar over 10 episode: -99.919 avegare return across last 100 episodes: -99.919 state values: tensor(0.6978) 1000
13 1000 -1000.0 -99.99568287525881 number episode from 10: 13 avegar over 10 episode: -99.924 avegare return across last 100 episodes: -99.924 state values: tensor(0.6895) 1000
14 1000 -1000.0 -99.99568287525881 number episode from 10: 14 avegar over 10 episode: -99.929 avegare return across last 100 episodes: -99.929 state values: tensor(0.6895) 1000
15 1000 -1000.0 -99.99568287525881 number episode from 10: 15 avegar over 10 episode: -99.933 avegare return across last 100 episodes: -99.933 state values: tensor(0.6896) 1000
16 1000 -1000.0 -99.99568287525881 number episode from 10: 16 avegar over 10 episode: -99.937 avegare return across last 100 episodes: -99.937 state values: tensor(0.7019) 1000
17 1000 -1000.0 -99.99568287525881 number episode from 10: 17 avegar over 10 episode: -99.94 avegare return across last 100 episodes: -99.94 state values: tensor(0.6900) 1000
18 1000 -1000.0 -99.99568287525881 number episode from 10: 18 avegar over 10 episode: -99.943 avegare return across last 100 episodes: -99.943 state values: tensor(0.6895) 1000
19 1000 -1000.0 -99.99568287525881 number episode from 10: 19 avegar over 10 episode: -99.946 avegare return across last 100 episodes: -99.946 state values: tensor(0.6901) 1000
20 1000 -1000.0 -99.99568287525881 number episode from 10: 20 avegar over 10 episode: -99.948 avegare return across last 100 episodes: -99.948 state values: tensor(0.7082) 1000
21 1000 -1000.0 -99.99568287525881 number episode from 10: 21 avegar over 10 episode: -99.95 avegare return across last 100 episodes: -99.95 state values: tensor(0.6892) 1000
22 1000 -1000.0 -99.99568287525881 number episode from 10: 22 avegar over 10 episode: -99.952 avegare return across last 100 episodes: -99.952 state values: tensor(0.6894) 1000
23 1000 -1000.0 -99.99568287525881 number episode from 10: 23 avegar over 10 episode: -99.954 avegare return across last 100 episodes: -99.954 state values: tensor(0.6962) 1000
24 1000 -1000.0 -99.99568287525881 number episode from 10: 24 avegar over 10 episode: -99.956 avegare return across last 100 episodes: -99.956 state values: tensor(0.7007) 1000
25 1000 -1000.0 -99.99568287525881 number episode from 10: 25 avegar over 10 episode: -99.957 avegare return across last 100 episodes: -99.957 state values: tensor(0.6891) 1000
26 1000 -1000.0 -99.99568287525881 number episode from 10: 26 avegar over 10 episode: -99.959 avegare return across last 100 episodes: -99.959 state values: tensor(0.6896) 1000
27 1000 -1000.0 -99.99568287525881 number episode from 10: 27 avegar over 10 episode: -99.96 avegare return across last 100 episodes: -99.96 state values: tensor(0.6896) 1000
28 1000 -1000.0 -99.99568287525881 number episode from 10: 28 avegar over 10 episode: -99.961 avegare return across last 100 episodes: -99.961 state values: tensor(0.7004) 1000
29 1000 -1000.0 -99.99568287525881 number episode from 10: 29 avegar over 10 episode: -99.962 avegare return across last 100 episodes: -99.962 state values: tensor(0.6893) 1000
30 1000 -1000.0 -99.99568287525881 number episode from 10: 30 avegar over 10 episode: -99.963 avegare return across last 100 episodes: -99.963 state values: tensor(0.6892) 1000
31 1000 -1000.0 -99.99568287525881 number episode from 10: 31 avegar over 10 episode: -99.964 avegare return across last 100 episodes: -99.964 state values: tensor(0.6962) 1000
32 1000 -1000.0 -99.99568287525881 number episode from 10: 32 avegar over 10 episode: -99.965 avegare return across last 100 episodes: -99.965 state values: tensor(0.6892) 1000
33 1000 -1000.0 -99.99568287525881 number episode from 10: 33 avegar over 10 episode: -99.966 avegare return across last 100 episodes: -99.966 state values: tensor(0.6906) 1000
34 1000 -1000.0 -99.99568287525881 number episode from 10: 34 avegar over 10 episode: -99.967 avegare return across last 100 episodes: -99.967 state values: tensor(0.6979) 1000
35 1000 -1000.0 -99.99568287525881 number episode from 10: 35 avegar over 10 episode: -99.968 avegare return across last 100 episodes: -99.968 state values: tensor(0.6962) 1000
36 1000 -1000.0 -99.99568287525881 number episode from 10: 36 avegar over 10 episode: -99.969 avegare return across last 100 episodes: -99.969 state values: tensor(0.6915) 1000
37 1000 -1000.0 -99.99568287525881 number episode from 10: 37 avegar over 10 episode: -99.969 avegare return across last 100 episodes: -99.969 state values: tensor(0.6911) 1000
38 1000 -1000.0 -99.99568287525881 number episode from 10: 38 avegar over 10 episode: -99.97 avegare return across last 100 episodes: -99.97 state values: tensor(0.7105) 1000
39 1000 -1000.0 -99.99568287525881 number episode from 10: 39 avegar over 10 episode: -99.971 avegare return across last 100 episodes: -99.971 state values: tensor(0.6923) 1000
40 1000 -1000.0 -99.99568287525881 number episode from 10: 40 avegar over 10 episode: -99.971 avegare return across last 100 episodes: -99.971 state values: tensor(0.6971) 1000
41 1000 -1000.0 -99.99568287525881 number episode from 10: 41 avegar over 10 episode: -99.972 avegare return across last 100 episodes: -99.972 state values: tensor(0.6911) 1000
42 1000 -1000.0 -99.99568287525881 number episode from 10: 42 avegar over 10 episode: -99.972 avegare return across last 100 episodes: -99.972 state values: tensor(0.6935) 1000
43 1000 -1000.0 -99.99568287525881 number episode from 10: 43 avegar over 10 episode: -99.973 avegare return across last 100 episodes: -99.973 state values: tensor(0.6968) 1000
44 1000 -1000.0 -99.99568287525881 number episode from 10: 44 avegar over 10 episode: -99.973 avegare return across last 100 episodes: -99.973 state values: tensor(0.6909) 1000
45 1000 -1000.0 -99.99568287525881 number episode from 10: 45 avegar over 10 episode: -99.974 avegare return across last 100 episodes: -99.974 state values: tensor(0.6895) 1000
46 1000 -1000.0 -99.99568287525881 number episode from 10: 46 avegar over 10 episode: -99.974 avegare return across last 100 episodes: -99.974 state values: tensor(0.6916) 1000
47 1000 -1000.0 -99.99568287525881 number episode from 10: 47 avegar over 10 episode: -99.975 avegare return across last 100 episodes: -99.975 state values: tensor(0.7050) 1000
48 1000 -1000.0 -99.99568287525881 number episode from 10: 48 avegar over 10 episode: -99.975 avegare return across last 100 episodes: -99.975 state values: tensor(0.7016) 1000
49 1000 -1000.0 -99.99568287525881 number episode from 10: 49 avegar over 10 episode: -99.976 avegare return across last 100 episodes: -99.976 state values: tensor(0.6891) 1000
50 1000 -1000.0 -99.99568287525881 number episode from 10: 50 avegar over 10 episode: -99.976 avegare return across last 100 episodes: -99.976 state values: tensor(0.6897) 1000
51 1000 -1000.0 -99.99568287525881 number episode from 10: 51 avegar over 10 episode: -99.976 avegare return across last 100 episodes: -99.976 state values: tensor(0.6957) 1000
52 1000 -1000.0 -99.99568287525881 number episode from 10: 52 avegar over 10 episode: -99.977 avegare return across last 100 episodes: -99.977 state values: tensor(0.6896) 1000
53 1000 -1000.0 -99.99568287525881 number episode from 10: 53 avegar over 10 episode: -99.977 avegare return across last 100 episodes: -99.977 state values: tensor(0.6902) 1000
54 1000 -1000.0 -99.99568287525881 number episode from 10: 54 avegar over 10 episode: -99.978 avegare return across last 100 episodes: -99.978 state values: tensor(0.6994) 1000
55 1000 -1000.0 -99.99568287525881 number episode from 10: 55 avegar over 10 episode: -99.978 avegare return across last 100 episodes: -99.978 state values: tensor(0.6907) 1000
56 1000 -1000.0 -99.99568287525881 number episode from 10: 56 avegar over 10 episode: -99.978 avegare return across last 100 episodes: -99.978 state values: tensor(0.6986) 1000
57 1000 -1000.0 -99.99568287525881 number episode from 10: 57 avegar over 10 episode: -99.978 avegare return across last 100 episodes: -99.978 state values: tensor(0.6987) 1000
58 1000 -1000.0 -99.99568287525881 number episode from 10: 58 avegar over 10 episode: -99.979 avegare return across last 100 episodes: -99.979 state values: tensor(0.6906) 1000
59 1000 -1000.0 -99.99568287525881 number episode from 10: 59 avegar over 10 episode: -99.979 avegare return across last 100 episodes: -99.979 state values: tensor(0.6954) 1000
60 1000 -1000.0 -99.99568287525881 number episode from 10: 60 avegar over 10 episode: -99.979 avegare return across last 100 episodes: -99.979 state values: tensor(0.6906) 1000
61 1000 -1000.0 -99.99568287525881 number episode from 10: 61 avegar over 10 episode: -99.98 avegare return across last 100 episodes: -99.98 state values: tensor(0.6893) 1000
62 1000 -1000.0 -99.99568287525881 number episode from 10: 62 avegar over 10 episode: -99.98 avegare return across last 100 episodes: -99.98 state values: tensor(0.6999) 1000
63 1000 -1000.0 -99.99568287525881 number episode from 10: 63 avegar over 10 episode: -99.98 avegare return across last 100 episodes: -99.98 state values: tensor(0.6952) 1000
64 1000 -1000.0 -99.99568287525881 number episode from 10: 64 avegar over 10 episode: -99.98 avegare return across last 100 episodes: -99.98 state values: tensor(0.6891) 1000
65 1000 -1000.0 -99.99568287525881 number episode from 10: 65 avegar over 10 episode: -99.981 avegare return across last 100 episodes: -99.981 state values: tensor(0.6898) 1000
66 1000 -1000.0 -99.99568287525881 number episode from 10: 66 avegar over 10 episode: -99.981 avegare return across last 100 episodes: -99.981 state values: tensor(0.6892) 1000
67 1000 -1000.0 -99.99568287525881 number episode from 10: 67 avegar over 10 episode: -99.981 avegare return across last 100 episodes: -99.981 state values: tensor(0.6938) 1000
68 1000 -1000.0 -99.99568287525881 number episode from 10: 68 avegar over 10 episode: -99.981 avegare return across last 100 episodes: -99.981 state values: tensor(0.6893) 1000
69 1000 -1000.0 -99.99568287525881 number episode from 10: 69 avegar over 10 episode: -99.981 avegare return across last 100 episodes: -99.981 state values: tensor(0.6901) 1000
70 1000 -1000.0 -99.99568287525881 number episode from 10: 70 avegar over 10 episode: -99.982 avegare return across last 100 episodes: -99.982 state values: tensor(0.6932) 1000
71 1000 -1000.0 -99.99568287525881 number episode from 10: 71 avegar over 10 episode: -99.982 avegare return across last 100 episodes: -99.982 state values: tensor(0.6893) 1000
72 1000 -1000.0 -99.99568287525881 number episode from 10: 72 avegar over 10 episode: -99.982 avegare return across last 100 episodes: -99.982 state values: tensor(0.6893) 1000
73 1000 -1000.0 -99.99568287525881 number episode from 10: 73 avegar over 10 episode: -99.982 avegare return across last 100 episodes: -99.982 state values: tensor(0.6996) 1000
74 1000 -1000.0 -99.99568287525881 number episode from 10: 74 avegar over 10 episode: -99.982 avegare return across last 100 episodes: -99.982 state values: tensor(0.6973) 1000
75 1000 -1000.0 -99.99568287525881 number episode from 10: 75 avegar over 10 episode: -99.983 avegare return across last 100 episodes: -99.983 state values: tensor(0.6895) 1000
76 1000 -1000.0 -99.99568287525881 number episode from 10: 76 avegar over 10 episode: -99.983 avegare return across last 100 episodes: -99.983 state values: tensor(0.6892) 1000
77 1000 -1000.0 -99.99568287525881 number episode from 10: 77 avegar over 10 episode: -99.983 avegare return across last 100 episodes: -99.983 state values: tensor(0.6897) 1000
78 1000 -1000.0 -99.99568287525881 number episode from 10: 78 avegar over 10 episode: -99.983 avegare return across last 100 episodes: -99.983 state values: tensor(0.6958) 1000
79 1000 -1000.0 -99.99568287525881 number episode from 10: 79 avegar over 10 episode: -99.983 avegare return across last 100 episodes: -99.983 state values: tensor(0.6889) 1000
80 1000 -1000.0 -99.99568287525881 number episode from 10: 80 avegar over 10 episode: -99.983 avegare return across last 100 episodes: -99.983 state values: tensor(0.7032) 1000
81 1000 -1000.0 -99.99568287525881 number episode from 10: 81 avegar over 10 episode: -99.983 avegare return across last 100 episodes: -99.983 state values: tensor(0.7014) 1000
82 1000 -1000.0 -99.99568287525881 number episode from 10: 82 avegar over 10 episode: -99.984 avegare return across last 100 episodes: -99.984 state values: tensor(0.6983) 1000
83 1000 -1000.0 -99.99568287525881 number episode from 10: 83 avegar over 10 episode: -99.984 avegare return across last 100 episodes: -99.984 state values: tensor(0.7018) 1000
84 1000 -1000.0 -99.99568287525881 number episode from 10: 84 avegar over 10 episode: -99.984 avegare return across last 100 episodes: -99.984 state values: tensor(0.6894) 1000
85 1000 -1000.0 -99.99568287525881 number episode from 10: 85 avegar over 10 episode: -99.984 avegare return across last 100 episodes: -99.984 state values: tensor(0.6894) 1000
86 1000 -1000.0 -99.99568287525881 number episode from 10: 86 avegar over 10 episode: -99.984 avegare return across last 100 episodes: -99.984 state values: tensor(0.6933) 1000
87 1000 -1000.0 -99.99568287525881 number episode from 10: 87 avegar over 10 episode: -99.984 avegare return across last 100 episodes: -99.984 state values: tensor(0.6901) 1000
88 1000 -1000.0 -99.99568287525881 number episode from 10: 88 avegar over 10 episode: -99.984 avegare return across last 100 episodes: -99.984 state values: tensor(0.7047) 1000
89 1000 -1000.0 -99.99568287525881 number episode from 10: 89 avegar over 10 episode: -99.985 avegare return across last 100 episodes: -99.985 state values: tensor(0.6903) 1000
90 1000 -1000.0 -99.99568287525881 number episode from 10: 90 avegar over 10 episode: -99.985 avegare return across last 100 episodes: -99.985 state values: tensor(0.6935) 1000
91 1000 -1000.0 -99.99568287525881 number episode from 10: 91 avegar over 10 episode: -99.985 avegare return across last 100 episodes: -99.985 state values: tensor(0.6893) 1000
92 1000 -1000.0 -99.99568287525881 number episode from 10: 92 avegar over 10 episode: -99.985 avegare return across last 100 episodes: -99.985 state values: tensor(0.6907) 1000
93 1000 -1000.0 -99.99568287525881 number episode from 10: 93 avegar over 10 episode: -99.985 avegare return across last 100 episodes: -99.985 state values: tensor(0.6893) 1000
94 1000 -1000.0 -99.99568287525881 number episode from 10: 94 avegar over 10 episode: -99.985 avegare return across last 100 episodes: -99.985 state values: tensor(0.7004) 1000
95 1000 -1000.0 -99.99568287525881 number episode from 10: 95 avegar over 10 episode: -99.985 avegare return across last 100 episodes: -99.985 state values: tensor(0.6893) 1000
96 1000 -1000.0 -99.99568287525881 number episode from 10: 96 avegar over 10 episode: -99.985 avegare return across last 100 episodes: -99.985 state values: tensor(0.6897) 1000
97 1000 -1000.0 -99.99568287525881 number episode from 10: 97 avegar over 10 episode: -99.985 avegare return across last 100 episodes: -99.985 state values: tensor(0.6907) 1000
98 1000 -1000.0 -99.99568287525881 number episode from 10: 98 avegar over 10 episode: -99.986 avegare return across last 100 episodes: -99.986 state values: tensor(0.6893) 1000
99 1000 -1000.0 -99.99568287525881 number episode from 10: 99 avegar over 10 episode: -99.986 avegare return across last 100 episodes: -99.986 state values: tensor(0.7004) 1000
100 1000 -1000.0 -99.99568287525881 number episode from 10: 100 avegar over 10 episode: -99.986 avegare return across last 100 episodes: -99.996 state values: tensor(0.7005) 1000
101 1000 -1000.0 -99.99568287525881 number episode from 10: 101 avegar over 10 episode: -99.986 avegare return across last 100 episodes: -99.996 state values: tensor(0.6935) 1000
102 1000 -1000.0 -99.99568287525881 number episode from 10: 102 avegar over 10 episode: -99.986 avegare return across last 100 episodes: -99.996 state values: tensor(0.6956) 1000
103 1000 -1000.0 -99.99568287525881 number episode from 10: 103 avegar over 10 episode: -99.986 avegare return across last 100 episodes: -99.996 state values: tensor(0.6924) 1000
104 1000 -1000.0 -99.99568287525881 number episode from 10: 104 avegar over 10 episode: -99.986 avegare return across last 100 episodes: -99.996 state values: tensor(0.6935) 1000
105 1000 -1000.0 -99.99568287525881 number episode from 10: 105 avegar over 10 episode: -99.986 avegare return across last 100 episodes: -99.996 state values: tensor(0.7064) 1000
106 1000 -1000.0 -99.99568287525881 number episode from 10: 106 avegar over 10 episode: -99.986 avegare return across last 100 episodes: -99.996 state values: tensor(0.6999) 1000
107 1000 -1000.0 -99.99568287525881 number episode from 10: 107 avegar over 10 episode: -99.986 avegare return across last 100 episodes: -99.996 state values: tensor(0.6941) 1000
108 1000 -1000.0 -99.99568287525881 number episode from 10: 108 avegar over 10 episode: -99.987 avegare return across last 100 episodes: -99.996 state values: tensor(0.6968) 1000
109 1000 -1000.0 -99.99568287525881 number episode from 10: 109 avegar over 10 episode: -99.987 avegare return across last 100 episodes: -99.996 state values: tensor(0.6916) 1000
110 1000 -1000.0 -99.99568287525881 number episode from 10: 110 avegar over 10 episode: -99.987 avegare return across last 100 episodes: -99.996 state values: tensor(0.6893) 1000
111 1000 -1000.0 -99.99568287525881 number episode from 10: 111 avegar over 10 episode: -99.987 avegare return across last 100 episodes: -99.996 state values: tensor(0.6959) 1000
112 1000 -1000.0 -99.99568287525881 number episode from 10: 112 avegar over 10 episode: -99.987 avegare return across last 100 episodes: -99.996 state values: tensor(0.6985) 1000
113 1000 -1000.0 -99.99568287525881 number episode from 10: 113 avegar over 10 episode: -99.987 avegare return across last 100 episodes: -99.996 state values: tensor(0.6911) 1000
114 1000 -1000.0 -99.99568287525881 number episode from 10: 114 avegar over 10 episode: -99.987 avegare return across last 100 episodes: -99.996 state values: tensor(0.6894) 1000
115 1000 -1000.0 -99.99568287525881 number episode from 10: 115 avegar over 10 episode: -99.987 avegare return across last 100 episodes: -99.996 state values: tensor(0.6895) 1000
116 1000 -1000.0 -99.99568287525881 number episode from 10: 116 avegar over 10 episode: -99.987 avegare return across last 100 episodes: -99.996 state values: tensor(0.6895) 1000
117 1000 -1000.0 -99.99568287525881 number episode from 10: 117 avegar over 10 episode: -99.987 avegare return across last 100 episodes: -99.996 state values: tensor(0.6908) 1000
118 1000 -1000.0 -99.99568287525881 number episode from 10: 118 avegar over 10 episode: -99.987 avegare return across last 100 episodes: -99.996 state values: tensor(0.6908) 1000
119 1000 -1000.0 -99.99568287525881 number episode from 10: 119 avegar over 10 episode: -99.987 avegare return across last 100 episodes: -99.996 state values: tensor(0.6941) 1000
120 1000 -1000.0 -99.99568287525881 number episode from 10: 120 avegar over 10 episode: -99.987 avegare return across last 100 episodes: -99.996 state values: tensor(0.6893) 1000
121 1000 -1000.0 -99.99568287525881 number episode from 10: 121 avegar over 10 episode: -99.987 avegare return across last 100 episodes: -99.996 state values: tensor(0.6925) 1000
122 1000 -1000.0 -99.99568287525881 number episode from 10: 122 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.6936) 1000
123 1000 -1000.0 -99.99568287525881 number episode from 10: 123 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.6889) 1000
124 1000 -1000.0 -99.99568287525881 number episode from 10: 124 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.6923) 1000
125 1000 -1000.0 -99.99568287525881 number episode from 10: 125 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.6936) 1000
126 1000 -1000.0 -99.99568287525881 number episode from 10: 126 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.6943) 1000
127 1000 -1000.0 -99.99568287525881 number episode from 10: 127 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.6950) 1000
128 1000 -1000.0 -99.99568287525881 number episode from 10: 128 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.6967) 1000
129 1000 -1000.0 -99.99568287525881 number episode from 10: 129 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.6897) 1000
130 1000 -1000.0 -99.99568287525881 number episode from 10: 130 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.6895) 1000
131 1000 -1000.0 -99.99568287525881 number episode from 10: 131 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.6894) 1000
132 1000 -1000.0 -99.99568287525881 number episode from 10: 132 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.6978) 1000
133 1000 -1000.0 -99.99568287525881 number episode from 10: 133 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.7010) 1000
134 1000 -1000.0 -99.99568287525881 number episode from 10: 134 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.6919) 1000
135 1000 -1000.0 -99.99568287525881 number episode from 10: 135 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.6894) 1000
136 1000 -1000.0 -99.99568287525881 number episode from 10: 136 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.6891) 1000
137 1000 -1000.0 -99.99568287525881 number episode from 10: 137 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.6986) 1000
138 1000 -1000.0 -99.99568287525881 number episode from 10: 138 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.6965) 1000
139 1000 -1000.0 -99.99568287525881 number episode from 10: 139 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.6951) 1000
140 1000 -1000.0 -99.99568287525881 number episode from 10: 140 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.6916) 1000
141 1000 -1000.0 -99.99568287525881 number episode from 10: 141 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.6894) 1000
142 1000 -1000.0 -99.99568287525881 number episode from 10: 142 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.6893) 1000
143 1000 -1000.0 -99.99568287525881 number episode from 10: 143 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.6901) 1000
144 1000 -1000.0 -99.99568287525881 number episode from 10: 144 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.6894) 1000
145 1000 -1000.0 -99.99568287525881 number episode from 10: 145 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.7017) 1000
146 1000 -1000.0 -99.99568287525881 number episode from 10: 146 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.6896) 1000
147 1000 -1000.0 -99.99568287525881 number episode from 10: 147 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.6892) 1000
148 1000 -1000.0 -99.99568287525881 number episode from 10: 148 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.7007) 1000
149 1000 -1000.0 -99.99568287525881 number episode from 10: 149 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.7025) 1000
150 1000 -1000.0 -99.99568287525881 number episode from 10: 150 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.6916) 1000
151 1000 -1000.0 -99.99568287525881 number episode from 10: 151 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.6972) 1000
152 1000 -1000.0 -99.99568287525881 number episode from 10: 152 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.7028) 1000
153 1000 -1000.0 -99.99568287525881 number episode from 10: 153 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.6895) 1000
154 1000 -1000.0 -99.99568287525881 number episode from 10: 154 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.7098) 1000
155 1000 -1000.0 -99.99568287525881 number episode from 10: 155 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.7086) 1000
156 1000 -1000.0 -99.99568287525881 number episode from 10: 156 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.7059) 1000
157 1000 -1000.0 -99.99568287525881 number episode from 10: 157 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.6894) 1000
158 1000 -1000.0 -99.99568287525881 number episode from 10: 158 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.6898) 1000
159 1000 -1000.0 -99.99568287525881 number episode from 10: 159 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.6892) 1000
160 1000 -1000.0 -99.99568287525881 number episode from 10: 160 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.6895) 1000
161 1000 -1000.0 -99.99568287525881 number episode from 10: 161 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.7004) 1000
162 1000 -1000.0 -99.99568287525881 number episode from 10: 162 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.7025) 1000
163 1000 -1000.0 -99.99568287525881 number episode from 10: 163 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.6941) 1000
164 1000 -1000.0 -99.99568287525881 number episode from 10: 164 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.6894) 1000
165 1000 -1000.0 -99.99568287525881 number episode from 10: 165 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.6926) 1000
166 1000 -1000.0 -99.99568287525881 number episode from 10: 166 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.7006) 1000
167 1000 -1000.0 -99.99568287525881 number episode from 10: 167 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.6896) 1000
168 1000 -1000.0 -99.99568287525881 number episode from 10: 168 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.7014) 1000
169 1000 -1000.0 -99.99568287525881 number episode from 10: 169 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.6989) 1000
170 1000 -1000.0 -99.99568287525881 number episode from 10: 170 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.7101) 1000
171 1000 -1000.0 -99.99568287525881 number episode from 10: 171 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.6908) 1000
172 1000 -1000.0 -99.99568287525881 number episode from 10: 172 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.6896) 1000
173 1000 -1000.0 -99.99568287525881 number episode from 10: 173 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.6999) 1000
174 1000 -1000.0 -99.99568287525881 number episode from 10: 174 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.6946) 1000
175 1000 -1000.0 -99.99568287525881 number episode from 10: 175 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.6902) 1000
176 1000 -1000.0 -99.99568287525881 number episode from 10: 176 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.6945) 1000
177 1000 -1000.0 -99.99568287525881 number episode from 10: 177 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.6923) 1000
178 1000 -1000.0 -99.99568287525881 number episode from 10: 178 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.6916) 1000
179 1000 -1000.0 -99.99568287525881 number episode from 10: 179 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.6935) 1000
180 1000 -1000.0 -99.99568287525881 number episode from 10: 180 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.6917) 1000
181 1000 -1000.0 -99.99568287525881 number episode from 10: 181 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.6942) 1000
182 1000 -1000.0 -99.99568287525881 number episode from 10: 182 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.6918) 1000
183 1000 -1000.0 -99.99568287525881 number episode from 10: 183 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.6959) 1000
184 1000 -1000.0 -99.99568287525881 number episode from 10: 184 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.6954) 1000
185 1000 -1000.0 -99.99568287525881 number episode from 10: 185 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.6897) 1000
186 1000 -1000.0 -99.99568287525881 number episode from 10: 186 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.6911) 1000
187 1000 -1000.0 -99.99568287525881 number episode from 10: 187 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.6897) 1000
188 1000 -1000.0 -99.99568287525881 number episode from 10: 188 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.7002) 1000
189 1000 -1000.0 -99.99568287525881 number episode from 10: 189 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.6893) 1000
190 1000 -1000.0 -99.99568287525881 number episode from 10: 190 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.6893) 1000
191 1000 -1000.0 -99.99568287525881 number episode from 10: 191 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.7001) 1000
192 1000 -1000.0 -99.99568287525881 number episode from 10: 192 avegar over 10 episode: -99.991 avegare return across last 100 episodes: -99.996 state values: tensor(0.6989) 1000
193 1000 -1000.0 -99.99568287525881 number episode from 10: 193 avegar over 10 episode: -99.991 avegare return across last 100 episodes: -99.996 state values: tensor(0.7000) 1000
194 1000 -1000.0 -99.99568287525881 number episode from 10: 194 avegar over 10 episode: -99.991 avegare return across last 100 episodes: -99.996 state values: tensor(0.6937) 1000
195 1000 -1000.0 -99.99568287525881 number episode from 10: 195 avegar over 10 episode: -99.991 avegare return across last 100 episodes: -99.996 state values: tensor(0.6901) 1000
196 1000 -1000.0 -99.99568287525881 number episode from 10: 196 avegar over 10 episode: -99.991 avegare return across last 100 episodes: -99.996 state values: tensor(0.6890) 1000
197 1000 -1000.0 -99.99568287525881 number episode from 10: 197 avegar over 10 episode: -99.991 avegare return across last 100 episodes: -99.996 state values: tensor(0.6976) 1000
198 1000 -1000.0 -99.99568287525881 number episode from 10: 198 avegar over 10 episode: -99.991 avegare return across last 100 episodes: -99.996 state values: tensor(0.6893) 1000
199 1000 -1000.0 -99.99568287525881 number episode from 10: 199 avegar over 10 episode: -99.991 avegare return across last 100 episodes: -99.996 state values: tensor(0.6893) 1000
200 1000 -1000.0 -99.99568287525881 number episode from 10: 200 avegar over 10 episode: -99.991 avegare return across last 100 episodes: -99.996 state values: tensor(0.6922) 1000
Start! Seed: 32
0 1001 -1000.0 -98.99572604650622 number episode from 10: 0 avegar over 10 episode: -98.996 avegare return across last 100 episodes: -98.996 state values: tensor(0.7046) 1000
1 1000 -1000.0 -99.99568287525881 number episode from 10: 1 avegar over 10 episode: -99.496 avegare return across last 100 episodes: -99.496 state values: tensor(0.7040) 1000
2 1000 -1000.0 -99.99568287525881 number episode from 10: 2 avegar over 10 episode: -99.662 avegare return across last 100 episodes: -99.662 state values: tensor(0.7043) 1000
3 1000 -1000.0 -99.99568287525881 number episode from 10: 3 avegar over 10 episode: -99.746 avegare return across last 100 episodes: -99.746 state values: tensor(0.7039) 1000
4 1000 -1000.0 -99.99568287525881 number episode from 10: 4 avegar over 10 episode: -99.796 avegare return across last 100 episodes: -99.796 state values: tensor(0.7041) 1000
5 1000 -1000.0 -99.99568287525881 number episode from 10: 5 avegar over 10 episode: -99.829 avegare return across last 100 episodes: -99.829 state values: tensor(0.7049) 1000
6 1000 -1000.0 -99.99568287525881 number episode from 10: 6 avegar over 10 episode: -99.853 avegare return across last 100 episodes: -99.853 state values: tensor(0.7042) 1000
7 1000 -1000.0 -99.99568287525881 number episode from 10: 7 avegar over 10 episode: -99.871 avegare return across last 100 episodes: -99.871 state values: tensor(0.7039) 1000
8 1000 -1000.0 -99.99568287525881 number episode from 10: 8 avegar over 10 episode: -99.885 avegare return across last 100 episodes: -99.885 state values: tensor(0.7039) 1000
9 1000 -1000.0 -99.99568287525881 number episode from 10: 9 avegar over 10 episode: -99.896 avegare return across last 100 episodes: -99.896 state values: tensor(0.7048) 1000
10 1000 -1000.0 -99.99568287525881 number episode from 10: 10 avegar over 10 episode: -99.905 avegare return across last 100 episodes: -99.905 state values: tensor(0.7040) 1000
11 1000 -1000.0 -99.99568287525881 number episode from 10: 11 avegar over 10 episode: -99.912 avegare return across last 100 episodes: -99.912 state values: tensor(0.7044) 1000
12 1000 -1000.0 -99.99568287525881 number episode from 10: 12 avegar over 10 episode: -99.919 avegare return across last 100 episodes: -99.919 state values: tensor(0.7042) 1000
13 1000 -1000.0 -99.99568287525881 number episode from 10: 13 avegar over 10 episode: -99.924 avegare return across last 100 episodes: -99.924 state values: tensor(0.7039) 1000
14 1000 -1000.0 -99.99568287525881 number episode from 10: 14 avegar over 10 episode: -99.929 avegare return across last 100 episodes: -99.929 state values: tensor(0.7051) 1000
15 1000 -1000.0 -99.99568287525881 number episode from 10: 15 avegar over 10 episode: -99.933 avegare return across last 100 episodes: -99.933 state values: tensor(0.7039) 1000
16 1000 -1000.0 -99.99568287525881 number episode from 10: 16 avegar over 10 episode: -99.937 avegare return across last 100 episodes: -99.937 state values: tensor(0.7045) 1000
17 1000 -1000.0 -99.99568287525881 number episode from 10: 17 avegar over 10 episode: -99.94 avegare return across last 100 episodes: -99.94 state values: tensor(0.7042) 1000
18 1000 -1000.0 -99.99568287525881 number episode from 10: 18 avegar over 10 episode: -99.943 avegare return across last 100 episodes: -99.943 state values: tensor(0.7043) 1000
19 1000 -1000.0 -99.99568287525881 number episode from 10: 19 avegar over 10 episode: -99.946 avegare return across last 100 episodes: -99.946 state values: tensor(0.7048) 1000
20 1000 -1000.0 -99.99568287525881 number episode from 10: 20 avegar over 10 episode: -99.948 avegare return across last 100 episodes: -99.948 state values: tensor(0.7043) 1000
21 1000 -1000.0 -99.99568287525881 number episode from 10: 21 avegar over 10 episode: -99.95 avegare return across last 100 episodes: -99.95 state values: tensor(0.7045) 1000
22 1000 -1000.0 -99.99568287525881 number episode from 10: 22 avegar over 10 episode: -99.952 avegare return across last 100 episodes: -99.952 state values: tensor(0.7048) 1000
23 1000 -1000.0 -99.99568287525881 number episode from 10: 23 avegar over 10 episode: -99.954 avegare return across last 100 episodes: -99.954 state values: tensor(0.7039) 1000
24 1000 -1000.0 -99.99568287525881 number episode from 10: 24 avegar over 10 episode: -99.956 avegare return across last 100 episodes: -99.956 state values: tensor(0.7044) 1000
25 1000 -1000.0 -99.99568287525881 number episode from 10: 25 avegar over 10 episode: -99.957 avegare return across last 100 episodes: -99.957 state values: tensor(0.7040) 1000
26 1000 -1000.0 -99.99568287525881 number episode from 10: 26 avegar over 10 episode: -99.959 avegare return across last 100 episodes: -99.959 state values: tensor(0.7042) 1000
27 1000 -1000.0 -99.99568287525881 number episode from 10: 27 avegar over 10 episode: -99.96 avegare return across last 100 episodes: -99.96 state values: tensor(0.7040) 1000
28 1000 -1000.0 -99.99568287525881 number episode from 10: 28 avegar over 10 episode: -99.961 avegare return across last 100 episodes: -99.961 state values: tensor(0.7046) 1000
29 1000 -1000.0 -99.99568287525881 number episode from 10: 29 avegar over 10 episode: -99.962 avegare return across last 100 episodes: -99.962 state values: tensor(0.7048) 1000
30 1000 -1000.0 -99.99568287525881 number episode from 10: 30 avegar over 10 episode: -99.963 avegare return across last 100 episodes: -99.963 state values: tensor(0.7042) 1000
31 1000 -1000.0 -99.99568287525881 number episode from 10: 31 avegar over 10 episode: -99.964 avegare return across last 100 episodes: -99.964 state values: tensor(0.7041) 1000
32 1000 -1000.0 -99.99568287525881 number episode from 10: 32 avegar over 10 episode: -99.965 avegare return across last 100 episodes: -99.965 state values: tensor(0.7045) 1000
33 1000 -1000.0 -99.99568287525881 number episode from 10: 33 avegar over 10 episode: -99.966 avegare return across last 100 episodes: -99.966 state values: tensor(0.7043) 1000
34 1000 -1000.0 -99.99568287525881 number episode from 10: 34 avegar over 10 episode: -99.967 avegare return across last 100 episodes: -99.967 state values: tensor(0.7038) 1000
35 1000 -1000.0 -99.99568287525881 number episode from 10: 35 avegar over 10 episode: -99.968 avegare return across last 100 episodes: -99.968 state values: tensor(0.7040) 1000
36 1000 -1000.0 -99.99568287525881 number episode from 10: 36 avegar over 10 episode: -99.969 avegare return across last 100 episodes: -99.969 state values: tensor(0.7049) 1000
37 1000 -1000.0 -99.99568287525881 number episode from 10: 37 avegar over 10 episode: -99.969 avegare return across last 100 episodes: -99.969 state values: tensor(0.7043) 1000
38 1000 -1000.0 -99.99568287525881 number episode from 10: 38 avegar over 10 episode: -99.97 avegare return across last 100 episodes: -99.97 state values: tensor(0.7042) 1000
39 1000 -1000.0 -99.99568287525881 number episode from 10: 39 avegar over 10 episode: -99.971 avegare return across last 100 episodes: -99.971 state values: tensor(0.7041) 1000
40 1000 -1000.0 -99.99568287525881 number episode from 10: 40 avegar over 10 episode: -99.971 avegare return across last 100 episodes: -99.971 state values: tensor(0.7048) 1000
41 1000 -1000.0 -99.99568287525881 number episode from 10: 41 avegar over 10 episode: -99.972 avegare return across last 100 episodes: -99.972 state values: tensor(0.7047) 1000
42 1000 -1000.0 -99.99568287525881 number episode from 10: 42 avegar over 10 episode: -99.972 avegare return across last 100 episodes: -99.972 state values: tensor(0.7043) 1000
43 1000 -1000.0 -99.99568287525881 number episode from 10: 43 avegar over 10 episode: -99.973 avegare return across last 100 episodes: -99.973 state values: tensor(0.7046) 1000
44 1000 -1000.0 -99.99568287525881 number episode from 10: 44 avegar over 10 episode: -99.973 avegare return across last 100 episodes: -99.973 state values: tensor(0.7049) 1000
45 1000 -1000.0 -99.99568287525881 number episode from 10: 45 avegar over 10 episode: -99.974 avegare return across last 100 episodes: -99.974 state values: tensor(0.7044) 1000
46 1000 -1000.0 -99.99568287525881 number episode from 10: 46 avegar over 10 episode: -99.974 avegare return across last 100 episodes: -99.974 state values: tensor(0.7051) 1000
47 1000 -1000.0 -99.99568287525881 number episode from 10: 47 avegar over 10 episode: -99.975 avegare return across last 100 episodes: -99.975 state values: tensor(0.7044) 1000
48 1000 -1000.0 -99.99568287525881 number episode from 10: 48 avegar over 10 episode: -99.975 avegare return across last 100 episodes: -99.975 state values: tensor(0.7043) 1000
49 1000 -1000.0 -99.99568287525881 number episode from 10: 49 avegar over 10 episode: -99.976 avegare return across last 100 episodes: -99.976 state values: tensor(0.7044) 1000
50 1000 -1000.0 -99.99568287525881 number episode from 10: 50 avegar over 10 episode: -99.976 avegare return across last 100 episodes: -99.976 state values: tensor(0.7047) 1000
51 1000 -1000.0 -99.99568287525881 number episode from 10: 51 avegar over 10 episode: -99.976 avegare return across last 100 episodes: -99.976 state values: tensor(0.7039) 1000
52 1000 -1000.0 -99.99568287525881 number episode from 10: 52 avegar over 10 episode: -99.977 avegare return across last 100 episodes: -99.977 state values: tensor(0.7047) 1000
53 1000 -1000.0 -99.99568287525881 number episode from 10: 53 avegar over 10 episode: -99.977 avegare return across last 100 episodes: -99.977 state values: tensor(0.7041) 1000
54 1000 -1000.0 -99.99568287525881 number episode from 10: 54 avegar over 10 episode: -99.978 avegare return across last 100 episodes: -99.978 state values: tensor(0.7042) 1000
55 1000 -1000.0 -99.99568287525881 number episode from 10: 55 avegar over 10 episode: -99.978 avegare return across last 100 episodes: -99.978 state values: tensor(0.7039) 1000
56 1000 -1000.0 -99.99568287525881 number episode from 10: 56 avegar over 10 episode: -99.978 avegare return across last 100 episodes: -99.978 state values: tensor(0.7047) 1000
57 1000 -1000.0 -99.99568287525881 number episode from 10: 57 avegar over 10 episode: -99.978 avegare return across last 100 episodes: -99.978 state values: tensor(0.7044) 1000
58 1000 -1000.0 -99.99568287525881 number episode from 10: 58 avegar over 10 episode: -99.979 avegare return across last 100 episodes: -99.979 state values: tensor(0.7040) 1000
59 1000 -1000.0 -99.99568287525881 number episode from 10: 59 avegar over 10 episode: -99.979 avegare return across last 100 episodes: -99.979 state values: tensor(0.7047) 1000
60 1000 -1000.0 -99.99568287525881 number episode from 10: 60 avegar over 10 episode: -99.979 avegare return across last 100 episodes: -99.979 state values: tensor(0.7047) 1000
61 1000 -1000.0 -99.99568287525881 number episode from 10: 61 avegar over 10 episode: -99.98 avegare return across last 100 episodes: -99.98 state values: tensor(0.7042) 1000
62 1000 -1000.0 -99.99568287525881 number episode from 10: 62 avegar over 10 episode: -99.98 avegare return across last 100 episodes: -99.98 state values: tensor(0.7044) 1000
63 1000 -1000.0 -99.99568287525881 number episode from 10: 63 avegar over 10 episode: -99.98 avegare return across last 100 episodes: -99.98 state values: tensor(0.7043) 1000
64 1000 -1000.0 -99.99568287525881 number episode from 10: 64 avegar over 10 episode: -99.98 avegare return across last 100 episodes: -99.98 state values: tensor(0.7046) 1000
65 1000 -1000.0 -99.99568287525881 number episode from 10: 65 avegar over 10 episode: -99.981 avegare return across last 100 episodes: -99.981 state values: tensor(0.7041) 1000
66 1000 -1000.0 -99.99568287525881 number episode from 10: 66 avegar over 10 episode: -99.981 avegare return across last 100 episodes: -99.981 state values: tensor(0.7047) 1000
67 1000 -1000.0 -99.99568287525881 number episode from 10: 67 avegar over 10 episode: -99.981 avegare return across last 100 episodes: -99.981 state values: tensor(0.7048) 1000
68 1000 -1000.0 -99.99568287525881 number episode from 10: 68 avegar over 10 episode: -99.981 avegare return across last 100 episodes: -99.981 state values: tensor(0.7044) 1000
69 1000 -1000.0 -99.99568287525881 number episode from 10: 69 avegar over 10 episode: -99.981 avegare return across last 100 episodes: -99.981 state values: tensor(0.7043) 1000
70 1000 -1000.0 -99.99568287525881 number episode from 10: 70 avegar over 10 episode: -99.982 avegare return across last 100 episodes: -99.982 state values: tensor(0.7048) 1000
71 1000 -1000.0 -99.99568287525881 number episode from 10: 71 avegar over 10 episode: -99.982 avegare return across last 100 episodes: -99.982 state values: tensor(0.7046) 1000
72 1000 -1000.0 -99.99568287525881 number episode from 10: 72 avegar over 10 episode: -99.982 avegare return across last 100 episodes: -99.982 state values: tensor(0.7043) 1000
73 1000 -1000.0 -99.99568287525881 number episode from 10: 73 avegar over 10 episode: -99.982 avegare return across last 100 episodes: -99.982 state values: tensor(0.7046) 1000
74 1000 -1000.0 -99.99568287525881 number episode from 10: 74 avegar over 10 episode: -99.982 avegare return across last 100 episodes: -99.982 state values: tensor(0.7040) 1000
75 1000 -1000.0 -99.99568287525881 number episode from 10: 75 avegar over 10 episode: -99.983 avegare return across last 100 episodes: -99.983 state values: tensor(0.7048) 1000
76 1000 -1000.0 -99.99568287525881 number episode from 10: 76 avegar over 10 episode: -99.983 avegare return across last 100 episodes: -99.983 state values: tensor(0.7048) 1000
77 1000 -1000.0 -99.99568287525881 number episode from 10: 77 avegar over 10 episode: -99.983 avegare return across last 100 episodes: -99.983 state values: tensor(0.7046) 1000
78 1000 -1000.0 -99.99568287525881 number episode from 10: 78 avegar over 10 episode: -99.983 avegare return across last 100 episodes: -99.983 state values: tensor(0.7050) 1000
79 1000 -1000.0 -99.99568287525881 number episode from 10: 79 avegar over 10 episode: -99.983 avegare return across last 100 episodes: -99.983 state values: tensor(0.7044) 1000
80 1000 -1000.0 -99.99568287525881 number episode from 10: 80 avegar over 10 episode: -99.983 avegare return across last 100 episodes: -99.983 state values: tensor(0.7039) 1000
81 1000 -1000.0 -99.99568287525881 number episode from 10: 81 avegar over 10 episode: -99.983 avegare return across last 100 episodes: -99.983 state values: tensor(0.7039) 1000
82 1000 -1000.0 -99.99568287525881 number episode from 10: 82 avegar over 10 episode: -99.984 avegare return across last 100 episodes: -99.984 state values: tensor(0.7038) 1000
83 1000 -1000.0 -99.99568287525881 number episode from 10: 83 avegar over 10 episode: -99.984 avegare return across last 100 episodes: -99.984 state values: tensor(0.7045) 1000
84 1000 -1000.0 -99.99568287525881 number episode from 10: 84 avegar over 10 episode: -99.984 avegare return across last 100 episodes: -99.984 state values: tensor(0.7043) 1000
85 1000 -1000.0 -99.99568287525881 number episode from 10: 85 avegar over 10 episode: -99.984 avegare return across last 100 episodes: -99.984 state values: tensor(0.7049) 1000
86 1000 -1000.0 -99.99568287525881 number episode from 10: 86 avegar over 10 episode: -99.984 avegare return across last 100 episodes: -99.984 state values: tensor(0.7042) 1000
87 1000 -1000.0 -99.99568287525881 number episode from 10: 87 avegar over 10 episode: -99.984 avegare return across last 100 episodes: -99.984 state values: tensor(0.7046) 1000
88 1000 -1000.0 -99.99568287525881 number episode from 10: 88 avegar over 10 episode: -99.984 avegare return across last 100 episodes: -99.984 state values: tensor(0.7047) 1000
89 1000 -1000.0 -99.99568287525881 number episode from 10: 89 avegar over 10 episode: -99.985 avegare return across last 100 episodes: -99.985 state values: tensor(0.7046) 1000
90 1000 -1000.0 -99.99568287525881 number episode from 10: 90 avegar over 10 episode: -99.985 avegare return across last 100 episodes: -99.985 state values: tensor(0.7041) 1000
91 1000 -1000.0 -99.99568287525881 number episode from 10: 91 avegar over 10 episode: -99.985 avegare return across last 100 episodes: -99.985 state values: tensor(0.7045) 1000
92 1000 -1000.0 -99.99568287525881 number episode from 10: 92 avegar over 10 episode: -99.985 avegare return across last 100 episodes: -99.985 state values: tensor(0.7045) 1000
93 1000 -1000.0 -99.99568287525881 number episode from 10: 93 avegar over 10 episode: -99.985 avegare return across last 100 episodes: -99.985 state values: tensor(0.7042) 1000
94 1000 -1000.0 -99.99568287525881 number episode from 10: 94 avegar over 10 episode: -99.985 avegare return across last 100 episodes: -99.985 state values: tensor(0.7049) 1000
95 1000 -1000.0 -99.99568287525881 number episode from 10: 95 avegar over 10 episode: -99.985 avegare return across last 100 episodes: -99.985 state values: tensor(0.7045) 1000
96 1000 -1000.0 -99.99568287525881 number episode from 10: 96 avegar over 10 episode: -99.985 avegare return across last 100 episodes: -99.985 state values: tensor(0.7050) 1000
97 1000 -1000.0 -99.99568287525881 number episode from 10: 97 avegar over 10 episode: -99.985 avegare return across last 100 episodes: -99.985 state values: tensor(0.7046) 1000
98 1000 -1000.0 -99.99568287525881 number episode from 10: 98 avegar over 10 episode: -99.986 avegare return across last 100 episodes: -99.986 state values: tensor(0.7050) 1000
99 1000 -1000.0 -99.99568287525881 number episode from 10: 99 avegar over 10 episode: -99.986 avegare return across last 100 episodes: -99.986 state values: tensor(0.7046) 1000
100 1000 -1000.0 -99.99568287525881 number episode from 10: 100 avegar over 10 episode: -99.986 avegare return across last 100 episodes: -99.996 state values: tensor(0.7052) 1000
101 1000 -1000.0 -99.99568287525881 number episode from 10: 101 avegar over 10 episode: -99.986 avegare return across last 100 episodes: -99.996 state values: tensor(0.7044) 1000
102 1000 -1000.0 -99.99568287525881 number episode from 10: 102 avegar over 10 episode: -99.986 avegare return across last 100 episodes: -99.996 state values: tensor(0.7044) 1000
103 1000 -1000.0 -99.99568287525881 number episode from 10: 103 avegar over 10 episode: -99.986 avegare return across last 100 episodes: -99.996 state values: tensor(0.7046) 1000
104 1000 -1000.0 -99.99568287525881 number episode from 10: 104 avegar over 10 episode: -99.986 avegare return across last 100 episodes: -99.996 state values: tensor(0.7038) 1000
105 1000 -1000.0 -99.99568287525881 number episode from 10: 105 avegar over 10 episode: -99.986 avegare return across last 100 episodes: -99.996 state values: tensor(0.7039) 1000
106 1000 -1000.0 -99.99568287525881 number episode from 10: 106 avegar over 10 episode: -99.986 avegare return across last 100 episodes: -99.996 state values: tensor(0.7039) 1000
107 1000 -1000.0 -99.99568287525881 number episode from 10: 107 avegar over 10 episode: -99.986 avegare return across last 100 episodes: -99.996 state values: tensor(0.7047) 1000
108 1000 -1000.0 -99.99568287525881 number episode from 10: 108 avegar over 10 episode: -99.987 avegare return across last 100 episodes: -99.996 state values: tensor(0.7045) 1000
109 1000 -1000.0 -99.99568287525881 number episode from 10: 109 avegar over 10 episode: -99.987 avegare return across last 100 episodes: -99.996 state values: tensor(0.7042) 1000
110 1000 -1000.0 -99.99568287525881 number episode from 10: 110 avegar over 10 episode: -99.987 avegare return across last 100 episodes: -99.996 state values: tensor(0.7042) 1000
111 1000 -1000.0 -99.99568287525881 number episode from 10: 111 avegar over 10 episode: -99.987 avegare return across last 100 episodes: -99.996 state values: tensor(0.7045) 1000
112 1000 -1000.0 -99.99568287525881 number episode from 10: 112 avegar over 10 episode: -99.987 avegare return across last 100 episodes: -99.996 state values: tensor(0.7040) 1000
113 1000 -1000.0 -99.99568287525881 number episode from 10: 113 avegar over 10 episode: -99.987 avegare return across last 100 episodes: -99.996 state values: tensor(0.7044) 1000
114 1000 -1000.0 -99.99568287525881 number episode from 10: 114 avegar over 10 episode: -99.987 avegare return across last 100 episodes: -99.996 state values: tensor(0.7046) 1000
115 1000 -1000.0 -99.99568287525881 number episode from 10: 115 avegar over 10 episode: -99.987 avegare return across last 100 episodes: -99.996 state values: tensor(0.7040) 1000
116 1000 -1000.0 -99.99568287525881 number episode from 10: 116 avegar over 10 episode: -99.987 avegare return across last 100 episodes: -99.996 state values: tensor(0.7050) 1000
117 1000 -1000.0 -99.99568287525881 number episode from 10: 117 avegar over 10 episode: -99.987 avegare return across last 100 episodes: -99.996 state values: tensor(0.7043) 1000
118 1000 -1000.0 -99.99568287525881 number episode from 10: 118 avegar over 10 episode: -99.987 avegare return across last 100 episodes: -99.996 state values: tensor(0.7046) 1000
119 1000 -1000.0 -99.99568287525881 number episode from 10: 119 avegar over 10 episode: -99.987 avegare return across last 100 episodes: -99.996 state values: tensor(0.7044) 1000
120 1000 -1000.0 -99.99568287525881 number episode from 10: 120 avegar over 10 episode: -99.987 avegare return across last 100 episodes: -99.996 state values: tensor(0.7045) 1000
121 1000 -1000.0 -99.99568287525881 number episode from 10: 121 avegar over 10 episode: -99.987 avegare return across last 100 episodes: -99.996 state values: tensor(0.7042) 1000
122 1000 -1000.0 -99.99568287525881 number episode from 10: 122 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.7041) 1000
123 1000 -1000.0 -99.99568287525881 number episode from 10: 123 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.7039) 1000
124 1000 -1000.0 -99.99568287525881 number episode from 10: 124 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.7046) 1000
125 1000 -1000.0 -99.99568287525881 number episode from 10: 125 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.7040) 1000
126 1000 -1000.0 -99.99568287525881 number episode from 10: 126 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.7041) 1000
127 1000 -1000.0 -99.99568287525881 number episode from 10: 127 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.7039) 1000
128 1000 -1000.0 -99.99568287525881 number episode from 10: 128 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.7044) 1000
129 1000 -1000.0 -99.99568287525881 number episode from 10: 129 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.7040) 1000
130 1000 -1000.0 -99.99568287525881 number episode from 10: 130 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.7041) 1000
131 1000 -1000.0 -99.99568287525881 number episode from 10: 131 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.7041) 1000
132 1000 -1000.0 -99.99568287525881 number episode from 10: 132 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.7039) 1000
133 1000 -1000.0 -99.99568287525881 number episode from 10: 133 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.7047) 1000
134 1000 -1000.0 -99.99568287525881 number episode from 10: 134 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.7046) 1000
135 1000 -1000.0 -99.99568287525881 number episode from 10: 135 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.7039) 1000
136 1000 -1000.0 -99.99568287525881 number episode from 10: 136 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.7041) 1000
137 1000 -1000.0 -99.99568287525881 number episode from 10: 137 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.7040) 1000
138 1000 -1000.0 -99.99568287525881 number episode from 10: 138 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.7048) 1000
139 1000 -1000.0 -99.99568287525881 number episode from 10: 139 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.7039) 1000
140 1000 -1000.0 -99.99568287525881 number episode from 10: 140 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.7042) 1000
141 1000 -1000.0 -99.99568287525881 number episode from 10: 141 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.7043) 1000
142 1000 -1000.0 -99.99568287525881 number episode from 10: 142 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.7044) 1000
143 1000 -1000.0 -99.99568287525881 number episode from 10: 143 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.7045) 1000
144 1000 -1000.0 -99.99568287525881 number episode from 10: 144 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.7041) 1000
145 1000 -1000.0 -99.99568287525881 number episode from 10: 145 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.7040) 1000
146 1000 -1000.0 -99.99568287525881 number episode from 10: 146 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.7039) 1000
147 1000 -1000.0 -99.99568287525881 number episode from 10: 147 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.7038) 1000
148 1000 -1000.0 -99.99568287525881 number episode from 10: 148 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.7040) 1000
149 1000 -1000.0 -99.99568287525881 number episode from 10: 149 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.7043) 1000
150 1000 -1000.0 -99.99568287525881 number episode from 10: 150 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.7041) 1000
151 1000 -1000.0 -99.99568287525881 number episode from 10: 151 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.7043) 1000
152 1000 -1000.0 -99.99568287525881 number episode from 10: 152 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.7042) 1000
153 1000 -1000.0 -99.99568287525881 number episode from 10: 153 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.7044) 1000
154 1000 -1000.0 -99.99568287525881 number episode from 10: 154 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.7047) 1000
155 1000 -1000.0 -99.99568287525881 number episode from 10: 155 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.7041) 1000
156 1000 -1000.0 -99.99568287525881 number episode from 10: 156 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.7046) 1000
157 1000 -1000.0 -99.99568287525881 number episode from 10: 157 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.7047) 1000
158 1000 -1000.0 -99.99568287525881 number episode from 10: 158 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.7044) 1000
159 1000 -1000.0 -99.99568287525881 number episode from 10: 159 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.7048) 1000
160 1000 -1000.0 -99.99568287525881 number episode from 10: 160 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.7045) 1000
161 1000 -1000.0 -99.99568287525881 number episode from 10: 161 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.7046) 1000
162 1000 -1000.0 -99.99568287525881 number episode from 10: 162 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.7045) 1000
163 1000 -1000.0 -99.99568287525881 number episode from 10: 163 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.7041) 1000
164 1000 -1000.0 -99.99568287525881 number episode from 10: 164 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.7043) 1000
165 1000 -1000.0 -99.99568287525881 number episode from 10: 165 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.7048) 1000
166 1000 -1000.0 -99.99568287525881 number episode from 10: 166 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.7042) 1000
167 1000 -1000.0 -99.99568287525881 number episode from 10: 167 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.7050) 1000
168 1000 -1000.0 -99.99568287525881 number episode from 10: 168 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.7048) 1000
169 1000 -1000.0 -99.99568287525881 number episode from 10: 169 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.7047) 1000
170 1000 -1000.0 -99.99568287525881 number episode from 10: 170 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.7043) 1000
171 1000 -1000.0 -99.99568287525881 number episode from 10: 171 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.7043) 1000
172 1000 -1000.0 -99.99568287525881 number episode from 10: 172 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.7039) 1000
173 1000 -1000.0 -99.99568287525881 number episode from 10: 173 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.7045) 1000
174 1000 -1000.0 -99.99568287525881 number episode from 10: 174 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.7042) 1000
175 1000 -1000.0 -99.99568287525881 number episode from 10: 175 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.7047) 1000
176 1000 -1000.0 -99.99568287525881 number episode from 10: 176 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.7040) 1000
177 1000 -1000.0 -99.99568287525881 number episode from 10: 177 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.7043) 1000
178 1000 -1000.0 -99.99568287525881 number episode from 10: 178 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.7039) 1000
179 1000 -1000.0 -99.99568287525881 number episode from 10: 179 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.7041) 1000
180 1000 -1000.0 -99.99568287525881 number episode from 10: 180 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.7047) 1000
181 1000 -1000.0 -99.99568287525881 number episode from 10: 181 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.7042) 1000
182 1000 -1000.0 -99.99568287525881 number episode from 10: 182 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.7049) 1000
183 1000 -1000.0 -99.99568287525881 number episode from 10: 183 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.7043) 1000
184 1000 -1000.0 -99.99568287525881 number episode from 10: 184 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.7046) 1000
185 1000 -1000.0 -99.99568287525881 number episode from 10: 185 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.7041) 1000
186 1000 -1000.0 -99.99568287525881 number episode from 10: 186 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.7047) 1000
187 1000 -1000.0 -99.99568287525881 number episode from 10: 187 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.7047) 1000
188 1000 -1000.0 -99.99568287525881 number episode from 10: 188 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.7042) 1000
189 1000 -1000.0 -99.99568287525881 number episode from 10: 189 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.7045) 1000
190 1000 -1000.0 -99.99568287525881 number episode from 10: 190 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.7041) 1000
191 1000 -1000.0 -99.99568287525881 number episode from 10: 191 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.7043) 1000
192 1000 -1000.0 -99.99568287525881 number episode from 10: 192 avegar over 10 episode: -99.991 avegare return across last 100 episodes: -99.996 state values: tensor(0.7049) 1000
193 1000 -1000.0 -99.99568287525881 number episode from 10: 193 avegar over 10 episode: -99.991 avegare return across last 100 episodes: -99.996 state values: tensor(0.7044) 1000
194 1000 -1000.0 -99.99568287525881 number episode from 10: 194 avegar over 10 episode: -99.991 avegare return across last 100 episodes: -99.996 state values: tensor(0.7038) 1000
195 1000 -1000.0 -99.99568287525881 number episode from 10: 195 avegar over 10 episode: -99.991 avegare return across last 100 episodes: -99.996 state values: tensor(0.7042) 1000
196 1000 -1000.0 -99.99568287525881 number episode from 10: 196 avegar over 10 episode: -99.991 avegare return across last 100 episodes: -99.996 state values: tensor(0.7045) 1000
197 1000 -1000.0 -99.99568287525881 number episode from 10: 197 avegar over 10 episode: -99.991 avegare return across last 100 episodes: -99.996 state values: tensor(0.7042) 1000
198 1000 -1000.0 -99.99568287525881 number episode from 10: 198 avegar over 10 episode: -99.991 avegare return across last 100 episodes: -99.996 state values: tensor(0.7047) 1000
199 1000 -1000.0 -99.99568287525881 number episode from 10: 199 avegar over 10 episode: -99.991 avegare return across last 100 episodes: -99.996 state values: tensor(0.7041) 1000
200 1000 -1000.0 -99.99568287525881 number episode from 10: 200 avegar over 10 episode: -99.991 avegare return across last 100 episodes: -99.996 state values: tensor(0.7044) 1000
Start! Seed: 64
0 1001 -1000.0 -98.99572604650622 number episode from 10: 0 avegar over 10 episode: -98.996 avegare return across last 100 episodes: -98.996 state values: tensor(0.8139) 1000
1 1000 -1000.0 -99.99568287525881 number episode from 10: 1 avegar over 10 episode: -99.496 avegare return across last 100 episodes: -99.496 state values: tensor(0.8112) 1000
2 1000 -1000.0 -99.99568287525881 number episode from 10: 2 avegar over 10 episode: -99.662 avegare return across last 100 episodes: -99.662 state values: tensor(0.8482) 1000
3 1000 -1000.0 -99.99568287525881 number episode from 10: 3 avegar over 10 episode: -99.746 avegare return across last 100 episodes: -99.746 state values: tensor(0.8136) 1000
4 1000 -1000.0 -99.99568287525881 number episode from 10: 4 avegar over 10 episode: -99.796 avegare return across last 100 episodes: -99.796 state values: tensor(0.8119) 1000
5 1000 -1000.0 -99.99568287525881 number episode from 10: 5 avegar over 10 episode: -99.829 avegare return across last 100 episodes: -99.829 state values: tensor(0.8143) 1000
6 1000 -1000.0 -99.99568287525881 number episode from 10: 6 avegar over 10 episode: -99.853 avegare return across last 100 episodes: -99.853 state values: tensor(0.8506) 1000
7 1000 -1000.0 -99.99568287525881 number episode from 10: 7 avegar over 10 episode: -99.871 avegare return across last 100 episodes: -99.871 state values: tensor(0.8140) 1000
8 1000 -1000.0 -99.99568287525881 number episode from 10: 8 avegar over 10 episode: -99.885 avegare return across last 100 episodes: -99.885 state values: tensor(0.8145) 1000
9 1000 -1000.0 -99.99568287525881 number episode from 10: 9 avegar over 10 episode: -99.896 avegare return across last 100 episodes: -99.896 state values: tensor(0.8114) 1000
10 1000 -1000.0 -99.99568287525881 number episode from 10: 10 avegar over 10 episode: -99.905 avegare return across last 100 episodes: -99.905 state values: tensor(0.8479) 1000
11 1000 -1000.0 -99.99568287525881 number episode from 10: 11 avegar over 10 episode: -99.912 avegare return across last 100 episodes: -99.912 state values: tensor(0.8129) 1000
12 1000 -1000.0 -99.99568287525881 number episode from 10: 12 avegar over 10 episode: -99.919 avegare return across last 100 episodes: -99.919 state values: tensor(0.8123) 1000
13 1000 -1000.0 -99.99568287525881 number episode from 10: 13 avegar over 10 episode: -99.924 avegare return across last 100 episodes: -99.924 state values: tensor(0.8120) 1000
14 1000 -1000.0 -99.99568287525881 number episode from 10: 14 avegar over 10 episode: -99.929 avegare return across last 100 episodes: -99.929 state values: tensor(0.8134) 1000
15 1000 -1000.0 -99.99568287525881 number episode from 10: 15 avegar over 10 episode: -99.933 avegare return across last 100 episodes: -99.933 state values: tensor(0.8140) 1000
16 1000 -1000.0 -99.99568287525881 number episode from 10: 16 avegar over 10 episode: -99.937 avegare return across last 100 episodes: -99.937 state values: tensor(0.8117) 1000
17 1000 -1000.0 -99.99568287525881 number episode from 10: 17 avegar over 10 episode: -99.94 avegare return across last 100 episodes: -99.94 state values: tensor(0.8123) 1000
18 1000 -1000.0 -99.99568287525881 number episode from 10: 18 avegar over 10 episode: -99.943 avegare return across last 100 episodes: -99.943 state values: tensor(0.8138) 1000
19 1000 -1000.0 -99.99568287525881 number episode from 10: 19 avegar over 10 episode: -99.946 avegare return across last 100 episodes: -99.946 state values: tensor(0.8135) 1000
20 1000 -1000.0 -99.99568287525881 number episode from 10: 20 avegar over 10 episode: -99.948 avegare return across last 100 episodes: -99.948 state values: tensor(0.8139) 1000
21 1000 -1000.0 -99.99568287525881 number episode from 10: 21 avegar over 10 episode: -99.95 avegare return across last 100 episodes: -99.95 state values: tensor(0.8126) 1000
22 1000 -1000.0 -99.99568287525881 number episode from 10: 22 avegar over 10 episode: -99.952 avegare return across last 100 episodes: -99.952 state values: tensor(0.8118) 1000
23 1000 -1000.0 -99.99568287525881 number episode from 10: 23 avegar over 10 episode: -99.954 avegare return across last 100 episodes: -99.954 state values: tensor(0.8130) 1000
24 1000 -1000.0 -99.99568287525881 number episode from 10: 24 avegar over 10 episode: -99.956 avegare return across last 100 episodes: -99.956 state values: tensor(0.8123) 1000
25 1000 -1000.0 -99.99568287525881 number episode from 10: 25 avegar over 10 episode: -99.957 avegare return across last 100 episodes: -99.957 state values: tensor(0.8112) 1000
26 1000 -1000.0 -99.99568287525881 number episode from 10: 26 avegar over 10 episode: -99.959 avegare return across last 100 episodes: -99.959 state values: tensor(0.8492) 1000
27 1000 -1000.0 -99.99568287525881 number episode from 10: 27 avegar over 10 episode: -99.96 avegare return across last 100 episodes: -99.96 state values: tensor(0.8111) 1000
28 1000 -1000.0 -99.99568287525881 number episode from 10: 28 avegar over 10 episode: -99.961 avegare return across last 100 episodes: -99.961 state values: tensor(0.8134) 1000
29 1000 -1000.0 -99.99568287525881 number episode from 10: 29 avegar over 10 episode: -99.962 avegare return across last 100 episodes: -99.962 state values: tensor(0.8115) 1000
30 1000 -1000.0 -99.99568287525881 number episode from 10: 30 avegar over 10 episode: -99.963 avegare return across last 100 episodes: -99.963 state values: tensor(0.8116) 1000
31 1000 -1000.0 -99.99568287525881 number episode from 10: 31 avegar over 10 episode: -99.964 avegare return across last 100 episodes: -99.964 state values: tensor(0.8114) 1000
32 1000 -1000.0 -99.99568287525881 number episode from 10: 32 avegar over 10 episode: -99.965 avegare return across last 100 episodes: -99.965 state values: tensor(0.8495) 1000
33 1000 -1000.0 -99.99568287525881 number episode from 10: 33 avegar over 10 episode: -99.966 avegare return across last 100 episodes: -99.966 state values: tensor(0.8131) 1000
34 1000 -1000.0 -99.99568287525881 number episode from 10: 34 avegar over 10 episode: -99.967 avegare return across last 100 episodes: -99.967 state values: tensor(0.8497) 1000
35 1000 -1000.0 -99.99568287525881 number episode from 10: 35 avegar over 10 episode: -99.968 avegare return across last 100 episodes: -99.968 state values: tensor(0.8117) 1000
36 1000 -1000.0 -99.99568287525881 number episode from 10: 36 avegar over 10 episode: -99.969 avegare return across last 100 episodes: -99.969 state values: tensor(0.8115) 1000
37 1000 -1000.0 -99.99568287525881 number episode from 10: 37 avegar over 10 episode: -99.969 avegare return across last 100 episodes: -99.969 state values: tensor(0.8125) 1000
38 1000 -1000.0 -99.99568287525881 number episode from 10: 38 avegar over 10 episode: -99.97 avegare return across last 100 episodes: -99.97 state values: tensor(0.8114) 1000
39 1000 -1000.0 -99.99568287525881 number episode from 10: 39 avegar over 10 episode: -99.971 avegare return across last 100 episodes: -99.971 state values: tensor(0.8125) 1000
40 1000 -1000.0 -99.99568287525881 number episode from 10: 40 avegar over 10 episode: -99.971 avegare return across last 100 episodes: -99.971 state values: tensor(0.8125) 1000
41 1000 -1000.0 -99.99568287525881 number episode from 10: 41 avegar over 10 episode: -99.972 avegare return across last 100 episodes: -99.972 state values: tensor(0.8124) 1000
42 1000 -1000.0 -99.99568287525881 number episode from 10: 42 avegar over 10 episode: -99.972 avegare return across last 100 episodes: -99.972 state values: tensor(0.8128) 1000
43 1000 -1000.0 -99.99568287525881 number episode from 10: 43 avegar over 10 episode: -99.973 avegare return across last 100 episodes: -99.973 state values: tensor(0.8115) 1000
44 1000 -1000.0 -99.99568287525881 number episode from 10: 44 avegar over 10 episode: -99.973 avegare return across last 100 episodes: -99.973 state values: tensor(0.8119) 1000
45 1000 -1000.0 -99.99568287525881 number episode from 10: 45 avegar over 10 episode: -99.974 avegare return across last 100 episodes: -99.974 state values: tensor(0.8114) 1000
46 1000 -1000.0 -99.99568287525881 number episode from 10: 46 avegar over 10 episode: -99.974 avegare return across last 100 episodes: -99.974 state values: tensor(0.8140) 1000
47 1000 -1000.0 -99.99568287525881 number episode from 10: 47 avegar over 10 episode: -99.975 avegare return across last 100 episodes: -99.975 state values: tensor(0.8130) 1000
48 1000 -1000.0 -99.99568287525881 number episode from 10: 48 avegar over 10 episode: -99.975 avegare return across last 100 episodes: -99.975 state values: tensor(0.8138) 1000
49 1000 -1000.0 -99.99568287525881 number episode from 10: 49 avegar over 10 episode: -99.976 avegare return across last 100 episodes: -99.976 state values: tensor(0.8116) 1000
50 1000 -1000.0 -99.99568287525881 number episode from 10: 50 avegar over 10 episode: -99.976 avegare return across last 100 episodes: -99.976 state values: tensor(0.8118) 1000
51 1000 -1000.0 -99.99568287525881 number episode from 10: 51 avegar over 10 episode: -99.976 avegare return across last 100 episodes: -99.976 state values: tensor(0.8111) 1000
52 1000 -1000.0 -99.99568287525881 number episode from 10: 52 avegar over 10 episode: -99.977 avegare return across last 100 episodes: -99.977 state values: tensor(0.8113) 1000
53 1000 -1000.0 -99.99568287525881 number episode from 10: 53 avegar over 10 episode: -99.977 avegare return across last 100 episodes: -99.977 state values: tensor(0.8496) 1000
54 1000 -1000.0 -99.99568287525881 number episode from 10: 54 avegar over 10 episode: -99.978 avegare return across last 100 episodes: -99.978 state values: tensor(0.8124) 1000
55 1000 -1000.0 -99.99568287525881 number episode from 10: 55 avegar over 10 episode: -99.978 avegare return across last 100 episodes: -99.978 state values: tensor(0.8137) 1000
56 1000 -1000.0 -99.99568287525881 number episode from 10: 56 avegar over 10 episode: -99.978 avegare return across last 100 episodes: -99.978 state values: tensor(0.8134) 1000
57 1000 -1000.0 -99.99568287525881 number episode from 10: 57 avegar over 10 episode: -99.978 avegare return across last 100 episodes: -99.978 state values: tensor(0.8225) 1000
58 1000 -1000.0 -99.99568287525881 number episode from 10: 58 avegar over 10 episode: -99.979 avegare return across last 100 episodes: -99.979 state values: tensor(0.8111) 1000
59 1000 -1000.0 -99.99568287525881 number episode from 10: 59 avegar over 10 episode: -99.979 avegare return across last 100 episodes: -99.979 state values: tensor(0.8134) 1000
60 1000 -1000.0 -99.99568287525881 number episode from 10: 60 avegar over 10 episode: -99.979 avegare return across last 100 episodes: -99.979 state values: tensor(0.8489) 1000
61 1000 -1000.0 -99.99568287525881 number episode from 10: 61 avegar over 10 episode: -99.98 avegare return across last 100 episodes: -99.98 state values: tensor(0.8501) 1000
62 1000 -1000.0 -99.99568287525881 number episode from 10: 62 avegar over 10 episode: -99.98 avegare return across last 100 episodes: -99.98 state values: tensor(0.8120) 1000
63 1000 -1000.0 -99.99568287525881 number episode from 10: 63 avegar over 10 episode: -99.98 avegare return across last 100 episodes: -99.98 state values: tensor(0.8170) 1000
64 1000 -1000.0 -99.99568287525881 number episode from 10: 64 avegar over 10 episode: -99.98 avegare return across last 100 episodes: -99.98 state values: tensor(0.8113) 1000
65 1000 -1000.0 -99.99568287525881 number episode from 10: 65 avegar over 10 episode: -99.981 avegare return across last 100 episodes: -99.981 state values: tensor(0.8144) 1000
66 1000 -1000.0 -99.99568287525881 number episode from 10: 66 avegar over 10 episode: -99.981 avegare return across last 100 episodes: -99.981 state values: tensor(0.8138) 1000
67 1000 -1000.0 -99.99568287525881 number episode from 10: 67 avegar over 10 episode: -99.981 avegare return across last 100 episodes: -99.981 state values: tensor(0.8140) 1000
68 1000 -1000.0 -99.99568287525881 number episode from 10: 68 avegar over 10 episode: -99.981 avegare return across last 100 episodes: -99.981 state values: tensor(0.8111) 1000
69 1000 -1000.0 -99.99568287525881 number episode from 10: 69 avegar over 10 episode: -99.981 avegare return across last 100 episodes: -99.981 state values: tensor(0.8141) 1000
70 1000 -1000.0 -99.99568287525881 number episode from 10: 70 avegar over 10 episode: -99.982 avegare return across last 100 episodes: -99.982 state values: tensor(0.8494) 1000
71 1000 -1000.0 -99.99568287525881 number episode from 10: 71 avegar over 10 episode: -99.982 avegare return across last 100 episodes: -99.982 state values: tensor(0.8114) 1000
72 1000 -1000.0 -99.99568287525881 number episode from 10: 72 avegar over 10 episode: -99.982 avegare return across last 100 episodes: -99.982 state values: tensor(0.8133) 1000
73 1000 -1000.0 -99.99568287525881 number episode from 10: 73 avegar over 10 episode: -99.982 avegare return across last 100 episodes: -99.982 state values: tensor(0.8135) 1000
74 1000 -1000.0 -99.99568287525881 number episode from 10: 74 avegar over 10 episode: -99.982 avegare return across last 100 episodes: -99.982 state values: tensor(0.8130) 1000
75 1000 -1000.0 -99.99568287525881 number episode from 10: 75 avegar over 10 episode: -99.983 avegare return across last 100 episodes: -99.983 state values: tensor(0.8110) 1000
76 1000 -1000.0 -99.99568287525881 number episode from 10: 76 avegar over 10 episode: -99.983 avegare return across last 100 episodes: -99.983 state values: tensor(0.8129) 1000
77 1000 -1000.0 -99.99568287525881 number episode from 10: 77 avegar over 10 episode: -99.983 avegare return across last 100 episodes: -99.983 state values: tensor(0.8126) 1000
78 1000 -1000.0 -99.99568287525881 number episode from 10: 78 avegar over 10 episode: -99.983 avegare return across last 100 episodes: -99.983 state values: tensor(0.8114) 1000
79 1000 -1000.0 -99.99568287525881 number episode from 10: 79 avegar over 10 episode: -99.983 avegare return across last 100 episodes: -99.983 state values: tensor(0.8140) 1000
80 1000 -1000.0 -99.99568287525881 number episode from 10: 80 avegar over 10 episode: -99.983 avegare return across last 100 episodes: -99.983 state values: tensor(0.8430) 1000
81 1000 -1000.0 -99.99568287525881 number episode from 10: 81 avegar over 10 episode: -99.983 avegare return across last 100 episodes: -99.983 state values: tensor(0.8138) 1000
82 1000 -1000.0 -99.99568287525881 number episode from 10: 82 avegar over 10 episode: -99.984 avegare return across last 100 episodes: -99.984 state values: tensor(0.8494) 1000
83 1000 -1000.0 -99.99568287525881 number episode from 10: 83 avegar over 10 episode: -99.984 avegare return across last 100 episodes: -99.984 state values: tensor(0.8514) 1000
84 1000 -1000.0 -99.99568287525881 number episode from 10: 84 avegar over 10 episode: -99.984 avegare return across last 100 episodes: -99.984 state values: tensor(0.8139) 1000
85 1000 -1000.0 -99.99568287525881 number episode from 10: 85 avegar over 10 episode: -99.984 avegare return across last 100 episodes: -99.984 state values: tensor(0.8122) 1000
86 1000 -1000.0 -99.99568287525881 number episode from 10: 86 avegar over 10 episode: -99.984 avegare return across last 100 episodes: -99.984 state values: tensor(0.8117) 1000
87 1000 -1000.0 -99.99568287525881 number episode from 10: 87 avegar over 10 episode: -99.984 avegare return across last 100 episodes: -99.984 state values: tensor(0.8115) 1000
88 1000 -1000.0 -99.99568287525881 number episode from 10: 88 avegar over 10 episode: -99.984 avegare return across last 100 episodes: -99.984 state values: tensor(0.8506) 1000
89 1000 -1000.0 -99.99568287525881 number episode from 10: 89 avegar over 10 episode: -99.985 avegare return across last 100 episodes: -99.985 state values: tensor(0.8128) 1000
90 1000 -1000.0 -99.99568287525881 number episode from 10: 90 avegar over 10 episode: -99.985 avegare return across last 100 episodes: -99.985 state values: tensor(0.8119) 1000
91 1000 -1000.0 -99.99568287525881 number episode from 10: 91 avegar over 10 episode: -99.985 avegare return across last 100 episodes: -99.985 state values: tensor(0.8135) 1000
92 1000 -1000.0 -99.99568287525881 number episode from 10: 92 avegar over 10 episode: -99.985 avegare return across last 100 episodes: -99.985 state values: tensor(0.8500) 1000
93 1000 -1000.0 -99.99568287525881 number episode from 10: 93 avegar over 10 episode: -99.985 avegare return across last 100 episodes: -99.985 state values: tensor(0.8137) 1000
94 1000 -1000.0 -99.99568287525881 number episode from 10: 94 avegar over 10 episode: -99.985 avegare return across last 100 episodes: -99.985 state values: tensor(0.8116) 1000
95 1000 -1000.0 -99.99568287525881 number episode from 10: 95 avegar over 10 episode: -99.985 avegare return across last 100 episodes: -99.985 state values: tensor(0.8130) 1000
96 1000 -1000.0 -99.99568287525881 number episode from 10: 96 avegar over 10 episode: -99.985 avegare return across last 100 episodes: -99.985 state values: tensor(0.8495) 1000
97 1000 -1000.0 -99.99568287525881 number episode from 10: 97 avegar over 10 episode: -99.985 avegare return across last 100 episodes: -99.985 state values: tensor(0.8494) 1000
98 1000 -1000.0 -99.99568287525881 number episode from 10: 98 avegar over 10 episode: -99.986 avegare return across last 100 episodes: -99.986 state values: tensor(0.8116) 1000
99 1000 -1000.0 -99.99568287525881 number episode from 10: 99 avegar over 10 episode: -99.986 avegare return across last 100 episodes: -99.986 state values: tensor(0.8124) 1000
100 1000 -1000.0 -99.99568287525881 number episode from 10: 100 avegar over 10 episode: -99.986 avegare return across last 100 episodes: -99.996 state values: tensor(0.8127) 1000
101 1000 -1000.0 -99.99568287525881 number episode from 10: 101 avegar over 10 episode: -99.986 avegare return across last 100 episodes: -99.996 state values: tensor(0.8368) 1000
102 1000 -1000.0 -99.99568287525881 number episode from 10: 102 avegar over 10 episode: -99.986 avegare return across last 100 episodes: -99.996 state values: tensor(0.8121) 1000
103 1000 -1000.0 -99.99568287525881 number episode from 10: 103 avegar over 10 episode: -99.986 avegare return across last 100 episodes: -99.996 state values: tensor(0.8502) 1000
104 1000 -1000.0 -99.99568287525881 number episode from 10: 104 avegar over 10 episode: -99.986 avegare return across last 100 episodes: -99.996 state values: tensor(0.8131) 1000
105 1000 -1000.0 -99.99568287525881 number episode from 10: 105 avegar over 10 episode: -99.986 avegare return across last 100 episodes: -99.996 state values: tensor(0.8114) 1000
106 1000 -1000.0 -99.99568287525881 number episode from 10: 106 avegar over 10 episode: -99.986 avegare return across last 100 episodes: -99.996 state values: tensor(0.8181) 1000
107 1000 -1000.0 -99.99568287525881 number episode from 10: 107 avegar over 10 episode: -99.986 avegare return across last 100 episodes: -99.996 state values: tensor(0.8130) 1000
108 1000 -1000.0 -99.99568287525881 number episode from 10: 108 avegar over 10 episode: -99.987 avegare return across last 100 episodes: -99.996 state values: tensor(0.8499) 1000
109 1000 -1000.0 -99.99568287525881 number episode from 10: 109 avegar over 10 episode: -99.987 avegare return across last 100 episodes: -99.996 state values: tensor(0.8496) 1000
110 1000 -1000.0 -99.99568287525881 number episode from 10: 110 avegar over 10 episode: -99.987 avegare return across last 100 episodes: -99.996 state values: tensor(0.8142) 1000
111 1000 -1000.0 -99.99568287525881 number episode from 10: 111 avegar over 10 episode: -99.987 avegare return across last 100 episodes: -99.996 state values: tensor(0.8189) 1000
112 1000 -1000.0 -99.99568287525881 number episode from 10: 112 avegar over 10 episode: -99.987 avegare return across last 100 episodes: -99.996 state values: tensor(0.8501) 1000
113 1000 -1000.0 -99.99568287525881 number episode from 10: 113 avegar over 10 episode: -99.987 avegare return across last 100 episodes: -99.996 state values: tensor(0.8489) 1000
114 1000 -1000.0 -99.99568287525881 number episode from 10: 114 avegar over 10 episode: -99.987 avegare return across last 100 episodes: -99.996 state values: tensor(0.8510) 1000
115 1000 -1000.0 -99.99568287525881 number episode from 10: 115 avegar over 10 episode: -99.987 avegare return across last 100 episodes: -99.996 state values: tensor(0.8115) 1000
116 1000 -1000.0 -99.99568287525881 number episode from 10: 116 avegar over 10 episode: -99.987 avegare return across last 100 episodes: -99.996 state values: tensor(0.8125) 1000
117 1000 -1000.0 -99.99568287525881 number episode from 10: 117 avegar over 10 episode: -99.987 avegare return across last 100 episodes: -99.996 state values: tensor(0.8119) 1000
118 1000 -1000.0 -99.99568287525881 number episode from 10: 118 avegar over 10 episode: -99.987 avegare return across last 100 episodes: -99.996 state values: tensor(0.8116) 1000
119 1000 -1000.0 -99.99568287525881 number episode from 10: 119 avegar over 10 episode: -99.987 avegare return across last 100 episodes: -99.996 state values: tensor(0.8115) 1000
120 1000 -1000.0 -99.99568287525881 number episode from 10: 120 avegar over 10 episode: -99.987 avegare return across last 100 episodes: -99.996 state values: tensor(0.8129) 1000
121 1000 -1000.0 -99.99568287525881 number episode from 10: 121 avegar over 10 episode: -99.987 avegare return across last 100 episodes: -99.996 state values: tensor(0.8487) 1000
122 1000 -1000.0 -99.99568287525881 number episode from 10: 122 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.8490) 1000
123 1000 -1000.0 -99.99568287525881 number episode from 10: 123 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.8116) 1000
124 1000 -1000.0 -99.99568287525881 number episode from 10: 124 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.8294) 1000
125 1000 -1000.0 -99.99568287525881 number episode from 10: 125 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.8127) 1000
126 1000 -1000.0 -99.99568287525881 number episode from 10: 126 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.8117) 1000
127 1000 -1000.0 -99.99568287525881 number episode from 10: 127 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.8497) 1000
128 1000 -1000.0 -99.99568287525881 number episode from 10: 128 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.8126) 1000
129 1000 -1000.0 -99.99568287525881 number episode from 10: 129 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.8143) 1000
130 1000 -1000.0 -99.99568287525881 number episode from 10: 130 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.8116) 1000
131 1000 -1000.0 -99.99568287525881 number episode from 10: 131 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.8128) 1000
132 1000 -1000.0 -99.99568287525881 number episode from 10: 132 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.8123) 1000
133 1000 -1000.0 -99.99568287525881 number episode from 10: 133 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.8111) 1000
134 1000 -1000.0 -99.99568287525881 number episode from 10: 134 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.8117) 1000
135 1000 -1000.0 -99.99568287525881 number episode from 10: 135 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.8246) 1000
136 1000 -1000.0 -99.99568287525881 number episode from 10: 136 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.8135) 1000
137 1000 -1000.0 -99.99568287525881 number episode from 10: 137 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.8112) 1000
138 1000 -1000.0 -99.99568287525881 number episode from 10: 138 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.8135) 1000
139 1000 -1000.0 -99.99568287525881 number episode from 10: 139 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.8118) 1000
140 1000 -1000.0 -99.99568287525881 number episode from 10: 140 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.8471) 1000
141 1000 -1000.0 -99.99568287525881 number episode from 10: 141 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.8110) 1000
142 1000 -1000.0 -99.99568287525881 number episode from 10: 142 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.8119) 1000
143 1000 -1000.0 -99.99568287525881 number episode from 10: 143 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.8115) 1000
144 1000 -1000.0 -99.99568287525881 number episode from 10: 144 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.8115) 1000
145 1000 -1000.0 -99.99568287525881 number episode from 10: 145 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.8489) 1000
146 1000 -1000.0 -99.99568287525881 number episode from 10: 146 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.8120) 1000
147 1000 -1000.0 -99.99568287525881 number episode from 10: 147 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.8499) 1000
148 1000 -1000.0 -99.99568287525881 number episode from 10: 148 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.8140) 1000
149 1000 -1000.0 -99.99568287525881 number episode from 10: 149 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.8114) 1000
150 1000 -1000.0 -99.99568287525881 number episode from 10: 150 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.8113) 1000
151 1000 -1000.0 -99.99568287525881 number episode from 10: 151 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.8134) 1000
152 1000 -1000.0 -99.99568287525881 number episode from 10: 152 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.8503) 1000
153 1000 -1000.0 -99.99568287525881 number episode from 10: 153 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.8120) 1000
154 1000 -1000.0 -99.99568287525881 number episode from 10: 154 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.8138) 1000
155 1000 -1000.0 -99.99568287525881 number episode from 10: 155 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.8119) 1000
156 1000 -1000.0 -99.99568287525881 number episode from 10: 156 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.8185) 1000
157 1000 -1000.0 -99.99568287525881 number episode from 10: 157 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.8112) 1000
158 1000 -1000.0 -99.99568287525881 number episode from 10: 158 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.8128) 1000
159 1000 -1000.0 -99.99568287525881 number episode from 10: 159 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.8122) 1000
160 1000 -1000.0 -99.99568287525881 number episode from 10: 160 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.8117) 1000
161 1000 -1000.0 -99.99568287525881 number episode from 10: 161 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.8129) 1000
162 1000 -1000.0 -99.99568287525881 number episode from 10: 162 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.8504) 1000
163 1000 -1000.0 -99.99568287525881 number episode from 10: 163 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.8126) 1000
164 1000 -1000.0 -99.99568287525881 number episode from 10: 164 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.8144) 1000
165 1000 -1000.0 -99.99568287525881 number episode from 10: 165 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.8480) 1000
166 1000 -1000.0 -99.99568287525881 number episode from 10: 166 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.8136) 1000
167 1000 -1000.0 -99.99568287525881 number episode from 10: 167 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.8141) 1000
168 1000 -1000.0 -99.99568287525881 number episode from 10: 168 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.8115) 1000
169 1000 -1000.0 -99.99568287525881 number episode from 10: 169 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.8490) 1000
170 1000 -1000.0 -99.99568287525881 number episode from 10: 170 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.8136) 1000
171 1000 -1000.0 -99.99568287525881 number episode from 10: 171 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.8132) 1000
172 1000 -1000.0 -99.99568287525881 number episode from 10: 172 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.8120) 1000
173 1000 -1000.0 -99.99568287525881 number episode from 10: 173 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.8110) 1000
174 1000 -1000.0 -99.99568287525881 number episode from 10: 174 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.8111) 1000
175 1000 -1000.0 -99.99568287525881 number episode from 10: 175 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.8123) 1000
176 1000 -1000.0 -99.99568287525881 number episode from 10: 176 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.8134) 1000
177 1000 -1000.0 -99.99568287525881 number episode from 10: 177 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.8129) 1000
178 1000 -1000.0 -99.99568287525881 number episode from 10: 178 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.8115) 1000
179 1000 -1000.0 -99.99568287525881 number episode from 10: 179 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.8111) 1000
180 1000 -1000.0 -99.99568287525881 number episode from 10: 180 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.8136) 1000
181 1000 -1000.0 -99.99568287525881 number episode from 10: 181 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.8347) 1000
182 1000 -1000.0 -99.99568287525881 number episode from 10: 182 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.8513) 1000
183 1000 -1000.0 -99.99568287525881 number episode from 10: 183 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.8145) 1000
184 1000 -1000.0 -99.99568287525881 number episode from 10: 184 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.8123) 1000
185 1000 -1000.0 -99.99568287525881 number episode from 10: 185 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.8116) 1000
186 1000 -1000.0 -99.99568287525881 number episode from 10: 186 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.8114) 1000
187 1000 -1000.0 -99.99568287525881 number episode from 10: 187 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.8112) 1000
188 1000 -1000.0 -99.99568287525881 number episode from 10: 188 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.8139) 1000
189 1000 -1000.0 -99.99568287525881 number episode from 10: 189 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.8125) 1000
190 1000 -1000.0 -99.99568287525881 number episode from 10: 190 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.8111) 1000
191 1000 -1000.0 -99.99568287525881 number episode from 10: 191 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.8349) 1000
192 1000 -1000.0 -99.99568287525881 number episode from 10: 192 avegar over 10 episode: -99.991 avegare return across last 100 episodes: -99.996 state values: tensor(0.8141) 1000
193 1000 -1000.0 -99.99568287525881 number episode from 10: 193 avegar over 10 episode: -99.991 avegare return across last 100 episodes: -99.996 state values: tensor(0.8140) 1000
194 1000 -1000.0 -99.99568287525881 number episode from 10: 194 avegar over 10 episode: -99.991 avegare return across last 100 episodes: -99.996 state values: tensor(0.8112) 1000
195 1000 -1000.0 -99.99568287525881 number episode from 10: 195 avegar over 10 episode: -99.991 avegare return across last 100 episodes: -99.996 state values: tensor(0.8125) 1000
196 1000 -1000.0 -99.99568287525881 number episode from 10: 196 avegar over 10 episode: -99.991 avegare return across last 100 episodes: -99.996 state values: tensor(0.8120) 1000
197 1000 -1000.0 -99.99568287525881 number episode from 10: 197 avegar over 10 episode: -99.991 avegare return across last 100 episodes: -99.996 state values: tensor(0.8125) 1000
198 1000 -1000.0 -99.99568287525881 number episode from 10: 198 avegar over 10 episode: -99.991 avegare return across last 100 episodes: -99.996 state values: tensor(0.8115) 1000
199 1000 -1000.0 -99.99568287525881 number episode from 10: 199 avegar over 10 episode: -99.991 avegare return across last 100 episodes: -99.996 state values: tensor(0.8478) 1000
200 1000 -1000.0 -99.99568287525881 number episode from 10: 200 avegar over 10 episode: -99.991 avegare return across last 100 episodes: -99.996 state values: tensor(0.8133) 1000
Start! Seed: 96
0 1001 -1000.0 -98.99572604650622 number episode from 10: 0 avegar over 10 episode: -98.996 avegare return across last 100 episodes: -98.996 state values: tensor(0.7071) 1000
1 1000 -1000.0 -99.99568287525881 number episode from 10: 1 avegar over 10 episode: -99.496 avegare return across last 100 episodes: -99.496 state values: tensor(0.7047) 1000
2 1000 -1000.0 -99.99568287525881 number episode from 10: 2 avegar over 10 episode: -99.662 avegare return across last 100 episodes: -99.662 state values: tensor(0.7062) 1000
3 1000 -1000.0 -99.99568287525881 number episode from 10: 3 avegar over 10 episode: -99.746 avegare return across last 100 episodes: -99.746 state values: tensor(0.7034) 1000
4 1000 -1000.0 -99.99568287525881 number episode from 10: 4 avegar over 10 episode: -99.796 avegare return across last 100 episodes: -99.796 state values: tensor(0.7044) 1000
5 1000 -1000.0 -99.99568287525881 number episode from 10: 5 avegar over 10 episode: -99.829 avegare return across last 100 episodes: -99.829 state values: tensor(0.7051) 1000
6 1000 -1000.0 -99.99568287525881 number episode from 10: 6 avegar over 10 episode: -99.853 avegare return across last 100 episodes: -99.853 state values: tensor(0.7047) 1000
7 1000 -1000.0 -99.99568287525881 number episode from 10: 7 avegar over 10 episode: -99.871 avegare return across last 100 episodes: -99.871 state values: tensor(0.7057) 1000
8 1000 -1000.0 -99.99568287525881 number episode from 10: 8 avegar over 10 episode: -99.885 avegare return across last 100 episodes: -99.885 state values: tensor(0.7092) 1000
9 1000 -1000.0 -99.99568287525881 number episode from 10: 9 avegar over 10 episode: -99.896 avegare return across last 100 episodes: -99.896 state values: tensor(0.7106) 1000
10 1000 -1000.0 -99.99568287525881 number episode from 10: 10 avegar over 10 episode: -99.905 avegare return across last 100 episodes: -99.905 state values: tensor(0.7047) 1000
11 1000 -1000.0 -99.99568287525881 number episode from 10: 11 avegar over 10 episode: -99.912 avegare return across last 100 episodes: -99.912 state values: tensor(0.7045) 1000
12 1000 -1000.0 -99.99568287525881 number episode from 10: 12 avegar over 10 episode: -99.919 avegare return across last 100 episodes: -99.919 state values: tensor(0.7072) 1000
13 1000 -1000.0 -99.99568287525881 number episode from 10: 13 avegar over 10 episode: -99.924 avegare return across last 100 episodes: -99.924 state values: tensor(0.7043) 1000
14 1000 -1000.0 -99.99568287525881 number episode from 10: 14 avegar over 10 episode: -99.929 avegare return across last 100 episodes: -99.929 state values: tensor(0.7045) 1000
15 1000 -1000.0 -99.99568287525881 number episode from 10: 15 avegar over 10 episode: -99.933 avegare return across last 100 episodes: -99.933 state values: tensor(0.7032) 1000
16 1000 -1000.0 -99.99568287525881 number episode from 10: 16 avegar over 10 episode: -99.937 avegare return across last 100 episodes: -99.937 state values: tensor(0.7048) 1000
17 1000 -1000.0 -99.99568287525881 number episode from 10: 17 avegar over 10 episode: -99.94 avegare return across last 100 episodes: -99.94 state values: tensor(0.7034) 1000
18 1000 -1000.0 -99.99568287525881 number episode from 10: 18 avegar over 10 episode: -99.943 avegare return across last 100 episodes: -99.943 state values: tensor(0.7062) 1000
19 1000 -1000.0 -99.99568287525881 number episode from 10: 19 avegar over 10 episode: -99.946 avegare return across last 100 episodes: -99.946 state values: tensor(0.7043) 1000
20 1000 -1000.0 -99.99568287525881 number episode from 10: 20 avegar over 10 episode: -99.948 avegare return across last 100 episodes: -99.948 state values: tensor(0.7071) 1000
21 1000 -1000.0 -99.99568287525881 number episode from 10: 21 avegar over 10 episode: -99.95 avegare return across last 100 episodes: -99.95 state values: tensor(0.7100) 1000
22 1000 -1000.0 -99.99568287525881 number episode from 10: 22 avegar over 10 episode: -99.952 avegare return across last 100 episodes: -99.952 state values: tensor(0.7058) 1000
23 1000 -1000.0 -99.99568287525881 number episode from 10: 23 avegar over 10 episode: -99.954 avegare return across last 100 episodes: -99.954 state values: tensor(0.7042) 1000
24 1000 -1000.0 -99.99568287525881 number episode from 10: 24 avegar over 10 episode: -99.956 avegare return across last 100 episodes: -99.956 state values: tensor(0.7048) 1000
25 1000 -1000.0 -99.99568287525881 number episode from 10: 25 avegar over 10 episode: -99.957 avegare return across last 100 episodes: -99.957 state values: tensor(0.7067) 1000
26 1000 -1000.0 -99.99568287525881 number episode from 10: 26 avegar over 10 episode: -99.959 avegare return across last 100 episodes: -99.959 state values: tensor(0.7044) 1000
27 1000 -1000.0 -99.99568287525881 number episode from 10: 27 avegar over 10 episode: -99.96 avegare return across last 100 episodes: -99.96 state values: tensor(0.7113) 1000
28 1000 -1000.0 -99.99568287525881 number episode from 10: 28 avegar over 10 episode: -99.961 avegare return across last 100 episodes: -99.961 state values: tensor(0.7058) 1000
29 1000 -1000.0 -99.99568287525881 number episode from 10: 29 avegar over 10 episode: -99.962 avegare return across last 100 episodes: -99.962 state values: tensor(0.7067) 1000
30 1000 -1000.0 -99.99568287525881 number episode from 10: 30 avegar over 10 episode: -99.963 avegare return across last 100 episodes: -99.963 state values: tensor(0.7088) 1000
31 1000 -1000.0 -99.99568287525881 number episode from 10: 31 avegar over 10 episode: -99.964 avegare return across last 100 episodes: -99.964 state values: tensor(0.7077) 1000
32 1000 -1000.0 -99.99568287525881 number episode from 10: 32 avegar over 10 episode: -99.965 avegare return across last 100 episodes: -99.965 state values: tensor(0.7047) 1000
33 1000 -1000.0 -99.99568287525881 number episode from 10: 33 avegar over 10 episode: -99.966 avegare return across last 100 episodes: -99.966 state values: tensor(0.7097) 1000
34 1000 -1000.0 -99.99568287525881 number episode from 10: 34 avegar over 10 episode: -99.967 avegare return across last 100 episodes: -99.967 state values: tensor(0.7035) 1000
35 1000 -1000.0 -99.99568287525881 number episode from 10: 35 avegar over 10 episode: -99.968 avegare return across last 100 episodes: -99.968 state values: tensor(0.7107) 1000
36 1000 -1000.0 -99.99568287525881 number episode from 10: 36 avegar over 10 episode: -99.969 avegare return across last 100 episodes: -99.969 state values: tensor(0.7032) 1000
37 1000 -1000.0 -99.99568287525881 number episode from 10: 37 avegar over 10 episode: -99.969 avegare return across last 100 episodes: -99.969 state values: tensor(0.7046) 1000
38 1000 -1000.0 -99.99568287525881 number episode from 10: 38 avegar over 10 episode: -99.97 avegare return across last 100 episodes: -99.97 state values: tensor(0.7067) 1000
39 1000 -1000.0 -99.99568287525881 number episode from 10: 39 avegar over 10 episode: -99.971 avegare return across last 100 episodes: -99.971 state values: tensor(0.7039) 1000
40 1000 -1000.0 -99.99568287525881 number episode from 10: 40 avegar over 10 episode: -99.971 avegare return across last 100 episodes: -99.971 state values: tensor(0.7104) 1000
41 1000 -1000.0 -99.99568287525881 number episode from 10: 41 avegar over 10 episode: -99.972 avegare return across last 100 episodes: -99.972 state values: tensor(0.7083) 1000
42 1000 -1000.0 -99.99568287525881 number episode from 10: 42 avegar over 10 episode: -99.972 avegare return across last 100 episodes: -99.972 state values: tensor(0.7090) 1000
43 1000 -1000.0 -99.99568287525881 number episode from 10: 43 avegar over 10 episode: -99.973 avegare return across last 100 episodes: -99.973 state values: tensor(0.7057) 1000
44 1000 -1000.0 -99.99568287525881 number episode from 10: 44 avegar over 10 episode: -99.973 avegare return across last 100 episodes: -99.973 state values: tensor(0.7094) 1000
45 1000 -1000.0 -99.99568287525881 number episode from 10: 45 avegar over 10 episode: -99.974 avegare return across last 100 episodes: -99.974 state values: tensor(0.7061) 1000
46 1000 -1000.0 -99.99568287525881 number episode from 10: 46 avegar over 10 episode: -99.974 avegare return across last 100 episodes: -99.974 state values: tensor(0.7042) 1000
47 1000 -1000.0 -99.99568287525881 number episode from 10: 47 avegar over 10 episode: -99.975 avegare return across last 100 episodes: -99.975 state values: tensor(0.7033) 1000
48 1000 -1000.0 -99.99568287525881 number episode from 10: 48 avegar over 10 episode: -99.975 avegare return across last 100 episodes: -99.975 state values: tensor(0.7034) 1000
49 1000 -1000.0 -99.99568287525881 number episode from 10: 49 avegar over 10 episode: -99.976 avegare return across last 100 episodes: -99.976 state values: tensor(0.7068) 1000
50 1000 -1000.0 -99.99568287525881 number episode from 10: 50 avegar over 10 episode: -99.976 avegare return across last 100 episodes: -99.976 state values: tensor(0.7040) 1000
51 1000 -1000.0 -99.99568287525881 number episode from 10: 51 avegar over 10 episode: -99.976 avegare return across last 100 episodes: -99.976 state values: tensor(0.7038) 1000
52 1000 -1000.0 -99.99568287525881 number episode from 10: 52 avegar over 10 episode: -99.977 avegare return across last 100 episodes: -99.977 state values: tensor(0.7049) 1000
53 1000 -1000.0 -99.99568287525881 number episode from 10: 53 avegar over 10 episode: -99.977 avegare return across last 100 episodes: -99.977 state values: tensor(0.7069) 1000
54 1000 -1000.0 -99.99568287525881 number episode from 10: 54 avegar over 10 episode: -99.978 avegare return across last 100 episodes: -99.978 state values: tensor(0.7085) 1000
55 1000 -1000.0 -99.99568287525881 number episode from 10: 55 avegar over 10 episode: -99.978 avegare return across last 100 episodes: -99.978 state values: tensor(0.7099) 1000
56 1000 -1000.0 -99.99568287525881 number episode from 10: 56 avegar over 10 episode: -99.978 avegare return across last 100 episodes: -99.978 state values: tensor(0.7057) 1000
57 1000 -1000.0 -99.99568287525881 number episode from 10: 57 avegar over 10 episode: -99.978 avegare return across last 100 episodes: -99.978 state values: tensor(0.7044) 1000
58 1000 -1000.0 -99.99568287525881 number episode from 10: 58 avegar over 10 episode: -99.979 avegare return across last 100 episodes: -99.979 state values: tensor(0.7060) 1000
59 1000 -1000.0 -99.99568287525881 number episode from 10: 59 avegar over 10 episode: -99.979 avegare return across last 100 episodes: -99.979 state values: tensor(0.7106) 1000
60 1000 -1000.0 -99.99568287525881 number episode from 10: 60 avegar over 10 episode: -99.979 avegare return across last 100 episodes: -99.979 state values: tensor(0.7045) 1000
61 1000 -1000.0 -99.99568287525881 number episode from 10: 61 avegar over 10 episode: -99.98 avegare return across last 100 episodes: -99.98 state values: tensor(0.7040) 1000
62 1000 -1000.0 -99.99568287525881 number episode from 10: 62 avegar over 10 episode: -99.98 avegare return across last 100 episodes: -99.98 state values: tensor(0.7065) 1000
63 1000 -1000.0 -99.99568287525881 number episode from 10: 63 avegar over 10 episode: -99.98 avegare return across last 100 episodes: -99.98 state values: tensor(0.7056) 1000
64 1000 -1000.0 -99.99568287525881 number episode from 10: 64 avegar over 10 episode: -99.98 avegare return across last 100 episodes: -99.98 state values: tensor(0.7032) 1000
65 1000 -1000.0 -99.99568287525881 number episode from 10: 65 avegar over 10 episode: -99.981 avegare return across last 100 episodes: -99.981 state values: tensor(0.7043) 1000
66 1000 -1000.0 -99.99568287525881 number episode from 10: 66 avegar over 10 episode: -99.981 avegare return across last 100 episodes: -99.981 state values: tensor(0.7061) 1000
67 1000 -1000.0 -99.99568287525881 number episode from 10: 67 avegar over 10 episode: -99.981 avegare return across last 100 episodes: -99.981 state values: tensor(0.7032) 1000
68 1000 -1000.0 -99.99568287525881 number episode from 10: 68 avegar over 10 episode: -99.981 avegare return across last 100 episodes: -99.981 state values: tensor(0.7040) 1000
69 1000 -1000.0 -99.99568287525881 number episode from 10: 69 avegar over 10 episode: -99.981 avegare return across last 100 episodes: -99.981 state values: tensor(0.7037) 1000
70 1000 -1000.0 -99.99568287525881 number episode from 10: 70 avegar over 10 episode: -99.982 avegare return across last 100 episodes: -99.982 state values: tensor(0.7074) 1000
71 1000 -1000.0 -99.99568287525881 number episode from 10: 71 avegar over 10 episode: -99.982 avegare return across last 100 episodes: -99.982 state values: tensor(0.7034) 1000
72 1000 -1000.0 -99.99568287525881 number episode from 10: 72 avegar over 10 episode: -99.982 avegare return across last 100 episodes: -99.982 state values: tensor(0.7069) 1000
73 1000 -1000.0 -99.99568287525881 number episode from 10: 73 avegar over 10 episode: -99.982 avegare return across last 100 episodes: -99.982 state values: tensor(0.7043) 1000
74 1000 -1000.0 -99.99568287525881 number episode from 10: 74 avegar over 10 episode: -99.982 avegare return across last 100 episodes: -99.982 state values: tensor(0.7032) 1000
75 1000 -1000.0 -99.99568287525881 number episode from 10: 75 avegar over 10 episode: -99.983 avegare return across last 100 episodes: -99.983 state values: tensor(0.7106) 1000
76 1000 -1000.0 -99.99568287525881 number episode from 10: 76 avegar over 10 episode: -99.983 avegare return across last 100 episodes: -99.983 state values: tensor(0.7042) 1000
77 1000 -1000.0 -99.99568287525881 number episode from 10: 77 avegar over 10 episode: -99.983 avegare return across last 100 episodes: -99.983 state values: tensor(0.7036) 1000
78 1000 -1000.0 -99.99568287525881 number episode from 10: 78 avegar over 10 episode: -99.983 avegare return across last 100 episodes: -99.983 state values: tensor(0.7088) 1000
79 1000 -1000.0 -99.99568287525881 number episode from 10: 79 avegar over 10 episode: -99.983 avegare return across last 100 episodes: -99.983 state values: tensor(0.7044) 1000
80 1000 -1000.0 -99.99568287525881 number episode from 10: 80 avegar over 10 episode: -99.983 avegare return across last 100 episodes: -99.983 state values: tensor(0.7076) 1000
81 1000 -1000.0 -99.99568287525881 number episode from 10: 81 avegar over 10 episode: -99.983 avegare return across last 100 episodes: -99.983 state values: tensor(0.7046) 1000
82 1000 -1000.0 -99.99568287525881 number episode from 10: 82 avegar over 10 episode: -99.984 avegare return across last 100 episodes: -99.984 state values: tensor(0.7056) 1000
83 1000 -1000.0 -99.99568287525881 number episode from 10: 83 avegar over 10 episode: -99.984 avegare return across last 100 episodes: -99.984 state values: tensor(0.7037) 1000
84 1000 -1000.0 -99.99568287525881 number episode from 10: 84 avegar over 10 episode: -99.984 avegare return across last 100 episodes: -99.984 state values: tensor(0.7038) 1000
85 1000 -1000.0 -99.99568287525881 number episode from 10: 85 avegar over 10 episode: -99.984 avegare return across last 100 episodes: -99.984 state values: tensor(0.7038) 1000
86 1000 -1000.0 -99.99568287525881 number episode from 10: 86 avegar over 10 episode: -99.984 avegare return across last 100 episodes: -99.984 state values: tensor(0.7034) 1000
87 1000 -1000.0 -99.99568287525881 number episode from 10: 87 avegar over 10 episode: -99.984 avegare return across last 100 episodes: -99.984 state values: tensor(0.7043) 1000
88 1000 -1000.0 -99.99568287525881 number episode from 10: 88 avegar over 10 episode: -99.984 avegare return across last 100 episodes: -99.984 state values: tensor(0.7102) 1000
89 1000 -1000.0 -99.99568287525881 number episode from 10: 89 avegar over 10 episode: -99.985 avegare return across last 100 episodes: -99.985 state values: tensor(0.7064) 1000
90 1000 -1000.0 -99.99568287525881 number episode from 10: 90 avegar over 10 episode: -99.985 avegare return across last 100 episodes: -99.985 state values: tensor(0.7095) 1000
91 1000 -1000.0 -99.99568287525881 number episode from 10: 91 avegar over 10 episode: -99.985 avegare return across last 100 episodes: -99.985 state values: tensor(0.7074) 1000
92 1000 -1000.0 -99.99568287525881 number episode from 10: 92 avegar over 10 episode: -99.985 avegare return across last 100 episodes: -99.985 state values: tensor(0.7064) 1000
93 1000 -1000.0 -99.99568287525881 number episode from 10: 93 avegar over 10 episode: -99.985 avegare return across last 100 episodes: -99.985 state values: tensor(0.7107) 1000
94 1000 -1000.0 -99.99568287525881 number episode from 10: 94 avegar over 10 episode: -99.985 avegare return across last 100 episodes: -99.985 state values: tensor(0.7057) 1000
95 1000 -1000.0 -99.99568287525881 number episode from 10: 95 avegar over 10 episode: -99.985 avegare return across last 100 episodes: -99.985 state values: tensor(0.7052) 1000
96 1000 -1000.0 -99.99568287525881 number episode from 10: 96 avegar over 10 episode: -99.985 avegare return across last 100 episodes: -99.985 state values: tensor(0.7069) 1000
97 1000 -1000.0 -99.99568287525881 number episode from 10: 97 avegar over 10 episode: -99.985 avegare return across last 100 episodes: -99.985 state values: tensor(0.7063) 1000
98 1000 -1000.0 -99.99568287525881 number episode from 10: 98 avegar over 10 episode: -99.986 avegare return across last 100 episodes: -99.986 state values: tensor(0.7032) 1000
99 1000 -1000.0 -99.99568287525881 number episode from 10: 99 avegar over 10 episode: -99.986 avegare return across last 100 episodes: -99.986 state values: tensor(0.7099) 1000
100 1000 -1000.0 -99.99568287525881 number episode from 10: 100 avegar over 10 episode: -99.986 avegare return across last 100 episodes: -99.996 state values: tensor(0.7033) 1000
101 1000 -1000.0 -99.99568287525881 number episode from 10: 101 avegar over 10 episode: -99.986 avegare return across last 100 episodes: -99.996 state values: tensor(0.7049) 1000
102 1000 -1000.0 -99.99568287525881 number episode from 10: 102 avegar over 10 episode: -99.986 avegare return across last 100 episodes: -99.996 state values: tensor(0.7051) 1000
103 1000 -1000.0 -99.99568287525881 number episode from 10: 103 avegar over 10 episode: -99.986 avegare return across last 100 episodes: -99.996 state values: tensor(0.7032) 1000
104 1000 -1000.0 -99.99568287525881 number episode from 10: 104 avegar over 10 episode: -99.986 avegare return across last 100 episodes: -99.996 state values: tensor(0.7098) 1000
105 1000 -1000.0 -99.99568287525881 number episode from 10: 105 avegar over 10 episode: -99.986 avegare return across last 100 episodes: -99.996 state values: tensor(0.7070) 1000
106 1000 -1000.0 -99.99568287525881 number episode from 10: 106 avegar over 10 episode: -99.986 avegare return across last 100 episodes: -99.996 state values: tensor(0.7034) 1000
107 1000 -1000.0 -99.99568287525881 number episode from 10: 107 avegar over 10 episode: -99.986 avegare return across last 100 episodes: -99.996 state values: tensor(0.7036) 1000
108 1000 -1000.0 -99.99568287525881 number episode from 10: 108 avegar over 10 episode: -99.987 avegare return across last 100 episodes: -99.996 state values: tensor(0.7034) 1000
109 1000 -1000.0 -99.99568287525881 number episode from 10: 109 avegar over 10 episode: -99.987 avegare return across last 100 episodes: -99.996 state values: tensor(0.7108) 1000
110 1000 -1000.0 -99.99568287525881 number episode from 10: 110 avegar over 10 episode: -99.987 avegare return across last 100 episodes: -99.996 state values: tensor(0.7033) 1000
111 1000 -1000.0 -99.99568287525881 number episode from 10: 111 avegar over 10 episode: -99.987 avegare return across last 100 episodes: -99.996 state values: tensor(0.7037) 1000
112 1000 -1000.0 -99.99568287525881 number episode from 10: 112 avegar over 10 episode: -99.987 avegare return across last 100 episodes: -99.996 state values: tensor(0.7112) 1000
113 1000 -1000.0 -99.99568287525881 number episode from 10: 113 avegar over 10 episode: -99.987 avegare return across last 100 episodes: -99.996 state values: tensor(0.7038) 1000
114 1000 -1000.0 -99.99568287525881 number episode from 10: 114 avegar over 10 episode: -99.987 avegare return across last 100 episodes: -99.996 state values: tensor(0.7042) 1000
115 1000 -1000.0 -99.99568287525881 number episode from 10: 115 avegar over 10 episode: -99.987 avegare return across last 100 episodes: -99.996 state values: tensor(0.7041) 1000
116 1000 -1000.0 -99.99568287525881 number episode from 10: 116 avegar over 10 episode: -99.987 avegare return across last 100 episodes: -99.996 state values: tensor(0.7051) 1000
117 1000 -1000.0 -99.99568287525881 number episode from 10: 117 avegar over 10 episode: -99.987 avegare return across last 100 episodes: -99.996 state values: tensor(0.7034) 1000
118 1000 -1000.0 -99.99568287525881 number episode from 10: 118 avegar over 10 episode: -99.987 avegare return across last 100 episodes: -99.996 state values: tensor(0.7058) 1000
119 1000 -1000.0 -99.99568287525881 number episode from 10: 119 avegar over 10 episode: -99.987 avegare return across last 100 episodes: -99.996 state values: tensor(0.7040) 1000
120 1000 -1000.0 -99.99568287525881 number episode from 10: 120 avegar over 10 episode: -99.987 avegare return across last 100 episodes: -99.996 state values: tensor(0.7067) 1000
121 1000 -1000.0 -99.99568287525881 number episode from 10: 121 avegar over 10 episode: -99.987 avegare return across last 100 episodes: -99.996 state values: tensor(0.7066) 1000
122 1000 -1000.0 -99.99568287525881 number episode from 10: 122 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.7047) 1000
123 1000 -1000.0 -99.99568287525881 number episode from 10: 123 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.7038) 1000
124 1000 -1000.0 -99.99568287525881 number episode from 10: 124 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.7062) 1000
125 1000 -1000.0 -99.99568287525881 number episode from 10: 125 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.7036) 1000
126 1000 -1000.0 -99.99568287525881 number episode from 10: 126 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.7039) 1000
127 1000 -1000.0 -99.99568287525881 number episode from 10: 127 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.7032) 1000
128 1000 -1000.0 -99.99568287525881 number episode from 10: 128 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.7045) 1000
129 1000 -1000.0 -99.99568287525881 number episode from 10: 129 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.7064) 1000
130 1000 -1000.0 -99.99568287525881 number episode from 10: 130 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.7032) 1000
131 1000 -1000.0 -99.99568287525881 number episode from 10: 131 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.7114) 1000
132 1000 -1000.0 -99.99568287525881 number episode from 10: 132 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.7082) 1000
133 1000 -1000.0 -99.99568287525881 number episode from 10: 133 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.7056) 1000
134 1000 -1000.0 -99.99568287525881 number episode from 10: 134 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.7034) 1000
135 1000 -1000.0 -99.99568287525881 number episode from 10: 135 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.7076) 1000
136 1000 -1000.0 -99.99568287525881 number episode from 10: 136 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.7043) 1000
137 1000 -1000.0 -99.99568287525881 number episode from 10: 137 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.7034) 1000
138 1000 -1000.0 -99.99568287525881 number episode from 10: 138 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.7080) 1000
139 1000 -1000.0 -99.99568287525881 number episode from 10: 139 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.7055) 1000
140 1000 -1000.0 -99.99568287525881 number episode from 10: 140 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.7088) 1000
141 1000 -1000.0 -99.99568287525881 number episode from 10: 141 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.7057) 1000
142 1000 -1000.0 -99.99568287525881 number episode from 10: 142 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.7066) 1000
143 1000 -1000.0 -99.99568287525881 number episode from 10: 143 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.7034) 1000
144 1000 -1000.0 -99.99568287525881 number episode from 10: 144 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.7111) 1000
145 1000 -1000.0 -99.99568287525881 number episode from 10: 145 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.7085) 1000
146 1000 -1000.0 -99.99568287525881 number episode from 10: 146 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.7035) 1000
147 1000 -1000.0 -99.99568287525881 number episode from 10: 147 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.7070) 1000
148 1000 -1000.0 -99.99568287525881 number episode from 10: 148 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.7087) 1000
149 1000 -1000.0 -99.99568287525881 number episode from 10: 149 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.7052) 1000
150 1000 -1000.0 -99.99568287525881 number episode from 10: 150 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.7067) 1000
151 1000 -1000.0 -99.99568287525881 number episode from 10: 151 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.7109) 1000
152 1000 -1000.0 -99.99568287525881 number episode from 10: 152 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.7038) 1000
153 1000 -1000.0 -99.99568287525881 number episode from 10: 153 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.7058) 1000
154 1000 -1000.0 -99.99568287525881 number episode from 10: 154 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.7066) 1000
155 1000 -1000.0 -99.99568287525881 number episode from 10: 155 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.7056) 1000
156 1000 -1000.0 -99.99568287525881 number episode from 10: 156 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.7034) 1000
157 1000 -1000.0 -99.99568287525881 number episode from 10: 157 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.7045) 1000
158 1000 -1000.0 -99.99568287525881 number episode from 10: 158 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.7042) 1000
159 1000 -1000.0 -99.99568287525881 number episode from 10: 159 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.7044) 1000
160 1000 -1000.0 -99.99568287525881 number episode from 10: 160 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.7038) 1000
161 1000 -1000.0 -99.99568287525881 number episode from 10: 161 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.7054) 1000
162 1000 -1000.0 -99.99568287525881 number episode from 10: 162 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.7090) 1000
163 1000 -1000.0 -99.99568287525881 number episode from 10: 163 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.7034) 1000
164 1000 -1000.0 -99.99568287525881 number episode from 10: 164 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.7041) 1000
165 1000 -1000.0 -99.99568287525881 number episode from 10: 165 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.7094) 1000
166 1000 -1000.0 -99.99568287525881 number episode from 10: 166 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.7033) 1000
167 1000 -1000.0 -99.99568287525881 number episode from 10: 167 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.7037) 1000
168 1000 -1000.0 -99.99568287525881 number episode from 10: 168 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.7065) 1000
169 1000 -1000.0 -99.99568287525881 number episode from 10: 169 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.7057) 1000
170 1000 -1000.0 -99.99568287525881 number episode from 10: 170 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.7106) 1000
171 1000 -1000.0 -99.99568287525881 number episode from 10: 171 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.7042) 1000
172 1000 -1000.0 -99.99568287525881 number episode from 10: 172 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.7061) 1000
173 1000 -1000.0 -99.99568287525881 number episode from 10: 173 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.7032) 1000
174 1000 -1000.0 -99.99568287525881 number episode from 10: 174 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.7032) 1000
175 1000 -1000.0 -99.99568287525881 number episode from 10: 175 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.7106) 1000
176 1000 -1000.0 -99.99568287525881 number episode from 10: 176 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.7075) 1000
177 1000 -1000.0 -99.99568287525881 number episode from 10: 177 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.7047) 1000
178 1000 -1000.0 -99.99568287525881 number episode from 10: 178 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.7033) 1000
179 1000 -1000.0 -99.99568287525881 number episode from 10: 179 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.7033) 1000
180 1000 -1000.0 -99.99568287525881 number episode from 10: 180 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.7035) 1000
181 1000 -1000.0 -99.99568287525881 number episode from 10: 181 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.7064) 1000
182 1000 -1000.0 -99.99568287525881 number episode from 10: 182 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.7105) 1000
183 1000 -1000.0 -99.99568287525881 number episode from 10: 183 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.7037) 1000
184 1000 -1000.0 -99.99568287525881 number episode from 10: 184 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.7032) 1000
185 1000 -1000.0 -99.99568287525881 number episode from 10: 185 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.7084) 1000
186 1000 -1000.0 -99.99568287525881 number episode from 10: 186 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.7033) 1000
187 1000 -1000.0 -99.99568287525881 number episode from 10: 187 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.7034) 1000
188 1000 -1000.0 -99.99568287525881 number episode from 10: 188 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.7033) 1000
189 1000 -1000.0 -99.99568287525881 number episode from 10: 189 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.7034) 1000
190 1000 -1000.0 -99.99568287525881 number episode from 10: 190 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.7092) 1000
191 1000 -1000.0 -99.99568287525881 number episode from 10: 191 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.7039) 1000
192 1000 -1000.0 -99.99568287525881 number episode from 10: 192 avegar over 10 episode: -99.991 avegare return across last 100 episodes: -99.996 state values: tensor(0.7050) 1000
193 1000 -1000.0 -99.99568287525881 number episode from 10: 193 avegar over 10 episode: -99.991 avegare return across last 100 episodes: -99.996 state values: tensor(0.7037) 1000
194 1000 -1000.0 -99.99568287525881 number episode from 10: 194 avegar over 10 episode: -99.991 avegare return across last 100 episodes: -99.996 state values: tensor(0.7059) 1000
195 1000 -1000.0 -99.99568287525881 number episode from 10: 195 avegar over 10 episode: -99.991 avegare return across last 100 episodes: -99.996 state values: tensor(0.7045) 1000
196 1000 -1000.0 -99.99568287525881 number episode from 10: 196 avegar over 10 episode: -99.991 avegare return across last 100 episodes: -99.996 state values: tensor(0.7036) 1000
197 1000 -1000.0 -99.99568287525881 number episode from 10: 197 avegar over 10 episode: -99.991 avegare return across last 100 episodes: -99.996 state values: tensor(0.7036) 1000
198 1000 -1000.0 -99.99568287525881 number episode from 10: 198 avegar over 10 episode: -99.991 avegare return across last 100 episodes: -99.996 state values: tensor(0.7052) 1000
199 1000 -1000.0 -99.99568287525881 number episode from 10: 199 avegar over 10 episode: -99.991 avegare return across last 100 episodes: -99.996 state values: tensor(0.7039) 1000
200 1000 -1000.0 -99.99568287525881 number episode from 10: 200 avegar over 10 episode: -99.991 avegare return across last 100 episodes: -99.996 state values: tensor(0.7105) 1000
Start! Seed: 128
0 1001 -1000.0 -98.99572604650622 number episode from 10: 0 avegar over 10 episode: -98.996 avegare return across last 100 episodes: -98.996 state values: tensor(0.8624) 1000
1 1000 -1000.0 -99.99568287525881 number episode from 10: 1 avegar over 10 episode: -99.496 avegare return across last 100 episodes: -99.496 state values: tensor(0.8621) 1000
2 1000 -1000.0 -99.99568287525881 number episode from 10: 2 avegar over 10 episode: -99.662 avegare return across last 100 episodes: -99.662 state values: tensor(0.8622) 1000
3 1000 -1000.0 -99.99568287525881 number episode from 10: 3 avegar over 10 episode: -99.746 avegare return across last 100 episodes: -99.746 state values: tensor(0.8623) 1000
4 1000 -1000.0 -99.99568287525881 number episode from 10: 4 avegar over 10 episode: -99.796 avegare return across last 100 episodes: -99.796 state values: tensor(0.8620) 1000
5 1000 -1000.0 -99.99568287525881 number episode from 10: 5 avegar over 10 episode: -99.829 avegare return across last 100 episodes: -99.829 state values: tensor(0.8623) 1000
6 1000 -1000.0 -99.99568287525881 number episode from 10: 6 avegar over 10 episode: -99.853 avegare return across last 100 episodes: -99.853 state values: tensor(0.8622) 1000
7 1000 -1000.0 -99.99568287525881 number episode from 10: 7 avegar over 10 episode: -99.871 avegare return across last 100 episodes: -99.871 state values: tensor(0.8621) 1000
8 1000 -1000.0 -99.99568287525881 number episode from 10: 8 avegar over 10 episode: -99.885 avegare return across last 100 episodes: -99.885 state values: tensor(0.8621) 1000
9 1000 -1000.0 -99.99568287525881 number episode from 10: 9 avegar over 10 episode: -99.896 avegare return across last 100 episodes: -99.896 state values: tensor(0.8620) 1000
10 1000 -1000.0 -99.99568287525881 number episode from 10: 10 avegar over 10 episode: -99.905 avegare return across last 100 episodes: -99.905 state values: tensor(0.8624) 1000
11 1000 -1000.0 -99.99568287525881 number episode from 10: 11 avegar over 10 episode: -99.912 avegare return across last 100 episodes: -99.912 state values: tensor(0.8622) 1000
12 1000 -1000.0 -99.99568287525881 number episode from 10: 12 avegar over 10 episode: -99.919 avegare return across last 100 episodes: -99.919 state values: tensor(0.8619) 1000
13 1000 -1000.0 -99.99568287525881 number episode from 10: 13 avegar over 10 episode: -99.924 avegare return across last 100 episodes: -99.924 state values: tensor(0.8624) 1000
14 1000 -1000.0 -99.99568287525881 number episode from 10: 14 avegar over 10 episode: -99.929 avegare return across last 100 episodes: -99.929 state values: tensor(0.8622) 1000
15 1000 -1000.0 -99.99568287525881 number episode from 10: 15 avegar over 10 episode: -99.933 avegare return across last 100 episodes: -99.933 state values: tensor(0.8620) 1000
16 1000 -1000.0 -99.99568287525881 number episode from 10: 16 avegar over 10 episode: -99.937 avegare return across last 100 episodes: -99.937 state values: tensor(0.8623) 1000
17 1000 -1000.0 -99.99568287525881 number episode from 10: 17 avegar over 10 episode: -99.94 avegare return across last 100 episodes: -99.94 state values: tensor(0.8623) 1000
18 1000 -1000.0 -99.99568287525881 number episode from 10: 18 avegar over 10 episode: -99.943 avegare return across last 100 episodes: -99.943 state values: tensor(0.8623) 1000
19 1000 -1000.0 -99.99568287525881 number episode from 10: 19 avegar over 10 episode: -99.946 avegare return across last 100 episodes: -99.946 state values: tensor(0.8622) 1000
20 1000 -1000.0 -99.99568287525881 number episode from 10: 20 avegar over 10 episode: -99.948 avegare return across last 100 episodes: -99.948 state values: tensor(0.8622) 1000
21 1000 -1000.0 -99.99568287525881 number episode from 10: 21 avegar over 10 episode: -99.95 avegare return across last 100 episodes: -99.95 state values: tensor(0.8623) 1000
22 1000 -1000.0 -99.99568287525881 number episode from 10: 22 avegar over 10 episode: -99.952 avegare return across last 100 episodes: -99.952 state values: tensor(0.8623) 1000
23 1000 -1000.0 -99.99568287525881 number episode from 10: 23 avegar over 10 episode: -99.954 avegare return across last 100 episodes: -99.954 state values: tensor(0.8622) 1000
24 1000 -1000.0 -99.99568287525881 number episode from 10: 24 avegar over 10 episode: -99.956 avegare return across last 100 episodes: -99.956 state values: tensor(0.8624) 1000
25 1000 -1000.0 -99.99568287525881 number episode from 10: 25 avegar over 10 episode: -99.957 avegare return across last 100 episodes: -99.957 state values: tensor(0.8621) 1000
26 1000 -1000.0 -99.99568287525881 number episode from 10: 26 avegar over 10 episode: -99.959 avegare return across last 100 episodes: -99.959 state values: tensor(0.8620) 1000
27 1000 -1000.0 -99.99568287525881 number episode from 10: 27 avegar over 10 episode: -99.96 avegare return across last 100 episodes: -99.96 state values: tensor(0.8622) 1000
28 1000 -1000.0 -99.99568287525881 number episode from 10: 28 avegar over 10 episode: -99.961 avegare return across last 100 episodes: -99.961 state values: tensor(0.8620) 1000
29 1000 -1000.0 -99.99568287525881 number episode from 10: 29 avegar over 10 episode: -99.962 avegare return across last 100 episodes: -99.962 state values: tensor(0.8624) 1000
30 1000 -1000.0 -99.99568287525881 number episode from 10: 30 avegar over 10 episode: -99.963 avegare return across last 100 episodes: -99.963 state values: tensor(0.8622) 1000
31 1000 -1000.0 -99.99568287525881 number episode from 10: 31 avegar over 10 episode: -99.964 avegare return across last 100 episodes: -99.964 state values: tensor(0.8622) 1000
32 1000 -1000.0 -99.99568287525881 number episode from 10: 32 avegar over 10 episode: -99.965 avegare return across last 100 episodes: -99.965 state values: tensor(0.8623) 1000
33 1000 -1000.0 -99.99568287525881 number episode from 10: 33 avegar over 10 episode: -99.966 avegare return across last 100 episodes: -99.966 state values: tensor(0.8621) 1000
34 1000 -1000.0 -99.99568287525881 number episode from 10: 34 avegar over 10 episode: -99.967 avegare return across last 100 episodes: -99.967 state values: tensor(0.8620) 1000
35 1000 -1000.0 -99.99568287525881 number episode from 10: 35 avegar over 10 episode: -99.968 avegare return across last 100 episodes: -99.968 state values: tensor(0.8622) 1000
36 1000 -1000.0 -99.99568287525881 number episode from 10: 36 avegar over 10 episode: -99.969 avegare return across last 100 episodes: -99.969 state values: tensor(0.8622) 1000
37 1000 -1000.0 -99.99568287525881 number episode from 10: 37 avegar over 10 episode: -99.969 avegare return across last 100 episodes: -99.969 state values: tensor(0.8620) 1000
38 1000 -1000.0 -99.99568287525881 number episode from 10: 38 avegar over 10 episode: -99.97 avegare return across last 100 episodes: -99.97 state values: tensor(0.8621) 1000
39 1000 -1000.0 -99.99568287525881 number episode from 10: 39 avegar over 10 episode: -99.971 avegare return across last 100 episodes: -99.971 state values: tensor(0.8622) 1000
40 1000 -1000.0 -99.99568287525881 number episode from 10: 40 avegar over 10 episode: -99.971 avegare return across last 100 episodes: -99.971 state values: tensor(0.8622) 1000
41 1000 -1000.0 -99.99568287525881 number episode from 10: 41 avegar over 10 episode: -99.972 avegare return across last 100 episodes: -99.972 state values: tensor(0.8618) 1000
42 1000 -1000.0 -99.99568287525881 number episode from 10: 42 avegar over 10 episode: -99.972 avegare return across last 100 episodes: -99.972 state values: tensor(0.8623) 1000
43 1000 -1000.0 -99.99568287525881 number episode from 10: 43 avegar over 10 episode: -99.973 avegare return across last 100 episodes: -99.973 state values: tensor(0.8622) 1000
44 1000 -1000.0 -99.99568287525881 number episode from 10: 44 avegar over 10 episode: -99.973 avegare return across last 100 episodes: -99.973 state values: tensor(0.8622) 1000
45 1000 -1000.0 -99.99568287525881 number episode from 10: 45 avegar over 10 episode: -99.974 avegare return across last 100 episodes: -99.974 state values: tensor(0.8622) 1000
46 1000 -1000.0 -99.99568287525881 number episode from 10: 46 avegar over 10 episode: -99.974 avegare return across last 100 episodes: -99.974 state values: tensor(0.8622) 1000
47 1000 -1000.0 -99.99568287525881 number episode from 10: 47 avegar over 10 episode: -99.975 avegare return across last 100 episodes: -99.975 state values: tensor(0.8622) 1000
48 1000 -1000.0 -99.99568287525881 number episode from 10: 48 avegar over 10 episode: -99.975 avegare return across last 100 episodes: -99.975 state values: tensor(0.8624) 1000
49 1000 -1000.0 -99.99568287525881 number episode from 10: 49 avegar over 10 episode: -99.976 avegare return across last 100 episodes: -99.976 state values: tensor(0.8624) 1000
50 1000 -1000.0 -99.99568287525881 number episode from 10: 50 avegar over 10 episode: -99.976 avegare return across last 100 episodes: -99.976 state values: tensor(0.8622) 1000
51 1000 -1000.0 -99.99568287525881 number episode from 10: 51 avegar over 10 episode: -99.976 avegare return across last 100 episodes: -99.976 state values: tensor(0.8622) 1000
52 1000 -1000.0 -99.99568287525881 number episode from 10: 52 avegar over 10 episode: -99.977 avegare return across last 100 episodes: -99.977 state values: tensor(0.8618) 1000
53 1000 -1000.0 -99.99568287525881 number episode from 10: 53 avegar over 10 episode: -99.977 avegare return across last 100 episodes: -99.977 state values: tensor(0.8623) 1000
54 1000 -1000.0 -99.99568287525881 number episode from 10: 54 avegar over 10 episode: -99.978 avegare return across last 100 episodes: -99.978 state values: tensor(0.8623) 1000
55 1000 -1000.0 -99.99568287525881 number episode from 10: 55 avegar over 10 episode: -99.978 avegare return across last 100 episodes: -99.978 state values: tensor(0.8622) 1000
56 1000 -1000.0 -99.99568287525881 number episode from 10: 56 avegar over 10 episode: -99.978 avegare return across last 100 episodes: -99.978 state values: tensor(0.8623) 1000
57 1000 -1000.0 -99.99568287525881 number episode from 10: 57 avegar over 10 episode: -99.978 avegare return across last 100 episodes: -99.978 state values: tensor(0.8620) 1000
58 1000 -1000.0 -99.99568287525881 number episode from 10: 58 avegar over 10 episode: -99.979 avegare return across last 100 episodes: -99.979 state values: tensor(0.8621) 1000
59 1000 -1000.0 -99.99568287525881 number episode from 10: 59 avegar over 10 episode: -99.979 avegare return across last 100 episodes: -99.979 state values: tensor(0.8624) 1000
60 1000 -1000.0 -99.99568287525881 number episode from 10: 60 avegar over 10 episode: -99.979 avegare return across last 100 episodes: -99.979 state values: tensor(0.8623) 1000
61 1000 -1000.0 -99.99568287525881 number episode from 10: 61 avegar over 10 episode: -99.98 avegare return across last 100 episodes: -99.98 state values: tensor(0.8622) 1000
62 1000 -1000.0 -99.99568287525881 number episode from 10: 62 avegar over 10 episode: -99.98 avegare return across last 100 episodes: -99.98 state values: tensor(0.8622) 1000
63 1000 -1000.0 -99.99568287525881 number episode from 10: 63 avegar over 10 episode: -99.98 avegare return across last 100 episodes: -99.98 state values: tensor(0.8623) 1000
64 1000 -1000.0 -99.99568287525881 number episode from 10: 64 avegar over 10 episode: -99.98 avegare return across last 100 episodes: -99.98 state values: tensor(0.8618) 1000
65 1000 -1000.0 -99.99568287525881 number episode from 10: 65 avegar over 10 episode: -99.981 avegare return across last 100 episodes: -99.981 state values: tensor(0.8621) 1000
66 1000 -1000.0 -99.99568287525881 number episode from 10: 66 avegar over 10 episode: -99.981 avegare return across last 100 episodes: -99.981 state values: tensor(0.8621) 1000
67 1000 -1000.0 -99.99568287525881 number episode from 10: 67 avegar over 10 episode: -99.981 avegare return across last 100 episodes: -99.981 state values: tensor(0.8624) 1000
68 1000 -1000.0 -99.99568287525881 number episode from 10: 68 avegar over 10 episode: -99.981 avegare return across last 100 episodes: -99.981 state values: tensor(0.8624) 1000
69 1000 -1000.0 -99.99568287525881 number episode from 10: 69 avegar over 10 episode: -99.981 avegare return across last 100 episodes: -99.981 state values: tensor(0.8622) 1000
70 1000 -1000.0 -99.99568287525881 number episode from 10: 70 avegar over 10 episode: -99.982 avegare return across last 100 episodes: -99.982 state values: tensor(0.8623) 1000
71 1000 -1000.0 -99.99568287525881 number episode from 10: 71 avegar over 10 episode: -99.982 avegare return across last 100 episodes: -99.982 state values: tensor(0.8619) 1000
72 1000 -1000.0 -99.99568287525881 number episode from 10: 72 avegar over 10 episode: -99.982 avegare return across last 100 episodes: -99.982 state values: tensor(0.8622) 1000
73 1000 -1000.0 -99.99568287525881 number episode from 10: 73 avegar over 10 episode: -99.982 avegare return across last 100 episodes: -99.982 state values: tensor(0.8621) 1000
74 1000 -1000.0 -99.99568287525881 number episode from 10: 74 avegar over 10 episode: -99.982 avegare return across last 100 episodes: -99.982 state values: tensor(0.8621) 1000
75 1000 -1000.0 -99.99568287525881 number episode from 10: 75 avegar over 10 episode: -99.983 avegare return across last 100 episodes: -99.983 state values: tensor(0.8621) 1000
76 1000 -1000.0 -99.99568287525881 number episode from 10: 76 avegar over 10 episode: -99.983 avegare return across last 100 episodes: -99.983 state values: tensor(0.8620) 1000
77 1000 -1000.0 -99.99568287525881 number episode from 10: 77 avegar over 10 episode: -99.983 avegare return across last 100 episodes: -99.983 state values: tensor(0.8621) 1000
78 1000 -1000.0 -99.99568287525881 number episode from 10: 78 avegar over 10 episode: -99.983 avegare return across last 100 episodes: -99.983 state values: tensor(0.8621) 1000
79 1000 -1000.0 -99.99568287525881 number episode from 10: 79 avegar over 10 episode: -99.983 avegare return across last 100 episodes: -99.983 state values: tensor(0.8622) 1000
80 1000 -1000.0 -99.99568287525881 number episode from 10: 80 avegar over 10 episode: -99.983 avegare return across last 100 episodes: -99.983 state values: tensor(0.8622) 1000
81 1000 -1000.0 -99.99568287525881 number episode from 10: 81 avegar over 10 episode: -99.983 avegare return across last 100 episodes: -99.983 state values: tensor(0.8621) 1000
82 1000 -1000.0 -99.99568287525881 number episode from 10: 82 avegar over 10 episode: -99.984 avegare return across last 100 episodes: -99.984 state values: tensor(0.8621) 1000
83 1000 -1000.0 -99.99568287525881 number episode from 10: 83 avegar over 10 episode: -99.984 avegare return across last 100 episodes: -99.984 state values: tensor(0.8622) 1000
84 1000 -1000.0 -99.99568287525881 number episode from 10: 84 avegar over 10 episode: -99.984 avegare return across last 100 episodes: -99.984 state values: tensor(0.8624) 1000
85 1000 -1000.0 -99.99568287525881 number episode from 10: 85 avegar over 10 episode: -99.984 avegare return across last 100 episodes: -99.984 state values: tensor(0.8623) 1000
86 1000 -1000.0 -99.99568287525881 number episode from 10: 86 avegar over 10 episode: -99.984 avegare return across last 100 episodes: -99.984 state values: tensor(0.8623) 1000
87 1000 -1000.0 -99.99568287525881 number episode from 10: 87 avegar over 10 episode: -99.984 avegare return across last 100 episodes: -99.984 state values: tensor(0.8622) 1000
88 1000 -1000.0 -99.99568287525881 number episode from 10: 88 avegar over 10 episode: -99.984 avegare return across last 100 episodes: -99.984 state values: tensor(0.8623) 1000
89 1000 -1000.0 -99.99568287525881 number episode from 10: 89 avegar over 10 episode: -99.985 avegare return across last 100 episodes: -99.985 state values: tensor(0.8621) 1000
90 1000 -1000.0 -99.99568287525881 number episode from 10: 90 avegar over 10 episode: -99.985 avegare return across last 100 episodes: -99.985 state values: tensor(0.8622) 1000
91 1000 -1000.0 -99.99568287525881 number episode from 10: 91 avegar over 10 episode: -99.985 avegare return across last 100 episodes: -99.985 state values: tensor(0.8623) 1000
92 1000 -1000.0 -99.99568287525881 number episode from 10: 92 avegar over 10 episode: -99.985 avegare return across last 100 episodes: -99.985 state values: tensor(0.8620) 1000
93 1000 -1000.0 -99.99568287525881 number episode from 10: 93 avegar over 10 episode: -99.985 avegare return across last 100 episodes: -99.985 state values: tensor(0.8623) 1000
94 1000 -1000.0 -99.99568287525881 number episode from 10: 94 avegar over 10 episode: -99.985 avegare return across last 100 episodes: -99.985 state values: tensor(0.8620) 1000
95 1000 -1000.0 -99.99568287525881 number episode from 10: 95 avegar over 10 episode: -99.985 avegare return across last 100 episodes: -99.985 state values: tensor(0.8624) 1000
96 1000 -1000.0 -99.99568287525881 number episode from 10: 96 avegar over 10 episode: -99.985 avegare return across last 100 episodes: -99.985 state values: tensor(0.8623) 1000
97 1000 -1000.0 -99.99568287525881 number episode from 10: 97 avegar over 10 episode: -99.985 avegare return across last 100 episodes: -99.985 state values: tensor(0.8622) 1000
98 1000 -1000.0 -99.99568287525881 number episode from 10: 98 avegar over 10 episode: -99.986 avegare return across last 100 episodes: -99.986 state values: tensor(0.8620) 1000
99 1000 -1000.0 -99.99568287525881 number episode from 10: 99 avegar over 10 episode: -99.986 avegare return across last 100 episodes: -99.986 state values: tensor(0.8621) 1000
100 1000 -1000.0 -99.99568287525881 number episode from 10: 100 avegar over 10 episode: -99.986 avegare return across last 100 episodes: -99.996 state values: tensor(0.8618) 1000
101 1000 -1000.0 -99.99568287525881 number episode from 10: 101 avegar over 10 episode: -99.986 avegare return across last 100 episodes: -99.996 state values: tensor(0.8622) 1000
102 1000 -1000.0 -99.99568287525881 number episode from 10: 102 avegar over 10 episode: -99.986 avegare return across last 100 episodes: -99.996 state values: tensor(0.8623) 1000
103 1000 -1000.0 -99.99568287525881 number episode from 10: 103 avegar over 10 episode: -99.986 avegare return across last 100 episodes: -99.996 state values: tensor(0.8624) 1000
104 1000 -1000.0 -99.99568287525881 number episode from 10: 104 avegar over 10 episode: -99.986 avegare return across last 100 episodes: -99.996 state values: tensor(0.8623) 1000
105 1000 -1000.0 -99.99568287525881 number episode from 10: 105 avegar over 10 episode: -99.986 avegare return across last 100 episodes: -99.996 state values: tensor(0.8622) 1000
106 1000 -1000.0 -99.99568287525881 number episode from 10: 106 avegar over 10 episode: -99.986 avegare return across last 100 episodes: -99.996 state values: tensor(0.8622) 1000
107 1000 -1000.0 -99.99568287525881 number episode from 10: 107 avegar over 10 episode: -99.986 avegare return across last 100 episodes: -99.996 state values: tensor(0.8621) 1000
108 1000 -1000.0 -99.99568287525881 number episode from 10: 108 avegar over 10 episode: -99.987 avegare return across last 100 episodes: -99.996 state values: tensor(0.8623) 1000
109 1000 -1000.0 -99.99568287525881 number episode from 10: 109 avegar over 10 episode: -99.987 avegare return across last 100 episodes: -99.996 state values: tensor(0.8622) 1000
110 1000 -1000.0 -99.99568287525881 number episode from 10: 110 avegar over 10 episode: -99.987 avegare return across last 100 episodes: -99.996 state values: tensor(0.8621) 1000
111 1000 -1000.0 -99.99568287525881 number episode from 10: 111 avegar over 10 episode: -99.987 avegare return across last 100 episodes: -99.996 state values: tensor(0.8624) 1000
112 1000 -1000.0 -99.99568287525881 number episode from 10: 112 avegar over 10 episode: -99.987 avegare return across last 100 episodes: -99.996 state values: tensor(0.8621) 1000
113 1000 -1000.0 -99.99568287525881 number episode from 10: 113 avegar over 10 episode: -99.987 avegare return across last 100 episodes: -99.996 state values: tensor(0.8623) 1000
114 1000 -1000.0 -99.99568287525881 number episode from 10: 114 avegar over 10 episode: -99.987 avegare return across last 100 episodes: -99.996 state values: tensor(0.8621) 1000
115 1000 -1000.0 -99.99568287525881 number episode from 10: 115 avegar over 10 episode: -99.987 avegare return across last 100 episodes: -99.996 state values: tensor(0.8621) 1000
116 1000 -1000.0 -99.99568287525881 number episode from 10: 116 avegar over 10 episode: -99.987 avegare return across last 100 episodes: -99.996 state values: tensor(0.8623) 1000
117 1000 -1000.0 -99.99568287525881 number episode from 10: 117 avegar over 10 episode: -99.987 avegare return across last 100 episodes: -99.996 state values: tensor(0.8623) 1000
118 1000 -1000.0 -99.99568287525881 number episode from 10: 118 avegar over 10 episode: -99.987 avegare return across last 100 episodes: -99.996 state values: tensor(0.8619) 1000
119 1000 -1000.0 -99.99568287525881 number episode from 10: 119 avegar over 10 episode: -99.987 avegare return across last 100 episodes: -99.996 state values: tensor(0.8623) 1000
120 1000 -1000.0 -99.99568287525881 number episode from 10: 120 avegar over 10 episode: -99.987 avegare return across last 100 episodes: -99.996 state values: tensor(0.8622) 1000
121 1000 -1000.0 -99.99568287525881 number episode from 10: 121 avegar over 10 episode: -99.987 avegare return across last 100 episodes: -99.996 state values: tensor(0.8623) 1000
122 1000 -1000.0 -99.99568287525881 number episode from 10: 122 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.8620) 1000
123 1000 -1000.0 -99.99568287525881 number episode from 10: 123 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.8624) 1000
124 1000 -1000.0 -99.99568287525881 number episode from 10: 124 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.8624) 1000
125 1000 -1000.0 -99.99568287525881 number episode from 10: 125 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.8620) 1000
126 1000 -1000.0 -99.99568287525881 number episode from 10: 126 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.8621) 1000
127 1000 -1000.0 -99.99568287525881 number episode from 10: 127 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.8623) 1000
128 1000 -1000.0 -99.99568287525881 number episode from 10: 128 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.8621) 1000
129 1000 -1000.0 -99.99568287525881 number episode from 10: 129 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.8624) 1000
130 1000 -1000.0 -99.99568287525881 number episode from 10: 130 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.8621) 1000
131 1000 -1000.0 -99.99568287525881 number episode from 10: 131 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.8623) 1000
132 1000 -1000.0 -99.99568287525881 number episode from 10: 132 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.8622) 1000
133 1000 -1000.0 -99.99568287525881 number episode from 10: 133 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.8620) 1000
134 1000 -1000.0 -99.99568287525881 number episode from 10: 134 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.8624) 1000
135 1000 -1000.0 -99.99568287525881 number episode from 10: 135 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.8623) 1000
136 1000 -1000.0 -99.99568287525881 number episode from 10: 136 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.8624) 1000
137 1000 -1000.0 -99.99568287525881 number episode from 10: 137 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.8623) 1000
138 1000 -1000.0 -99.99568287525881 number episode from 10: 138 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.8622) 1000
139 1000 -1000.0 -99.99568287525881 number episode from 10: 139 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.8622) 1000
140 1000 -1000.0 -99.99568287525881 number episode from 10: 140 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.8621) 1000
141 1000 -1000.0 -99.99568287525881 number episode from 10: 141 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.8622) 1000
142 1000 -1000.0 -99.99568287525881 number episode from 10: 142 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.8622) 1000
143 1000 -1000.0 -99.99568287525881 number episode from 10: 143 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.8620) 1000
144 1000 -1000.0 -99.99568287525881 number episode from 10: 144 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.8622) 1000
145 1000 -1000.0 -99.99568287525881 number episode from 10: 145 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.8623) 1000
146 1000 -1000.0 -99.99568287525881 number episode from 10: 146 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.8621) 1000
147 1000 -1000.0 -99.99568287525881 number episode from 10: 147 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.8622) 1000
148 1000 -1000.0 -99.99568287525881 number episode from 10: 148 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.8624) 1000
149 1000 -1000.0 -99.99568287525881 number episode from 10: 149 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.8623) 1000
150 1000 -1000.0 -99.99568287525881 number episode from 10: 150 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.8623) 1000
151 1000 -1000.0 -99.99568287525881 number episode from 10: 151 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.8621) 1000
152 1000 -1000.0 -99.99568287525881 number episode from 10: 152 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.8624) 1000
153 1000 -1000.0 -99.99568287525881 number episode from 10: 153 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.8621) 1000
154 1000 -1000.0 -99.99568287525881 number episode from 10: 154 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.8619) 1000
155 1000 -1000.0 -99.99568287525881 number episode from 10: 155 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.8623) 1000
156 1000 -1000.0 -99.99568287525881 number episode from 10: 156 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.8622) 1000
157 1000 -1000.0 -99.99568287525881 number episode from 10: 157 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.8622) 1000
158 1000 -1000.0 -99.99568287525881 number episode from 10: 158 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.8620) 1000
159 1000 -1000.0 -99.99568287525881 number episode from 10: 159 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.8622) 1000
160 1000 -1000.0 -99.99568287525881 number episode from 10: 160 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.8620) 1000
161 1000 -1000.0 -99.99568287525881 number episode from 10: 161 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.8624) 1000
162 1000 -1000.0 -99.99568287525881 number episode from 10: 162 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.8623) 1000
163 1000 -1000.0 -99.99568287525881 number episode from 10: 163 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.8622) 1000
164 1000 -1000.0 -99.99568287525881 number episode from 10: 164 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.8621) 1000
165 1000 -1000.0 -99.99568287525881 number episode from 10: 165 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.8623) 1000
166 1000 -1000.0 -99.99568287525881 number episode from 10: 166 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.8622) 1000
167 1000 -1000.0 -99.99568287525881 number episode from 10: 167 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.8623) 1000
168 1000 -1000.0 -99.99568287525881 number episode from 10: 168 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.8623) 1000
169 1000 -1000.0 -99.99568287525881 number episode from 10: 169 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.8623) 1000
170 1000 -1000.0 -99.99568287525881 number episode from 10: 170 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.8623) 1000
171 1000 -1000.0 -99.99568287525881 number episode from 10: 171 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.8624) 1000
172 1000 -1000.0 -99.99568287525881 number episode from 10: 172 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.8622) 1000
173 1000 -1000.0 -99.99568287525881 number episode from 10: 173 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.8622) 1000
174 1000 -1000.0 -99.99568287525881 number episode from 10: 174 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.8619) 1000
175 1000 -1000.0 -99.99568287525881 number episode from 10: 175 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.8623) 1000
176 1000 -1000.0 -99.99568287525881 number episode from 10: 176 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.8622) 1000
177 1000 -1000.0 -99.99568287525881 number episode from 10: 177 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.8623) 1000
178 1000 -1000.0 -99.99568287525881 number episode from 10: 178 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.8621) 1000
179 1000 -1000.0 -99.99568287525881 number episode from 10: 179 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.8621) 1000
180 1000 -1000.0 -99.99568287525881 number episode from 10: 180 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.8622) 1000
181 1000 -1000.0 -99.99568287525881 number episode from 10: 181 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.8622) 1000
182 1000 -1000.0 -99.99568287525881 number episode from 10: 182 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.8623) 1000
183 1000 -1000.0 -99.99568287525881 number episode from 10: 183 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.8623) 1000
184 1000 -1000.0 -99.99568287525881 number episode from 10: 184 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.8623) 1000
185 1000 -1000.0 -99.99568287525881 number episode from 10: 185 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.8621) 1000
186 1000 -1000.0 -99.99568287525881 number episode from 10: 186 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.8621) 1000
187 1000 -1000.0 -99.99568287525881 number episode from 10: 187 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.8623) 1000
188 1000 -1000.0 -99.99568287525881 number episode from 10: 188 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.8623) 1000
189 1000 -1000.0 -99.99568287525881 number episode from 10: 189 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.8624) 1000
190 1000 -1000.0 -99.99568287525881 number episode from 10: 190 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.8621) 1000
191 1000 -1000.0 -99.99568287525881 number episode from 10: 191 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.8623) 1000
192 1000 -1000.0 -99.99568287525881 number episode from 10: 192 avegar over 10 episode: -99.991 avegare return across last 100 episodes: -99.996 state values: tensor(0.8622) 1000
193 1000 -1000.0 -99.99568287525881 number episode from 10: 193 avegar over 10 episode: -99.991 avegare return across last 100 episodes: -99.996 state values: tensor(0.8620) 1000
194 1000 -1000.0 -99.99568287525881 number episode from 10: 194 avegar over 10 episode: -99.991 avegare return across last 100 episodes: -99.996 state values: tensor(0.8622) 1000
195 1000 -1000.0 -99.99568287525881 number episode from 10: 195 avegar over 10 episode: -99.991 avegare return across last 100 episodes: -99.996 state values: tensor(0.8622) 1000
196 1000 -1000.0 -99.99568287525881 number episode from 10: 196 avegar over 10 episode: -99.991 avegare return across last 100 episodes: -99.996 state values: tensor(0.8623) 1000
197 1000 -1000.0 -99.99568287525881 number episode from 10: 197 avegar over 10 episode: -99.991 avegare return across last 100 episodes: -99.996 state values: tensor(0.8623) 1000
198 1000 -1000.0 -99.99568287525881 number episode from 10: 198 avegar over 10 episode: -99.991 avegare return across last 100 episodes: -99.996 state values: tensor(0.8621) 1000
199 1000 -1000.0 -99.99568287525881 number episode from 10: 199 avegar over 10 episode: -99.991 avegare return across last 100 episodes: -99.996 state values: tensor(0.8620) 1000
200 1000 -1000.0 -99.99568287525881 number episode from 10: 200 avegar over 10 episode: -99.991 avegare return across last 100 episodes: -99.996 state values: tensor(0.8620) 1000
Start! Seed: 160
0 1001 -1000.0 -98.99572604650622 number episode from 10: 0 avegar over 10 episode: -98.996 avegare return across last 100 episodes: -98.996 state values: tensor(0.8284) 1000
1 1000 -1000.0 -99.99568287525881 number episode from 10: 1 avegar over 10 episode: -99.496 avegare return across last 100 episodes: -99.496 state values: tensor(0.8227) 1000
2 1000 -1000.0 -99.99568287525881 number episode from 10: 2 avegar over 10 episode: -99.662 avegare return across last 100 episodes: -99.662 state values: tensor(0.8189) 1000
3 1000 -1000.0 -99.99568287525881 number episode from 10: 3 avegar over 10 episode: -99.746 avegare return across last 100 episodes: -99.746 state values: tensor(0.8293) 1000
4 1000 -1000.0 -99.99568287525881 number episode from 10: 4 avegar over 10 episode: -99.796 avegare return across last 100 episodes: -99.796 state values: tensor(0.8218) 1000
5 1000 -1000.0 -99.99568287525881 number episode from 10: 5 avegar over 10 episode: -99.829 avegare return across last 100 episodes: -99.829 state values: tensor(0.8219) 1000
6 1000 -1000.0 -99.99568287525881 number episode from 10: 6 avegar over 10 episode: -99.853 avegare return across last 100 episodes: -99.853 state values: tensor(0.8290) 1000
7 1000 -1000.0 -99.99568287525881 number episode from 10: 7 avegar over 10 episode: -99.871 avegare return across last 100 episodes: -99.871 state values: tensor(0.8215) 1000
8 1000 -1000.0 -99.99568287525881 number episode from 10: 8 avegar over 10 episode: -99.885 avegare return across last 100 episodes: -99.885 state values: tensor(0.8246) 1000
9 1000 -1000.0 -99.99568287525881 number episode from 10: 9 avegar over 10 episode: -99.896 avegare return across last 100 episodes: -99.896 state values: tensor(0.8250) 1000
10 1000 -1000.0 -99.99568287525881 number episode from 10: 10 avegar over 10 episode: -99.905 avegare return across last 100 episodes: -99.905 state values: tensor(0.8249) 1000
11 1000 -1000.0 -99.99568287525881 number episode from 10: 11 avegar over 10 episode: -99.912 avegare return across last 100 episodes: -99.912 state values: tensor(0.8263) 1000
12 1000 -1000.0 -99.99568287525881 number episode from 10: 12 avegar over 10 episode: -99.919 avegare return across last 100 episodes: -99.919 state values: tensor(0.8287) 1000
13 1000 -1000.0 -99.99568287525881 number episode from 10: 13 avegar over 10 episode: -99.924 avegare return across last 100 episodes: -99.924 state values: tensor(0.8272) 1000
14 1000 -1000.0 -99.99568287525881 number episode from 10: 14 avegar over 10 episode: -99.929 avegare return across last 100 episodes: -99.929 state values: tensor(0.8206) 1000
15 1000 -1000.0 -99.99568287525881 number episode from 10: 15 avegar over 10 episode: -99.933 avegare return across last 100 episodes: -99.933 state values: tensor(0.8285) 1000
16 1000 -1000.0 -99.99568287525881 number episode from 10: 16 avegar over 10 episode: -99.937 avegare return across last 100 episodes: -99.937 state values: tensor(0.8285) 1000
17 1000 -1000.0 -99.99568287525881 number episode from 10: 17 avegar over 10 episode: -99.94 avegare return across last 100 episodes: -99.94 state values: tensor(0.8227) 1000
18 1000 -1000.0 -99.99568287525881 number episode from 10: 18 avegar over 10 episode: -99.943 avegare return across last 100 episodes: -99.943 state values: tensor(0.8293) 1000
19 1000 -1000.0 -99.99568287525881 number episode from 10: 19 avegar over 10 episode: -99.946 avegare return across last 100 episodes: -99.946 state values: tensor(0.8160) 1000
20 1000 -1000.0 -99.99568287525881 number episode from 10: 20 avegar over 10 episode: -99.948 avegare return across last 100 episodes: -99.948 state values: tensor(0.8295) 1000
21 1000 -1000.0 -99.99568287525881 number episode from 10: 21 avegar over 10 episode: -99.95 avegare return across last 100 episodes: -99.95 state values: tensor(0.8293) 1000
22 1000 -1000.0 -99.99568287525881 number episode from 10: 22 avegar over 10 episode: -99.952 avegare return across last 100 episodes: -99.952 state values: tensor(0.8262) 1000
23 1000 -1000.0 -99.99568287525881 number episode from 10: 23 avegar over 10 episode: -99.954 avegare return across last 100 episodes: -99.954 state values: tensor(0.8237) 1000
24 1000 -1000.0 -99.99568287525881 number episode from 10: 24 avegar over 10 episode: -99.956 avegare return across last 100 episodes: -99.956 state values: tensor(0.8263) 1000
25 1000 -1000.0 -99.99568287525881 number episode from 10: 25 avegar over 10 episode: -99.957 avegare return across last 100 episodes: -99.957 state values: tensor(0.8228) 1000
26 1000 -1000.0 -99.99568287525881 number episode from 10: 26 avegar over 10 episode: -99.959 avegare return across last 100 episodes: -99.959 state values: tensor(0.8216) 1000
27 1000 -1000.0 -99.99568287525881 number episode from 10: 27 avegar over 10 episode: -99.96 avegare return across last 100 episodes: -99.96 state values: tensor(0.8191) 1000
28 1000 -1000.0 -99.99568287525881 number episode from 10: 28 avegar over 10 episode: -99.961 avegare return across last 100 episodes: -99.961 state values: tensor(0.8278) 1000
29 1000 -1000.0 -99.99568287525881 number episode from 10: 29 avegar over 10 episode: -99.962 avegare return across last 100 episodes: -99.962 state values: tensor(0.8278) 1000
30 1000 -1000.0 -99.99568287525881 number episode from 10: 30 avegar over 10 episode: -99.963 avegare return across last 100 episodes: -99.963 state values: tensor(0.8199) 1000
31 1000 -1000.0 -99.99568287525881 number episode from 10: 31 avegar over 10 episode: -99.964 avegare return across last 100 episodes: -99.964 state values: tensor(0.8207) 1000
32 1000 -1000.0 -99.99568287525881 number episode from 10: 32 avegar over 10 episode: -99.965 avegare return across last 100 episodes: -99.965 state values: tensor(0.8284) 1000
33 1000 -1000.0 -99.99568287525881 number episode from 10: 33 avegar over 10 episode: -99.966 avegare return across last 100 episodes: -99.966 state values: tensor(0.8162) 1000
34 1000 -1000.0 -99.99568287525881 number episode from 10: 34 avegar over 10 episode: -99.967 avegare return across last 100 episodes: -99.967 state values: tensor(0.8261) 1000
35 1000 -1000.0 -99.99568287525881 number episode from 10: 35 avegar over 10 episode: -99.968 avegare return across last 100 episodes: -99.968 state values: tensor(0.8203) 1000
36 1000 -1000.0 -99.99568287525881 number episode from 10: 36 avegar over 10 episode: -99.969 avegare return across last 100 episodes: -99.969 state values: tensor(0.8202) 1000
37 1000 -1000.0 -99.99568287525881 number episode from 10: 37 avegar over 10 episode: -99.969 avegare return across last 100 episodes: -99.969 state values: tensor(0.8185) 1000
38 1000 -1000.0 -99.99568287525881 number episode from 10: 38 avegar over 10 episode: -99.97 avegare return across last 100 episodes: -99.97 state values: tensor(0.8223) 1000
39 1000 -1000.0 -99.99568287525881 number episode from 10: 39 avegar over 10 episode: -99.971 avegare return across last 100 episodes: -99.971 state values: tensor(0.8186) 1000
40 1000 -1000.0 -99.99568287525881 number episode from 10: 40 avegar over 10 episode: -99.971 avegare return across last 100 episodes: -99.971 state values: tensor(0.8248) 1000
41 1000 -1000.0 -99.99568287525881 number episode from 10: 41 avegar over 10 episode: -99.972 avegare return across last 100 episodes: -99.972 state values: tensor(0.8228) 1000
42 1000 -1000.0 -99.99568287525881 number episode from 10: 42 avegar over 10 episode: -99.972 avegare return across last 100 episodes: -99.972 state values: tensor(0.8289) 1000
43 1000 -1000.0 -99.99568287525881 number episode from 10: 43 avegar over 10 episode: -99.973 avegare return across last 100 episodes: -99.973 state values: tensor(0.8289) 1000
44 1000 -1000.0 -99.99568287525881 number episode from 10: 44 avegar over 10 episode: -99.973 avegare return across last 100 episodes: -99.973 state values: tensor(0.8255) 1000
45 1000 -1000.0 -99.99568287525881 number episode from 10: 45 avegar over 10 episode: -99.974 avegare return across last 100 episodes: -99.974 state values: tensor(0.8205) 1000
46 1000 -1000.0 -99.99568287525881 number episode from 10: 46 avegar over 10 episode: -99.974 avegare return across last 100 episodes: -99.974 state values: tensor(0.8197) 1000
47 1000 -1000.0 -99.99568287525881 number episode from 10: 47 avegar over 10 episode: -99.975 avegare return across last 100 episodes: -99.975 state values: tensor(0.8282) 1000
48 1000 -1000.0 -99.99568287525881 number episode from 10: 48 avegar over 10 episode: -99.975 avegare return across last 100 episodes: -99.975 state values: tensor(0.8235) 1000
49 1000 -1000.0 -99.99568287525881 number episode from 10: 49 avegar over 10 episode: -99.976 avegare return across last 100 episodes: -99.976 state values: tensor(0.8251) 1000
50 1000 -1000.0 -99.99568287525881 number episode from 10: 50 avegar over 10 episode: -99.976 avegare return across last 100 episodes: -99.976 state values: tensor(0.8223) 1000
51 1000 -1000.0 -99.99568287525881 number episode from 10: 51 avegar over 10 episode: -99.976 avegare return across last 100 episodes: -99.976 state values: tensor(0.8283) 1000
52 1000 -1000.0 -99.99568287525881 number episode from 10: 52 avegar over 10 episode: -99.977 avegare return across last 100 episodes: -99.977 state values: tensor(0.8293) 1000
53 1000 -1000.0 -99.99568287525881 number episode from 10: 53 avegar over 10 episode: -99.977 avegare return across last 100 episodes: -99.977 state values: tensor(0.8290) 1000
54 1000 -1000.0 -99.99568287525881 number episode from 10: 54 avegar over 10 episode: -99.978 avegare return across last 100 episodes: -99.978 state values: tensor(0.8282) 1000
55 1000 -1000.0 -99.99568287525881 number episode from 10: 55 avegar over 10 episode: -99.978 avegare return across last 100 episodes: -99.978 state values: tensor(0.8158) 1000
56 1000 -1000.0 -99.99568287525881 number episode from 10: 56 avegar over 10 episode: -99.978 avegare return across last 100 episodes: -99.978 state values: tensor(0.8291) 1000
57 1000 -1000.0 -99.99568287525881 number episode from 10: 57 avegar over 10 episode: -99.978 avegare return across last 100 episodes: -99.978 state values: tensor(0.8208) 1000
58 1000 -1000.0 -99.99568287525881 number episode from 10: 58 avegar over 10 episode: -99.979 avegare return across last 100 episodes: -99.979 state values: tensor(0.8264) 1000
59 1000 -1000.0 -99.99568287525881 number episode from 10: 59 avegar over 10 episode: -99.979 avegare return across last 100 episodes: -99.979 state values: tensor(0.8289) 1000
60 1000 -1000.0 -99.99568287525881 number episode from 10: 60 avegar over 10 episode: -99.979 avegare return across last 100 episodes: -99.979 state values: tensor(0.8191) 1000
61 1000 -1000.0 -99.99568287525881 number episode from 10: 61 avegar over 10 episode: -99.98 avegare return across last 100 episodes: -99.98 state values: tensor(0.8243) 1000
62 1000 -1000.0 -99.99568287525881 number episode from 10: 62 avegar over 10 episode: -99.98 avegare return across last 100 episodes: -99.98 state values: tensor(0.8234) 1000
63 1000 -1000.0 -99.99568287525881 number episode from 10: 63 avegar over 10 episode: -99.98 avegare return across last 100 episodes: -99.98 state values: tensor(0.8293) 1000
64 1000 -1000.0 -99.99568287525881 number episode from 10: 64 avegar over 10 episode: -99.98 avegare return across last 100 episodes: -99.98 state values: tensor(0.8273) 1000
65 1000 -1000.0 -99.99568287525881 number episode from 10: 65 avegar over 10 episode: -99.981 avegare return across last 100 episodes: -99.981 state values: tensor(0.8266) 1000
66 1000 -1000.0 -99.99568287525881 number episode from 10: 66 avegar over 10 episode: -99.981 avegare return across last 100 episodes: -99.981 state values: tensor(0.8286) 1000
67 1000 -1000.0 -99.99568287525881 number episode from 10: 67 avegar over 10 episode: -99.981 avegare return across last 100 episodes: -99.981 state values: tensor(0.8270) 1000
68 1000 -1000.0 -99.99568287525881 number episode from 10: 68 avegar over 10 episode: -99.981 avegare return across last 100 episodes: -99.981 state values: tensor(0.8285) 1000
69 1000 -1000.0 -99.99568287525881 number episode from 10: 69 avegar over 10 episode: -99.981 avegare return across last 100 episodes: -99.981 state values: tensor(0.8207) 1000
70 1000 -1000.0 -99.99568287525881 number episode from 10: 70 avegar over 10 episode: -99.982 avegare return across last 100 episodes: -99.982 state values: tensor(0.8288) 1000
71 1000 -1000.0 -99.99568287525881 number episode from 10: 71 avegar over 10 episode: -99.982 avegare return across last 100 episodes: -99.982 state values: tensor(0.8198) 1000
72 1000 -1000.0 -99.99568287525881 number episode from 10: 72 avegar over 10 episode: -99.982 avegare return across last 100 episodes: -99.982 state values: tensor(0.8192) 1000
73 1000 -1000.0 -99.99568287525881 number episode from 10: 73 avegar over 10 episode: -99.982 avegare return across last 100 episodes: -99.982 state values: tensor(0.8206) 1000
74 1000 -1000.0 -99.99568287525881 number episode from 10: 74 avegar over 10 episode: -99.982 avegare return across last 100 episodes: -99.982 state values: tensor(0.8286) 1000
75 1000 -1000.0 -99.99568287525881 number episode from 10: 75 avegar over 10 episode: -99.983 avegare return across last 100 episodes: -99.983 state values: tensor(0.8283) 1000
76 1000 -1000.0 -99.99568287525881 number episode from 10: 76 avegar over 10 episode: -99.983 avegare return across last 100 episodes: -99.983 state values: tensor(0.8280) 1000
77 1000 -1000.0 -99.99568287525881 number episode from 10: 77 avegar over 10 episode: -99.983 avegare return across last 100 episodes: -99.983 state values: tensor(0.8283) 1000
78 1000 -1000.0 -99.99568287525881 number episode from 10: 78 avegar over 10 episode: -99.983 avegare return across last 100 episodes: -99.983 state values: tensor(0.8232) 1000
79 1000 -1000.0 -99.99568287525881 number episode from 10: 79 avegar over 10 episode: -99.983 avegare return across last 100 episodes: -99.983 state values: tensor(0.8252) 1000
80 1000 -1000.0 -99.99568287525881 number episode from 10: 80 avegar over 10 episode: -99.983 avegare return across last 100 episodes: -99.983 state values: tensor(0.8195) 1000
81 1000 -1000.0 -99.99568287525881 number episode from 10: 81 avegar over 10 episode: -99.983 avegare return across last 100 episodes: -99.983 state values: tensor(0.8282) 1000
82 1000 -1000.0 -99.99568287525881 number episode from 10: 82 avegar over 10 episode: -99.984 avegare return across last 100 episodes: -99.984 state values: tensor(0.8205) 1000
83 1000 -1000.0 -99.99568287525881 number episode from 10: 83 avegar over 10 episode: -99.984 avegare return across last 100 episodes: -99.984 state values: tensor(0.8265) 1000
84 1000 -1000.0 -99.99568287525881 number episode from 10: 84 avegar over 10 episode: -99.984 avegare return across last 100 episodes: -99.984 state values: tensor(0.8226) 1000
85 1000 -1000.0 -99.99568287525881 number episode from 10: 85 avegar over 10 episode: -99.984 avegare return across last 100 episodes: -99.984 state values: tensor(0.8289) 1000
86 1000 -1000.0 -99.99568287525881 number episode from 10: 86 avegar over 10 episode: -99.984 avegare return across last 100 episodes: -99.984 state values: tensor(0.8287) 1000
87 1000 -1000.0 -99.99568287525881 number episode from 10: 87 avegar over 10 episode: -99.984 avegare return across last 100 episodes: -99.984 state values: tensor(0.8293) 1000
88 1000 -1000.0 -99.99568287525881 number episode from 10: 88 avegar over 10 episode: -99.984 avegare return across last 100 episodes: -99.984 state values: tensor(0.8216) 1000
89 1000 -1000.0 -99.99568287525881 number episode from 10: 89 avegar over 10 episode: -99.985 avegare return across last 100 episodes: -99.985 state values: tensor(0.8216) 1000
90 1000 -1000.0 -99.99568287525881 number episode from 10: 90 avegar over 10 episode: -99.985 avegare return across last 100 episodes: -99.985 state values: tensor(0.8198) 1000
91 1000 -1000.0 -99.99568287525881 number episode from 10: 91 avegar over 10 episode: -99.985 avegare return across last 100 episodes: -99.985 state values: tensor(0.8232) 1000
92 1000 -1000.0 -99.99568287525881 number episode from 10: 92 avegar over 10 episode: -99.985 avegare return across last 100 episodes: -99.985 state values: tensor(0.8227) 1000
93 1000 -1000.0 -99.99568287525881 number episode from 10: 93 avegar over 10 episode: -99.985 avegare return across last 100 episodes: -99.985 state values: tensor(0.8298) 1000
94 1000 -1000.0 -99.99568287525881 number episode from 10: 94 avegar over 10 episode: -99.985 avegare return across last 100 episodes: -99.985 state values: tensor(0.8245) 1000
95 1000 -1000.0 -99.99568287525881 number episode from 10: 95 avegar over 10 episode: -99.985 avegare return across last 100 episodes: -99.985 state values: tensor(0.8173) 1000
96 1000 -1000.0 -99.99568287525881 number episode from 10: 96 avegar over 10 episode: -99.985 avegare return across last 100 episodes: -99.985 state values: tensor(0.8219) 1000
97 1000 -1000.0 -99.99568287525881 number episode from 10: 97 avegar over 10 episode: -99.985 avegare return across last 100 episodes: -99.985 state values: tensor(0.8238) 1000
98 1000 -1000.0 -99.99568287525881 number episode from 10: 98 avegar over 10 episode: -99.986 avegare return across last 100 episodes: -99.986 state values: tensor(0.8225) 1000
99 1000 -1000.0 -99.99568287525881 number episode from 10: 99 avegar over 10 episode: -99.986 avegare return across last 100 episodes: -99.986 state values: tensor(0.8232) 1000
100 1000 -1000.0 -99.99568287525881 number episode from 10: 100 avegar over 10 episode: -99.986 avegare return across last 100 episodes: -99.996 state values: tensor(0.8232) 1000
101 1000 -1000.0 -99.99568287525881 number episode from 10: 101 avegar over 10 episode: -99.986 avegare return across last 100 episodes: -99.996 state values: tensor(0.8270) 1000
102 1000 -1000.0 -99.99568287525881 number episode from 10: 102 avegar over 10 episode: -99.986 avegare return across last 100 episodes: -99.996 state values: tensor(0.8285) 1000
103 1000 -1000.0 -99.99568287525881 number episode from 10: 103 avegar over 10 episode: -99.986 avegare return across last 100 episodes: -99.996 state values: tensor(0.8295) 1000
104 1000 -1000.0 -99.99568287525881 number episode from 10: 104 avegar over 10 episode: -99.986 avegare return across last 100 episodes: -99.996 state values: tensor(0.8242) 1000
105 1000 -1000.0 -99.99568287525881 number episode from 10: 105 avegar over 10 episode: -99.986 avegare return across last 100 episodes: -99.996 state values: tensor(0.8291) 1000
106 1000 -1000.0 -99.99568287525881 number episode from 10: 106 avegar over 10 episode: -99.986 avegare return across last 100 episodes: -99.996 state values: tensor(0.8201) 1000
107 1000 -1000.0 -99.99568287525881 number episode from 10: 107 avegar over 10 episode: -99.986 avegare return across last 100 episodes: -99.996 state values: tensor(0.8294) 1000
108 1000 -1000.0 -99.99568287525881 number episode from 10: 108 avegar over 10 episode: -99.987 avegare return across last 100 episodes: -99.996 state values: tensor(0.8214) 1000
109 1000 -1000.0 -99.99568287525881 number episode from 10: 109 avegar over 10 episode: -99.987 avegare return across last 100 episodes: -99.996 state values: tensor(0.8222) 1000
110 1000 -1000.0 -99.99568287525881 number episode from 10: 110 avegar over 10 episode: -99.987 avegare return across last 100 episodes: -99.996 state values: tensor(0.8215) 1000
111 1000 -1000.0 -99.99568287525881 number episode from 10: 111 avegar over 10 episode: -99.987 avegare return across last 100 episodes: -99.996 state values: tensor(0.8287) 1000
112 1000 -1000.0 -99.99568287525881 number episode from 10: 112 avegar over 10 episode: -99.987 avegare return across last 100 episodes: -99.996 state values: tensor(0.8165) 1000
113 1000 -1000.0 -99.99568287525881 number episode from 10: 113 avegar over 10 episode: -99.987 avegare return across last 100 episodes: -99.996 state values: tensor(0.8220) 1000
114 1000 -1000.0 -99.99568287525881 number episode from 10: 114 avegar over 10 episode: -99.987 avegare return across last 100 episodes: -99.996 state values: tensor(0.8283) 1000
115 1000 -1000.0 -99.99568287525881 number episode from 10: 115 avegar over 10 episode: -99.987 avegare return across last 100 episodes: -99.996 state values: tensor(0.8283) 1000
116 1000 -1000.0 -99.99568287525881 number episode from 10: 116 avegar over 10 episode: -99.987 avegare return across last 100 episodes: -99.996 state values: tensor(0.8234) 1000
117 1000 -1000.0 -99.99568287525881 number episode from 10: 117 avegar over 10 episode: -99.987 avegare return across last 100 episodes: -99.996 state values: tensor(0.8293) 1000
118 1000 -1000.0 -99.99568287525881 number episode from 10: 118 avegar over 10 episode: -99.987 avegare return across last 100 episodes: -99.996 state values: tensor(0.8286) 1000
119 1000 -1000.0 -99.99568287525881 number episode from 10: 119 avegar over 10 episode: -99.987 avegare return across last 100 episodes: -99.996 state values: tensor(0.8241) 1000
120 1000 -1000.0 -99.99568287525881 number episode from 10: 120 avegar over 10 episode: -99.987 avegare return across last 100 episodes: -99.996 state values: tensor(0.8283) 1000
121 1000 -1000.0 -99.99568287525881 number episode from 10: 121 avegar over 10 episode: -99.987 avegare return across last 100 episodes: -99.996 state values: tensor(0.8173) 1000
122 1000 -1000.0 -99.99568287525881 number episode from 10: 122 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.8232) 1000
123 1000 -1000.0 -99.99568287525881 number episode from 10: 123 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.8236) 1000
124 1000 -1000.0 -99.99568287525881 number episode from 10: 124 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.8239) 1000
125 1000 -1000.0 -99.99568287525881 number episode from 10: 125 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.8274) 1000
126 1000 -1000.0 -99.99568287525881 number episode from 10: 126 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.8188) 1000
127 1000 -1000.0 -99.99568287525881 number episode from 10: 127 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.8235) 1000
128 1000 -1000.0 -99.99568287525881 number episode from 10: 128 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.8287) 1000
129 1000 -1000.0 -99.99568287525881 number episode from 10: 129 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.8260) 1000
130 1000 -1000.0 -99.99568287525881 number episode from 10: 130 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.8297) 1000
131 1000 -1000.0 -99.99568287525881 number episode from 10: 131 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.8216) 1000
132 1000 -1000.0 -99.99568287525881 number episode from 10: 132 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.8160) 1000
133 1000 -1000.0 -99.99568287525881 number episode from 10: 133 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.8235) 1000
134 1000 -1000.0 -99.99568287525881 number episode from 10: 134 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.8243) 1000
135 1000 -1000.0 -99.99568287525881 number episode from 10: 135 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.8250) 1000
136 1000 -1000.0 -99.99568287525881 number episode from 10: 136 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.8209) 1000
137 1000 -1000.0 -99.99568287525881 number episode from 10: 137 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.8281) 1000
138 1000 -1000.0 -99.99568287525881 number episode from 10: 138 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.8209) 1000
139 1000 -1000.0 -99.99568287525881 number episode from 10: 139 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.8277) 1000
140 1000 -1000.0 -99.99568287525881 number episode from 10: 140 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.8288) 1000
141 1000 -1000.0 -99.99568287525881 number episode from 10: 141 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.8292) 1000
142 1000 -1000.0 -99.99568287525881 number episode from 10: 142 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.8292) 1000
143 1000 -1000.0 -99.99568287525881 number episode from 10: 143 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.8255) 1000
144 1000 -1000.0 -99.99568287525881 number episode from 10: 144 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.8286) 1000
145 1000 -1000.0 -99.99568287525881 number episode from 10: 145 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.8232) 1000
146 1000 -1000.0 -99.99568287525881 number episode from 10: 146 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.8276) 1000
147 1000 -1000.0 -99.99568287525881 number episode from 10: 147 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.8205) 1000
148 1000 -1000.0 -99.99568287525881 number episode from 10: 148 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.8277) 1000
149 1000 -1000.0 -99.99568287525881 number episode from 10: 149 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.8242) 1000
150 1000 -1000.0 -99.99568287525881 number episode from 10: 150 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.8263) 1000
151 1000 -1000.0 -99.99568287525881 number episode from 10: 151 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.8250) 1000
152 1000 -1000.0 -99.99568287525881 number episode from 10: 152 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.8272) 1000
153 1000 -1000.0 -99.99568287525881 number episode from 10: 153 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.8283) 1000
154 1000 -1000.0 -99.99568287525881 number episode from 10: 154 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.8233) 1000
155 1000 -1000.0 -99.99568287525881 number episode from 10: 155 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.8212) 1000
156 1000 -1000.0 -99.99568287525881 number episode from 10: 156 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.8191) 1000
157 1000 -1000.0 -99.99568287525881 number episode from 10: 157 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.8287) 1000
158 1000 -1000.0 -99.99568287525881 number episode from 10: 158 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.8215) 1000
159 1000 -1000.0 -99.99568287525881 number episode from 10: 159 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.8282) 1000
160 1000 -1000.0 -99.99568287525881 number episode from 10: 160 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.8212) 1000
161 1000 -1000.0 -99.99568287525881 number episode from 10: 161 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.8282) 1000
162 1000 -1000.0 -99.99568287525881 number episode from 10: 162 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.8292) 1000
163 1000 -1000.0 -99.99568287525881 number episode from 10: 163 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.8238) 1000
164 1000 -1000.0 -99.99568287525881 number episode from 10: 164 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.8285) 1000
165 1000 -1000.0 -99.99568287525881 number episode from 10: 165 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.8305) 1000
166 1000 -1000.0 -99.99568287525881 number episode from 10: 166 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.8288) 1000
167 1000 -1000.0 -99.99568287525881 number episode from 10: 167 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.8292) 1000
168 1000 -1000.0 -99.99568287525881 number episode from 10: 168 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.8294) 1000
169 1000 -1000.0 -99.99568287525881 number episode from 10: 169 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.8289) 1000
170 1000 -1000.0 -99.99568287525881 number episode from 10: 170 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.8206) 1000
171 1000 -1000.0 -99.99568287525881 number episode from 10: 171 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.8279) 1000
172 1000 -1000.0 -99.99568287525881 number episode from 10: 172 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.8284) 1000
173 1000 -1000.0 -99.99568287525881 number episode from 10: 173 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.8278) 1000
174 1000 -1000.0 -99.99568287525881 number episode from 10: 174 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.8249) 1000
175 1000 -1000.0 -99.99568287525881 number episode from 10: 175 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.8176) 1000
176 1000 -1000.0 -99.99568287525881 number episode from 10: 176 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.8215) 1000
177 1000 -1000.0 -99.99568287525881 number episode from 10: 177 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.8223) 1000
178 1000 -1000.0 -99.99568287525881 number episode from 10: 178 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.8295) 1000
179 1000 -1000.0 -99.99568287525881 number episode from 10: 179 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.8277) 1000
180 1000 -1000.0 -99.99568287525881 number episode from 10: 180 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.8209) 1000
181 1000 -1000.0 -99.99568287525881 number episode from 10: 181 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.8190) 1000
182 1000 -1000.0 -99.99568287525881 number episode from 10: 182 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.8229) 1000
183 1000 -1000.0 -99.99568287525881 number episode from 10: 183 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.8202) 1000
184 1000 -1000.0 -99.99568287525881 number episode from 10: 184 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.8242) 1000
185 1000 -1000.0 -99.99568287525881 number episode from 10: 185 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.8205) 1000
186 1000 -1000.0 -99.99568287525881 number episode from 10: 186 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.8239) 1000
187 1000 -1000.0 -99.99568287525881 number episode from 10: 187 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.8275) 1000
188 1000 -1000.0 -99.99568287525881 number episode from 10: 188 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.8244) 1000
189 1000 -1000.0 -99.99568287525881 number episode from 10: 189 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.8282) 1000
190 1000 -1000.0 -99.99568287525881 number episode from 10: 190 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.8257) 1000
191 1000 -1000.0 -99.99568287525881 number episode from 10: 191 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.8242) 1000
192 1000 -1000.0 -99.99568287525881 number episode from 10: 192 avegar over 10 episode: -99.991 avegare return across last 100 episodes: -99.996 state values: tensor(0.8207) 1000
193 1000 -1000.0 -99.99568287525881 number episode from 10: 193 avegar over 10 episode: -99.991 avegare return across last 100 episodes: -99.996 state values: tensor(0.8290) 1000
194 1000 -1000.0 -99.99568287525881 number episode from 10: 194 avegar over 10 episode: -99.991 avegare return across last 100 episodes: -99.996 state values: tensor(0.8245) 1000
195 1000 -1000.0 -99.99568287525881 number episode from 10: 195 avegar over 10 episode: -99.991 avegare return across last 100 episodes: -99.996 state values: tensor(0.8288) 1000
196 1000 -1000.0 -99.99568287525881 number episode from 10: 196 avegar over 10 episode: -99.991 avegare return across last 100 episodes: -99.996 state values: tensor(0.8252) 1000
197 1000 -1000.0 -99.99568287525881 number episode from 10: 197 avegar over 10 episode: -99.991 avegare return across last 100 episodes: -99.996 state values: tensor(0.8290) 1000
198 1000 -1000.0 -99.99568287525881 number episode from 10: 198 avegar over 10 episode: -99.991 avegare return across last 100 episodes: -99.996 state values: tensor(0.8292) 1000
199 1000 -1000.0 -99.99568287525881 number episode from 10: 199 avegar over 10 episode: -99.991 avegare return across last 100 episodes: -99.996 state values: tensor(0.8246) 1000
200 1000 -1000.0 -99.99568287525881 number episode from 10: 200 avegar over 10 episode: -99.991 avegare return across last 100 episodes: -99.996 state values: tensor(0.8286) 1000
Start! Seed: 192
0 521 -520.0 -98.46796967728812 number episode from 10: 0 avegar over 10 episode: -98.468 avegare return across last 100 episodes: -98.468 state values: tensor(0.8932) 520
1 620 -620.0 -99.80329262156505 number episode from 10: 1 avegar over 10 episode: -99.136 avegare return across last 100 episodes: -99.136 state values: tensor(0.8903) 620
2 1000 -1000.0 -99.99568287525881 number episode from 10: 2 avegar over 10 episode: -99.422 avegare return across last 100 episodes: -99.422 state values: tensor(0.8200) 1000
3 514 -514.0 -99.42919203690323 number episode from 10: 3 avegar over 10 episode: -99.424 avegare return across last 100 episodes: -99.424 state values: tensor(0.8858) 514
4 533 -533.0 -99.52841637065397 number episode from 10: 4 avegar over 10 episode: -99.445 avegare return across last 100 episodes: -99.445 state values: tensor(0.8892) 533
5 536 -536.0 -99.54242287602918 number episode from 10: 5 avegar over 10 episode: -99.461 avegare return across last 100 episodes: -99.461 state values: tensor(0.8922) 536
6 520 -520.0 -99.46259563362437 number episode from 10: 6 avegar over 10 episode: -99.461 avegare return across last 100 episodes: -99.461 state values: tensor(0.8884) 520
7 519 -519.0 -99.45716730669129 number episode from 10: 7 avegar over 10 episode: -99.461 avegare return across last 100 episodes: -99.461 state values: tensor(0.8839) 519
8 623 -623.0 -99.80913502741193 number episode from 10: 8 avegar over 10 episode: -99.5 avegare return across last 100 episodes: -99.5 state values: tensor(0.8907) 623
9 537 -537.0 -99.5469986472689 number episode from 10: 9 avegar over 10 episode: -99.504 avegare return across last 100 episodes: -99.504 state values: tensor(0.8927) 537
10 523 -523.0 -99.47855708071009 number episode from 10: 10 avegar over 10 episode: -99.502 avegare return across last 100 episodes: -99.502 state values: tensor(0.8964) 523
11 911 -911.0 -99.98944003987278 number episode from 10: 11 avegar over 10 episode: -99.543 avegare return across last 100 episodes: -99.543 state values: tensor(0.8551) 911
12 433 -433.0 -98.71163398374672 number episode from 10: 12 avegar over 10 episode: -99.479 avegare return across last 100 episodes: -99.479 state values: tensor(0.8894) 433
13 544 -544.0 -99.57777313656436 number episode from 10: 13 avegar over 10 episode: -99.486 avegare return across last 100 episodes: -99.486 state values: tensor(0.9028) 544
14 1000 -1000.0 -99.99568287525881 number episode from 10: 14 avegar over 10 episode: -99.52 avegare return across last 100 episodes: -99.52 state values: tensor(0.8196) 1000
15 902 -902.0 -99.98844032758407 number episode from 10: 15 avegar over 10 episode: -99.549 avegare return across last 100 episodes: -99.549 state values: tensor(0.8560) 902
16 436 -436.0 -98.74989974279546 number episode from 10: 16 avegar over 10 episode: -99.502 avegare return across last 100 episodes: -99.502 state values: tensor(0.8919) 436
17 514 -514.0 -99.42919203690323 number episode from 10: 17 avegar over 10 episode: -99.498 avegare return across last 100 episodes: -99.498 state values: tensor(0.8833) 514
18 437 -437.0 -98.76240074536751 number episode from 10: 18 avegar over 10 episode: -99.459 avegare return across last 100 episodes: -99.459 state values: tensor(0.8922) 437
19 534 -534.0 -99.53313220694743 number episode from 10: 19 avegar over 10 episode: -99.463 avegare return across last 100 episodes: -99.463 state values: tensor(0.8901) 534
20 1000 -1000.0 -99.99568287525881 number episode from 10: 20 avegar over 10 episode: -99.488 avegare return across last 100 episodes: -99.488 state values: tensor(0.8288) 1000
21 524 -524.0 -99.483771509903 number episode from 10: 21 avegar over 10 episode: -99.488 avegare return across last 100 episodes: -99.488 state values: tensor(0.8874) 524
22 542 -542.0 -99.56920022096149 number episode from 10: 22 avegar over 10 episode: -99.492 avegare return across last 100 episodes: -99.492 state values: tensor(0.9027) 542
23 430 -430.0 -98.67219690399219 number episode from 10: 23 avegar over 10 episode: -99.457 avegare return across last 100 episodes: -99.457 state values: tensor(0.8904) 430
24 1000 -1000.0 -99.99568287525881 number episode from 10: 24 avegar over 10 episode: -99.479 avegare return across last 100 episodes: -99.479 state values: tensor(0.8194) 1000
25 514 -514.0 -99.42919203690323 number episode from 10: 25 avegar over 10 episode: -99.477 avegare return across last 100 episodes: -99.477 state values: tensor(0.8866) 514
26 431 -431.0 -98.68547493495227 number episode from 10: 26 avegar over 10 episode: -99.448 avegare return across last 100 episodes: -99.448 state values: tensor(0.8897) 431
27 629 -629.0 -99.82030441709234 number episode from 10: 27 avegar over 10 episode: -99.461 avegare return across last 100 episodes: -99.461 state values: tensor(0.8957) 629
28 433 -433.0 -98.71163398374672 number episode from 10: 28 avegar over 10 episode: -99.435 avegare return across last 100 episodes: -99.435 state values: tensor(0.8901) 433
29 520 -520.0 -99.46259563362437 number episode from 10: 29 avegar over 10 episode: -99.436 avegare return across last 100 episodes: -99.436 state values: tensor(0.8898) 520
30 432 -432.0 -98.69862018560275 number episode from 10: 30 avegar over 10 episode: -99.412 avegare return across last 100 episodes: -99.412 state values: tensor(0.8897) 432
31 1000 -1000.0 -99.99568287525881 number episode from 10: 31 avegar over 10 episode: -99.431 avegare return across last 100 episodes: -99.431 state values: tensor(0.8442) 1000
32 1000 -1000.0 -99.99568287525881 number episode from 10: 32 avegar over 10 episode: -99.448 avegare return across last 100 episodes: -99.448 state values: tensor(0.8444) 1000
33 544 -544.0 -99.57777313656436 number episode from 10: 33 avegar over 10 episode: -99.452 avegare return across last 100 episodes: -99.452 state values: tensor(0.9029) 544
34 523 -523.0 -99.47855708071009 number episode from 10: 34 avegar over 10 episode: -99.452 avegare return across last 100 episodes: -99.452 state values: tensor(0.8898) 523
35 520 -520.0 -99.46259563362437 number episode from 10: 35 avegar over 10 episode: -99.453 avegare return across last 100 episodes: -99.453 state values: tensor(0.8899) 520
36 1000 -1000.0 -99.99568287525881 number episode from 10: 36 avegar over 10 episode: -99.467 avegare return across last 100 episodes: -99.467 state values: tensor(0.8199) 1000
37 530 -530.0 -99.51398112401843 number episode from 10: 37 avegar over 10 episode: -99.469 avegare return across last 100 episodes: -99.469 state values: tensor(0.8903) 530
38 1000 -1000.0 -99.99568287525881 number episode from 10: 38 avegar over 10 episode: -99.482 avegare return across last 100 episodes: -99.482 state values: tensor(0.8204) 1000
39 1000 -1000.0 -99.99568287525881 number episode from 10: 39 avegar over 10 episode: -99.495 avegare return across last 100 episodes: -99.495 state values: tensor(0.8205) 1000
40 518 -518.0 -99.45168414817302 number episode from 10: 40 avegar over 10 episode: -99.494 avegare return across last 100 episodes: -99.494 state values: tensor(0.8935) 518
41 514 -514.0 -99.42919203690323 number episode from 10: 41 avegar over 10 episode: -99.492 avegare return across last 100 episodes: -99.492 state values: tensor(0.8869) 514
42 536 -536.0 -99.54242287602918 number episode from 10: 42 avegar over 10 episode: -99.493 avegare return across last 100 episodes: -99.493 state values: tensor(0.8911) 536
43 517 -517.0 -99.44614560421516 number episode from 10: 43 avegar over 10 episode: -99.492 avegare return across last 100 episodes: -99.492 state values: tensor(0.8874) 517
44 544 -544.0 -99.57777313656436 number episode from 10: 44 avegar over 10 episode: -99.494 avegare return across last 100 episodes: -99.494 state values: tensor(0.9018) 544
45 1000 -1000.0 -99.99568287525881 number episode from 10: 45 avegar over 10 episode: -99.505 avegare return across last 100 episodes: -99.505 state values: tensor(0.8198) 1000
46 619 -619.0 -99.80130567834854 number episode from 10: 46 avegar over 10 episode: -99.511 avegare return across last 100 episodes: -99.511 state values: tensor(0.8958) 619
47 535 -535.0 -99.53780088487795 number episode from 10: 47 avegar over 10 episode: -99.512 avegare return across last 100 episodes: -99.512 state values: tensor(0.9050) 535
48 517 -517.0 -99.44614560421516 number episode from 10: 48 avegar over 10 episode: -99.511 avegare return across last 100 episodes: -99.511 state values: tensor(0.8872) 517
49 529 -529.0 -99.50907184244286 number episode from 10: 49 avegar over 10 episode: -99.511 avegare return across last 100 episodes: -99.511 state values: tensor(0.8889) 529
50 509 -509.0 -99.3997750416455 number episode from 10: 50 avegar over 10 episode: -99.508 avegare return across last 100 episodes: -99.508 state values: tensor(0.8844) 509
51 610 -610.0 -99.78249527067084 number episode from 10: 51 avegar over 10 episode: -99.514 avegare return across last 100 episodes: -99.514 state values: tensor(0.8872) 610
52 544 -544.0 -99.57777313656436 number episode from 10: 52 avegar over 10 episode: -99.515 avegare return across last 100 episodes: -99.515 state values: tensor(0.9016) 544
53 522 -522.0 -99.47328998051525 number episode from 10: 53 avegar over 10 episode: -99.514 avegare return across last 100 episodes: -99.514 state values: tensor(0.8921) 522
54 516 -516.0 -99.44055111536885 number episode from 10: 54 avegar over 10 episode: -99.513 avegare return across last 100 episodes: -99.513 state values: tensor(0.8860) 516
55 524 -524.0 -99.483771509903 number episode from 10: 55 avegar over 10 episode: -99.512 avegare return across last 100 episodes: -99.512 state values: tensor(0.8962) 524
56 518 -518.0 -99.45168414817302 number episode from 10: 56 avegar over 10 episode: -99.511 avegare return across last 100 episodes: -99.511 state values: tensor(0.8889) 518
57 534 -534.0 -99.53313220694743 number episode from 10: 57 avegar over 10 episode: -99.512 avegare return across last 100 episodes: -99.512 state values: tensor(0.8930) 534
58 520 -520.0 -99.46259563362437 number episode from 10: 58 avegar over 10 episode: -99.511 avegare return across last 100 episodes: -99.511 state values: tensor(0.8898) 520
59 518 -518.0 -99.45168414817302 number episode from 10: 59 avegar over 10 episode: -99.51 avegare return across last 100 episodes: -99.51 state values: tensor(0.8919) 518
60 434 -434.0 -98.72451764390925 number episode from 10: 60 avegar over 10 episode: -99.497 avegare return across last 100 episodes: -99.497 state values: tensor(0.8911) 434
61 520 -520.0 -99.46259563362437 number episode from 10: 61 avegar over 10 episode: -99.496 avegare return across last 100 episodes: -99.496 state values: tensor(0.8905) 520
62 523 -523.0 -99.47855708071009 number episode from 10: 62 avegar over 10 episode: -99.496 avegare return across last 100 episodes: -99.496 state values: tensor(0.8956) 523
63 547 -547.0 -99.59031369663526 number episode from 10: 63 avegar over 10 episode: -99.498 avegare return across last 100 episodes: -99.498 state values: tensor(0.9026) 547
64 548 -548.0 -99.59441055966892 number episode from 10: 64 avegar over 10 episode: -99.499 avegare return across last 100 episodes: -99.499 state values: tensor(0.9009) 548
65 433 -433.0 -98.71163398374672 number episode from 10: 65 avegar over 10 episode: -99.487 avegare return across last 100 episodes: -99.487 state values: tensor(0.8925) 433
66 541 -541.0 -99.56484870804191 number episode from 10: 66 avegar over 10 episode: -99.488 avegare return across last 100 episodes: -99.488 state values: tensor(0.8986) 541
67 519 -519.0 -99.45716730669129 number episode from 10: 67 avegar over 10 episode: -99.488 avegare return across last 100 episodes: -99.488 state values: tensor(0.8891) 519
68 444 -444.0 -98.84647662016155 number episode from 10: 68 avegar over 10 episode: -99.479 avegare return across last 100 episodes: -99.479 state values: tensor(0.9058) 444
69 516 -516.0 -99.44055111536885 number episode from 10: 69 avegar over 10 episode: -99.478 avegare return across last 100 episodes: -99.478 state values: tensor(0.8869) 516
70 425 -425.0 -98.60376762496365 number episode from 10: 70 avegar over 10 episode: -99.466 avegare return across last 100 episodes: -99.466 state values: tensor(0.8909) 425
71 1000 -1000.0 -99.99568287525881 number episode from 10: 71 avegar over 10 episode: -99.473 avegare return across last 100 episodes: -99.473 state values: tensor(0.8195) 1000
72 418 -418.0 -98.50200162663309 number episode from 10: 72 avegar over 10 episode: -99.46 avegare return across last 100 episodes: -99.46 state values: tensor(0.8959) 418
73 419 -419.0 -98.51698161036676 number episode from 10: 73 avegar over 10 episode: -99.447 avegare return across last 100 episodes: -99.447 state values: tensor(0.8917) 419
74 535 -535.0 -99.53780088487795 number episode from 10: 74 avegar over 10 episode: -99.448 avegare return across last 100 episodes: -99.448 state values: tensor(0.8972) 535
75 547 -547.0 -99.59031369663526 number episode from 10: 75 avegar over 10 episode: -99.45 avegare return across last 100 episodes: -99.45 state values: tensor(0.9047) 547
76 518 -518.0 -99.45168414817302 number episode from 10: 76 avegar over 10 episode: -99.45 avegare return across last 100 episodes: -99.45 state values: tensor(0.8923) 518
77 903 -903.0 -99.98855592430823 number episode from 10: 77 avegar over 10 episode: -99.457 avegare return across last 100 episodes: -99.457 state values: tensor(0.8566) 903
78 519 -519.0 -99.45716730669129 number episode from 10: 78 avegar over 10 episode: -99.457 avegare return across last 100 episodes: -99.457 state values: tensor(0.8881) 519
79 513 -513.0 -99.42342629990226 number episode from 10: 79 avegar over 10 episode: -99.457 avegare return across last 100 episodes: -99.457 state values: tensor(0.8837) 513
80 432 -432.0 -98.69862018560275 number episode from 10: 80 avegar over 10 episode: -99.447 avegare return across last 100 episodes: -99.447 state values: tensor(0.8908) 432
81 515 -515.0 -99.4349001165342 number episode from 10: 81 avegar over 10 episode: -99.447 avegare return across last 100 episodes: -99.447 state values: tensor(0.8866) 515
82 514 -514.0 -99.42919203690323 number episode from 10: 82 avegar over 10 episode: -99.447 avegare return across last 100 episodes: -99.447 state values: tensor(0.8850) 514
83 517 -517.0 -99.44614560421516 number episode from 10: 83 avegar over 10 episode: -99.447 avegare return across last 100 episodes: -99.447 state values: tensor(0.8873) 517
84 438 -438.0 -98.77477673791384 number episode from 10: 84 avegar over 10 episode: -99.439 avegare return across last 100 episodes: -99.439 state values: tensor(0.8885) 438
85 532 -532.0 -99.52365289965047 number episode from 10: 85 avegar over 10 episode: -99.44 avegare return across last 100 episodes: -99.44 state values: tensor(0.9001) 532
86 1000 -1000.0 -99.99568287525881 number episode from 10: 86 avegar over 10 episode: -99.446 avegare return across last 100 episodes: -99.446 state values: tensor(0.8200) 1000
87 439 -439.0 -98.7870289705347 number episode from 10: 87 avegar over 10 episode: -99.439 avegare return across last 100 episodes: -99.439 state values: tensor(0.8902) 439
88 514 -514.0 -99.42919203690323 number episode from 10: 88 avegar over 10 episode: -99.439 avegare return across last 100 episodes: -99.439 state values: tensor(0.8876) 514
89 526 -526.0 -99.49404445685593 number episode from 10: 89 avegar over 10 episode: -99.439 avegare return across last 100 episodes: -99.439 state values: tensor(0.8957) 526
90 527 -527.0 -99.49910401228738 number episode from 10: 90 avegar over 10 episode: -99.44 avegare return across last 100 episodes: -99.44 state values: tensor(0.8906) 527
91 625 -625.0 -99.81293324036642 number episode from 10: 91 avegar over 10 episode: -99.444 avegare return across last 100 episodes: -99.444 state values: tensor(0.8977) 625
92 515 -515.0 -99.4349001165342 number episode from 10: 92 avegar over 10 episode: -99.444 avegare return across last 100 episodes: -99.444 state values: tensor(0.8883) 515
93 529 -529.0 -99.50907184244286 number episode from 10: 93 avegar over 10 episode: -99.445 avegare return across last 100 episodes: -99.445 state values: tensor(0.8895) 529
94 437 -437.0 -98.76240074536751 number episode from 10: 94 avegar over 10 episode: -99.437 avegare return across last 100 episodes: -99.437 state values: tensor(0.8964) 437
95 421 -421.0 -98.54649367632047 number episode from 10: 95 avegar over 10 episode: -99.428 avegare return across last 100 episodes: -99.428 state values: tensor(0.8911) 421
96 515 -515.0 -99.4349001165342 number episode from 10: 96 avegar over 10 episode: -99.428 avegare return across last 100 episodes: -99.428 state values: tensor(0.8849) 515
97 533 -533.0 -99.52841637065397 number episode from 10: 97 avegar over 10 episode: -99.429 avegare return across last 100 episodes: -99.429 state values: tensor(0.9012) 533
98 445 -445.0 -98.85801185395994 number episode from 10: 98 avegar over 10 episode: -99.424 avegare return across last 100 episodes: -99.424 state values: tensor(0.8912) 445
99 521 -521.0 -99.46796967728812 number episode from 10: 99 avegar over 10 episode: -99.424 avegare return across last 100 episodes: -99.424 state values: tensor(0.8892) 521
100 1000 -1000.0 -99.99568287525881 number episode from 10: 100 avegar over 10 episode: -99.43 avegare return across last 100 episodes: -99.439 state values: tensor(0.8202) 1000
101 531 -531.0 -99.51884131277825 number episode from 10: 101 avegar over 10 episode: -99.43 avegare return across last 100 episodes: -99.436 state values: tensor(0.8894) 531
102 426 -426.0 -98.61772994871401 number episode from 10: 102 avegar over 10 episode: -99.423 avegare return across last 100 episodes: -99.423 state values: tensor(0.8897) 426
103 533 -533.0 -99.52841637065397 number episode from 10: 103 avegar over 10 episode: -99.424 avegare return across last 100 episodes: -99.424 state values: tensor(0.8912) 533
104 518 -518.0 -99.45168414817302 number episode from 10: 104 avegar over 10 episode: -99.424 avegare return across last 100 episodes: -99.423 state values: tensor(0.8901) 518
105 518 -518.0 -99.45168414817302 number episode from 10: 105 avegar over 10 episode: -99.424 avegare return across last 100 episodes: -99.422 state values: tensor(0.8855) 518
106 630 -630.0 -99.82210137292142 number episode from 10: 106 avegar over 10 episode: -99.428 avegare return across last 100 episodes: -99.426 state values: tensor(0.8967) 630
107 523 -523.0 -99.47855708071009 number episode from 10: 107 avegar over 10 episode: -99.428 avegare return across last 100 episodes: -99.426 state values: tensor(0.8903) 523
108 535 -535.0 -99.53780088487795 number episode from 10: 108 avegar over 10 episode: -99.429 avegare return across last 100 episodes: -99.423 state values: tensor(0.8914) 535
109 513 -513.0 -99.42342629990226 number episode from 10: 109 avegar over 10 episode: -99.429 avegare return across last 100 episodes: -99.422 state values: tensor(0.8845) 513
110 1000 -1000.0 -99.99568287525881 number episode from 10: 110 avegar over 10 episode: -99.434 avegare return across last 100 episodes: -99.427 state values: tensor(0.8441) 1000
111 556 -556.0 -99.62574449581848 number episode from 10: 111 avegar over 10 episode: -99.436 avegare return across last 100 episodes: -99.423 state values: tensor(0.9045) 556
112 530 -530.0 -99.51398112401843 number episode from 10: 112 avegar over 10 episode: -99.437 avegare return across last 100 episodes: -99.431 state values: tensor(0.9014) 530
113 518 -518.0 -99.45168414817302 number episode from 10: 113 avegar over 10 episode: -99.437 avegare return across last 100 episodes: -99.43 state values: tensor(0.8890) 518
114 519 -519.0 -99.45716730669129 number episode from 10: 114 avegar over 10 episode: -99.437 avegare return across last 100 episodes: -99.425 state values: tensor(0.8894) 519
115 436 -436.0 -98.74989974279546 number episode from 10: 115 avegar over 10 episode: -99.431 avegare return across last 100 episodes: -99.412 state values: tensor(0.8900) 436
116 541 -541.0 -99.56484870804191 number episode from 10: 116 avegar over 10 episode: -99.432 avegare return across last 100 episodes: -99.42 state values: tensor(0.8940) 541
117 431 -431.0 -98.68547493495227 number episode from 10: 117 avegar over 10 episode: -99.426 avegare return across last 100 episodes: -99.413 state values: tensor(0.8902) 431
118 529 -529.0 -99.50907184244286 number episode from 10: 118 avegar over 10 episode: -99.427 avegare return across last 100 episodes: -99.42 state values: tensor(0.8916) 529
119 528 -528.0 -99.5041129721645 number episode from 10: 119 avegar over 10 episode: -99.427 avegare return across last 100 episodes: -99.42 state values: tensor(0.8925) 528
120 1000 -1000.0 -99.99568287525881 number episode from 10: 120 avegar over 10 episode: -99.432 avegare return across last 100 episodes: -99.42 state values: tensor(0.8200) 1000
121 1000 -1000.0 -99.99568287525881 number episode from 10: 121 avegar over 10 episode: -99.437 avegare return across last 100 episodes: -99.425 state values: tensor(0.8202) 1000
122 627 -627.0 -99.81665586888313 number episode from 10: 122 avegar over 10 episode: -99.44 avegare return across last 100 episodes: -99.428 state values: tensor(0.8958) 627
123 425 -425.0 -98.60376762496365 number episode from 10: 123 avegar over 10 episode: -99.433 avegare return across last 100 episodes: -99.427 state values: tensor(0.8933) 425
124 1000 -1000.0 -99.99568287525881 number episode from 10: 124 avegar over 10 episode: -99.437 avegare return across last 100 episodes: -99.427 state values: tensor(0.8200) 1000
125 543 -543.0 -99.57350821875188 number episode from 10: 125 avegar over 10 episode: -99.439 avegare return across last 100 episodes: -99.429 state values: tensor(0.9029) 543
126 1000 -1000.0 -99.99568287525881 number episode from 10: 126 avegar over 10 episode: -99.443 avegare return across last 100 episodes: -99.442 state values: tensor(0.8199) 1000
127 625 -625.0 -99.81293324036642 number episode from 10: 127 avegar over 10 episode: -99.446 avegare return across last 100 episodes: -99.442 state values: tensor(0.8928) 625
128 434 -434.0 -98.72451764390925 number episode from 10: 128 avegar over 10 episode: -99.44 avegare return across last 100 episodes: -99.442 state values: tensor(0.8913) 434
129 532 -532.0 -99.52365289965047 number episode from 10: 129 avegar over 10 episode: -99.441 avegare return across last 100 episodes: -99.442 state values: tensor(0.8894) 532
130 530 -530.0 -99.51398112401843 number episode from 10: 130 avegar over 10 episode: -99.441 avegare return across last 100 episodes: -99.45 state values: tensor(0.9006) 530
131 513 -513.0 -99.42342629990226 number episode from 10: 131 avegar over 10 episode: -99.441 avegare return across last 100 episodes: -99.445 state values: tensor(0.8879) 513
132 547 -547.0 -99.59031369663526 number episode from 10: 132 avegar over 10 episode: -99.442 avegare return across last 100 episodes: -99.441 state values: tensor(0.9027) 547
133 532 -532.0 -99.52365289965047 number episode from 10: 133 avegar over 10 episode: -99.443 avegare return across last 100 episodes: -99.44 state values: tensor(0.8916) 532
134 518 -518.0 -99.45168414817302 number episode from 10: 134 avegar over 10 episode: -99.443 avegare return across last 100 episodes: -99.44 state values: tensor(0.8894) 518
135 431 -431.0 -98.68547493495227 number episode from 10: 135 avegar over 10 episode: -99.438 avegare return across last 100 episodes: -99.432 state values: tensor(0.8909) 431
136 517 -517.0 -99.44614560421516 number episode from 10: 136 avegar over 10 episode: -99.438 avegare return across last 100 episodes: -99.427 state values: tensor(0.8894) 517
137 643 -643.0 -99.8438902147759 number episode from 10: 137 avegar over 10 episode: -99.441 avegare return across last 100 episodes: -99.43 state values: tensor(0.8996) 643
138 533 -533.0 -99.52841637065397 number episode from 10: 138 avegar over 10 episode: -99.441 avegare return across last 100 episodes: -99.425 state values: tensor(0.9031) 533
139 622 -622.0 -99.80720709839589 number episode from 10: 139 avegar over 10 episode: -99.444 avegare return across last 100 episodes: -99.423 state values: tensor(0.8883) 622
140 513 -513.0 -99.42342629990226 number episode from 10: 140 avegar over 10 episode: -99.444 avegare return across last 100 episodes: -99.423 state values: tensor(0.8845) 513
141 551 -551.0 -99.60645697163618 number episode from 10: 141 avegar over 10 episode: -99.445 avegare return across last 100 episodes: -99.425 state values: tensor(0.9033) 551
142 519 -519.0 -99.45716730669129 number episode from 10: 142 avegar over 10 episode: -99.445 avegare return across last 100 episodes: -99.424 state values: tensor(0.8889) 519
143 518 -518.0 -99.45168414817302 number episode from 10: 143 avegar over 10 episode: -99.445 avegare return across last 100 episodes: -99.424 state values: tensor(0.8861) 518
144 522 -522.0 -99.47328998051525 number episode from 10: 144 avegar over 10 episode: -99.445 avegare return across last 100 episodes: -99.423 state values: tensor(0.8867) 522
145 434 -434.0 -98.72451764390925 number episode from 10: 145 avegar over 10 episode: -99.44 avegare return across last 100 episodes: -99.41 state values: tensor(0.8916) 434
146 519 -519.0 -99.45716730669129 number episode from 10: 146 avegar over 10 episode: -99.44 avegare return across last 100 episodes: -99.407 state values: tensor(0.8838) 519
147 522 -522.0 -99.47328998051525 number episode from 10: 147 avegar over 10 episode: -99.441 avegare return across last 100 episodes: -99.406 state values: tensor(0.8923) 522
148 434 -434.0 -98.72451764390925 number episode from 10: 148 avegar over 10 episode: -99.436 avegare return across last 100 episodes: -99.399 state values: tensor(0.8894) 434
149 523 -523.0 -99.47855708071009 number episode from 10: 149 avegar over 10 episode: -99.436 avegare return across last 100 episodes: -99.399 state values: tensor(0.8845) 523
150 1000 -1000.0 -99.99568287525881 number episode from 10: 150 avegar over 10 episode: -99.44 avegare return across last 100 episodes: -99.405 state values: tensor(0.8208) 1000
151 671 -671.0 -99.88218093417017 number episode from 10: 151 avegar over 10 episode: -99.443 avegare return across last 100 episodes: -99.406 state values: tensor(0.8700) 671
152 517 -517.0 -99.44614560421516 number episode from 10: 152 avegar over 10 episode: -99.443 avegare return across last 100 episodes: -99.404 state values: tensor(0.8865) 517
153 542 -542.0 -99.56920022096149 number episode from 10: 153 avegar over 10 episode: -99.443 avegare return across last 100 episodes: -99.405 state values: tensor(0.9015) 542
154 993 -993.0 -99.9953682166697 number episode from 10: 154 avegar over 10 episode: -99.447 avegare return across last 100 episodes: -99.411 state values: tensor(0.8601) 993
155 435 -435.0 -98.73727246747016 number episode from 10: 155 avegar over 10 episode: -99.442 avegare return across last 100 episodes: -99.403 state values: tensor(0.8924) 435
156 535 -535.0 -99.53780088487795 number episode from 10: 156 avegar over 10 episode: -99.443 avegare return across last 100 episodes: -99.404 state values: tensor(0.8917) 535
157 758 -758.0 -99.95085520758803 number episode from 10: 157 avegar over 10 episode: -99.446 avegare return across last 100 episodes: -99.408 state values: tensor(0.8646) 758
158 433 -433.0 -98.71163398374672 number episode from 10: 158 avegar over 10 episode: -99.442 avegare return across last 100 episodes: -99.401 state values: tensor(0.8909) 433
159 434 -434.0 -98.72451764390925 number episode from 10: 159 avegar over 10 episode: -99.437 avegare return across last 100 episodes: -99.394 state values: tensor(0.8894) 434
160 1000 -1000.0 -99.99568287525881 number episode from 10: 160 avegar over 10 episode: -99.441 avegare return across last 100 episodes: -99.406 state values: tensor(0.8335) 1000
161 523 -523.0 -99.47855708071009 number episode from 10: 161 avegar over 10 episode: -99.441 avegare return across last 100 episodes: -99.406 state values: tensor(0.8923) 523
162 529 -529.0 -99.50907184244286 number episode from 10: 162 avegar over 10 episode: -99.441 avegare return across last 100 episodes: -99.407 state values: tensor(0.9021) 529
163 622 -622.0 -99.80720709839589 number episode from 10: 163 avegar over 10 episode: -99.444 avegare return across last 100 episodes: -99.409 state values: tensor(0.8906) 622
164 517 -517.0 -99.44614560421516 number episode from 10: 164 avegar over 10 episode: -99.444 avegare return across last 100 episodes: -99.407 state values: tensor(0.8897) 517
165 627 -627.0 -99.81665586888313 number episode from 10: 165 avegar over 10 episode: -99.446 avegare return across last 100 episodes: -99.419 state values: tensor(0.8952) 627
166 517 -517.0 -99.44614560421516 number episode from 10: 166 avegar over 10 episode: -99.446 avegare return across last 100 episodes: -99.417 state values: tensor(0.8882) 517
167 434 -434.0 -98.72451764390925 number episode from 10: 167 avegar over 10 episode: -99.442 avegare return across last 100 episodes: -99.41 state values: tensor(0.8911) 434
168 436 -436.0 -98.74989974279546 number episode from 10: 168 avegar over 10 episode: -99.437 avegare return across last 100 episodes: -99.409 state values: tensor(0.8912) 436
169 526 -526.0 -99.49404445685593 number episode from 10: 169 avegar over 10 episode: -99.438 avegare return across last 100 episodes: -99.41 state values: tensor(0.8925) 526
170 518 -518.0 -99.45168414817302 number episode from 10: 170 avegar over 10 episode: -99.438 avegare return across last 100 episodes: -99.418 state values: tensor(0.8882) 518
171 530 -530.0 -99.51398112401843 number episode from 10: 171 avegar over 10 episode: -99.438 avegare return across last 100 episodes: -99.413 state values: tensor(0.8892) 530
172 646 -646.0 -99.84852683150685 number episode from 10: 172 avegar over 10 episode: -99.441 avegare return across last 100 episodes: -99.427 state values: tensor(0.8986) 646
173 536 -536.0 -99.54242287602918 number episode from 10: 173 avegar over 10 episode: -99.441 avegare return across last 100 episodes: -99.437 state values: tensor(0.8939) 536
174 433 -433.0 -98.71163398374672 number episode from 10: 174 avegar over 10 episode: -99.437 avegare return across last 100 episodes: -99.429 state values: tensor(0.8909) 433
175 515 -515.0 -99.4349001165342 number episode from 10: 175 avegar over 10 episode: -99.437 avegare return across last 100 episodes: -99.427 state values: tensor(0.8858) 515
176 1000 -1000.0 -99.99568287525881 number episode from 10: 176 avegar over 10 episode: -99.44 avegare return across last 100 episodes: -99.433 state values: tensor(0.8356) 1000
177 533 -533.0 -99.52841637065397 number episode from 10: 177 avegar over 10 episode: -99.441 avegare return across last 100 episodes: -99.428 state values: tensor(0.8949) 533
178 733 -733.0 -99.9368173786718 number episode from 10: 178 avegar over 10 episode: -99.443 avegare return across last 100 episodes: -99.433 state values: tensor(0.8621) 733
179 531 -531.0 -99.51884131277825 number episode from 10: 179 avegar over 10 episode: -99.444 avegare return across last 100 episodes: -99.434 state values: tensor(0.8901) 531
180 1000 -1000.0 -99.99568287525881 number episode from 10: 180 avegar over 10 episode: -99.447 avegare return across last 100 episodes: -99.447 state values: tensor(0.8206) 1000
181 590 -590.0 -99.73407154367938 number episode from 10: 181 avegar over 10 episode: -99.449 avegare return across last 100 episodes: -99.45 state values: tensor(0.8742) 590
182 514 -514.0 -99.42919203690323 number episode from 10: 182 avegar over 10 episode: -99.448 avegare return across last 100 episodes: -99.45 state values: tensor(0.8846) 514
183 433 -433.0 -98.71163398374672 number episode from 10: 183 avegar over 10 episode: -99.444 avegare return across last 100 episodes: -99.442 state values: tensor(0.8914) 433
184 547 -547.0 -99.59031369663526 number episode from 10: 184 avegar over 10 episode: -99.445 avegare return across last 100 episodes: -99.451 state values: tensor(0.9052) 547
185 532 -532.0 -99.52365289965047 number episode from 10: 185 avegar over 10 episode: -99.446 avegare return across last 100 episodes: -99.451 state values: tensor(0.9003) 532
186 1000 -1000.0 -99.99568287525881 number episode from 10: 186 avegar over 10 episode: -99.449 avegare return across last 100 episodes: -99.451 state values: tensor(0.8201) 1000
187 1000 -1000.0 -99.99568287525881 number episode from 10: 187 avegar over 10 episode: -99.451 avegare return across last 100 episodes: -99.463 state values: tensor(0.8199) 1000
188 515 -515.0 -99.4349001165342 number episode from 10: 188 avegar over 10 episode: -99.451 avegare return across last 100 episodes: -99.463 state values: tensor(0.8881) 515
189 437 -437.0 -98.76240074536751 number episode from 10: 189 avegar over 10 episode: -99.448 avegare return across last 100 episodes: -99.455 state values: tensor(0.8903) 437
190 535 -535.0 -99.53780088487795 number episode from 10: 190 avegar over 10 episode: -99.448 avegare return across last 100 episodes: -99.456 state values: tensor(0.9007) 535
191 432 -432.0 -98.69862018560275 number episode from 10: 191 avegar over 10 episode: -99.444 avegare return across last 100 episodes: -99.445 state values: tensor(0.8906) 432
192 618 -618.0 -99.79929866499853 number episode from 10: 192 avegar over 10 episode: -99.446 avegare return across last 100 episodes: -99.448 state values: tensor(0.8865) 618
193 437 -437.0 -98.76240074536751 number episode from 10: 193 avegar over 10 episode: -99.443 avegare return across last 100 episodes: -99.441 state values: tensor(0.8921) 437
194 435 -435.0 -98.73727246747016 number episode from 10: 194 avegar over 10 episode: -99.439 avegare return across last 100 episodes: -99.441 state values: tensor(0.8912) 435
195 619 -619.0 -99.80130567834854 number episode from 10: 195 avegar over 10 episode: -99.441 avegare return across last 100 episodes: -99.453 state values: tensor(0.8805) 619
196 532 -532.0 -99.52365289965047 number episode from 10: 196 avegar over 10 episode: -99.441 avegare return across last 100 episodes: -99.454 state values: tensor(0.8910) 532
197 518 -518.0 -99.45168414817302 number episode from 10: 197 avegar over 10 episode: -99.441 avegare return across last 100 episodes: -99.453 state values: tensor(0.8845) 518
198 1000 -1000.0 -99.99568287525881 number episode from 10: 198 avegar over 10 episode: -99.444 avegare return across last 100 episodes: -99.465 state values: tensor(0.8553) 1000
199 521 -521.0 -99.46796967728812 number episode from 10: 199 avegar over 10 episode: -99.444 avegare return across last 100 episodes: -99.465 state values: tensor(0.8883) 521
200 518 -518.0 -99.45168414817302 number episode from 10: 200 avegar over 10 episode: -99.444 avegare return across last 100 episodes: -99.459 state values: tensor(0.8819) 518
Start! Seed: 224
0 1001 -1000.0 -98.99572604650622 number episode from 10: 0 avegar over 10 episode: -98.996 avegare return across last 100 episodes: -98.996 state values: tensor(0.9447) 1000
1 1000 -1000.0 -99.99568287525881 number episode from 10: 1 avegar over 10 episode: -99.496 avegare return across last 100 episodes: -99.496 state values: tensor(0.9415) 1000
2 1000 -1000.0 -99.99568287525881 number episode from 10: 2 avegar over 10 episode: -99.662 avegare return across last 100 episodes: -99.662 state values: tensor(0.9454) 1000
3 1000 -1000.0 -99.99568287525881 number episode from 10: 3 avegar over 10 episode: -99.746 avegare return across last 100 episodes: -99.746 state values: tensor(0.9470) 1000
4 1000 -1000.0 -99.99568287525881 number episode from 10: 4 avegar over 10 episode: -99.796 avegare return across last 100 episodes: -99.796 state values: tensor(0.9423) 1000
5 1000 -1000.0 -99.99568287525881 number episode from 10: 5 avegar over 10 episode: -99.829 avegare return across last 100 episodes: -99.829 state values: tensor(0.9000) 1000
6 1000 -1000.0 -99.99568287525881 number episode from 10: 6 avegar over 10 episode: -99.853 avegare return across last 100 episodes: -99.853 state values: tensor(0.9437) 1000
7 1000 -1000.0 -99.99568287525881 number episode from 10: 7 avegar over 10 episode: -99.871 avegare return across last 100 episodes: -99.871 state values: tensor(0.9433) 1000
8 1000 -1000.0 -99.99568287525881 number episode from 10: 8 avegar over 10 episode: -99.885 avegare return across last 100 episodes: -99.885 state values: tensor(0.9232) 1000
9 1000 -1000.0 -99.99568287525881 number episode from 10: 9 avegar over 10 episode: -99.896 avegare return across last 100 episodes: -99.896 state values: tensor(0.8962) 1000
10 1000 -1000.0 -99.99568287525881 number episode from 10: 10 avegar over 10 episode: -99.905 avegare return across last 100 episodes: -99.905 state values: tensor(0.9454) 1000
11 1000 -1000.0 -99.99568287525881 number episode from 10: 11 avegar over 10 episode: -99.912 avegare return across last 100 episodes: -99.912 state values: tensor(0.8969) 1000
12 1000 -1000.0 -99.99568287525881 number episode from 10: 12 avegar over 10 episode: -99.919 avegare return across last 100 episodes: -99.919 state values: tensor(0.8991) 1000
13 1000 -1000.0 -99.99568287525881 number episode from 10: 13 avegar over 10 episode: -99.924 avegare return across last 100 episodes: -99.924 state values: tensor(0.9476) 1000
14 1000 -1000.0 -99.99568287525881 number episode from 10: 14 avegar over 10 episode: -99.929 avegare return across last 100 episodes: -99.929 state values: tensor(0.9009) 1000
15 1000 -1000.0 -99.99568287525881 number episode from 10: 15 avegar over 10 episode: -99.933 avegare return across last 100 episodes: -99.933 state values: tensor(0.9424) 1000
16 1000 -1000.0 -99.99568287525881 number episode from 10: 16 avegar over 10 episode: -99.937 avegare return across last 100 episodes: -99.937 state values: tensor(0.9008) 1000
17 1000 -1000.0 -99.99568287525881 number episode from 10: 17 avegar over 10 episode: -99.94 avegare return across last 100 episodes: -99.94 state values: tensor(0.9421) 1000
18 1000 -1000.0 -99.99568287525881 number episode from 10: 18 avegar over 10 episode: -99.943 avegare return across last 100 episodes: -99.943 state values: tensor(0.9444) 1000
19 1000 -1000.0 -99.99568287525881 number episode from 10: 19 avegar over 10 episode: -99.946 avegare return across last 100 episodes: -99.946 state values: tensor(0.9467) 1000
20 1000 -1000.0 -99.99568287525881 number episode from 10: 20 avegar over 10 episode: -99.948 avegare return across last 100 episodes: -99.948 state values: tensor(0.9474) 1000
21 1000 -1000.0 -99.99568287525881 number episode from 10: 21 avegar over 10 episode: -99.95 avegare return across last 100 episodes: -99.95 state values: tensor(0.8946) 1000
22 1000 -1000.0 -99.99568287525881 number episode from 10: 22 avegar over 10 episode: -99.952 avegare return across last 100 episodes: -99.952 state values: tensor(0.9442) 1000
23 1000 -1000.0 -99.99568287525881 number episode from 10: 23 avegar over 10 episode: -99.954 avegare return across last 100 episodes: -99.954 state values: tensor(0.9469) 1000
24 1000 -1000.0 -99.99568287525881 number episode from 10: 24 avegar over 10 episode: -99.956 avegare return across last 100 episodes: -99.956 state values: tensor(0.9455) 1000
25 1000 -1000.0 -99.99568287525881 number episode from 10: 25 avegar over 10 episode: -99.957 avegare return across last 100 episodes: -99.957 state values: tensor(0.8962) 1000
26 1000 -1000.0 -99.99568287525881 number episode from 10: 26 avegar over 10 episode: -99.959 avegare return across last 100 episodes: -99.959 state values: tensor(0.9416) 1000
27 1000 -1000.0 -99.99568287525881 number episode from 10: 27 avegar over 10 episode: -99.96 avegare return across last 100 episodes: -99.96 state values: tensor(0.8954) 1000
28 1000 -1000.0 -99.99568287525881 number episode from 10: 28 avegar over 10 episode: -99.961 avegare return across last 100 episodes: -99.961 state values: tensor(0.9012) 1000
29 1000 -1000.0 -99.99568287525881 number episode from 10: 29 avegar over 10 episode: -99.962 avegare return across last 100 episodes: -99.962 state values: tensor(0.9010) 1000
30 1000 -1000.0 -99.99568287525881 number episode from 10: 30 avegar over 10 episode: -99.963 avegare return across last 100 episodes: -99.963 state values: tensor(0.9251) 1000
31 1000 -1000.0 -99.99568287525881 number episode from 10: 31 avegar over 10 episode: -99.964 avegare return across last 100 episodes: -99.964 state values: tensor(0.9442) 1000
32 1000 -1000.0 -99.99568287525881 number episode from 10: 32 avegar over 10 episode: -99.965 avegare return across last 100 episodes: -99.965 state values: tensor(0.8964) 1000
33 1000 -1000.0 -99.99568287525881 number episode from 10: 33 avegar over 10 episode: -99.966 avegare return across last 100 episodes: -99.966 state values: tensor(0.9475) 1000
34 1000 -1000.0 -99.99568287525881 number episode from 10: 34 avegar over 10 episode: -99.967 avegare return across last 100 episodes: -99.967 state values: tensor(0.9028) 1000
35 1000 -1000.0 -99.99568287525881 number episode from 10: 35 avegar over 10 episode: -99.968 avegare return across last 100 episodes: -99.968 state values: tensor(0.9444) 1000
36 1000 -1000.0 -99.99568287525881 number episode from 10: 36 avegar over 10 episode: -99.969 avegare return across last 100 episodes: -99.969 state values: tensor(0.9352) 1000
37 1000 -1000.0 -99.99568287525881 number episode from 10: 37 avegar over 10 episode: -99.969 avegare return across last 100 episodes: -99.969 state values: tensor(0.8968) 1000
38 1000 -1000.0 -99.99568287525881 number episode from 10: 38 avegar over 10 episode: -99.97 avegare return across last 100 episodes: -99.97 state values: tensor(0.9461) 1000
39 1000 -1000.0 -99.99568287525881 number episode from 10: 39 avegar over 10 episode: -99.971 avegare return across last 100 episodes: -99.971 state values: tensor(0.9436) 1000
40 1000 -1000.0 -99.99568287525881 number episode from 10: 40 avegar over 10 episode: -99.971 avegare return across last 100 episodes: -99.971 state values: tensor(0.9459) 1000
41 1000 -1000.0 -99.99568287525881 number episode from 10: 41 avegar over 10 episode: -99.972 avegare return across last 100 episodes: -99.972 state values: tensor(0.9475) 1000
42 1000 -1000.0 -99.99568287525881 number episode from 10: 42 avegar over 10 episode: -99.972 avegare return across last 100 episodes: -99.972 state values: tensor(0.9370) 1000
43 1000 -1000.0 -99.99568287525881 number episode from 10: 43 avegar over 10 episode: -99.973 avegare return across last 100 episodes: -99.973 state values: tensor(0.8983) 1000
44 1000 -1000.0 -99.99568287525881 number episode from 10: 44 avegar over 10 episode: -99.973 avegare return across last 100 episodes: -99.973 state values: tensor(0.8999) 1000
45 1000 -1000.0 -99.99568287525881 number episode from 10: 45 avegar over 10 episode: -99.974 avegare return across last 100 episodes: -99.974 state values: tensor(0.8947) 1000
46 1000 -1000.0 -99.99568287525881 number episode from 10: 46 avegar over 10 episode: -99.974 avegare return across last 100 episodes: -99.974 state values: tensor(0.8954) 1000
47 1000 -1000.0 -99.99568287525881 number episode from 10: 47 avegar over 10 episode: -99.975 avegare return across last 100 episodes: -99.975 state values: tensor(0.8950) 1000
48 1000 -1000.0 -99.99568287525881 number episode from 10: 48 avegar over 10 episode: -99.975 avegare return across last 100 episodes: -99.975 state values: tensor(0.9470) 1000
49 1000 -1000.0 -99.99568287525881 number episode from 10: 49 avegar over 10 episode: -99.976 avegare return across last 100 episodes: -99.976 state values: tensor(0.8979) 1000
50 1000 -1000.0 -99.99568287525881 number episode from 10: 50 avegar over 10 episode: -99.976 avegare return across last 100 episodes: -99.976 state values: tensor(0.8953) 1000
51 1000 -1000.0 -99.99568287525881 number episode from 10: 51 avegar over 10 episode: -99.976 avegare return across last 100 episodes: -99.976 state values: tensor(0.8983) 1000
52 1000 -1000.0 -99.99568287525881 number episode from 10: 52 avegar over 10 episode: -99.977 avegare return across last 100 episodes: -99.977 state values: tensor(0.8966) 1000
53 1000 -1000.0 -99.99568287525881 number episode from 10: 53 avegar over 10 episode: -99.977 avegare return across last 100 episodes: -99.977 state values: tensor(0.9043) 1000
54 1000 -1000.0 -99.99568287525881 number episode from 10: 54 avegar over 10 episode: -99.978 avegare return across last 100 episodes: -99.978 state values: tensor(0.9443) 1000
55 1000 -1000.0 -99.99568287525881 number episode from 10: 55 avegar over 10 episode: -99.978 avegare return across last 100 episodes: -99.978 state values: tensor(0.8992) 1000
56 1000 -1000.0 -99.99568287525881 number episode from 10: 56 avegar over 10 episode: -99.978 avegare return across last 100 episodes: -99.978 state values: tensor(0.8949) 1000
57 1000 -1000.0 -99.99568287525881 number episode from 10: 57 avegar over 10 episode: -99.978 avegare return across last 100 episodes: -99.978 state values: tensor(0.9109) 1000
58 1000 -1000.0 -99.99568287525881 number episode from 10: 58 avegar over 10 episode: -99.979 avegare return across last 100 episodes: -99.979 state values: tensor(0.8992) 1000
59 1000 -1000.0 -99.99568287525881 number episode from 10: 59 avegar over 10 episode: -99.979 avegare return across last 100 episodes: -99.979 state values: tensor(0.8978) 1000
60 1000 -1000.0 -99.99568287525881 number episode from 10: 60 avegar over 10 episode: -99.979 avegare return across last 100 episodes: -99.979 state values: tensor(0.8959) 1000
61 1000 -1000.0 -99.99568287525881 number episode from 10: 61 avegar over 10 episode: -99.98 avegare return across last 100 episodes: -99.98 state values: tensor(0.9474) 1000
62 1000 -1000.0 -99.99568287525881 number episode from 10: 62 avegar over 10 episode: -99.98 avegare return across last 100 episodes: -99.98 state values: tensor(0.9424) 1000
63 1000 -1000.0 -99.99568287525881 number episode from 10: 63 avegar over 10 episode: -99.98 avegare return across last 100 episodes: -99.98 state values: tensor(0.9439) 1000
64 1000 -1000.0 -99.99568287525881 number episode from 10: 64 avegar over 10 episode: -99.98 avegare return across last 100 episodes: -99.98 state values: tensor(0.8970) 1000
65 1000 -1000.0 -99.99568287525881 number episode from 10: 65 avegar over 10 episode: -99.981 avegare return across last 100 episodes: -99.981 state values: tensor(0.9003) 1000
66 1000 -1000.0 -99.99568287525881 number episode from 10: 66 avegar over 10 episode: -99.981 avegare return across last 100 episodes: -99.981 state values: tensor(0.8954) 1000
67 1000 -1000.0 -99.99568287525881 number episode from 10: 67 avegar over 10 episode: -99.981 avegare return across last 100 episodes: -99.981 state values: tensor(0.9433) 1000
68 1000 -1000.0 -99.99568287525881 number episode from 10: 68 avegar over 10 episode: -99.981 avegare return across last 100 episodes: -99.981 state values: tensor(0.8956) 1000
69 1000 -1000.0 -99.99568287525881 number episode from 10: 69 avegar over 10 episode: -99.981 avegare return across last 100 episodes: -99.981 state values: tensor(0.8960) 1000
70 1000 -1000.0 -99.99568287525881 number episode from 10: 70 avegar over 10 episode: -99.982 avegare return across last 100 episodes: -99.982 state values: tensor(0.9042) 1000
71 1000 -1000.0 -99.99568287525881 number episode from 10: 71 avegar over 10 episode: -99.982 avegare return across last 100 episodes: -99.982 state values: tensor(0.8964) 1000
72 1000 -1000.0 -99.99568287525881 number episode from 10: 72 avegar over 10 episode: -99.982 avegare return across last 100 episodes: -99.982 state values: tensor(0.8966) 1000
73 1000 -1000.0 -99.99568287525881 number episode from 10: 73 avegar over 10 episode: -99.982 avegare return across last 100 episodes: -99.982 state values: tensor(0.8981) 1000
74 1000 -1000.0 -99.99568287525881 number episode from 10: 74 avegar over 10 episode: -99.982 avegare return across last 100 episodes: -99.982 state values: tensor(0.9223) 1000
75 1000 -1000.0 -99.99568287525881 number episode from 10: 75 avegar over 10 episode: -99.983 avegare return across last 100 episodes: -99.983 state values: tensor(0.9386) 1000
76 1000 -1000.0 -99.99568287525881 number episode from 10: 76 avegar over 10 episode: -99.983 avegare return across last 100 episodes: -99.983 state values: tensor(0.9398) 1000
77 1000 -1000.0 -99.99568287525881 number episode from 10: 77 avegar over 10 episode: -99.983 avegare return across last 100 episodes: -99.983 state values: tensor(0.9480) 1000
78 1000 -1000.0 -99.99568287525881 number episode from 10: 78 avegar over 10 episode: -99.983 avegare return across last 100 episodes: -99.983 state values: tensor(0.9455) 1000
79 1000 -1000.0 -99.99568287525881 number episode from 10: 79 avegar over 10 episode: -99.983 avegare return across last 100 episodes: -99.983 state values: tensor(0.9479) 1000
80 1000 -1000.0 -99.99568287525881 number episode from 10: 80 avegar over 10 episode: -99.983 avegare return across last 100 episodes: -99.983 state values: tensor(0.9439) 1000
81 1000 -1000.0 -99.99568287525881 number episode from 10: 81 avegar over 10 episode: -99.983 avegare return across last 100 episodes: -99.983 state values: tensor(0.8951) 1000
82 1000 -1000.0 -99.99568287525881 number episode from 10: 82 avegar over 10 episode: -99.984 avegare return across last 100 episodes: -99.984 state values: tensor(0.9440) 1000
83 1000 -1000.0 -99.99568287525881 number episode from 10: 83 avegar over 10 episode: -99.984 avegare return across last 100 episodes: -99.984 state values: tensor(0.9434) 1000
84 1000 -1000.0 -99.99568287525881 number episode from 10: 84 avegar over 10 episode: -99.984 avegare return across last 100 episodes: -99.984 state values: tensor(0.9438) 1000
85 1000 -1000.0 -99.99568287525881 number episode from 10: 85 avegar over 10 episode: -99.984 avegare return across last 100 episodes: -99.984 state values: tensor(0.9475) 1000
86 1000 -1000.0 -99.99568287525881 number episode from 10: 86 avegar over 10 episode: -99.984 avegare return across last 100 episodes: -99.984 state values: tensor(0.8987) 1000
87 1000 -1000.0 -99.99568287525881 number episode from 10: 87 avegar over 10 episode: -99.984 avegare return across last 100 episodes: -99.984 state values: tensor(0.8947) 1000
88 1000 -1000.0 -99.99568287525881 number episode from 10: 88 avegar over 10 episode: -99.984 avegare return across last 100 episodes: -99.984 state values: tensor(0.9205) 1000
89 1000 -1000.0 -99.99568287525881 number episode from 10: 89 avegar over 10 episode: -99.985 avegare return across last 100 episodes: -99.985 state values: tensor(0.8975) 1000
90 1000 -1000.0 -99.99568287525881 number episode from 10: 90 avegar over 10 episode: -99.985 avegare return across last 100 episodes: -99.985 state values: tensor(0.8987) 1000
91 1000 -1000.0 -99.99568287525881 number episode from 10: 91 avegar over 10 episode: -99.985 avegare return across last 100 episodes: -99.985 state values: tensor(0.9443) 1000
92 1000 -1000.0 -99.99568287525881 number episode from 10: 92 avegar over 10 episode: -99.985 avegare return across last 100 episodes: -99.985 state values: tensor(0.9243) 1000
93 1000 -1000.0 -99.99568287525881 number episode from 10: 93 avegar over 10 episode: -99.985 avegare return across last 100 episodes: -99.985 state values: tensor(0.8952) 1000
94 1000 -1000.0 -99.99568287525881 number episode from 10: 94 avegar over 10 episode: -99.985 avegare return across last 100 episodes: -99.985 state values: tensor(0.9430) 1000
95 1000 -1000.0 -99.99568287525881 number episode from 10: 95 avegar over 10 episode: -99.985 avegare return across last 100 episodes: -99.985 state values: tensor(0.9269) 1000
96 1000 -1000.0 -99.99568287525881 number episode from 10: 96 avegar over 10 episode: -99.985 avegare return across last 100 episodes: -99.985 state values: tensor(0.9002) 1000
97 1000 -1000.0 -99.99568287525881 number episode from 10: 97 avegar over 10 episode: -99.985 avegare return across last 100 episodes: -99.985 state values: tensor(0.9031) 1000
98 1000 -1000.0 -99.99568287525881 number episode from 10: 98 avegar over 10 episode: -99.986 avegare return across last 100 episodes: -99.986 state values: tensor(0.8978) 1000
99 1000 -1000.0 -99.99568287525881 number episode from 10: 99 avegar over 10 episode: -99.986 avegare return across last 100 episodes: -99.986 state values: tensor(0.9470) 1000
100 1000 -1000.0 -99.99568287525881 number episode from 10: 100 avegar over 10 episode: -99.986 avegare return across last 100 episodes: -99.996 state values: tensor(0.9010) 1000
101 1000 -1000.0 -99.99568287525881 number episode from 10: 101 avegar over 10 episode: -99.986 avegare return across last 100 episodes: -99.996 state values: tensor(0.8987) 1000
102 1000 -1000.0 -99.99568287525881 number episode from 10: 102 avegar over 10 episode: -99.986 avegare return across last 100 episodes: -99.996 state values: tensor(0.8964) 1000
103 1000 -1000.0 -99.99568287525881 number episode from 10: 103 avegar over 10 episode: -99.986 avegare return across last 100 episodes: -99.996 state values: tensor(0.8962) 1000
104 1000 -1000.0 -99.99568287525881 number episode from 10: 104 avegar over 10 episode: -99.986 avegare return across last 100 episodes: -99.996 state values: tensor(0.9447) 1000
105 1000 -1000.0 -99.99568287525881 number episode from 10: 105 avegar over 10 episode: -99.986 avegare return across last 100 episodes: -99.996 state values: tensor(0.8974) 1000
106 1000 -1000.0 -99.99568287525881 number episode from 10: 106 avegar over 10 episode: -99.986 avegare return across last 100 episodes: -99.996 state values: tensor(0.8998) 1000
107 1000 -1000.0 -99.99568287525881 number episode from 10: 107 avegar over 10 episode: -99.986 avegare return across last 100 episodes: -99.996 state values: tensor(0.9423) 1000
108 1000 -1000.0 -99.99568287525881 number episode from 10: 108 avegar over 10 episode: -99.987 avegare return across last 100 episodes: -99.996 state values: tensor(0.9072) 1000
109 1000 -1000.0 -99.99568287525881 number episode from 10: 109 avegar over 10 episode: -99.987 avegare return across last 100 episodes: -99.996 state values: tensor(0.9472) 1000
110 1000 -1000.0 -99.99568287525881 number episode from 10: 110 avegar over 10 episode: -99.987 avegare return across last 100 episodes: -99.996 state values: tensor(0.9013) 1000
111 1000 -1000.0 -99.99568287525881 number episode from 10: 111 avegar over 10 episode: -99.987 avegare return across last 100 episodes: -99.996 state values: tensor(0.9459) 1000
112 1000 -1000.0 -99.99568287525881 number episode from 10: 112 avegar over 10 episode: -99.987 avegare return across last 100 episodes: -99.996 state values: tensor(0.9443) 1000
113 1000 -1000.0 -99.99568287525881 number episode from 10: 113 avegar over 10 episode: -99.987 avegare return across last 100 episodes: -99.996 state values: tensor(0.9147) 1000
114 1000 -1000.0 -99.99568287525881 number episode from 10: 114 avegar over 10 episode: -99.987 avegare return across last 100 episodes: -99.996 state values: tensor(0.9052) 1000
115 1000 -1000.0 -99.99568287525881 number episode from 10: 115 avegar over 10 episode: -99.987 avegare return across last 100 episodes: -99.996 state values: tensor(0.8947) 1000
116 1000 -1000.0 -99.99568287525881 number episode from 10: 116 avegar over 10 episode: -99.987 avegare return across last 100 episodes: -99.996 state values: tensor(0.9040) 1000
117 1000 -1000.0 -99.99568287525881 number episode from 10: 117 avegar over 10 episode: -99.987 avegare return across last 100 episodes: -99.996 state values: tensor(0.9458) 1000
118 1000 -1000.0 -99.99568287525881 number episode from 10: 118 avegar over 10 episode: -99.987 avegare return across last 100 episodes: -99.996 state values: tensor(0.9144) 1000
119 1000 -1000.0 -99.99568287525881 number episode from 10: 119 avegar over 10 episode: -99.987 avegare return across last 100 episodes: -99.996 state values: tensor(0.8961) 1000
120 1000 -1000.0 -99.99568287525881 number episode from 10: 120 avegar over 10 episode: -99.987 avegare return across last 100 episodes: -99.996 state values: tensor(0.8956) 1000
121 1000 -1000.0 -99.99568287525881 number episode from 10: 121 avegar over 10 episode: -99.987 avegare return across last 100 episodes: -99.996 state values: tensor(0.9467) 1000
122 1000 -1000.0 -99.99568287525881 number episode from 10: 122 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.9456) 1000
123 1000 -1000.0 -99.99568287525881 number episode from 10: 123 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.9469) 1000
124 1000 -1000.0 -99.99568287525881 number episode from 10: 124 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.9014) 1000
125 1000 -1000.0 -99.99568287525881 number episode from 10: 125 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.8965) 1000
126 1000 -1000.0 -99.99568287525881 number episode from 10: 126 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.9389) 1000
127 1000 -1000.0 -99.99568287525881 number episode from 10: 127 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.9348) 1000
128 1000 -1000.0 -99.99568287525881 number episode from 10: 128 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.9427) 1000
129 1000 -1000.0 -99.99568287525881 number episode from 10: 129 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.9467) 1000
130 1000 -1000.0 -99.99568287525881 number episode from 10: 130 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.9439) 1000
131 1000 -1000.0 -99.99568287525881 number episode from 10: 131 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.9377) 1000
132 1000 -1000.0 -99.99568287525881 number episode from 10: 132 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.9472) 1000
133 1000 -1000.0 -99.99568287525881 number episode from 10: 133 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.9024) 1000
134 1000 -1000.0 -99.99568287525881 number episode from 10: 134 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.9323) 1000
135 1000 -1000.0 -99.99568287525881 number episode from 10: 135 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.9455) 1000
136 1000 -1000.0 -99.99568287525881 number episode from 10: 136 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.8968) 1000
137 1000 -1000.0 -99.99568287525881 number episode from 10: 137 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.9448) 1000
138 1000 -1000.0 -99.99568287525881 number episode from 10: 138 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.9434) 1000
139 1000 -1000.0 -99.99568287525881 number episode from 10: 139 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.9438) 1000
140 1000 -1000.0 -99.99568287525881 number episode from 10: 140 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.9008) 1000
141 1000 -1000.0 -99.99568287525881 number episode from 10: 141 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.9471) 1000
142 1000 -1000.0 -99.99568287525881 number episode from 10: 142 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.9457) 1000
143 1000 -1000.0 -99.99568287525881 number episode from 10: 143 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.9441) 1000
144 1000 -1000.0 -99.99568287525881 number episode from 10: 144 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.9031) 1000
145 1000 -1000.0 -99.99568287525881 number episode from 10: 145 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.9441) 1000
146 1000 -1000.0 -99.99568287525881 number episode from 10: 146 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.8951) 1000
147 1000 -1000.0 -99.99568287525881 number episode from 10: 147 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.9470) 1000
148 1000 -1000.0 -99.99568287525881 number episode from 10: 148 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.8947) 1000
149 1000 -1000.0 -99.99568287525881 number episode from 10: 149 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.9424) 1000
150 1000 -1000.0 -99.99568287525881 number episode from 10: 150 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.9454) 1000
151 1000 -1000.0 -99.99568287525881 number episode from 10: 151 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.9470) 1000
152 1000 -1000.0 -99.99568287525881 number episode from 10: 152 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.9459) 1000
153 1000 -1000.0 -99.99568287525881 number episode from 10: 153 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.9459) 1000
154 1000 -1000.0 -99.99568287525881 number episode from 10: 154 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.9439) 1000
155 1000 -1000.0 -99.99568287525881 number episode from 10: 155 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.9473) 1000
156 1000 -1000.0 -99.99568287525881 number episode from 10: 156 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.9461) 1000
157 1000 -1000.0 -99.99568287525881 number episode from 10: 157 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.9466) 1000
158 1000 -1000.0 -99.99568287525881 number episode from 10: 158 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.9431) 1000
159 1000 -1000.0 -99.99568287525881 number episode from 10: 159 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.9446) 1000
160 1000 -1000.0 -99.99568287525881 number episode from 10: 160 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.9020) 1000
161 1000 -1000.0 -99.99568287525881 number episode from 10: 161 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.9012) 1000
162 1000 -1000.0 -99.99568287525881 number episode from 10: 162 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.9006) 1000
163 1000 -1000.0 -99.99568287525881 number episode from 10: 163 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.8963) 1000
164 1000 -1000.0 -99.99568287525881 number episode from 10: 164 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.9439) 1000
165 1000 -1000.0 -99.99568287525881 number episode from 10: 165 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.8980) 1000
166 1000 -1000.0 -99.99568287525881 number episode from 10: 166 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.9086) 1000
167 1000 -1000.0 -99.99568287525881 number episode from 10: 167 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.9472) 1000
168 1000 -1000.0 -99.99568287525881 number episode from 10: 168 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.9003) 1000
169 1000 -1000.0 -99.99568287525881 number episode from 10: 169 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.8955) 1000
170 1000 -1000.0 -99.99568287525881 number episode from 10: 170 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.9018) 1000
171 1000 -1000.0 -99.99568287525881 number episode from 10: 171 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.9088) 1000
172 1000 -1000.0 -99.99568287525881 number episode from 10: 172 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.9051) 1000
173 1000 -1000.0 -99.99568287525881 number episode from 10: 173 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.9442) 1000
174 1000 -1000.0 -99.99568287525881 number episode from 10: 174 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.9413) 1000
175 1000 -1000.0 -99.99568287525881 number episode from 10: 175 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.9418) 1000
176 1000 -1000.0 -99.99568287525881 number episode from 10: 176 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.9443) 1000
177 1000 -1000.0 -99.99568287525881 number episode from 10: 177 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.9030) 1000
178 1000 -1000.0 -99.99568287525881 number episode from 10: 178 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.9478) 1000
179 1000 -1000.0 -99.99568287525881 number episode from 10: 179 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.8965) 1000
180 1000 -1000.0 -99.99568287525881 number episode from 10: 180 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.8984) 1000
181 1000 -1000.0 -99.99568287525881 number episode from 10: 181 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.9456) 1000
182 1000 -1000.0 -99.99568287525881 number episode from 10: 182 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.9468) 1000
183 1000 -1000.0 -99.99568287525881 number episode from 10: 183 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.8948) 1000
184 1000 -1000.0 -99.99568287525881 number episode from 10: 184 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.9447) 1000
185 1000 -1000.0 -99.99568287525881 number episode from 10: 185 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.9475) 1000
186 1000 -1000.0 -99.99568287525881 number episode from 10: 186 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.8956) 1000
187 1000 -1000.0 -99.99568287525881 number episode from 10: 187 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.9472) 1000
188 1000 -1000.0 -99.99568287525881 number episode from 10: 188 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.9457) 1000
189 1000 -1000.0 -99.99568287525881 number episode from 10: 189 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.9304) 1000
190 1000 -1000.0 -99.99568287525881 number episode from 10: 190 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.8962) 1000
191 1000 -1000.0 -99.99568287525881 number episode from 10: 191 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.8980) 1000
192 1000 -1000.0 -99.99568287525881 number episode from 10: 192 avegar over 10 episode: -99.991 avegare return across last 100 episodes: -99.996 state values: tensor(0.8978) 1000
193 1000 -1000.0 -99.99568287525881 number episode from 10: 193 avegar over 10 episode: -99.991 avegare return across last 100 episodes: -99.996 state values: tensor(0.8947) 1000
194 1000 -1000.0 -99.99568287525881 number episode from 10: 194 avegar over 10 episode: -99.991 avegare return across last 100 episodes: -99.996 state values: tensor(0.9463) 1000
195 1000 -1000.0 -99.99568287525881 number episode from 10: 195 avegar over 10 episode: -99.991 avegare return across last 100 episodes: -99.996 state values: tensor(0.9351) 1000
196 1000 -1000.0 -99.99568287525881 number episode from 10: 196 avegar over 10 episode: -99.991 avegare return across last 100 episodes: -99.996 state values: tensor(0.9394) 1000
197 1000 -1000.0 -99.99568287525881 number episode from 10: 197 avegar over 10 episode: -99.991 avegare return across last 100 episodes: -99.996 state values: tensor(0.9455) 1000
198 1000 -1000.0 -99.99568287525881 number episode from 10: 198 avegar over 10 episode: -99.991 avegare return across last 100 episodes: -99.996 state values: tensor(0.9470) 1000
199 1000 -1000.0 -99.99568287525881 number episode from 10: 199 avegar over 10 episode: -99.991 avegare return across last 100 episodes: -99.996 state values: tensor(0.9448) 1000
200 1000 -1000.0 -99.99568287525881 number episode from 10: 200 avegar over 10 episode: -99.991 avegare return across last 100 episodes: -99.996 state values: tensor(0.9457) 1000
Start! Seed: 256
0 1001 -1000.0 -98.99572604650622 number episode from 10: 0 avegar over 10 episode: -98.996 avegare return across last 100 episodes: -98.996 state values: tensor(0.8939) 1000
1 1000 -1000.0 -99.99568287525881 number episode from 10: 1 avegar over 10 episode: -99.496 avegare return across last 100 episodes: -99.496 state values: tensor(0.8938) 1000
2 1000 -1000.0 -99.99568287525881 number episode from 10: 2 avegar over 10 episode: -99.662 avegare return across last 100 episodes: -99.662 state values: tensor(0.8939) 1000
3 1000 -1000.0 -99.99568287525881 number episode from 10: 3 avegar over 10 episode: -99.746 avegare return across last 100 episodes: -99.746 state values: tensor(0.8940) 1000
4 1000 -1000.0 -99.99568287525881 number episode from 10: 4 avegar over 10 episode: -99.796 avegare return across last 100 episodes: -99.796 state values: tensor(0.8938) 1000
5 1000 -1000.0 -99.99568287525881 number episode from 10: 5 avegar over 10 episode: -99.829 avegare return across last 100 episodes: -99.829 state values: tensor(0.8939) 1000
6 1000 -1000.0 -99.99568287525881 number episode from 10: 6 avegar over 10 episode: -99.853 avegare return across last 100 episodes: -99.853 state values: tensor(0.8941) 1000
7 1000 -1000.0 -99.99568287525881 number episode from 10: 7 avegar over 10 episode: -99.871 avegare return across last 100 episodes: -99.871 state values: tensor(0.8939) 1000
8 1000 -1000.0 -99.99568287525881 number episode from 10: 8 avegar over 10 episode: -99.885 avegare return across last 100 episodes: -99.885 state values: tensor(0.8940) 1000
9 1000 -1000.0 -99.99568287525881 number episode from 10: 9 avegar over 10 episode: -99.896 avegare return across last 100 episodes: -99.896 state values: tensor(0.8939) 1000
10 1000 -1000.0 -99.99568287525881 number episode from 10: 10 avegar over 10 episode: -99.905 avegare return across last 100 episodes: -99.905 state values: tensor(0.8939) 1000
11 1000 -1000.0 -99.99568287525881 number episode from 10: 11 avegar over 10 episode: -99.912 avegare return across last 100 episodes: -99.912 state values: tensor(0.8909) 1000
12 1000 -1000.0 -99.99568287525881 number episode from 10: 12 avegar over 10 episode: -99.919 avegare return across last 100 episodes: -99.919 state values: tensor(0.8943) 1000
13 1000 -1000.0 -99.99568287525881 number episode from 10: 13 avegar over 10 episode: -99.924 avegare return across last 100 episodes: -99.924 state values: tensor(0.8940) 1000
14 1000 -1000.0 -99.99568287525881 number episode from 10: 14 avegar over 10 episode: -99.929 avegare return across last 100 episodes: -99.929 state values: tensor(0.8929) 1000
15 1000 -1000.0 -99.99568287525881 number episode from 10: 15 avegar over 10 episode: -99.933 avegare return across last 100 episodes: -99.933 state values: tensor(0.8940) 1000
16 1000 -1000.0 -99.99568287525881 number episode from 10: 16 avegar over 10 episode: -99.937 avegare return across last 100 episodes: -99.937 state values: tensor(0.8939) 1000
17 1000 -1000.0 -99.99568287525881 number episode from 10: 17 avegar over 10 episode: -99.94 avegare return across last 100 episodes: -99.94 state values: tensor(0.8939) 1000
18 1000 -1000.0 -99.99568287525881 number episode from 10: 18 avegar over 10 episode: -99.943 avegare return across last 100 episodes: -99.943 state values: tensor(0.8940) 1000
19 1000 -1000.0 -99.99568287525881 number episode from 10: 19 avegar over 10 episode: -99.946 avegare return across last 100 episodes: -99.946 state values: tensor(0.8940) 1000
20 1000 -1000.0 -99.99568287525881 number episode from 10: 20 avegar over 10 episode: -99.948 avegare return across last 100 episodes: -99.948 state values: tensor(0.8940) 1000
21 1000 -1000.0 -99.99568287525881 number episode from 10: 21 avegar over 10 episode: -99.95 avegare return across last 100 episodes: -99.95 state values: tensor(0.8940) 1000
22 1000 -1000.0 -99.99568287525881 number episode from 10: 22 avegar over 10 episode: -99.952 avegare return across last 100 episodes: -99.952 state values: tensor(0.8924) 1000
23 1000 -1000.0 -99.99568287525881 number episode from 10: 23 avegar over 10 episode: -99.954 avegare return across last 100 episodes: -99.954 state values: tensor(0.8940) 1000
24 1000 -1000.0 -99.99568287525881 number episode from 10: 24 avegar over 10 episode: -99.956 avegare return across last 100 episodes: -99.956 state values: tensor(0.8939) 1000
25 1000 -1000.0 -99.99568287525881 number episode from 10: 25 avegar over 10 episode: -99.957 avegare return across last 100 episodes: -99.957 state values: tensor(0.8943) 1000
26 1000 -1000.0 -99.99568287525881 number episode from 10: 26 avegar over 10 episode: -99.959 avegare return across last 100 episodes: -99.959 state values: tensor(0.8940) 1000
27 1000 -1000.0 -99.99568287525881 number episode from 10: 27 avegar over 10 episode: -99.96 avegare return across last 100 episodes: -99.96 state values: tensor(0.8940) 1000
28 1000 -1000.0 -99.99568287525881 number episode from 10: 28 avegar over 10 episode: -99.961 avegare return across last 100 episodes: -99.961 state values: tensor(0.8939) 1000
29 1000 -1000.0 -99.99568287525881 number episode from 10: 29 avegar over 10 episode: -99.962 avegare return across last 100 episodes: -99.962 state values: tensor(0.8919) 1000
30 1000 -1000.0 -99.99568287525881 number episode from 10: 30 avegar over 10 episode: -99.963 avegare return across last 100 episodes: -99.963 state values: tensor(0.8939) 1000
31 1000 -1000.0 -99.99568287525881 number episode from 10: 31 avegar over 10 episode: -99.964 avegare return across last 100 episodes: -99.964 state values: tensor(0.8939) 1000
32 1000 -1000.0 -99.99568287525881 number episode from 10: 32 avegar over 10 episode: -99.965 avegare return across last 100 episodes: -99.965 state values: tensor(0.8880) 1000
33 1000 -1000.0 -99.99568287525881 number episode from 10: 33 avegar over 10 episode: -99.966 avegare return across last 100 episodes: -99.966 state values: tensor(0.8942) 1000
34 1000 -1000.0 -99.99568287525881 number episode from 10: 34 avegar over 10 episode: -99.967 avegare return across last 100 episodes: -99.967 state values: tensor(0.8941) 1000
35 1000 -1000.0 -99.99568287525881 number episode from 10: 35 avegar over 10 episode: -99.968 avegare return across last 100 episodes: -99.968 state values: tensor(0.8938) 1000
36 1000 -1000.0 -99.99568287525881 number episode from 10: 36 avegar over 10 episode: -99.969 avegare return across last 100 episodes: -99.969 state values: tensor(0.8938) 1000
37 1000 -1000.0 -99.99568287525881 number episode from 10: 37 avegar over 10 episode: -99.969 avegare return across last 100 episodes: -99.969 state values: tensor(0.8897) 1000
38 1000 -1000.0 -99.99568287525881 number episode from 10: 38 avegar over 10 episode: -99.97 avegare return across last 100 episodes: -99.97 state values: tensor(0.8942) 1000
39 1000 -1000.0 -99.99568287525881 number episode from 10: 39 avegar over 10 episode: -99.971 avegare return across last 100 episodes: -99.971 state values: tensor(0.8944) 1000
40 1000 -1000.0 -99.99568287525881 number episode from 10: 40 avegar over 10 episode: -99.971 avegare return across last 100 episodes: -99.971 state values: tensor(0.8939) 1000
41 1000 -1000.0 -99.99568287525881 number episode from 10: 41 avegar over 10 episode: -99.972 avegare return across last 100 episodes: -99.972 state values: tensor(0.8940) 1000
42 1000 -1000.0 -99.99568287525881 number episode from 10: 42 avegar over 10 episode: -99.972 avegare return across last 100 episodes: -99.972 state values: tensor(0.8940) 1000
43 1000 -1000.0 -99.99568287525881 number episode from 10: 43 avegar over 10 episode: -99.973 avegare return across last 100 episodes: -99.973 state values: tensor(0.8943) 1000
44 1000 -1000.0 -99.99568287525881 number episode from 10: 44 avegar over 10 episode: -99.973 avegare return across last 100 episodes: -99.973 state values: tensor(0.8938) 1000
45 1000 -1000.0 -99.99568287525881 number episode from 10: 45 avegar over 10 episode: -99.974 avegare return across last 100 episodes: -99.974 state values: tensor(0.8929) 1000
46 1000 -1000.0 -99.99568287525881 number episode from 10: 46 avegar over 10 episode: -99.974 avegare return across last 100 episodes: -99.974 state values: tensor(0.8940) 1000
47 1000 -1000.0 -99.99568287525881 number episode from 10: 47 avegar over 10 episode: -99.975 avegare return across last 100 episodes: -99.975 state values: tensor(0.8939) 1000
48 1000 -1000.0 -99.99568287525881 number episode from 10: 48 avegar over 10 episode: -99.975 avegare return across last 100 episodes: -99.975 state values: tensor(0.8939) 1000
49 1000 -1000.0 -99.99568287525881 number episode from 10: 49 avegar over 10 episode: -99.976 avegare return across last 100 episodes: -99.976 state values: tensor(0.8939) 1000
50 1000 -1000.0 -99.99568287525881 number episode from 10: 50 avegar over 10 episode: -99.976 avegare return across last 100 episodes: -99.976 state values: tensor(0.8942) 1000
51 1000 -1000.0 -99.99568287525881 number episode from 10: 51 avegar over 10 episode: -99.976 avegare return across last 100 episodes: -99.976 state values: tensor(0.8939) 1000
52 1000 -1000.0 -99.99568287525881 number episode from 10: 52 avegar over 10 episode: -99.977 avegare return across last 100 episodes: -99.977 state values: tensor(0.8929) 1000
53 1000 -1000.0 -99.99568287525881 number episode from 10: 53 avegar over 10 episode: -99.977 avegare return across last 100 episodes: -99.977 state values: tensor(0.8918) 1000
54 1000 -1000.0 -99.99568287525881 number episode from 10: 54 avegar over 10 episode: -99.978 avegare return across last 100 episodes: -99.978 state values: tensor(0.8925) 1000
55 1000 -1000.0 -99.99568287525881 number episode from 10: 55 avegar over 10 episode: -99.978 avegare return across last 100 episodes: -99.978 state values: tensor(0.8941) 1000
56 1000 -1000.0 -99.99568287525881 number episode from 10: 56 avegar over 10 episode: -99.978 avegare return across last 100 episodes: -99.978 state values: tensor(0.8928) 1000
57 1000 -1000.0 -99.99568287525881 number episode from 10: 57 avegar over 10 episode: -99.978 avegare return across last 100 episodes: -99.978 state values: tensor(0.8931) 1000
58 1000 -1000.0 -99.99568287525881 number episode from 10: 58 avegar over 10 episode: -99.979 avegare return across last 100 episodes: -99.979 state values: tensor(0.8940) 1000
59 1000 -1000.0 -99.99568287525881 number episode from 10: 59 avegar over 10 episode: -99.979 avegare return across last 100 episodes: -99.979 state values: tensor(0.8939) 1000
60 1000 -1000.0 -99.99568287525881 number episode from 10: 60 avegar over 10 episode: -99.979 avegare return across last 100 episodes: -99.979 state values: tensor(0.8941) 1000
61 1000 -1000.0 -99.99568287525881 number episode from 10: 61 avegar over 10 episode: -99.98 avegare return across last 100 episodes: -99.98 state values: tensor(0.8939) 1000
62 1000 -1000.0 -99.99568287525881 number episode from 10: 62 avegar over 10 episode: -99.98 avegare return across last 100 episodes: -99.98 state values: tensor(0.8908) 1000
63 1000 -1000.0 -99.99568287525881 number episode from 10: 63 avegar over 10 episode: -99.98 avegare return across last 100 episodes: -99.98 state values: tensor(0.8939) 1000
64 1000 -1000.0 -99.99568287525881 number episode from 10: 64 avegar over 10 episode: -99.98 avegare return across last 100 episodes: -99.98 state values: tensor(0.8929) 1000
65 1000 -1000.0 -99.99568287525881 number episode from 10: 65 avegar over 10 episode: -99.981 avegare return across last 100 episodes: -99.981 state values: tensor(0.8941) 1000
66 1000 -1000.0 -99.99568287525881 number episode from 10: 66 avegar over 10 episode: -99.981 avegare return across last 100 episodes: -99.981 state values: tensor(0.8939) 1000
67 1000 -1000.0 -99.99568287525881 number episode from 10: 67 avegar over 10 episode: -99.981 avegare return across last 100 episodes: -99.981 state values: tensor(0.8940) 1000
68 1000 -1000.0 -99.99568287525881 number episode from 10: 68 avegar over 10 episode: -99.981 avegare return across last 100 episodes: -99.981 state values: tensor(0.8915) 1000
69 1000 -1000.0 -99.99568287525881 number episode from 10: 69 avegar over 10 episode: -99.981 avegare return across last 100 episodes: -99.981 state values: tensor(0.8939) 1000
70 1000 -1000.0 -99.99568287525881 number episode from 10: 70 avegar over 10 episode: -99.982 avegare return across last 100 episodes: -99.982 state values: tensor(0.8940) 1000
71 1000 -1000.0 -99.99568287525881 number episode from 10: 71 avegar over 10 episode: -99.982 avegare return across last 100 episodes: -99.982 state values: tensor(0.8940) 1000
72 1000 -1000.0 -99.99568287525881 number episode from 10: 72 avegar over 10 episode: -99.982 avegare return across last 100 episodes: -99.982 state values: tensor(0.8941) 1000
73 1000 -1000.0 -99.99568287525881 number episode from 10: 73 avegar over 10 episode: -99.982 avegare return across last 100 episodes: -99.982 state values: tensor(0.8941) 1000
74 1000 -1000.0 -99.99568287525881 number episode from 10: 74 avegar over 10 episode: -99.982 avegare return across last 100 episodes: -99.982 state values: tensor(0.8941) 1000
75 1000 -1000.0 -99.99568287525881 number episode from 10: 75 avegar over 10 episode: -99.983 avegare return across last 100 episodes: -99.983 state values: tensor(0.8941) 1000
76 1000 -1000.0 -99.99568287525881 number episode from 10: 76 avegar over 10 episode: -99.983 avegare return across last 100 episodes: -99.983 state values: tensor(0.8934) 1000
77 1000 -1000.0 -99.99568287525881 number episode from 10: 77 avegar over 10 episode: -99.983 avegare return across last 100 episodes: -99.983 state values: tensor(0.8941) 1000
78 1000 -1000.0 -99.99568287525881 number episode from 10: 78 avegar over 10 episode: -99.983 avegare return across last 100 episodes: -99.983 state values: tensor(0.8941) 1000
79 1000 -1000.0 -99.99568287525881 number episode from 10: 79 avegar over 10 episode: -99.983 avegare return across last 100 episodes: -99.983 state values: tensor(0.8940) 1000
80 1000 -1000.0 -99.99568287525881 number episode from 10: 80 avegar over 10 episode: -99.983 avegare return across last 100 episodes: -99.983 state values: tensor(0.8940) 1000
81 1000 -1000.0 -99.99568287525881 number episode from 10: 81 avegar over 10 episode: -99.983 avegare return across last 100 episodes: -99.983 state values: tensor(0.8939) 1000
82 1000 -1000.0 -99.99568287525881 number episode from 10: 82 avegar over 10 episode: -99.984 avegare return across last 100 episodes: -99.984 state values: tensor(0.8941) 1000
83 1000 -1000.0 -99.99568287525881 number episode from 10: 83 avegar over 10 episode: -99.984 avegare return across last 100 episodes: -99.984 state values: tensor(0.8930) 1000
84 1000 -1000.0 -99.99568287525881 number episode from 10: 84 avegar over 10 episode: -99.984 avegare return across last 100 episodes: -99.984 state values: tensor(0.8942) 1000
85 1000 -1000.0 -99.99568287525881 number episode from 10: 85 avegar over 10 episode: -99.984 avegare return across last 100 episodes: -99.984 state values: tensor(0.8931) 1000
86 1000 -1000.0 -99.99568287525881 number episode from 10: 86 avegar over 10 episode: -99.984 avegare return across last 100 episodes: -99.984 state values: tensor(0.8939) 1000
87 1000 -1000.0 -99.99568287525881 number episode from 10: 87 avegar over 10 episode: -99.984 avegare return across last 100 episodes: -99.984 state values: tensor(0.8941) 1000
88 1000 -1000.0 -99.99568287525881 number episode from 10: 88 avegar over 10 episode: -99.984 avegare return across last 100 episodes: -99.984 state values: tensor(0.8940) 1000
89 1000 -1000.0 -99.99568287525881 number episode from 10: 89 avegar over 10 episode: -99.985 avegare return across last 100 episodes: -99.985 state values: tensor(0.8939) 1000
90 1000 -1000.0 -99.99568287525881 number episode from 10: 90 avegar over 10 episode: -99.985 avegare return across last 100 episodes: -99.985 state values: tensor(0.8940) 1000
91 1000 -1000.0 -99.99568287525881 number episode from 10: 91 avegar over 10 episode: -99.985 avegare return across last 100 episodes: -99.985 state values: tensor(0.8941) 1000
92 1000 -1000.0 -99.99568287525881 number episode from 10: 92 avegar over 10 episode: -99.985 avegare return across last 100 episodes: -99.985 state values: tensor(0.8940) 1000
93 1000 -1000.0 -99.99568287525881 number episode from 10: 93 avegar over 10 episode: -99.985 avegare return across last 100 episodes: -99.985 state values: tensor(0.8940) 1000
94 1000 -1000.0 -99.99568287525881 number episode from 10: 94 avegar over 10 episode: -99.985 avegare return across last 100 episodes: -99.985 state values: tensor(0.8942) 1000
95 1000 -1000.0 -99.99568287525881 number episode from 10: 95 avegar over 10 episode: -99.985 avegare return across last 100 episodes: -99.985 state values: tensor(0.8939) 1000
96 1000 -1000.0 -99.99568287525881 number episode from 10: 96 avegar over 10 episode: -99.985 avegare return across last 100 episodes: -99.985 state values: tensor(0.8882) 1000
97 1000 -1000.0 -99.99568287525881 number episode from 10: 97 avegar over 10 episode: -99.985 avegare return across last 100 episodes: -99.985 state values: tensor(0.8940) 1000
98 1000 -1000.0 -99.99568287525881 number episode from 10: 98 avegar over 10 episode: -99.986 avegare return across last 100 episodes: -99.986 state values: tensor(0.8941) 1000
99 1000 -1000.0 -99.99568287525881 number episode from 10: 99 avegar over 10 episode: -99.986 avegare return across last 100 episodes: -99.986 state values: tensor(0.8940) 1000
100 1000 -1000.0 -99.99568287525881 number episode from 10: 100 avegar over 10 episode: -99.986 avegare return across last 100 episodes: -99.996 state values: tensor(0.8939) 1000
101 1000 -1000.0 -99.99568287525881 number episode from 10: 101 avegar over 10 episode: -99.986 avegare return across last 100 episodes: -99.996 state values: tensor(0.8940) 1000
102 1000 -1000.0 -99.99568287525881 number episode from 10: 102 avegar over 10 episode: -99.986 avegare return across last 100 episodes: -99.996 state values: tensor(0.8941) 1000
103 1000 -1000.0 -99.99568287525881 number episode from 10: 103 avegar over 10 episode: -99.986 avegare return across last 100 episodes: -99.996 state values: tensor(0.8940) 1000
104 1000 -1000.0 -99.99568287525881 number episode from 10: 104 avegar over 10 episode: -99.986 avegare return across last 100 episodes: -99.996 state values: tensor(0.8941) 1000
105 1000 -1000.0 -99.99568287525881 number episode from 10: 105 avegar over 10 episode: -99.986 avegare return across last 100 episodes: -99.996 state values: tensor(0.8942) 1000
106 1000 -1000.0 -99.99568287525881 number episode from 10: 106 avegar over 10 episode: -99.986 avegare return across last 100 episodes: -99.996 state values: tensor(0.8940) 1000
107 1000 -1000.0 -99.99568287525881 number episode from 10: 107 avegar over 10 episode: -99.986 avegare return across last 100 episodes: -99.996 state values: tensor(0.8941) 1000
108 1000 -1000.0 -99.99568287525881 number episode from 10: 108 avegar over 10 episode: -99.987 avegare return across last 100 episodes: -99.996 state values: tensor(0.8939) 1000
109 1000 -1000.0 -99.99568287525881 number episode from 10: 109 avegar over 10 episode: -99.987 avegare return across last 100 episodes: -99.996 state values: tensor(0.8939) 1000
110 1000 -1000.0 -99.99568287525881 number episode from 10: 110 avegar over 10 episode: -99.987 avegare return across last 100 episodes: -99.996 state values: tensor(0.8929) 1000
111 1000 -1000.0 -99.99568287525881 number episode from 10: 111 avegar over 10 episode: -99.987 avegare return across last 100 episodes: -99.996 state values: tensor(0.8899) 1000
112 1000 -1000.0 -99.99568287525881 number episode from 10: 112 avegar over 10 episode: -99.987 avegare return across last 100 episodes: -99.996 state values: tensor(0.8940) 1000
113 1000 -1000.0 -99.99568287525881 number episode from 10: 113 avegar over 10 episode: -99.987 avegare return across last 100 episodes: -99.996 state values: tensor(0.8941) 1000
114 1000 -1000.0 -99.99568287525881 number episode from 10: 114 avegar over 10 episode: -99.987 avegare return across last 100 episodes: -99.996 state values: tensor(0.8915) 1000
115 1000 -1000.0 -99.99568287525881 number episode from 10: 115 avegar over 10 episode: -99.987 avegare return across last 100 episodes: -99.996 state values: tensor(0.8940) 1000
116 1000 -1000.0 -99.99568287525881 number episode from 10: 116 avegar over 10 episode: -99.987 avegare return across last 100 episodes: -99.996 state values: tensor(0.8904) 1000
117 1000 -1000.0 -99.99568287525881 number episode from 10: 117 avegar over 10 episode: -99.987 avegare return across last 100 episodes: -99.996 state values: tensor(0.8942) 1000
118 1000 -1000.0 -99.99568287525881 number episode from 10: 118 avegar over 10 episode: -99.987 avegare return across last 100 episodes: -99.996 state values: tensor(0.8939) 1000
119 1000 -1000.0 -99.99568287525881 number episode from 10: 119 avegar over 10 episode: -99.987 avegare return across last 100 episodes: -99.996 state values: tensor(0.8939) 1000
120 1000 -1000.0 -99.99568287525881 number episode from 10: 120 avegar over 10 episode: -99.987 avegare return across last 100 episodes: -99.996 state values: tensor(0.8908) 1000
121 1000 -1000.0 -99.99568287525881 number episode from 10: 121 avegar over 10 episode: -99.987 avegare return across last 100 episodes: -99.996 state values: tensor(0.8941) 1000
122 1000 -1000.0 -99.99568287525881 number episode from 10: 122 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.8912) 1000
123 1000 -1000.0 -99.99568287525881 number episode from 10: 123 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.8925) 1000
124 1000 -1000.0 -99.99568287525881 number episode from 10: 124 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.8939) 1000
125 1000 -1000.0 -99.99568287525881 number episode from 10: 125 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.8939) 1000
126 1000 -1000.0 -99.99568287525881 number episode from 10: 126 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.8940) 1000
127 1000 -1000.0 -99.99568287525881 number episode from 10: 127 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.8939) 1000
128 1000 -1000.0 -99.99568287525881 number episode from 10: 128 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.8941) 1000
129 1000 -1000.0 -99.99568287525881 number episode from 10: 129 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.8943) 1000
130 1000 -1000.0 -99.99568287525881 number episode from 10: 130 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.8939) 1000
131 1000 -1000.0 -99.99568287525881 number episode from 10: 131 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.8918) 1000
132 1000 -1000.0 -99.99568287525881 number episode from 10: 132 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.8942) 1000
133 1000 -1000.0 -99.99568287525881 number episode from 10: 133 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.8938) 1000
134 1000 -1000.0 -99.99568287525881 number episode from 10: 134 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.8939) 1000
135 1000 -1000.0 -99.99568287525881 number episode from 10: 135 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.8940) 1000
136 1000 -1000.0 -99.99568287525881 number episode from 10: 136 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.8938) 1000
137 1000 -1000.0 -99.99568287525881 number episode from 10: 137 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.8934) 1000
138 1000 -1000.0 -99.99568287525881 number episode from 10: 138 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.8940) 1000
139 1000 -1000.0 -99.99568287525881 number episode from 10: 139 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.8913) 1000
140 1000 -1000.0 -99.99568287525881 number episode from 10: 140 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.8940) 1000
141 1000 -1000.0 -99.99568287525881 number episode from 10: 141 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.8943) 1000
142 1000 -1000.0 -99.99568287525881 number episode from 10: 142 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.8920) 1000
143 1000 -1000.0 -99.99568287525881 number episode from 10: 143 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.8939) 1000
144 1000 -1000.0 -99.99568287525881 number episode from 10: 144 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.8941) 1000
145 1000 -1000.0 -99.99568287525881 number episode from 10: 145 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.8903) 1000
146 1000 -1000.0 -99.99568287525881 number episode from 10: 146 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.8942) 1000
147 1000 -1000.0 -99.99568287525881 number episode from 10: 147 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.8939) 1000
148 1000 -1000.0 -99.99568287525881 number episode from 10: 148 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.8941) 1000
149 1000 -1000.0 -99.99568287525881 number episode from 10: 149 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.8939) 1000
150 1000 -1000.0 -99.99568287525881 number episode from 10: 150 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.8940) 1000
151 1000 -1000.0 -99.99568287525881 number episode from 10: 151 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.8882) 1000
152 1000 -1000.0 -99.99568287525881 number episode from 10: 152 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.8942) 1000
153 1000 -1000.0 -99.99568287525881 number episode from 10: 153 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.8942) 1000
154 1000 -1000.0 -99.99568287525881 number episode from 10: 154 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.8939) 1000
155 1000 -1000.0 -99.99568287525881 number episode from 10: 155 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.8940) 1000
156 1000 -1000.0 -99.99568287525881 number episode from 10: 156 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.8940) 1000
157 1000 -1000.0 -99.99568287525881 number episode from 10: 157 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.8939) 1000
158 1000 -1000.0 -99.99568287525881 number episode from 10: 158 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.8941) 1000
159 1000 -1000.0 -99.99568287525881 number episode from 10: 159 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.8939) 1000
160 1000 -1000.0 -99.99568287525881 number episode from 10: 160 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.8939) 1000
161 1000 -1000.0 -99.99568287525881 number episode from 10: 161 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.8940) 1000
162 1000 -1000.0 -99.99568287525881 number episode from 10: 162 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.8941) 1000
163 1000 -1000.0 -99.99568287525881 number episode from 10: 163 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.8939) 1000
164 1000 -1000.0 -99.99568287525881 number episode from 10: 164 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.8940) 1000
165 1000 -1000.0 -99.99568287525881 number episode from 10: 165 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.8939) 1000
166 1000 -1000.0 -99.99568287525881 number episode from 10: 166 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.8941) 1000
167 1000 -1000.0 -99.99568287525881 number episode from 10: 167 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.8930) 1000
168 1000 -1000.0 -99.99568287525881 number episode from 10: 168 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.8940) 1000
169 1000 -1000.0 -99.99568287525881 number episode from 10: 169 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.8940) 1000
170 1000 -1000.0 -99.99568287525881 number episode from 10: 170 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.8900) 1000
171 1000 -1000.0 -99.99568287525881 number episode from 10: 171 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.8940) 1000
172 1000 -1000.0 -99.99568287525881 number episode from 10: 172 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.8940) 1000
173 1000 -1000.0 -99.99568287525881 number episode from 10: 173 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.8939) 1000
174 1000 -1000.0 -99.99568287525881 number episode from 10: 174 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.8940) 1000
175 1000 -1000.0 -99.99568287525881 number episode from 10: 175 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.8938) 1000
176 1000 -1000.0 -99.99568287525881 number episode from 10: 176 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.8941) 1000
177 1000 -1000.0 -99.99568287525881 number episode from 10: 177 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.8938) 1000
178 1000 -1000.0 -99.99568287525881 number episode from 10: 178 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.8939) 1000
179 1000 -1000.0 -99.99568287525881 number episode from 10: 179 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.8939) 1000
180 1000 -1000.0 -99.99568287525881 number episode from 10: 180 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.8940) 1000
181 1000 -1000.0 -99.99568287525881 number episode from 10: 181 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.8941) 1000
182 1000 -1000.0 -99.99568287525881 number episode from 10: 182 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.8923) 1000
183 1000 -1000.0 -99.99568287525881 number episode from 10: 183 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.8881) 1000
184 1000 -1000.0 -99.99568287525881 number episode from 10: 184 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.8889) 1000
185 1000 -1000.0 -99.99568287525881 number episode from 10: 185 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.8939) 1000
186 1000 -1000.0 -99.99568287525881 number episode from 10: 186 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.8940) 1000
187 1000 -1000.0 -99.99568287525881 number episode from 10: 187 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.8942) 1000
188 1000 -1000.0 -99.99568287525881 number episode from 10: 188 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.8880) 1000
189 1000 -1000.0 -99.99568287525881 number episode from 10: 189 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.8940) 1000
190 1000 -1000.0 -99.99568287525881 number episode from 10: 190 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.8942) 1000
191 1000 -1000.0 -99.99568287525881 number episode from 10: 191 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.8943) 1000
192 1000 -1000.0 -99.99568287525881 number episode from 10: 192 avegar over 10 episode: -99.991 avegare return across last 100 episodes: -99.996 state values: tensor(0.8881) 1000
193 1000 -1000.0 -99.99568287525881 number episode from 10: 193 avegar over 10 episode: -99.991 avegare return across last 100 episodes: -99.996 state values: tensor(0.8941) 1000
194 1000 -1000.0 -99.99568287525881 number episode from 10: 194 avegar over 10 episode: -99.991 avegare return across last 100 episodes: -99.996 state values: tensor(0.8906) 1000
195 1000 -1000.0 -99.99568287525881 number episode from 10: 195 avegar over 10 episode: -99.991 avegare return across last 100 episodes: -99.996 state values: tensor(0.8941) 1000
196 1000 -1000.0 -99.99568287525881 number episode from 10: 196 avegar over 10 episode: -99.991 avegare return across last 100 episodes: -99.996 state values: tensor(0.8938) 1000
197 1000 -1000.0 -99.99568287525881 number episode from 10: 197 avegar over 10 episode: -99.991 avegare return across last 100 episodes: -99.996 state values: tensor(0.8939) 1000
198 1000 -1000.0 -99.99568287525881 number episode from 10: 198 avegar over 10 episode: -99.991 avegare return across last 100 episodes: -99.996 state values: tensor(0.8944) 1000
199 1000 -1000.0 -99.99568287525881 number episode from 10: 199 avegar over 10 episode: -99.991 avegare return across last 100 episodes: -99.996 state values: tensor(0.8943) 1000
200 1000 -1000.0 -99.99568287525881 number episode from 10: 200 avegar over 10 episode: -99.991 avegare return across last 100 episodes: -99.996 state values: tensor(0.8940) 1000
Start! Seed: 288
0 1001 -1000.0 -98.99572604650622 number episode from 10: 0 avegar over 10 episode: -98.996 avegare return across last 100 episodes: -98.996 state values: tensor(0.6733) 1000
1 1000 -1000.0 -99.99568287525881 number episode from 10: 1 avegar over 10 episode: -99.496 avegare return across last 100 episodes: -99.496 state values: tensor(0.6755) 1000
2 1000 -1000.0 -99.99568287525881 number episode from 10: 2 avegar over 10 episode: -99.662 avegare return across last 100 episodes: -99.662 state values: tensor(0.6803) 1000
3 1000 -1000.0 -99.99568287525881 number episode from 10: 3 avegar over 10 episode: -99.746 avegare return across last 100 episodes: -99.746 state values: tensor(0.6787) 1000
4 1000 -1000.0 -99.99568287525881 number episode from 10: 4 avegar over 10 episode: -99.796 avegare return across last 100 episodes: -99.796 state values: tensor(0.6735) 1000
5 1000 -1000.0 -99.99568287525881 number episode from 10: 5 avegar over 10 episode: -99.829 avegare return across last 100 episodes: -99.829 state values: tensor(0.6732) 1000
6 1000 -1000.0 -99.99568287525881 number episode from 10: 6 avegar over 10 episode: -99.853 avegare return across last 100 episodes: -99.853 state values: tensor(0.6742) 1000
7 1000 -1000.0 -99.99568287525881 number episode from 10: 7 avegar over 10 episode: -99.871 avegare return across last 100 episodes: -99.871 state values: tensor(0.6797) 1000
8 1000 -1000.0 -99.99568287525881 number episode from 10: 8 avegar over 10 episode: -99.885 avegare return across last 100 episodes: -99.885 state values: tensor(0.6742) 1000
9 1000 -1000.0 -99.99568287525881 number episode from 10: 9 avegar over 10 episode: -99.896 avegare return across last 100 episodes: -99.896 state values: tensor(0.6747) 1000
10 1000 -1000.0 -99.99568287525881 number episode from 10: 10 avegar over 10 episode: -99.905 avegare return across last 100 episodes: -99.905 state values: tensor(0.6734) 1000
11 1000 -1000.0 -99.99568287525881 number episode from 10: 11 avegar over 10 episode: -99.912 avegare return across last 100 episodes: -99.912 state values: tensor(0.6762) 1000
12 1000 -1000.0 -99.99568287525881 number episode from 10: 12 avegar over 10 episode: -99.919 avegare return across last 100 episodes: -99.919 state values: tensor(0.6745) 1000
13 1000 -1000.0 -99.99568287525881 number episode from 10: 13 avegar over 10 episode: -99.924 avegare return across last 100 episodes: -99.924 state values: tensor(0.6764) 1000
14 1000 -1000.0 -99.99568287525881 number episode from 10: 14 avegar over 10 episode: -99.929 avegare return across last 100 episodes: -99.929 state values: tensor(0.6751) 1000
15 1000 -1000.0 -99.99568287525881 number episode from 10: 15 avegar over 10 episode: -99.933 avegare return across last 100 episodes: -99.933 state values: tensor(0.6756) 1000
16 1000 -1000.0 -99.99568287525881 number episode from 10: 16 avegar over 10 episode: -99.937 avegare return across last 100 episodes: -99.937 state values: tensor(0.6768) 1000
17 1000 -1000.0 -99.99568287525881 number episode from 10: 17 avegar over 10 episode: -99.94 avegare return across last 100 episodes: -99.94 state values: tensor(0.6742) 1000
18 1000 -1000.0 -99.99568287525881 number episode from 10: 18 avegar over 10 episode: -99.943 avegare return across last 100 episodes: -99.943 state values: tensor(0.6803) 1000
19 1000 -1000.0 -99.99568287525881 number episode from 10: 19 avegar over 10 episode: -99.946 avegare return across last 100 episodes: -99.946 state values: tensor(0.6807) 1000
20 1000 -1000.0 -99.99568287525881 number episode from 10: 20 avegar over 10 episode: -99.948 avegare return across last 100 episodes: -99.948 state values: tensor(0.6765) 1000
21 1000 -1000.0 -99.99568287525881 number episode from 10: 21 avegar over 10 episode: -99.95 avegare return across last 100 episodes: -99.95 state values: tensor(0.6737) 1000
22 1000 -1000.0 -99.99568287525881 number episode from 10: 22 avegar over 10 episode: -99.952 avegare return across last 100 episodes: -99.952 state values: tensor(0.6737) 1000
23 1000 -1000.0 -99.99568287525881 number episode from 10: 23 avegar over 10 episode: -99.954 avegare return across last 100 episodes: -99.954 state values: tensor(0.6772) 1000
24 1000 -1000.0 -99.99568287525881 number episode from 10: 24 avegar over 10 episode: -99.956 avegare return across last 100 episodes: -99.956 state values: tensor(0.6781) 1000
25 1000 -1000.0 -99.99568287525881 number episode from 10: 25 avegar over 10 episode: -99.957 avegare return across last 100 episodes: -99.957 state values: tensor(0.6782) 1000
26 1000 -1000.0 -99.99568287525881 number episode from 10: 26 avegar over 10 episode: -99.959 avegare return across last 100 episodes: -99.959 state values: tensor(0.6740) 1000
27 1000 -1000.0 -99.99568287525881 number episode from 10: 27 avegar over 10 episode: -99.96 avegare return across last 100 episodes: -99.96 state values: tensor(0.6765) 1000
28 1000 -1000.0 -99.99568287525881 number episode from 10: 28 avegar over 10 episode: -99.961 avegare return across last 100 episodes: -99.961 state values: tensor(0.6746) 1000
29 1000 -1000.0 -99.99568287525881 number episode from 10: 29 avegar over 10 episode: -99.962 avegare return across last 100 episodes: -99.962 state values: tensor(0.6815) 1000
30 1000 -1000.0 -99.99568287525881 number episode from 10: 30 avegar over 10 episode: -99.963 avegare return across last 100 episodes: -99.963 state values: tensor(0.6733) 1000
31 1000 -1000.0 -99.99568287525881 number episode from 10: 31 avegar over 10 episode: -99.964 avegare return across last 100 episodes: -99.964 state values: tensor(0.6787) 1000
32 1000 -1000.0 -99.99568287525881 number episode from 10: 32 avegar over 10 episode: -99.965 avegare return across last 100 episodes: -99.965 state values: tensor(0.6751) 1000
33 1000 -1000.0 -99.99568287525881 number episode from 10: 33 avegar over 10 episode: -99.966 avegare return across last 100 episodes: -99.966 state values: tensor(0.6733) 1000
34 1000 -1000.0 -99.99568287525881 number episode from 10: 34 avegar over 10 episode: -99.967 avegare return across last 100 episodes: -99.967 state values: tensor(0.6736) 1000
35 1000 -1000.0 -99.99568287525881 number episode from 10: 35 avegar over 10 episode: -99.968 avegare return across last 100 episodes: -99.968 state values: tensor(0.6758) 1000
36 1000 -1000.0 -99.99568287525881 number episode from 10: 36 avegar over 10 episode: -99.969 avegare return across last 100 episodes: -99.969 state values: tensor(0.6806) 1000
37 1000 -1000.0 -99.99568287525881 number episode from 10: 37 avegar over 10 episode: -99.969 avegare return across last 100 episodes: -99.969 state values: tensor(0.6733) 1000
38 1000 -1000.0 -99.99568287525881 number episode from 10: 38 avegar over 10 episode: -99.97 avegare return across last 100 episodes: -99.97 state values: tensor(0.6733) 1000
39 1000 -1000.0 -99.99568287525881 number episode from 10: 39 avegar over 10 episode: -99.971 avegare return across last 100 episodes: -99.971 state values: tensor(0.6738) 1000
40 1000 -1000.0 -99.99568287525881 number episode from 10: 40 avegar over 10 episode: -99.971 avegare return across last 100 episodes: -99.971 state values: tensor(0.6778) 1000
41 1000 -1000.0 -99.99568287525881 number episode from 10: 41 avegar over 10 episode: -99.972 avegare return across last 100 episodes: -99.972 state values: tensor(0.6734) 1000
42 1000 -1000.0 -99.99568287525881 number episode from 10: 42 avegar over 10 episode: -99.972 avegare return across last 100 episodes: -99.972 state values: tensor(0.6738) 1000
43 1000 -1000.0 -99.99568287525881 number episode from 10: 43 avegar over 10 episode: -99.973 avegare return across last 100 episodes: -99.973 state values: tensor(0.6732) 1000
44 1000 -1000.0 -99.99568287525881 number episode from 10: 44 avegar over 10 episode: -99.973 avegare return across last 100 episodes: -99.973 state values: tensor(0.6732) 1000
45 1000 -1000.0 -99.99568287525881 number episode from 10: 45 avegar over 10 episode: -99.974 avegare return across last 100 episodes: -99.974 state values: tensor(0.6755) 1000
46 1000 -1000.0 -99.99568287525881 number episode from 10: 46 avegar over 10 episode: -99.974 avegare return across last 100 episodes: -99.974 state values: tensor(0.6732) 1000
47 1000 -1000.0 -99.99568287525881 number episode from 10: 47 avegar over 10 episode: -99.975 avegare return across last 100 episodes: -99.975 state values: tensor(0.6735) 1000
48 1000 -1000.0 -99.99568287525881 number episode from 10: 48 avegar over 10 episode: -99.975 avegare return across last 100 episodes: -99.975 state values: tensor(0.6744) 1000
49 1000 -1000.0 -99.99568287525881 number episode from 10: 49 avegar over 10 episode: -99.976 avegare return across last 100 episodes: -99.976 state values: tensor(0.6735) 1000
50 1000 -1000.0 -99.99568287525881 number episode from 10: 50 avegar over 10 episode: -99.976 avegare return across last 100 episodes: -99.976 state values: tensor(0.6733) 1000
51 1000 -1000.0 -99.99568287525881 number episode from 10: 51 avegar over 10 episode: -99.976 avegare return across last 100 episodes: -99.976 state values: tensor(0.6767) 1000
52 1000 -1000.0 -99.99568287525881 number episode from 10: 52 avegar over 10 episode: -99.977 avegare return across last 100 episodes: -99.977 state values: tensor(0.6737) 1000
53 1000 -1000.0 -99.99568287525881 number episode from 10: 53 avegar over 10 episode: -99.977 avegare return across last 100 episodes: -99.977 state values: tensor(0.6736) 1000
54 1000 -1000.0 -99.99568287525881 number episode from 10: 54 avegar over 10 episode: -99.978 avegare return across last 100 episodes: -99.978 state values: tensor(0.6766) 1000
55 1000 -1000.0 -99.99568287525881 number episode from 10: 55 avegar over 10 episode: -99.978 avegare return across last 100 episodes: -99.978 state values: tensor(0.6734) 1000
56 1000 -1000.0 -99.99568287525881 number episode from 10: 56 avegar over 10 episode: -99.978 avegare return across last 100 episodes: -99.978 state values: tensor(0.6736) 1000
57 1000 -1000.0 -99.99568287525881 number episode from 10: 57 avegar over 10 episode: -99.978 avegare return across last 100 episodes: -99.978 state values: tensor(0.6803) 1000
58 1000 -1000.0 -99.99568287525881 number episode from 10: 58 avegar over 10 episode: -99.979 avegare return across last 100 episodes: -99.979 state values: tensor(0.6800) 1000
59 1000 -1000.0 -99.99568287525881 number episode from 10: 59 avegar over 10 episode: -99.979 avegare return across last 100 episodes: -99.979 state values: tensor(0.6808) 1000
60 1000 -1000.0 -99.99568287525881 number episode from 10: 60 avegar over 10 episode: -99.979 avegare return across last 100 episodes: -99.979 state values: tensor(0.6735) 1000
61 1000 -1000.0 -99.99568287525881 number episode from 10: 61 avegar over 10 episode: -99.98 avegare return across last 100 episodes: -99.98 state values: tensor(0.6743) 1000
62 1000 -1000.0 -99.99568287525881 number episode from 10: 62 avegar over 10 episode: -99.98 avegare return across last 100 episodes: -99.98 state values: tensor(0.6733) 1000
63 1000 -1000.0 -99.99568287525881 number episode from 10: 63 avegar over 10 episode: -99.98 avegare return across last 100 episodes: -99.98 state values: tensor(0.6767) 1000
64 1000 -1000.0 -99.99568287525881 number episode from 10: 64 avegar over 10 episode: -99.98 avegare return across last 100 episodes: -99.98 state values: tensor(0.6743) 1000
65 1000 -1000.0 -99.99568287525881 number episode from 10: 65 avegar over 10 episode: -99.981 avegare return across last 100 episodes: -99.981 state values: tensor(0.6785) 1000
66 1000 -1000.0 -99.99568287525881 number episode from 10: 66 avegar over 10 episode: -99.981 avegare return across last 100 episodes: -99.981 state values: tensor(0.6804) 1000
67 1000 -1000.0 -99.99568287525881 number episode from 10: 67 avegar over 10 episode: -99.981 avegare return across last 100 episodes: -99.981 state values: tensor(0.6737) 1000
68 1000 -1000.0 -99.99568287525881 number episode from 10: 68 avegar over 10 episode: -99.981 avegare return across last 100 episodes: -99.981 state values: tensor(0.6760) 1000
69 1000 -1000.0 -99.99568287525881 number episode from 10: 69 avegar over 10 episode: -99.981 avegare return across last 100 episodes: -99.981 state values: tensor(0.6737) 1000
70 1000 -1000.0 -99.99568287525881 number episode from 10: 70 avegar over 10 episode: -99.982 avegare return across last 100 episodes: -99.982 state values: tensor(0.6737) 1000
71 1000 -1000.0 -99.99568287525881 number episode from 10: 71 avegar over 10 episode: -99.982 avegare return across last 100 episodes: -99.982 state values: tensor(0.6780) 1000
72 1000 -1000.0 -99.99568287525881 number episode from 10: 72 avegar over 10 episode: -99.982 avegare return across last 100 episodes: -99.982 state values: tensor(0.6734) 1000
73 1000 -1000.0 -99.99568287525881 number episode from 10: 73 avegar over 10 episode: -99.982 avegare return across last 100 episodes: -99.982 state values: tensor(0.6735) 1000
74 1000 -1000.0 -99.99568287525881 number episode from 10: 74 avegar over 10 episode: -99.982 avegare return across last 100 episodes: -99.982 state values: tensor(0.6740) 1000
75 1000 -1000.0 -99.99568287525881 number episode from 10: 75 avegar over 10 episode: -99.983 avegare return across last 100 episodes: -99.983 state values: tensor(0.6763) 1000
76 1000 -1000.0 -99.99568287525881 number episode from 10: 76 avegar over 10 episode: -99.983 avegare return across last 100 episodes: -99.983 state values: tensor(0.6746) 1000
77 1000 -1000.0 -99.99568287525881 number episode from 10: 77 avegar over 10 episode: -99.983 avegare return across last 100 episodes: -99.983 state values: tensor(0.6768) 1000
78 1000 -1000.0 -99.99568287525881 number episode from 10: 78 avegar over 10 episode: -99.983 avegare return across last 100 episodes: -99.983 state values: tensor(0.6759) 1000
79 1000 -1000.0 -99.99568287525881 number episode from 10: 79 avegar over 10 episode: -99.983 avegare return across last 100 episodes: -99.983 state values: tensor(0.6777) 1000
80 1000 -1000.0 -99.99568287525881 number episode from 10: 80 avegar over 10 episode: -99.983 avegare return across last 100 episodes: -99.983 state values: tensor(0.6734) 1000
81 1000 -1000.0 -99.99568287525881 number episode from 10: 81 avegar over 10 episode: -99.983 avegare return across last 100 episodes: -99.983 state values: tensor(0.6734) 1000
82 1000 -1000.0 -99.99568287525881 number episode from 10: 82 avegar over 10 episode: -99.984 avegare return across last 100 episodes: -99.984 state values: tensor(0.6793) 1000
83 1000 -1000.0 -99.99568287525881 number episode from 10: 83 avegar over 10 episode: -99.984 avegare return across last 100 episodes: -99.984 state values: tensor(0.6786) 1000
84 1000 -1000.0 -99.99568287525881 number episode from 10: 84 avegar over 10 episode: -99.984 avegare return across last 100 episodes: -99.984 state values: tensor(0.6763) 1000
85 1000 -1000.0 -99.99568287525881 number episode from 10: 85 avegar over 10 episode: -99.984 avegare return across last 100 episodes: -99.984 state values: tensor(0.6757) 1000
86 1000 -1000.0 -99.99568287525881 number episode from 10: 86 avegar over 10 episode: -99.984 avegare return across last 100 episodes: -99.984 state values: tensor(0.6733) 1000
87 1000 -1000.0 -99.99568287525881 number episode from 10: 87 avegar over 10 episode: -99.984 avegare return across last 100 episodes: -99.984 state values: tensor(0.6737) 1000
88 1000 -1000.0 -99.99568287525881 number episode from 10: 88 avegar over 10 episode: -99.984 avegare return across last 100 episodes: -99.984 state values: tensor(0.6734) 1000
89 1000 -1000.0 -99.99568287525881 number episode from 10: 89 avegar over 10 episode: -99.985 avegare return across last 100 episodes: -99.985 state values: tensor(0.6736) 1000
90 1000 -1000.0 -99.99568287525881 number episode from 10: 90 avegar over 10 episode: -99.985 avegare return across last 100 episodes: -99.985 state values: tensor(0.6757) 1000
91 1000 -1000.0 -99.99568287525881 number episode from 10: 91 avegar over 10 episode: -99.985 avegare return across last 100 episodes: -99.985 state values: tensor(0.6775) 1000
92 1000 -1000.0 -99.99568287525881 number episode from 10: 92 avegar over 10 episode: -99.985 avegare return across last 100 episodes: -99.985 state values: tensor(0.6764) 1000
93 1000 -1000.0 -99.99568287525881 number episode from 10: 93 avegar over 10 episode: -99.985 avegare return across last 100 episodes: -99.985 state values: tensor(0.6734) 1000
94 1000 -1000.0 -99.99568287525881 number episode from 10: 94 avegar over 10 episode: -99.985 avegare return across last 100 episodes: -99.985 state values: tensor(0.6793) 1000
95 1000 -1000.0 -99.99568287525881 number episode from 10: 95 avegar over 10 episode: -99.985 avegare return across last 100 episodes: -99.985 state values: tensor(0.6737) 1000
96 1000 -1000.0 -99.99568287525881 number episode from 10: 96 avegar over 10 episode: -99.985 avegare return across last 100 episodes: -99.985 state values: tensor(0.6735) 1000
97 1000 -1000.0 -99.99568287525881 number episode from 10: 97 avegar over 10 episode: -99.985 avegare return across last 100 episodes: -99.985 state values: tensor(0.6733) 1000
98 1000 -1000.0 -99.99568287525881 number episode from 10: 98 avegar over 10 episode: -99.986 avegare return across last 100 episodes: -99.986 state values: tensor(0.6737) 1000
99 1000 -1000.0 -99.99568287525881 number episode from 10: 99 avegar over 10 episode: -99.986 avegare return across last 100 episodes: -99.986 state values: tensor(0.6793) 1000
100 1000 -1000.0 -99.99568287525881 number episode from 10: 100 avegar over 10 episode: -99.986 avegare return across last 100 episodes: -99.996 state values: tensor(0.6738) 1000
101 1000 -1000.0 -99.99568287525881 number episode from 10: 101 avegar over 10 episode: -99.986 avegare return across last 100 episodes: -99.996 state values: tensor(0.6754) 1000
102 1000 -1000.0 -99.99568287525881 number episode from 10: 102 avegar over 10 episode: -99.986 avegare return across last 100 episodes: -99.996 state values: tensor(0.6734) 1000
103 1000 -1000.0 -99.99568287525881 number episode from 10: 103 avegar over 10 episode: -99.986 avegare return across last 100 episodes: -99.996 state values: tensor(0.6754) 1000
104 1000 -1000.0 -99.99568287525881 number episode from 10: 104 avegar over 10 episode: -99.986 avegare return across last 100 episodes: -99.996 state values: tensor(0.6735) 1000
105 1000 -1000.0 -99.99568287525881 number episode from 10: 105 avegar over 10 episode: -99.986 avegare return across last 100 episodes: -99.996 state values: tensor(0.6733) 1000
106 1000 -1000.0 -99.99568287525881 number episode from 10: 106 avegar over 10 episode: -99.986 avegare return across last 100 episodes: -99.996 state values: tensor(0.6746) 1000
107 1000 -1000.0 -99.99568287525881 number episode from 10: 107 avegar over 10 episode: -99.986 avegare return across last 100 episodes: -99.996 state values: tensor(0.6732) 1000
108 1000 -1000.0 -99.99568287525881 number episode from 10: 108 avegar over 10 episode: -99.987 avegare return across last 100 episodes: -99.996 state values: tensor(0.6745) 1000
109 1000 -1000.0 -99.99568287525881 number episode from 10: 109 avegar over 10 episode: -99.987 avegare return across last 100 episodes: -99.996 state values: tensor(0.6731) 1000
110 1000 -1000.0 -99.99568287525881 number episode from 10: 110 avegar over 10 episode: -99.987 avegare return across last 100 episodes: -99.996 state values: tensor(0.6745) 1000
111 1000 -1000.0 -99.99568287525881 number episode from 10: 111 avegar over 10 episode: -99.987 avegare return across last 100 episodes: -99.996 state values: tensor(0.6776) 1000
112 1000 -1000.0 -99.99568287525881 number episode from 10: 112 avegar over 10 episode: -99.987 avegare return across last 100 episodes: -99.996 state values: tensor(0.6758) 1000
113 1000 -1000.0 -99.99568287525881 number episode from 10: 113 avegar over 10 episode: -99.987 avegare return across last 100 episodes: -99.996 state values: tensor(0.6776) 1000
114 1000 -1000.0 -99.99568287525881 number episode from 10: 114 avegar over 10 episode: -99.987 avegare return across last 100 episodes: -99.996 state values: tensor(0.6747) 1000
115 1000 -1000.0 -99.99568287525881 number episode from 10: 115 avegar over 10 episode: -99.987 avegare return across last 100 episodes: -99.996 state values: tensor(0.6736) 1000
116 1000 -1000.0 -99.99568287525881 number episode from 10: 116 avegar over 10 episode: -99.987 avegare return across last 100 episodes: -99.996 state values: tensor(0.6732) 1000
117 1000 -1000.0 -99.99568287525881 number episode from 10: 117 avegar over 10 episode: -99.987 avegare return across last 100 episodes: -99.996 state values: tensor(0.6733) 1000
118 1000 -1000.0 -99.99568287525881 number episode from 10: 118 avegar over 10 episode: -99.987 avegare return across last 100 episodes: -99.996 state values: tensor(0.6732) 1000
119 1000 -1000.0 -99.99568287525881 number episode from 10: 119 avegar over 10 episode: -99.987 avegare return across last 100 episodes: -99.996 state values: tensor(0.6736) 1000
120 1000 -1000.0 -99.99568287525881 number episode from 10: 120 avegar over 10 episode: -99.987 avegare return across last 100 episodes: -99.996 state values: tensor(0.6736) 1000
121 1000 -1000.0 -99.99568287525881 number episode from 10: 121 avegar over 10 episode: -99.987 avegare return across last 100 episodes: -99.996 state values: tensor(0.6754) 1000
122 1000 -1000.0 -99.99568287525881 number episode from 10: 122 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.6781) 1000
123 1000 -1000.0 -99.99568287525881 number episode from 10: 123 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.6731) 1000
124 1000 -1000.0 -99.99568287525881 number episode from 10: 124 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.6755) 1000
125 1000 -1000.0 -99.99568287525881 number episode from 10: 125 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.6735) 1000
126 1000 -1000.0 -99.99568287525881 number episode from 10: 126 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.6780) 1000
127 1000 -1000.0 -99.99568287525881 number episode from 10: 127 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.6736) 1000
128 1000 -1000.0 -99.99568287525881 number episode from 10: 128 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.6740) 1000
129 1000 -1000.0 -99.99568287525881 number episode from 10: 129 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.6781) 1000
130 1000 -1000.0 -99.99568287525881 number episode from 10: 130 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.6738) 1000
131 1000 -1000.0 -99.99568287525881 number episode from 10: 131 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.6769) 1000
132 1000 -1000.0 -99.99568287525881 number episode from 10: 132 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.6734) 1000
133 1000 -1000.0 -99.99568287525881 number episode from 10: 133 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.6734) 1000
134 1000 -1000.0 -99.99568287525881 number episode from 10: 134 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.6785) 1000
135 1000 -1000.0 -99.99568287525881 number episode from 10: 135 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.6766) 1000
136 1000 -1000.0 -99.99568287525881 number episode from 10: 136 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.6736) 1000
137 1000 -1000.0 -99.99568287525881 number episode from 10: 137 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.6763) 1000
138 1000 -1000.0 -99.99568287525881 number episode from 10: 138 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.6770) 1000
139 1000 -1000.0 -99.99568287525881 number episode from 10: 139 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.6800) 1000
140 1000 -1000.0 -99.99568287525881 number episode from 10: 140 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.6756) 1000
141 1000 -1000.0 -99.99568287525881 number episode from 10: 141 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.6734) 1000
142 1000 -1000.0 -99.99568287525881 number episode from 10: 142 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.6822) 1000
143 1000 -1000.0 -99.99568287525881 number episode from 10: 143 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.6758) 1000
144 1000 -1000.0 -99.99568287525881 number episode from 10: 144 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.6802) 1000
145 1000 -1000.0 -99.99568287525881 number episode from 10: 145 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.6780) 1000
146 1000 -1000.0 -99.99568287525881 number episode from 10: 146 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.6791) 1000
147 1000 -1000.0 -99.99568287525881 number episode from 10: 147 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.6734) 1000
148 1000 -1000.0 -99.99568287525881 number episode from 10: 148 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.6735) 1000
149 1000 -1000.0 -99.99568287525881 number episode from 10: 149 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.6763) 1000
150 1000 -1000.0 -99.99568287525881 number episode from 10: 150 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.6757) 1000
151 1000 -1000.0 -99.99568287525881 number episode from 10: 151 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.6740) 1000
152 1000 -1000.0 -99.99568287525881 number episode from 10: 152 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.6791) 1000
153 1000 -1000.0 -99.99568287525881 number episode from 10: 153 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.6732) 1000
154 1000 -1000.0 -99.99568287525881 number episode from 10: 154 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.6762) 1000
155 1000 -1000.0 -99.99568287525881 number episode from 10: 155 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.6776) 1000
156 1000 -1000.0 -99.99568287525881 number episode from 10: 156 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.6789) 1000
157 1000 -1000.0 -99.99568287525881 number episode from 10: 157 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.6740) 1000
158 1000 -1000.0 -99.99568287525881 number episode from 10: 158 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.6749) 1000
159 1000 -1000.0 -99.99568287525881 number episode from 10: 159 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.6755) 1000
160 1000 -1000.0 -99.99568287525881 number episode from 10: 160 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.6756) 1000
161 1000 -1000.0 -99.99568287525881 number episode from 10: 161 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.6742) 1000
162 1000 -1000.0 -99.99568287525881 number episode from 10: 162 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.6777) 1000
163 1000 -1000.0 -99.99568287525881 number episode from 10: 163 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.6792) 1000
164 1000 -1000.0 -99.99568287525881 number episode from 10: 164 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.6732) 1000
165 1000 -1000.0 -99.99568287525881 number episode from 10: 165 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.6760) 1000
166 1000 -1000.0 -99.99568287525881 number episode from 10: 166 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.6778) 1000
167 1000 -1000.0 -99.99568287525881 number episode from 10: 167 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.6772) 1000
168 1000 -1000.0 -99.99568287525881 number episode from 10: 168 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.6807) 1000
169 1000 -1000.0 -99.99568287525881 number episode from 10: 169 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.6801) 1000
170 1000 -1000.0 -99.99568287525881 number episode from 10: 170 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.6734) 1000
171 1000 -1000.0 -99.99568287525881 number episode from 10: 171 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.6761) 1000
172 1000 -1000.0 -99.99568287525881 number episode from 10: 172 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.6798) 1000
173 1000 -1000.0 -99.99568287525881 number episode from 10: 173 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.6802) 1000
174 1000 -1000.0 -99.99568287525881 number episode from 10: 174 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.6754) 1000
175 1000 -1000.0 -99.99568287525881 number episode from 10: 175 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.6780) 1000
176 1000 -1000.0 -99.99568287525881 number episode from 10: 176 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.6734) 1000
177 1000 -1000.0 -99.99568287525881 number episode from 10: 177 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.6798) 1000
178 1000 -1000.0 -99.99568287525881 number episode from 10: 178 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.6738) 1000
179 1000 -1000.0 -99.99568287525881 number episode from 10: 179 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.6799) 1000
180 1000 -1000.0 -99.99568287525881 number episode from 10: 180 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.6769) 1000
181 1000 -1000.0 -99.99568287525881 number episode from 10: 181 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.6748) 1000
182 1000 -1000.0 -99.99568287525881 number episode from 10: 182 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.6737) 1000
183 1000 -1000.0 -99.99568287525881 number episode from 10: 183 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.6735) 1000
184 1000 -1000.0 -99.99568287525881 number episode from 10: 184 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.6778) 1000
185 1000 -1000.0 -99.99568287525881 number episode from 10: 185 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.6734) 1000
186 1000 -1000.0 -99.99568287525881 number episode from 10: 186 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.6733) 1000
187 1000 -1000.0 -99.99568287525881 number episode from 10: 187 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.6810) 1000
188 1000 -1000.0 -99.99568287525881 number episode from 10: 188 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.6732) 1000
189 1000 -1000.0 -99.99568287525881 number episode from 10: 189 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.6735) 1000
190 1000 -1000.0 -99.99568287525881 number episode from 10: 190 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.6734) 1000
191 1000 -1000.0 -99.99568287525881 number episode from 10: 191 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.6733) 1000
192 1000 -1000.0 -99.99568287525881 number episode from 10: 192 avegar over 10 episode: -99.991 avegare return across last 100 episodes: -99.996 state values: tensor(0.6770) 1000
193 1000 -1000.0 -99.99568287525881 number episode from 10: 193 avegar over 10 episode: -99.991 avegare return across last 100 episodes: -99.996 state values: tensor(0.6807) 1000
194 1000 -1000.0 -99.99568287525881 number episode from 10: 194 avegar over 10 episode: -99.991 avegare return across last 100 episodes: -99.996 state values: tensor(0.6803) 1000
195 1000 -1000.0 -99.99568287525881 number episode from 10: 195 avegar over 10 episode: -99.991 avegare return across last 100 episodes: -99.996 state values: tensor(0.6780) 1000
196 1000 -1000.0 -99.99568287525881 number episode from 10: 196 avegar over 10 episode: -99.991 avegare return across last 100 episodes: -99.996 state values: tensor(0.6736) 1000
197 1000 -1000.0 -99.99568287525881 number episode from 10: 197 avegar over 10 episode: -99.991 avegare return across last 100 episodes: -99.996 state values: tensor(0.6744) 1000
198 1000 -1000.0 -99.99568287525881 number episode from 10: 198 avegar over 10 episode: -99.991 avegare return across last 100 episodes: -99.996 state values: tensor(0.6751) 1000
199 1000 -1000.0 -99.99568287525881 number episode from 10: 199 avegar over 10 episode: -99.991 avegare return across last 100 episodes: -99.996 state values: tensor(0.6776) 1000
200 1000 -1000.0 -99.99568287525881 number episode from 10: 200 avegar over 10 episode: -99.991 avegare return across last 100 episodes: -99.996 state values: tensor(0.6771) 1000
