OrderedDict([('nn_lr', 0.0001), ('reg_A', 0.001), ('eps_decay_steps', 1), ('update_freq', 1000), ('data_length', 50000), ('fqi_rep', 1)])
/project/6029407/janjua/Offline-Online-RL-Augmentation/Offline-Online-RL/TTN_network.py:72: UserWarning: nn.init.xavier_uniform is now deprecated in favor of nn.init.xavier_uniform_.
  nn.init.xavier_uniform(m.weight)
Data already exists at: Data/Mountaincar_50000+.npy
offline 15 Mountaincar 50000
Parameters: OrderedDict([('nn_lr', 0.001), ('reg_A', 0.001), ('eps_decay_steps', 1), ('update_freq', 1000), ('data_length', 50000), ('fqi_rep', 1)])
Nnet params: {'loss_features': 'semi_MSTDE', 'beta1': 0.0, 'beta2': 0.99, 'eps_init': 1.0, 'eps_final': 0.01, 'num_actions': 3, 'replay_memory_size': 50000, 'replay_init_size': 5000, 'batch_size': 32, 'fqi_reg_type': 'prev', 'data_aug_type': 'ras', 'data_aug_prob': 0.1, 'random_shift_pad': 4, 'ras_alpha': 0.8, 'ras_beta': 1.4}
load offline data!!!!!
/project/6029407/janjua/Offline-Online-RL-Augmentation/Offline-Online-RL/replay_memory.py:52: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  temp = T.tensor((d.item().get('state')), dtype=T.float32)
/project/6029407/janjua/Offline-Online-RL-Augmentation/Offline-Online-RL/replay_memory.py:54: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.state_memory[:len(temp), :] = T.tensor((d.item().get('state')), dtype=T.float32)
/project/6029407/janjua/Offline-Online-RL-Augmentation/Offline-Online-RL/replay_memory.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.new_state_memory[:len(temp), :] = T.tensor((d.item().get('nstate')), dtype=T.float32)
/project/6029407/janjua/Offline-Online-RL-Augmentation/Offline-Online-RL/replay_memory.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.action_memory[:len(temp)] = T.tensor((d.item().get('action')), dtype=T.int64)
/project/6029407/janjua/Offline-Online-RL-Augmentation/Offline-Online-RL/replay_memory.py:57: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.new_action_memory[:len(temp)] = T.tensor((d.item().get('naction')), dtype=T.int64)
/project/6029407/janjua/Offline-Online-RL-Augmentation/Offline-Online-RL/replay_memory.py:58: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.reward_memory[:len(temp)] = T.tensor((d.item().get('reward')), dtype=T.float32)
/project/6029407/janjua/Offline-Online-RL-Augmentation/Offline-Online-RL/replay_memory.py:59: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.terminal_memory[:len(temp)] = T.tensor((d.item().get('done')), dtype=T.bool)
mem_cntr: 50000 ; mem_size: 50000
/project/6029407/janjua/Offline-Online-RL-Augmentation/Offline-Online-RL/replay_memory.py:249: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  temp = T.tensor((d.item().get('state')), dtype=T.float32)
/project/6029407/janjua/Offline-Online-RL-Augmentation/Offline-Online-RL/replay_memory.py:251: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.state_memory[:len(temp), :] = T.tensor((d.item().get('state')), dtype=T.float32)
/project/6029407/janjua/Offline-Online-RL-Augmentation/Offline-Online-RL/replay_memory.py:252: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.new_state_memory[:len(temp), :] = T.tensor((d.item().get('nstate')), dtype=T.float32)
/project/6029407/janjua/Offline-Online-RL-Augmentation/Offline-Online-RL/replay_memory.py:253: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.action_memory[:len(temp)] = T.tensor((d.item().get('action')), dtype=T.int64)
/project/6029407/janjua/Offline-Online-RL-Augmentation/Offline-Online-RL/replay_memory.py:254: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.new_action_memory[:len(temp)] = T.tensor((d.item().get('naction')), dtype=T.int64)
/project/6029407/janjua/Offline-Online-RL-Augmentation/Offline-Online-RL/replay_memory.py:255: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.reward_memory[:len(temp)] = T.tensor((d.item().get('reward')), dtype=T.float32)
/project/6029407/janjua/Offline-Online-RL-Augmentation/Offline-Online-RL/replay_memory.py:256: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.terminal_memory[:len(temp)] = T.tensor((d.item().get('done')), dtype=T.bool)
/project/6029407/janjua/Offline-Online-RL-Augmentation/Offline-Online-RL/mix_ttn_agent_online_offline.py:155: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  states = T.tensor(state).to(self.q_eval.device)
/project/6029407/janjua/Offline-Online-RL-Augmentation/Offline-Online-RL/mix_ttn_agent_online_offline.py:156: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  rewards = T.tensor(reward).to(self.q_eval.device)
/project/6029407/janjua/Offline-Online-RL-Augmentation/Offline-Online-RL/mix_ttn_agent_online_offline.py:157: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  dones = T.tensor(done).to(self.q_eval.device)
/project/6029407/janjua/Offline-Online-RL-Augmentation/Offline-Online-RL/mix_ttn_agent_online_offline.py:158: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  actions = T.tensor(action).to(self.q_eval.device)
/project/6029407/janjua/Offline-Online-RL-Augmentation/Offline-Online-RL/mix_ttn_agent_online_offline.py:159: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  states_ = T.tensor(new_state).to(self.q_eval.device)
/project/6029407/janjua/Offline-Online-RL-Augmentation/Offline-Online-RL/mix_ttn_agent_online_offline.py:160: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  actions_ = T.tensor(new_action).to(self.q_eval.device)
/project/6029407/janjua/Offline-Online-RL-Augmentation/Offline-Online-RL/mix_ttn_agent_online_offline.py:169: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  states = T.tensor(state).to(self.q_eval.device)
/project/6029407/janjua/Offline-Online-RL-Augmentation/Offline-Online-RL/mix_ttn_agent_online_offline.py:170: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  rewards = T.tensor(reward).to(self.q_eval.device)
/project/6029407/janjua/Offline-Online-RL-Augmentation/Offline-Online-RL/mix_ttn_agent_online_offline.py:171: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  dones = T.tensor(done).to(self.q_eval.device)
/project/6029407/janjua/Offline-Online-RL-Augmentation/Offline-Online-RL/mix_ttn_agent_online_offline.py:172: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  actions = T.tensor(action).to(self.q_eval.device)
/project/6029407/janjua/Offline-Online-RL-Augmentation/Offline-Online-RL/mix_ttn_agent_online_offline.py:173: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  states_ = T.tensor(new_state).to(self.q_eval.device)
/project/6029407/janjua/Offline-Online-RL-Augmentation/Offline-Online-RL/mix_ttn_agent_online_offline.py:174: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  actions_ = T.tensor(new_action).to(self.q_eval.device)
nn.learn_nn_feature_fqi FQI:  998
/project/6029407/janjua/Offline-Online-RL-Augmentation/Offline-Online-RL/mix_ttn_agent_online_offline.py:704: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  states_all = T.tensor(self.memory.state_memory[:mem_index, :]).to(self.q_eval.device)
/project/6029407/janjua/Offline-Online-RL-Augmentation/Offline-Online-RL/mix_ttn_agent_online_offline.py:705: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  actions_all = T.tensor(self.memory.action_memory[:mem_index]).to(self.q_eval.device)
/project/6029407/janjua/Offline-Online-RL-Augmentation/Offline-Online-RL/mix_ttn_agent_online_offline.py:706: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  rewards_all = T.tensor(self.memory.reward_memory[:mem_index]).to(self.q_eval.device)
/project/6029407/janjua/Offline-Online-RL-Augmentation/Offline-Online-RL/mix_ttn_agent_online_offline.py:707: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  states_all_ = T.tensor(self.memory.new_state_memory[:mem_index, :]).to(self.q_eval.device)
/project/6029407/janjua/Offline-Online-RL-Augmentation/Offline-Online-RL/mix_ttn_agent_online_offline.py:708: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  actions_all_ = T.tensor(self.memory.new_action_memory[:mem_index]).to(self.q_eval.device)
/project/6029407/janjua/Offline-Online-RL-Augmentation/Offline-Online-RL/mix_ttn_agent_online_offline.py:709: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  dones_all = T.tensor(self.memory.terminal_memory[:mem_index]).to(self.q_eval.device)
/project/6029407/janjua/Offline-Online-RL-Augmentation/Offline-Online-RL/mix_ttn_agent_online_offline.py:794: UserWarning: torch.lstsq is deprecated in favor of torch.linalg.lstsq and will be removed in a future PyTorch release.
torch.linalg.lstsq has reversed arguments and does not return the QR decomposition in the returned tuple (although it returns other information about the problem).
To get the qr decomposition consider using torch.linalg.qr.
The returned solution in torch.lstsq stored the residuals of the solution in the last m - n columns of the returned value whenever m > n. In torch.linalg.lstsq, the residuals in the field 'residuals' of the returned named tuple.
The unpacking of the solution, as in
X, _ = torch.lstsq(B, A).solution[:A.size(1)]
should be replaced with
X = torch.linalg.lstsq(A, B).solution (Triggered internally at  /tmp/coulombc/pytorch_build_2021-11-09_14-57-01/avx2/python3.7/pytorch/aten/src/ATen/native/BatchLinearAlgebra.cpp:3657.)
  new_weights = T.lstsq(b, A)[0]  # T.mm(A.inverse(), b) #T.lstsq(b, A)[0]  #T.mm(A.inverse(), b) #tf.matrix_solve(A, b)
nn.learn_nn_feature_fqi FQI:  1998
nn.learn_nn_feature_fqi FQI:  2998
nn.learn_nn_feature_fqi FQI:  3998
nn.learn_nn_feature_fqi FQI:  4998
nn.learn_nn_feature_fqi FQI:  5998
nn.learn_nn_feature_fqi FQI:  6998
nn.learn_nn_feature_fqi FQI:  7998
nn.learn_nn_feature_fqi FQI:  8998
nn.learn_nn_feature_fqi FQI:  9998
nn.learn_nn_feature_fqi FQI:  10998
nn.learn_nn_feature_fqi FQI:  11998
nn.learn_nn_feature_fqi FQI:  12998
nn.learn_nn_feature_fqi FQI:  13998
nn.learn_nn_feature_fqi FQI:  14998
nn.learn_nn_feature_fqi FQI:  15998
nn.learn_nn_feature_fqi FQI:  16998
nn.learn_nn_feature_fqi FQI:  17998
nn.learn_nn_feature_fqi FQI:  18998
nn.learn_nn_feature_fqi FQI:  19998
nn.learn_nn_feature_fqi FQI:  20998
nn.learn_nn_feature_fqi FQI:  21998
nn.learn_nn_feature_fqi FQI:  22998
nn.learn_nn_feature_fqi FQI:  23998
nn.learn_nn_feature_fqi FQI:  24998
nn.learn_nn_feature_fqi FQI:  25998
nn.learn_nn_feature_fqi FQI:  26998
nn.learn_nn_feature_fqi FQI:  27998
nn.learn_nn_feature_fqi FQI:  28998
nn.learn_nn_feature_fqi FQI:  29998
nn.learn_nn_feature_fqi FQI:  30998
nn.learn_nn_feature_fqi FQI:  31998
nn.learn_nn_feature_fqi FQI:  32998
nn.learn_nn_feature_fqi FQI:  33998
nn.learn_nn_feature_fqi FQI:  34998
nn.learn_nn_feature_fqi FQI:  35998
nn.learn_nn_feature_fqi FQI:  36998
nn.learn_nn_feature_fqi FQI:  37998
nn.learn_nn_feature_fqi FQI:  38998
nn.learn_nn_feature_fqi FQI:  39998
nn.learn_nn_feature_fqi FQI:  40998
nn.learn_nn_feature_fqi FQI:  41998
nn.learn_nn_feature_fqi FQI:  42998
nn.learn_nn_feature_fqi FQI:  43998
nn.learn_nn_feature_fqi FQI:  44998
nn.learn_nn_feature_fqi FQI:  45998
nn.learn_nn_feature_fqi FQI:  46998
nn.learn_nn_feature_fqi FQI:  47998
nn.learn_nn_feature_fqi FQI:  48998
nn.learn_nn_feature_fqi FQI:  49998
nn.learn_nn_feature_fqi FQI:  50998
nn.learn_nn_feature_fqi FQI:  51998
nn.learn_nn_feature_fqi FQI:  52998
nn.learn_nn_feature_fqi FQI:  53998
nn.learn_nn_feature_fqi FQI:  54998
nn.learn_nn_feature_fqi FQI:  55998
nn.learn_nn_feature_fqi FQI:  56998
nn.learn_nn_feature_fqi FQI:  57998
nn.learn_nn_feature_fqi FQI:  58998
nn.learn_nn_feature_fqi FQI:  59998
nn.learn_nn_feature_fqi FQI:  60998
nn.learn_nn_feature_fqi FQI:  61998
nn.learn_nn_feature_fqi FQI:  62998
nn.learn_nn_feature_fqi FQI:  63998
nn.learn_nn_feature_fqi FQI:  64998
nn.learn_nn_feature_fqi FQI:  65998
nn.learn_nn_feature_fqi FQI:  66998
nn.learn_nn_feature_fqi FQI:  67998
nn.learn_nn_feature_fqi FQI:  68998
nn.learn_nn_feature_fqi FQI:  69998
nn.learn_nn_feature_fqi FQI:  70998
nn.learn_nn_feature_fqi FQI:  71998
nn.learn_nn_feature_fqi FQI:  72998
nn.learn_nn_feature_fqi FQI:  73998
nn.learn_nn_feature_fqi FQI:  74998
nn.learn_nn_feature_fqi FQI:  75998
nn.learn_nn_feature_fqi FQI:  76998
nn.learn_nn_feature_fqi FQI:  77998
nn.learn_nn_feature_fqi FQI:  78998
nn.learn_nn_feature_fqi FQI:  79998
nn.learn_nn_feature_fqi FQI:  80998
nn.learn_nn_feature_fqi FQI:  81998
nn.learn_nn_feature_fqi FQI:  82998
nn.learn_nn_feature_fqi FQI:  83998
nn.learn_nn_feature_fqi FQI:  84998
nn.learn_nn_feature_fqi FQI:  85998
nn.learn_nn_feature_fqi FQI:  86998
nn.learn_nn_feature_fqi FQI:  87998
nn.learn_nn_feature_fqi FQI:  88998
nn.learn_nn_feature_fqi FQI:  89998
nn.learn_nn_feature_fqi FQI:  90998
nn.learn_nn_feature_fqi FQI:  91998
nn.learn_nn_feature_fqi FQI:  92998
nn.learn_nn_feature_fqi FQI:  93998
nn.learn_nn_feature_fqi FQI:  94998
nn.learn_nn_feature_fqi FQI:  95998
nn.learn_nn_feature_fqi FQI:  96998
nn.learn_nn_feature_fqi FQI:  97998
nn.learn_nn_feature_fqi FQI:  98998
nn.learn_nn_feature_fqi FQI:  99998
nn.learn_nn_feature_fqi FQI:  100998
nn.learn_nn_feature_fqi FQI:  101998
nn.learn_nn_feature_fqi FQI:  102998
nn.learn_nn_feature_fqi FQI:  103998
nn.learn_nn_feature_fqi FQI:  104998
nn.learn_nn_feature_fqi FQI:  105998
nn.learn_nn_feature_fqi FQI:  106998
nn.learn_nn_feature_fqi FQI:  107998
nn.learn_nn_feature_fqi FQI:  108998
nn.learn_nn_feature_fqi FQI:  109998
nn.learn_nn_feature_fqi FQI:  110998
nn.learn_nn_feature_fqi FQI:  111998
nn.learn_nn_feature_fqi FQI:  112998
nn.learn_nn_feature_fqi FQI:  113998
nn.learn_nn_feature_fqi FQI:  114998
nn.learn_nn_feature_fqi FQI:  115998
nn.learn_nn_feature_fqi FQI:  116998
nn.learn_nn_feature_fqi FQI:  117998
nn.learn_nn_feature_fqi FQI:  118998
nn.learn_nn_feature_fqi FQI:  119998
nn.learn_nn_feature_fqi FQI:  120998
nn.learn_nn_feature_fqi FQI:  121998
nn.learn_nn_feature_fqi FQI:  122998
nn.learn_nn_feature_fqi FQI:  123998
nn.learn_nn_feature_fqi FQI:  124998
nn.learn_nn_feature_fqi FQI:  125998
nn.learn_nn_feature_fqi FQI:  126998
nn.learn_nn_feature_fqi FQI:  127998
nn.learn_nn_feature_fqi FQI:  128998
nn.learn_nn_feature_fqi FQI:  129998
nn.learn_nn_feature_fqi FQI:  130998
nn.learn_nn_feature_fqi FQI:  131998
nn.learn_nn_feature_fqi FQI:  132998
nn.learn_nn_feature_fqi FQI:  133998
nn.learn_nn_feature_fqi FQI:  134998
nn.learn_nn_feature_fqi FQI:  135998
nn.learn_nn_feature_fqi FQI:  136998
nn.learn_nn_feature_fqi FQI:  137998
nn.learn_nn_feature_fqi FQI:  138998
nn.learn_nn_feature_fqi FQI:  139998
nn.learn_nn_feature_fqi FQI:  140998
nn.learn_nn_feature_fqi FQI:  141998
nn.learn_nn_feature_fqi FQI:  142998
nn.learn_nn_feature_fqi FQI:  143998
nn.learn_nn_feature_fqi FQI:  144998
nn.learn_nn_feature_fqi FQI:  145998
nn.learn_nn_feature_fqi FQI:  146998
nn.learn_nn_feature_fqi FQI:  147998
nn.learn_nn_feature_fqi FQI:  148998
nn.learn_nn_feature_fqi FQI:  149998
nn.learn_nn_feature_fqi FQI:  150998
nn.learn_nn_feature_fqi FQI:  151998
nn.learn_nn_feature_fqi FQI:  152998
nn.learn_nn_feature_fqi FQI:  153998
nn.learn_nn_feature_fqi FQI:  154998
nn.learn_nn_feature_fqi FQI:  155998
/project/6029407/janjua/Offline-Online-RL-Augmentation/Offline-Online-RL/mix_ttn_agent_online_offline.py:213: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /tmp/coulombc/pytorch_build_2021-11-09_14-57-01/avx2/python3.7/pytorch/torch/csrc/utils/tensor_new.cpp:198.)
  state = T.tensor([observation], dtype=T.float).to(self.q_eval.device)
0 1001 -1000.0 -98.99572604650622 number episode from 10: 0 avegar over 10 episode: -98.996 avegare return across last 100 episodes: -98.996 state values: tensor(0.6569) 1000
1 1000 -1000.0 -99.99568287525881 number episode from 10: 1 avegar over 10 episode: -99.496 avegare return across last 100 episodes: -99.496 state values: tensor(0.6555) 1000
2 1000 -1000.0 -99.99568287525881 number episode from 10: 2 avegar over 10 episode: -99.662 avegare return across last 100 episodes: -99.662 state values: tensor(0.6555) 1000
3 1000 -1000.0 -99.99568287525881 number episode from 10: 3 avegar over 10 episode: -99.746 avegare return across last 100 episodes: -99.746 state values: tensor(0.6555) 1000
4 1000 -1000.0 -99.99568287525881 number episode from 10: 4 avegar over 10 episode: -99.796 avegare return across last 100 episodes: -99.796 state values: tensor(0.6555) 1000
5 1000 -1000.0 -99.99568287525881 number episode from 10: 5 avegar over 10 episode: -99.829 avegare return across last 100 episodes: -99.829 state values: tensor(0.6569) 1000
6 1000 -1000.0 -99.99568287525881 number episode from 10: 6 avegar over 10 episode: -99.853 avegare return across last 100 episodes: -99.853 state values: tensor(0.6553) 1000
7 1000 -1000.0 -99.99568287525881 number episode from 10: 7 avegar over 10 episode: -99.871 avegare return across last 100 episodes: -99.871 state values: tensor(0.6564) 1000
8 1000 -1000.0 -99.99568287525881 number episode from 10: 8 avegar over 10 episode: -99.885 avegare return across last 100 episodes: -99.885 state values: tensor(0.6568) 1000
9 1000 -1000.0 -99.99568287525881 number episode from 10: 9 avegar over 10 episode: -99.896 avegare return across last 100 episodes: -99.896 state values: tensor(0.6574) 1000
10 1000 -1000.0 -99.99568287525881 number episode from 10: 10 avegar over 10 episode: -99.905 avegare return across last 100 episodes: -99.905 state values: tensor(0.6574) 1000
11 1000 -1000.0 -99.99568287525881 number episode from 10: 11 avegar over 10 episode: -99.912 avegare return across last 100 episodes: -99.912 state values: tensor(0.6558) 1000
12 1000 -1000.0 -99.99568287525881 number episode from 10: 12 avegar over 10 episode: -99.919 avegare return across last 100 episodes: -99.919 state values: tensor(0.6570) 1000
13 1000 -1000.0 -99.99568287525881 number episode from 10: 13 avegar over 10 episode: -99.924 avegare return across last 100 episodes: -99.924 state values: tensor(0.6556) 1000
14 1000 -1000.0 -99.99568287525881 number episode from 10: 14 avegar over 10 episode: -99.929 avegare return across last 100 episodes: -99.929 state values: tensor(0.6556) 1000
15 1000 -1000.0 -99.99568287525881 number episode from 10: 15 avegar over 10 episode: -99.933 avegare return across last 100 episodes: -99.933 state values: tensor(0.6557) 1000
16 1000 -1000.0 -99.99568287525881 number episode from 10: 16 avegar over 10 episode: -99.937 avegare return across last 100 episodes: -99.937 state values: tensor(0.6569) 1000
17 1000 -1000.0 -99.99568287525881 number episode from 10: 17 avegar over 10 episode: -99.94 avegare return across last 100 episodes: -99.94 state values: tensor(0.6557) 1000
18 1000 -1000.0 -99.99568287525881 number episode from 10: 18 avegar over 10 episode: -99.943 avegare return across last 100 episodes: -99.943 state values: tensor(0.6559) 1000
19 1000 -1000.0 -99.99568287525881 number episode from 10: 19 avegar over 10 episode: -99.946 avegare return across last 100 episodes: -99.946 state values: tensor(0.6557) 1000
20 1000 -1000.0 -99.99568287525881 number episode from 10: 20 avegar over 10 episode: -99.948 avegare return across last 100 episodes: -99.948 state values: tensor(0.6569) 1000
21 1000 -1000.0 -99.99568287525881 number episode from 10: 21 avegar over 10 episode: -99.95 avegare return across last 100 episodes: -99.95 state values: tensor(0.6554) 1000
22 1000 -1000.0 -99.99568287525881 number episode from 10: 22 avegar over 10 episode: -99.952 avegare return across last 100 episodes: -99.952 state values: tensor(0.6555) 1000
23 1000 -1000.0 -99.99568287525881 number episode from 10: 23 avegar over 10 episode: -99.954 avegare return across last 100 episodes: -99.954 state values: tensor(0.6575) 1000
24 1000 -1000.0 -99.99568287525881 number episode from 10: 24 avegar over 10 episode: -99.956 avegare return across last 100 episodes: -99.956 state values: tensor(0.6568) 1000
25 1000 -1000.0 -99.99568287525881 number episode from 10: 25 avegar over 10 episode: -99.957 avegare return across last 100 episodes: -99.957 state values: tensor(0.6556) 1000
26 1000 -1000.0 -99.99568287525881 number episode from 10: 26 avegar over 10 episode: -99.959 avegare return across last 100 episodes: -99.959 state values: tensor(0.6554) 1000
27 1000 -1000.0 -99.99568287525881 number episode from 10: 27 avegar over 10 episode: -99.96 avegare return across last 100 episodes: -99.96 state values: tensor(0.6556) 1000
28 1000 -1000.0 -99.99568287525881 number episode from 10: 28 avegar over 10 episode: -99.961 avegare return across last 100 episodes: -99.961 state values: tensor(0.6574) 1000
29 1000 -1000.0 -99.99568287525881 number episode from 10: 29 avegar over 10 episode: -99.962 avegare return across last 100 episodes: -99.962 state values: tensor(0.6553) 1000
30 1000 -1000.0 -99.99568287525881 number episode from 10: 30 avegar over 10 episode: -99.963 avegare return across last 100 episodes: -99.963 state values: tensor(0.6561) 1000
31 1000 -1000.0 -99.99568287525881 number episode from 10: 31 avegar over 10 episode: -99.964 avegare return across last 100 episodes: -99.964 state values: tensor(0.6553) 1000
32 1000 -1000.0 -99.99568287525881 number episode from 10: 32 avegar over 10 episode: -99.965 avegare return across last 100 episodes: -99.965 state values: tensor(0.6567) 1000
33 1000 -1000.0 -99.99568287525881 number episode from 10: 33 avegar over 10 episode: -99.966 avegare return across last 100 episodes: -99.966 state values: tensor(0.6558) 1000
34 1000 -1000.0 -99.99568287525881 number episode from 10: 34 avegar over 10 episode: -99.967 avegare return across last 100 episodes: -99.967 state values: tensor(0.6568) 1000
35 1000 -1000.0 -99.99568287525881 number episode from 10: 35 avegar over 10 episode: -99.968 avegare return across last 100 episodes: -99.968 state values: tensor(0.6566) 1000
36 1000 -1000.0 -99.99568287525881 number episode from 10: 36 avegar over 10 episode: -99.969 avegare return across last 100 episodes: -99.969 state values: tensor(0.6556) 1000
37 1000 -1000.0 -99.99568287525881 number episode from 10: 37 avegar over 10 episode: -99.969 avegare return across last 100 episodes: -99.969 state values: tensor(0.6553) 1000
38 1000 -1000.0 -99.99568287525881 number episode from 10: 38 avegar over 10 episode: -99.97 avegare return across last 100 episodes: -99.97 state values: tensor(0.6571) 1000
39 1000 -1000.0 -99.99568287525881 number episode from 10: 39 avegar over 10 episode: -99.971 avegare return across last 100 episodes: -99.971 state values: tensor(0.6572) 1000
40 1000 -1000.0 -99.99568287525881 number episode from 10: 40 avegar over 10 episode: -99.971 avegare return across last 100 episodes: -99.971 state values: tensor(0.6563) 1000
41 1000 -1000.0 -99.99568287525881 number episode from 10: 41 avegar over 10 episode: -99.972 avegare return across last 100 episodes: -99.972 state values: tensor(0.6558) 1000
42 1000 -1000.0 -99.99568287525881 number episode from 10: 42 avegar over 10 episode: -99.972 avegare return across last 100 episodes: -99.972 state values: tensor(0.6553) 1000
43 1000 -1000.0 -99.99568287525881 number episode from 10: 43 avegar over 10 episode: -99.973 avegare return across last 100 episodes: -99.973 state values: tensor(0.6568) 1000
44 1000 -1000.0 -99.99568287525881 number episode from 10: 44 avegar over 10 episode: -99.973 avegare return across last 100 episodes: -99.973 state values: tensor(0.6556) 1000
45 1000 -1000.0 -99.99568287525881 number episode from 10: 45 avegar over 10 episode: -99.974 avegare return across last 100 episodes: -99.974 state values: tensor(0.6557) 1000
46 1000 -1000.0 -99.99568287525881 number episode from 10: 46 avegar over 10 episode: -99.974 avegare return across last 100 episodes: -99.974 state values: tensor(0.6557) 1000
47 1000 -1000.0 -99.99568287525881 number episode from 10: 47 avegar over 10 episode: -99.975 avegare return across last 100 episodes: -99.975 state values: tensor(0.6573) 1000
48 1000 -1000.0 -99.99568287525881 number episode from 10: 48 avegar over 10 episode: -99.975 avegare return across last 100 episodes: -99.975 state values: tensor(0.6569) 1000
49 1000 -1000.0 -99.99568287525881 number episode from 10: 49 avegar over 10 episode: -99.976 avegare return across last 100 episodes: -99.976 state values: tensor(0.6556) 1000
50 1000 -1000.0 -99.99568287525881 number episode from 10: 50 avegar over 10 episode: -99.976 avegare return across last 100 episodes: -99.976 state values: tensor(0.6554) 1000
51 1000 -1000.0 -99.99568287525881 number episode from 10: 51 avegar over 10 episode: -99.976 avegare return across last 100 episodes: -99.976 state values: tensor(0.6574) 1000
52 1000 -1000.0 -99.99568287525881 number episode from 10: 52 avegar over 10 episode: -99.977 avegare return across last 100 episodes: -99.977 state values: tensor(0.6556) 1000
53 1000 -1000.0 -99.99568287525881 number episode from 10: 53 avegar over 10 episode: -99.977 avegare return across last 100 episodes: -99.977 state values: tensor(0.6556) 1000
54 1000 -1000.0 -99.99568287525881 number episode from 10: 54 avegar over 10 episode: -99.978 avegare return across last 100 episodes: -99.978 state values: tensor(0.6572) 1000
55 1000 -1000.0 -99.99568287525881 number episode from 10: 55 avegar over 10 episode: -99.978 avegare return across last 100 episodes: -99.978 state values: tensor(0.6556) 1000
56 1000 -1000.0 -99.99568287525881 number episode from 10: 56 avegar over 10 episode: -99.978 avegare return across last 100 episodes: -99.978 state values: tensor(0.6557) 1000
57 1000 -1000.0 -99.99568287525881 number episode from 10: 57 avegar over 10 episode: -99.978 avegare return across last 100 episodes: -99.978 state values: tensor(0.6569) 1000
58 1000 -1000.0 -99.99568287525881 number episode from 10: 58 avegar over 10 episode: -99.979 avegare return across last 100 episodes: -99.979 state values: tensor(0.6556) 1000
59 1000 -1000.0 -99.99568287525881 number episode from 10: 59 avegar over 10 episode: -99.979 avegare return across last 100 episodes: -99.979 state values: tensor(0.6568) 1000
60 1000 -1000.0 -99.99568287525881 number episode from 10: 60 avegar over 10 episode: -99.979 avegare return across last 100 episodes: -99.979 state values: tensor(0.6553) 1000
61 1000 -1000.0 -99.99568287525881 number episode from 10: 61 avegar over 10 episode: -99.98 avegare return across last 100 episodes: -99.98 state values: tensor(0.6555) 1000
62 1000 -1000.0 -99.99568287525881 number episode from 10: 62 avegar over 10 episode: -99.98 avegare return across last 100 episodes: -99.98 state values: tensor(0.6562) 1000
63 1000 -1000.0 -99.99568287525881 number episode from 10: 63 avegar over 10 episode: -99.98 avegare return across last 100 episodes: -99.98 state values: tensor(0.6553) 1000
64 1000 -1000.0 -99.99568287525881 number episode from 10: 64 avegar over 10 episode: -99.98 avegare return across last 100 episodes: -99.98 state values: tensor(0.6566) 1000
65 1000 -1000.0 -99.99568287525881 number episode from 10: 65 avegar over 10 episode: -99.981 avegare return across last 100 episodes: -99.981 state values: tensor(0.6569) 1000
66 1000 -1000.0 -99.99568287525881 number episode from 10: 66 avegar over 10 episode: -99.981 avegare return across last 100 episodes: -99.981 state values: tensor(0.6565) 1000
67 1000 -1000.0 -99.99568287525881 number episode from 10: 67 avegar over 10 episode: -99.981 avegare return across last 100 episodes: -99.981 state values: tensor(0.6559) 1000
68 1000 -1000.0 -99.99568287525881 number episode from 10: 68 avegar over 10 episode: -99.981 avegare return across last 100 episodes: -99.981 state values: tensor(0.6559) 1000
69 1000 -1000.0 -99.99568287525881 number episode from 10: 69 avegar over 10 episode: -99.981 avegare return across last 100 episodes: -99.981 state values: tensor(0.6552) 1000
70 1000 -1000.0 -99.99568287525881 number episode from 10: 70 avegar over 10 episode: -99.982 avegare return across last 100 episodes: -99.982 state values: tensor(0.6557) 1000
71 1000 -1000.0 -99.99568287525881 number episode from 10: 71 avegar over 10 episode: -99.982 avegare return across last 100 episodes: -99.982 state values: tensor(0.6553) 1000
72 1000 -1000.0 -99.99568287525881 number episode from 10: 72 avegar over 10 episode: -99.982 avegare return across last 100 episodes: -99.982 state values: tensor(0.6572) 1000
73 1000 -1000.0 -99.99568287525881 number episode from 10: 73 avegar over 10 episode: -99.982 avegare return across last 100 episodes: -99.982 state values: tensor(0.6568) 1000
74 1000 -1000.0 -99.99568287525881 number episode from 10: 74 avegar over 10 episode: -99.982 avegare return across last 100 episodes: -99.982 state values: tensor(0.6567) 1000
75 1000 -1000.0 -99.99568287525881 number episode from 10: 75 avegar over 10 episode: -99.983 avegare return across last 100 episodes: -99.983 state values: tensor(0.6558) 1000
76 1000 -1000.0 -99.99568287525881 number episode from 10: 76 avegar over 10 episode: -99.983 avegare return across last 100 episodes: -99.983 state values: tensor(0.6556) 1000
77 1000 -1000.0 -99.99568287525881 number episode from 10: 77 avegar over 10 episode: -99.983 avegare return across last 100 episodes: -99.983 state values: tensor(0.6558) 1000
78 1000 -1000.0 -99.99568287525881 number episode from 10: 78 avegar over 10 episode: -99.983 avegare return across last 100 episodes: -99.983 state values: tensor(0.6553) 1000
79 1000 -1000.0 -99.99568287525881 number episode from 10: 79 avegar over 10 episode: -99.983 avegare return across last 100 episodes: -99.983 state values: tensor(0.6553) 1000
80 1000 -1000.0 -99.99568287525881 number episode from 10: 80 avegar over 10 episode: -99.983 avegare return across last 100 episodes: -99.983 state values: tensor(0.6574) 1000
81 1000 -1000.0 -99.99568287525881 number episode from 10: 81 avegar over 10 episode: -99.983 avegare return across last 100 episodes: -99.983 state values: tensor(0.6573) 1000
82 1000 -1000.0 -99.99568287525881 number episode from 10: 82 avegar over 10 episode: -99.984 avegare return across last 100 episodes: -99.984 state values: tensor(0.6572) 1000
83 1000 -1000.0 -99.99568287525881 number episode from 10: 83 avegar over 10 episode: -99.984 avegare return across last 100 episodes: -99.984 state values: tensor(0.6562) 1000
84 1000 -1000.0 -99.99568287525881 number episode from 10: 84 avegar over 10 episode: -99.984 avegare return across last 100 episodes: -99.984 state values: tensor(0.6560) 1000
85 1000 -1000.0 -99.99568287525881 number episode from 10: 85 avegar over 10 episode: -99.984 avegare return across last 100 episodes: -99.984 state values: tensor(0.6560) 1000
86 1000 -1000.0 -99.99568287525881 number episode from 10: 86 avegar over 10 episode: -99.984 avegare return across last 100 episodes: -99.984 state values: tensor(0.6571) 1000
87 1000 -1000.0 -99.99568287525881 number episode from 10: 87 avegar over 10 episode: -99.984 avegare return across last 100 episodes: -99.984 state values: tensor(0.6557) 1000
88 1000 -1000.0 -99.99568287525881 number episode from 10: 88 avegar over 10 episode: -99.984 avegare return across last 100 episodes: -99.984 state values: tensor(0.6573) 1000
89 1000 -1000.0 -99.99568287525881 number episode from 10: 89 avegar over 10 episode: -99.985 avegare return across last 100 episodes: -99.985 state values: tensor(0.6559) 1000
90 1000 -1000.0 -99.99568287525881 number episode from 10: 90 avegar over 10 episode: -99.985 avegare return across last 100 episodes: -99.985 state values: tensor(0.6573) 1000
91 1000 -1000.0 -99.99568287525881 number episode from 10: 91 avegar over 10 episode: -99.985 avegare return across last 100 episodes: -99.985 state values: tensor(0.6572) 1000
92 1000 -1000.0 -99.99568287525881 number episode from 10: 92 avegar over 10 episode: -99.985 avegare return across last 100 episodes: -99.985 state values: tensor(0.6558) 1000
93 1000 -1000.0 -99.99568287525881 number episode from 10: 93 avegar over 10 episode: -99.985 avegare return across last 100 episodes: -99.985 state values: tensor(0.6563) 1000
94 1000 -1000.0 -99.99568287525881 number episode from 10: 94 avegar over 10 episode: -99.985 avegare return across last 100 episodes: -99.985 state values: tensor(0.6568) 1000
95 1000 -1000.0 -99.99568287525881 number episode from 10: 95 avegar over 10 episode: -99.985 avegare return across last 100 episodes: -99.985 state values: tensor(0.6555) 1000
96 1000 -1000.0 -99.99568287525881 number episode from 10: 96 avegar over 10 episode: -99.985 avegare return across last 100 episodes: -99.985 state values: tensor(0.6556) 1000
97 1000 -1000.0 -99.99568287525881 number episode from 10: 97 avegar over 10 episode: -99.985 avegare return across last 100 episodes: -99.985 state values: tensor(0.6554) 1000
98 1000 -1000.0 -99.99568287525881 number episode from 10: 98 avegar over 10 episode: -99.986 avegare return across last 100 episodes: -99.986 state values: tensor(0.6575) 1000
99 1000 -1000.0 -99.99568287525881 number episode from 10: 99 avegar over 10 episode: -99.986 avegare return across last 100 episodes: -99.986 state values: tensor(0.6568) 1000
100 1000 -1000.0 -99.99568287525881 number episode from 10: 100 avegar over 10 episode: -99.986 avegare return across last 100 episodes: -99.996 state values: tensor(0.6573) 1000
101 1000 -1000.0 -99.99568287525881 number episode from 10: 101 avegar over 10 episode: -99.986 avegare return across last 100 episodes: -99.996 state values: tensor(0.6555) 1000
102 1000 -1000.0 -99.99568287525881 number episode from 10: 102 avegar over 10 episode: -99.986 avegare return across last 100 episodes: -99.996 state values: tensor(0.6560) 1000
103 1000 -1000.0 -99.99568287525881 number episode from 10: 103 avegar over 10 episode: -99.986 avegare return across last 100 episodes: -99.996 state values: tensor(0.6554) 1000
104 1000 -1000.0 -99.99568287525881 number episode from 10: 104 avegar over 10 episode: -99.986 avegare return across last 100 episodes: -99.996 state values: tensor(0.6555) 1000
105 1000 -1000.0 -99.99568287525881 number episode from 10: 105 avegar over 10 episode: -99.986 avegare return across last 100 episodes: -99.996 state values: tensor(0.6571) 1000
106 1000 -1000.0 -99.99568287525881 number episode from 10: 106 avegar over 10 episode: -99.986 avegare return across last 100 episodes: -99.996 state values: tensor(0.6569) 1000
107 1000 -1000.0 -99.99568287525881 number episode from 10: 107 avegar over 10 episode: -99.986 avegare return across last 100 episodes: -99.996 state values: tensor(0.6552) 1000
108 1000 -1000.0 -99.99568287525881 number episode from 10: 108 avegar over 10 episode: -99.987 avegare return across last 100 episodes: -99.996 state values: tensor(0.6573) 1000
109 1000 -1000.0 -99.99568287525881 number episode from 10: 109 avegar over 10 episode: -99.987 avegare return across last 100 episodes: -99.996 state values: tensor(0.6552) 1000
110 1000 -1000.0 -99.99568287525881 number episode from 10: 110 avegar over 10 episode: -99.987 avegare return across last 100 episodes: -99.996 state values: tensor(0.6557) 1000
111 1000 -1000.0 -99.99568287525881 number episode from 10: 111 avegar over 10 episode: -99.987 avegare return across last 100 episodes: -99.996 state values: tensor(0.6568) 1000
112 1000 -1000.0 -99.99568287525881 number episode from 10: 112 avegar over 10 episode: -99.987 avegare return across last 100 episodes: -99.996 state values: tensor(0.6557) 1000
113 1000 -1000.0 -99.99568287525881 number episode from 10: 113 avegar over 10 episode: -99.987 avegare return across last 100 episodes: -99.996 state values: tensor(0.6556) 1000
114 1000 -1000.0 -99.99568287525881 number episode from 10: 114 avegar over 10 episode: -99.987 avegare return across last 100 episodes: -99.996 state values: tensor(0.6571) 1000
115 1000 -1000.0 -99.99568287525881 number episode from 10: 115 avegar over 10 episode: -99.987 avegare return across last 100 episodes: -99.996 state values: tensor(0.6571) 1000
116 1000 -1000.0 -99.99568287525881 number episode from 10: 116 avegar over 10 episode: -99.987 avegare return across last 100 episodes: -99.996 state values: tensor(0.6570) 1000
117 1000 -1000.0 -99.99568287525881 number episode from 10: 117 avegar over 10 episode: -99.987 avegare return across last 100 episodes: -99.996 state values: tensor(0.6566) 1000
118 1000 -1000.0 -99.99568287525881 number episode from 10: 118 avegar over 10 episode: -99.987 avegare return across last 100 episodes: -99.996 state values: tensor(0.6554) 1000
119 1000 -1000.0 -99.99568287525881 number episode from 10: 119 avegar over 10 episode: -99.987 avegare return across last 100 episodes: -99.996 state values: tensor(0.6552) 1000
120 1000 -1000.0 -99.99568287525881 number episode from 10: 120 avegar over 10 episode: -99.987 avegare return across last 100 episodes: -99.996 state values: tensor(0.6554) 1000
121 1000 -1000.0 -99.99568287525881 number episode from 10: 121 avegar over 10 episode: -99.987 avegare return across last 100 episodes: -99.996 state values: tensor(0.6559) 1000
122 1000 -1000.0 -99.99568287525881 number episode from 10: 122 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.6560) 1000
123 1000 -1000.0 -99.99568287525881 number episode from 10: 123 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.6571) 1000
124 1000 -1000.0 -99.99568287525881 number episode from 10: 124 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.6556) 1000
125 1000 -1000.0 -99.99568287525881 number episode from 10: 125 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.6552) 1000
126 1000 -1000.0 -99.99568287525881 number episode from 10: 126 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.6563) 1000
127 1000 -1000.0 -99.99568287525881 number episode from 10: 127 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.6552) 1000
128 1000 -1000.0 -99.99568287525881 number episode from 10: 128 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.6560) 1000
129 1000 -1000.0 -99.99568287525881 number episode from 10: 129 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.6573) 1000
130 1000 -1000.0 -99.99568287525881 number episode from 10: 130 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.6564) 1000
131 1000 -1000.0 -99.99568287525881 number episode from 10: 131 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.6556) 1000
132 1000 -1000.0 -99.99568287525881 number episode from 10: 132 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.6565) 1000
133 1000 -1000.0 -99.99568287525881 number episode from 10: 133 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.6573) 1000
134 1000 -1000.0 -99.99568287525881 number episode from 10: 134 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.6555) 1000
135 1000 -1000.0 -99.99568287525881 number episode from 10: 135 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.6552) 1000
136 1000 -1000.0 -99.99568287525881 number episode from 10: 136 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.6555) 1000
137 1000 -1000.0 -99.99568287525881 number episode from 10: 137 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.6571) 1000
138 1000 -1000.0 -99.99568287525881 number episode from 10: 138 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.6567) 1000
139 1000 -1000.0 -99.99568287525881 number episode from 10: 139 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.6557) 1000
140 1000 -1000.0 -99.99568287525881 number episode from 10: 140 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.6553) 1000
141 1000 -1000.0 -99.99568287525881 number episode from 10: 141 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.6555) 1000
142 1000 -1000.0 -99.99568287525881 number episode from 10: 142 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.6557) 1000
143 1000 -1000.0 -99.99568287525881 number episode from 10: 143 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.6555) 1000
144 1000 -1000.0 -99.99568287525881 number episode from 10: 144 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.6570) 1000
145 1000 -1000.0 -99.99568287525881 number episode from 10: 145 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.6569) 1000
146 1000 -1000.0 -99.99568287525881 number episode from 10: 146 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.6561) 1000
147 1000 -1000.0 -99.99568287525881 number episode from 10: 147 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.6563) 1000
148 1000 -1000.0 -99.99568287525881 number episode from 10: 148 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.6570) 1000
149 1000 -1000.0 -99.99568287525881 number episode from 10: 149 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.6569) 1000
150 1000 -1000.0 -99.99568287525881 number episode from 10: 150 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.6553) 1000
151 1000 -1000.0 -99.99568287525881 number episode from 10: 151 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.6564) 1000
152 1000 -1000.0 -99.99568287525881 number episode from 10: 152 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.6571) 1000
153 1000 -1000.0 -99.99568287525881 number episode from 10: 153 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.6560) 1000
154 1000 -1000.0 -99.99568287525881 number episode from 10: 154 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.6574) 1000
155 1000 -1000.0 -99.99568287525881 number episode from 10: 155 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.6571) 1000
156 1000 -1000.0 -99.99568287525881 number episode from 10: 156 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.6571) 1000
157 1000 -1000.0 -99.99568287525881 number episode from 10: 157 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.6553) 1000
158 1000 -1000.0 -99.99568287525881 number episode from 10: 158 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.6557) 1000
159 1000 -1000.0 -99.99568287525881 number episode from 10: 159 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.6565) 1000
160 1000 -1000.0 -99.99568287525881 number episode from 10: 160 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.6569) 1000
161 1000 -1000.0 -99.99568287525881 number episode from 10: 161 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.6572) 1000
162 1000 -1000.0 -99.99568287525881 number episode from 10: 162 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.6563) 1000
163 1000 -1000.0 -99.99568287525881 number episode from 10: 163 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.6554) 1000
164 1000 -1000.0 -99.99568287525881 number episode from 10: 164 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.6556) 1000
165 1000 -1000.0 -99.99568287525881 number episode from 10: 165 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.6562) 1000
166 1000 -1000.0 -99.99568287525881 number episode from 10: 166 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.6574) 1000
167 1000 -1000.0 -99.99568287525881 number episode from 10: 167 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.6558) 1000
168 1000 -1000.0 -99.99568287525881 number episode from 10: 168 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.6573) 1000
169 1000 -1000.0 -99.99568287525881 number episode from 10: 169 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.6573) 1000
170 1000 -1000.0 -99.99568287525881 number episode from 10: 170 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.6572) 1000
171 1000 -1000.0 -99.99568287525881 number episode from 10: 171 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.6562) 1000
172 1000 -1000.0 -99.99568287525881 number episode from 10: 172 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.6565) 1000
173 1000 -1000.0 -99.99568287525881 number episode from 10: 173 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.6573) 1000
174 1000 -1000.0 -99.99568287525881 number episode from 10: 174 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.6556) 1000
175 1000 -1000.0 -99.99568287525881 number episode from 10: 175 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.6556) 1000
176 1000 -1000.0 -99.99568287525881 number episode from 10: 176 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.6557) 1000
177 1000 -1000.0 -99.99568287525881 number episode from 10: 177 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.6555) 1000
178 1000 -1000.0 -99.99568287525881 number episode from 10: 178 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.6553) 1000
179 1000 -1000.0 -99.99568287525881 number episode from 10: 179 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.6556) 1000
180 1000 -1000.0 -99.99568287525881 number episode from 10: 180 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.6554) 1000
181 1000 -1000.0 -99.99568287525881 number episode from 10: 181 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.6568) 1000
182 1000 -1000.0 -99.99568287525881 number episode from 10: 182 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.6555) 1000
183 1000 -1000.0 -99.99568287525881 number episode from 10: 183 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.6569) 1000
184 1000 -1000.0 -99.99568287525881 number episode from 10: 184 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.6559) 1000
185 1000 -1000.0 -99.99568287525881 number episode from 10: 185 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.6554) 1000
186 1000 -1000.0 -99.99568287525881 number episode from 10: 186 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.6555) 1000
187 1000 -1000.0 -99.99568287525881 number episode from 10: 187 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.6573) 1000
188 1000 -1000.0 -99.99568287525881 number episode from 10: 188 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.6569) 1000
189 1000 -1000.0 -99.99568287525881 number episode from 10: 189 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.6557) 1000
190 1000 -1000.0 -99.99568287525881 number episode from 10: 190 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.6558) 1000
191 1000 -1000.0 -99.99568287525881 number episode from 10: 191 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.6573) 1000
192 1000 -1000.0 -99.99568287525881 number episode from 10: 192 avegar over 10 episode: -99.991 avegare return across last 100 episodes: -99.996 state values: tensor(0.6573) 1000
193 1000 -1000.0 -99.99568287525881 number episode from 10: 193 avegar over 10 episode: -99.991 avegare return across last 100 episodes: -99.996 state values: tensor(0.6570) 1000
194 1000 -1000.0 -99.99568287525881 number episode from 10: 194 avegar over 10 episode: -99.991 avegare return across last 100 episodes: -99.996 state values: tensor(0.6552) 1000
195 1000 -1000.0 -99.99568287525881 number episode from 10: 195 avegar over 10 episode: -99.991 avegare return across last 100 episodes: -99.996 state values: tensor(0.6558) 1000
196 1000 -1000.0 -99.99568287525881 number episode from 10: 196 avegar over 10 episode: -99.991 avegare return across last 100 episodes: -99.996 state values: tensor(0.6557) 1000
197 1000 -1000.0 -99.99568287525881 number episode from 10: 197 avegar over 10 episode: -99.991 avegare return across last 100 episodes: -99.996 state values: tensor(0.6567) 1000
198 1000 -1000.0 -99.99568287525881 number episode from 10: 198 avegar over 10 episode: -99.991 avegare return across last 100 episodes: -99.996 state values: tensor(0.6556) 1000
199 1000 -1000.0 -99.99568287525881 number episode from 10: 199 avegar over 10 episode: -99.991 avegare return across last 100 episodes: -99.996 state values: tensor(0.6556) 1000
200 1000 -1000.0 -99.99568287525881 number episode from 10: 200 avegar over 10 episode: -99.991 avegare return across last 100 episodes: -99.996 state values: tensor(0.6555) 1000
load offline data!!!!!
mem_cntr: 50000 ; mem_size: 50000
nn.learn_nn_feature_fqi FQI:  998
nn.learn_nn_feature_fqi FQI:  1998
nn.learn_nn_feature_fqi FQI:  2998
nn.learn_nn_feature_fqi FQI:  3998
nn.learn_nn_feature_fqi FQI:  4998
nn.learn_nn_feature_fqi FQI:  5998
nn.learn_nn_feature_fqi FQI:  6998
nn.learn_nn_feature_fqi FQI:  7998
nn.learn_nn_feature_fqi FQI:  8998
nn.learn_nn_feature_fqi FQI:  9998
nn.learn_nn_feature_fqi FQI:  10998
nn.learn_nn_feature_fqi FQI:  11998
nn.learn_nn_feature_fqi FQI:  12998
nn.learn_nn_feature_fqi FQI:  13998
nn.learn_nn_feature_fqi FQI:  14998
nn.learn_nn_feature_fqi FQI:  15998
nn.learn_nn_feature_fqi FQI:  16998
nn.learn_nn_feature_fqi FQI:  17998
nn.learn_nn_feature_fqi FQI:  18998
nn.learn_nn_feature_fqi FQI:  19998
nn.learn_nn_feature_fqi FQI:  20998
nn.learn_nn_feature_fqi FQI:  21998
nn.learn_nn_feature_fqi FQI:  22998
nn.learn_nn_feature_fqi FQI:  23998
nn.learn_nn_feature_fqi FQI:  24998
nn.learn_nn_feature_fqi FQI:  25998
nn.learn_nn_feature_fqi FQI:  26998
nn.learn_nn_feature_fqi FQI:  27998
nn.learn_nn_feature_fqi FQI:  28998
nn.learn_nn_feature_fqi FQI:  29998
nn.learn_nn_feature_fqi FQI:  30998
nn.learn_nn_feature_fqi FQI:  31998
nn.learn_nn_feature_fqi FQI:  32998
nn.learn_nn_feature_fqi FQI:  33998
nn.learn_nn_feature_fqi FQI:  34998
nn.learn_nn_feature_fqi FQI:  35998
nn.learn_nn_feature_fqi FQI:  36998
nn.learn_nn_feature_fqi FQI:  37998
nn.learn_nn_feature_fqi FQI:  38998
nn.learn_nn_feature_fqi FQI:  39998
nn.learn_nn_feature_fqi FQI:  40998
nn.learn_nn_feature_fqi FQI:  41998
nn.learn_nn_feature_fqi FQI:  42998
nn.learn_nn_feature_fqi FQI:  43998
nn.learn_nn_feature_fqi FQI:  44998
nn.learn_nn_feature_fqi FQI:  45998
nn.learn_nn_feature_fqi FQI:  46998
nn.learn_nn_feature_fqi FQI:  47998
nn.learn_nn_feature_fqi FQI:  48998
nn.learn_nn_feature_fqi FQI:  49998
nn.learn_nn_feature_fqi FQI:  50998
nn.learn_nn_feature_fqi FQI:  51998
nn.learn_nn_feature_fqi FQI:  52998
nn.learn_nn_feature_fqi FQI:  53998
nn.learn_nn_feature_fqi FQI:  54998
nn.learn_nn_feature_fqi FQI:  55998
nn.learn_nn_feature_fqi FQI:  56998
nn.learn_nn_feature_fqi FQI:  57998
nn.learn_nn_feature_fqi FQI:  58998
nn.learn_nn_feature_fqi FQI:  59998
nn.learn_nn_feature_fqi FQI:  60998
nn.learn_nn_feature_fqi FQI:  61998
nn.learn_nn_feature_fqi FQI:  62998
nn.learn_nn_feature_fqi FQI:  63998
nn.learn_nn_feature_fqi FQI:  64998
nn.learn_nn_feature_fqi FQI:  65998
nn.learn_nn_feature_fqi FQI:  66998
nn.learn_nn_feature_fqi FQI:  67998
nn.learn_nn_feature_fqi FQI:  68998
nn.learn_nn_feature_fqi FQI:  69998
nn.learn_nn_feature_fqi FQI:  70998
nn.learn_nn_feature_fqi FQI:  71998
nn.learn_nn_feature_fqi FQI:  72998
nn.learn_nn_feature_fqi FQI:  73998
nn.learn_nn_feature_fqi FQI:  74998
nn.learn_nn_feature_fqi FQI:  75998
nn.learn_nn_feature_fqi FQI:  76998
nn.learn_nn_feature_fqi FQI:  77998
nn.learn_nn_feature_fqi FQI:  78998
nn.learn_nn_feature_fqi FQI:  79998
nn.learn_nn_feature_fqi FQI:  80998
nn.learn_nn_feature_fqi FQI:  81998
nn.learn_nn_feature_fqi FQI:  82998
nn.learn_nn_feature_fqi FQI:  83998
nn.learn_nn_feature_fqi FQI:  84998
nn.learn_nn_feature_fqi FQI:  85998
nn.learn_nn_feature_fqi FQI:  86998
nn.learn_nn_feature_fqi FQI:  87998
nn.learn_nn_feature_fqi FQI:  88998
nn.learn_nn_feature_fqi FQI:  89998
nn.learn_nn_feature_fqi FQI:  90998
nn.learn_nn_feature_fqi FQI:  91998
nn.learn_nn_feature_fqi FQI:  92998
nn.learn_nn_feature_fqi FQI:  93998
nn.learn_nn_feature_fqi FQI:  94998
nn.learn_nn_feature_fqi FQI:  95998
nn.learn_nn_feature_fqi FQI:  96998
nn.learn_nn_feature_fqi FQI:  97998
nn.learn_nn_feature_fqi FQI:  98998
nn.learn_nn_feature_fqi FQI:  99998
nn.learn_nn_feature_fqi FQI:  100998
nn.learn_nn_feature_fqi FQI:  101998
nn.learn_nn_feature_fqi FQI:  102998
nn.learn_nn_feature_fqi FQI:  103998
nn.learn_nn_feature_fqi FQI:  104998
nn.learn_nn_feature_fqi FQI:  105998
nn.learn_nn_feature_fqi FQI:  106998
nn.learn_nn_feature_fqi FQI:  107998
nn.learn_nn_feature_fqi FQI:  108998
nn.learn_nn_feature_fqi FQI:  109998
nn.learn_nn_feature_fqi FQI:  110998
nn.learn_nn_feature_fqi FQI:  111998
nn.learn_nn_feature_fqi FQI:  112998
nn.learn_nn_feature_fqi FQI:  113998
nn.learn_nn_feature_fqi FQI:  114998
nn.learn_nn_feature_fqi FQI:  115998
nn.learn_nn_feature_fqi FQI:  116998
nn.learn_nn_feature_fqi FQI:  117998
nn.learn_nn_feature_fqi FQI:  118998
nn.learn_nn_feature_fqi FQI:  119998
nn.learn_nn_feature_fqi FQI:  120998
nn.learn_nn_feature_fqi FQI:  121998
nn.learn_nn_feature_fqi FQI:  122998
nn.learn_nn_feature_fqi FQI:  123998
nn.learn_nn_feature_fqi FQI:  124998
nn.learn_nn_feature_fqi FQI:  125998
nn.learn_nn_feature_fqi FQI:  126998
nn.learn_nn_feature_fqi FQI:  127998
nn.learn_nn_feature_fqi FQI:  128998
nn.learn_nn_feature_fqi FQI:  129998
nn.learn_nn_feature_fqi FQI:  130998
nn.learn_nn_feature_fqi FQI:  131998
nn.learn_nn_feature_fqi FQI:  132998
nn.learn_nn_feature_fqi FQI:  133998
nn.learn_nn_feature_fqi FQI:  134998
nn.learn_nn_feature_fqi FQI:  135998
nn.learn_nn_feature_fqi FQI:  136998
nn.learn_nn_feature_fqi FQI:  137998
nn.learn_nn_feature_fqi FQI:  138998
nn.learn_nn_feature_fqi FQI:  139998
nn.learn_nn_feature_fqi FQI:  140998
nn.learn_nn_feature_fqi FQI:  141998
nn.learn_nn_feature_fqi FQI:  142998
nn.learn_nn_feature_fqi FQI:  143998
nn.learn_nn_feature_fqi FQI:  144998
nn.learn_nn_feature_fqi FQI:  145998
nn.learn_nn_feature_fqi FQI:  146998
nn.learn_nn_feature_fqi FQI:  147998
nn.learn_nn_feature_fqi FQI:  148998
nn.learn_nn_feature_fqi FQI:  149998
nn.learn_nn_feature_fqi FQI:  150998
nn.learn_nn_feature_fqi FQI:  151998
nn.learn_nn_feature_fqi FQI:  152998
nn.learn_nn_feature_fqi FQI:  153998
nn.learn_nn_feature_fqi FQI:  154998
nn.learn_nn_feature_fqi FQI:  155998
0 1001 -1000.0 -98.99572604650622 number episode from 10: 0 avegar over 10 episode: -98.996 avegare return across last 100 episodes: -98.996 state values: tensor(0.9595) 1000
1 286 -286.0 -94.3549777909171 number episode from 10: 1 avegar over 10 episode: -96.675 avegare return across last 100 episodes: -96.675 state values: tensor(0.7714) 286
2 253 -253.0 -92.13490028263506 number episode from 10: 2 avegar over 10 episode: -95.162 avegare return across last 100 episodes: -95.162 state values: tensor(0.7372) 253
3 256 -256.0 -92.36850160934051 number episode from 10: 3 avegar over 10 episode: -94.464 avegare return across last 100 episodes: -94.464 state values: tensor(0.7388) 256
4 285 -285.0 -94.29795736456273 number episode from 10: 4 avegar over 10 episode: -94.43 avegare return across last 100 episodes: -94.43 state values: tensor(0.7784) 285
5 250 -250.0 -91.89414838378175 number episode from 10: 5 avegar over 10 episode: -94.008 avegare return across last 100 episodes: -94.008 state values: tensor(0.7434) 250
6 278 -278.0 -93.88235744602936 number episode from 10: 6 avegar over 10 episode: -93.99 avegare return across last 100 episodes: -93.99 state values: tensor(0.7723) 278
7 274 -274.0 -93.63140957251046 number episode from 10: 7 avegar over 10 episode: -93.945 avegare return across last 100 episodes: -93.945 state values: tensor(0.7694) 274
8 281 -281.0 -94.06405754752483 number episode from 10: 8 avegar over 10 episode: -93.958 avegare return across last 100 episodes: -93.958 state values: tensor(0.7685) 281
9 247 -247.0 -91.64602703267936 number episode from 10: 9 avegar over 10 episode: -93.727 avegare return across last 100 episodes: -93.727 state values: tensor(0.7382) 247
10 278 -278.0 -93.88235744602936 number episode from 10: 10 avegar over 10 episode: -93.741 avegare return across last 100 episodes: -93.741 state values: tensor(0.7671) 278
11 257 -257.0 -92.44481659324711 number episode from 10: 11 avegar over 10 episode: -93.633 avegare return across last 100 episodes: -93.633 state values: tensor(0.7325) 257
12 775 -775.0 -99.95857373174603 number episode from 10: 12 avegar over 10 episode: -94.12 avegare return across last 100 episodes: -94.12 state values: tensor(0.9064) 775
13 273 -273.0 -93.5670803762732 number episode from 10: 13 avegar over 10 episode: -94.08 avegare return across last 100 episodes: -94.08 state values: tensor(0.7623) 273
14 374 -374.0 -97.66888993521565 number episode from 10: 14 avegar over 10 episode: -94.319 avegare return across last 100 episodes: -94.319 state values: tensor(0.7731) 374
15 285 -285.0 -94.29795736456273 number episode from 10: 15 avegar over 10 episode: -94.318 avegare return across last 100 episodes: -94.318 state values: tensor(0.7741) 285
16 253 -253.0 -92.13490028263506 number episode from 10: 16 avegar over 10 episode: -94.19 avegare return across last 100 episodes: -94.19 state values: tensor(0.7476) 253
17 1000 -1000.0 -99.99568287525881 number episode from 10: 17 avegar over 10 episode: -94.512 avegare return across last 100 episodes: -94.512 state values: tensor(0.9510) 1000
18 261 -261.0 -92.74252096465497 number episode from 10: 18 avegar over 10 episode: -94.419 avegare return across last 100 episodes: -94.419 state values: tensor(0.7415) 261
19 247 -247.0 -91.64602703267936 number episode from 10: 19 avegar over 10 episode: -94.28 avegare return across last 100 episodes: -94.28 state values: tensor(0.7426) 247
20 389 -389.0 -97.99510931319382 number episode from 10: 20 avegar over 10 episode: -94.457 avegare return across last 100 episodes: -94.457 state values: tensor(0.7724) 389
21 249 -249.0 -91.81227109472904 number episode from 10: 21 avegar over 10 episode: -94.337 avegare return across last 100 episodes: -94.337 state values: tensor(0.7349) 249
22 246 -246.0 -91.56164346735288 number episode from 10: 22 avegar over 10 episode: -94.216 avegare return across last 100 episodes: -94.216 state values: tensor(0.7429) 246
23 284 -284.0 -94.24036097430579 number episode from 10: 23 avegar over 10 episode: -94.217 avegare return across last 100 episodes: -94.217 state values: tensor(0.7738) 284
24 990 -990.0 -99.99522643707735 number episode from 10: 24 avegar over 10 episode: -94.449 avegare return across last 100 episodes: -94.449 state values: tensor(0.9337) 990
25 246 -246.0 -91.56164346735288 number episode from 10: 25 avegar over 10 episode: -94.338 avegare return across last 100 episodes: -94.338 state values: tensor(0.7421) 246
26 281 -281.0 -94.06405754752483 number episode from 10: 26 avegar over 10 episode: -94.327 avegare return across last 100 episodes: -94.327 state values: tensor(0.7725) 281
27 263 -263.0 -92.88694479745833 number episode from 10: 27 avegar over 10 episode: -94.276 avegare return across last 100 episodes: -94.276 state values: tensor(0.7520) 263
28 978 -978.0 -99.9946145708541 number episode from 10: 28 avegar over 10 episode: -94.473 avegare return across last 100 episodes: -94.473 state values: tensor(0.9323) 978
29 248 -248.0 -91.72956676235256 number episode from 10: 29 avegar over 10 episode: -94.382 avegare return across last 100 episodes: -94.382 state values: tensor(0.7425) 248
30 1000 -1000.0 -99.99568287525881 number episode from 10: 30 avegar over 10 episode: -94.563 avegare return across last 100 episodes: -94.563 state values: tensor(0.9522) 1000
31 249 -249.0 -91.81227109472904 number episode from 10: 31 avegar over 10 episode: -94.477 avegare return across last 100 episodes: -94.477 state values: tensor(0.7447) 249
32 252 -252.0 -92.0554548309445 number episode from 10: 32 avegar over 10 episode: -94.403 avegare return across last 100 episodes: -94.403 state values: tensor(0.7356) 252
33 257 -257.0 -92.44481659324711 number episode from 10: 33 avegar over 10 episode: -94.346 avegare return across last 100 episodes: -94.346 state values: tensor(0.7397) 257
34 248 -248.0 -91.72956676235256 number episode from 10: 34 avegar over 10 episode: -94.271 avegare return across last 100 episodes: -94.271 state values: tensor(0.7423) 248
35 267 -267.0 -93.16722755352873 number episode from 10: 35 avegar over 10 episode: -94.24 avegare return across last 100 episodes: -94.24 state values: tensor(0.7556) 267
36 244 -244.0 -91.39031064927343 number episode from 10: 36 avegar over 10 episode: -94.163 avegare return across last 100 episodes: -94.163 state values: tensor(0.7372) 244
37 1000 -1000.0 -99.99568287525881 number episode from 10: 37 avegar over 10 episode: -94.317 avegare return across last 100 episodes: -94.317 state values: tensor(0.9535) 1000
38 251 -251.0 -91.97520689994394 number episode from 10: 38 avegar over 10 episode: -94.257 avegare return across last 100 episodes: -94.257 state values: tensor(0.7281) 251
39 251 -251.0 -91.97520689994394 number episode from 10: 39 avegar over 10 episode: -94.2 avegare return across last 100 episodes: -94.2 state values: tensor(0.7468) 251
40 1000 -1000.0 -99.99568287525881 number episode from 10: 40 avegar over 10 episode: -94.341 avegare return across last 100 episodes: -94.341 state values: tensor(0.9556) 1000
41 248 -248.0 -91.72956676235256 number episode from 10: 41 avegar over 10 episode: -94.279 avegare return across last 100 episodes: -94.279 state values: tensor(0.7430) 248
42 263 -263.0 -92.88694479745833 number episode from 10: 42 avegar over 10 episode: -94.247 avegare return across last 100 episodes: -94.247 state values: tensor(0.7515) 263
43 250 -250.0 -91.89414838378175 number episode from 10: 43 avegar over 10 episode: -94.193 avegare return across last 100 episodes: -94.193 state values: tensor(0.7398) 250
44 245 -245.0 -91.47640754278069 number episode from 10: 44 avegar over 10 episode: -94.133 avegare return across last 100 episodes: -94.133 state values: tensor(0.7375) 245
45 251 -251.0 -91.97520689994394 number episode from 10: 45 avegar over 10 episode: -94.086 avegare return across last 100 episodes: -94.086 state values: tensor(0.7440) 251
46 244 -244.0 -91.39031064927343 number episode from 10: 46 avegar over 10 episode: -94.029 avegare return across last 100 episodes: -94.029 state values: tensor(0.7373) 244
47 259 -259.0 -92.5951647430415 number episode from 10: 47 avegar over 10 episode: -93.999 avegare return across last 100 episodes: -93.999 state values: tensor(0.7415) 259
48 248 -248.0 -91.72956676235256 number episode from 10: 48 avegar over 10 episode: -93.952 avegare return across last 100 episodes: -93.952 state values: tensor(0.7449) 248
49 1000 -1000.0 -99.99568287525881 number episode from 10: 49 avegar over 10 episode: -94.073 avegare return across last 100 episodes: -94.073 state values: tensor(0.9543) 1000
50 247 -247.0 -91.64602703267936 number episode from 10: 50 avegar over 10 episode: -94.026 avegare return across last 100 episodes: -94.026 state values: tensor(0.7399) 247
51 261 -261.0 -92.74252096465497 number episode from 10: 51 avegar over 10 episode: -94.001 avegare return across last 100 episodes: -94.001 state values: tensor(0.7506) 261
52 249 -249.0 -91.81227109472904 number episode from 10: 52 avegar over 10 episode: -93.96 avegare return across last 100 episodes: -93.96 state values: tensor(0.7439) 249
53 276 -276.0 -93.7581445220175 number episode from 10: 53 avegar over 10 episode: -93.956 avegare return across last 100 episodes: -93.956 state values: tensor(0.7667) 276
54 247 -247.0 -91.64602703267936 number episode from 10: 54 avegar over 10 episode: -93.914 avegare return across last 100 episodes: -93.914 state values: tensor(0.7436) 247
55 276 -276.0 -93.7581445220175 number episode from 10: 55 avegar over 10 episode: -93.911 avegare return across last 100 episodes: -93.911 state values: tensor(0.7659) 276
56 249 -249.0 -91.81227109472904 number episode from 10: 56 avegar over 10 episode: -93.874 avegare return across last 100 episodes: -93.874 state values: tensor(0.7428) 249
57 245 -245.0 -91.47640754278069 number episode from 10: 57 avegar over 10 episode: -93.833 avegare return across last 100 episodes: -93.833 state values: tensor(0.7417) 245
58 247 -247.0 -91.64602703267936 number episode from 10: 58 avegar over 10 episode: -93.796 avegare return across last 100 episodes: -93.796 state values: tensor(0.7416) 247
59 1000 -1000.0 -99.99568287525881 number episode from 10: 59 avegar over 10 episode: -93.899 avegare return across last 100 episodes: -93.899 state values: tensor(0.9539) 1000
60 244 -244.0 -91.39031064927343 number episode from 10: 60 avegar over 10 episode: -93.858 avegare return across last 100 episodes: -93.858 state values: tensor(0.7374) 244
61 1000 -1000.0 -99.99568287525881 number episode from 10: 61 avegar over 10 episode: -93.957 avegare return across last 100 episodes: -93.957 state values: tensor(0.9504) 1000
62 271 -271.0 -93.43646605068176 number episode from 10: 62 avegar over 10 episode: -93.949 avegare return across last 100 episodes: -93.949 state values: tensor(0.7593) 271
63 1000 -1000.0 -99.99568287525881 number episode from 10: 63 avegar over 10 episode: -94.043 avegare return across last 100 episodes: -94.043 state values: tensor(0.9552) 1000
64 252 -252.0 -92.0554548309445 number episode from 10: 64 avegar over 10 episode: -94.013 avegare return across last 100 episodes: -94.013 state values: tensor(0.7414) 252
65 277 -277.0 -93.82056307679733 number episode from 10: 65 avegar over 10 episode: -94.01 avegare return across last 100 episodes: -94.01 state values: tensor(0.7713) 277
66 1000 -1000.0 -99.99568287525881 number episode from 10: 66 avegar over 10 episode: -94.099 avegare return across last 100 episodes: -94.099 state values: tensor(0.9532) 1000
67 246 -246.0 -91.56164346735288 number episode from 10: 67 avegar over 10 episode: -94.062 avegare return across last 100 episodes: -94.062 state values: tensor(0.7392) 246
68 247 -247.0 -91.64602703267936 number episode from 10: 68 avegar over 10 episode: -94.027 avegare return across last 100 episodes: -94.027 state values: tensor(0.7357) 247
69 249 -249.0 -91.81227109472904 number episode from 10: 69 avegar over 10 episode: -93.995 avegare return across last 100 episodes: -93.995 state values: tensor(0.7450) 249
70 247 -247.0 -91.64602703267936 number episode from 10: 70 avegar over 10 episode: -93.962 avegare return across last 100 episodes: -93.962 state values: tensor(0.7436) 247
71 250 -250.0 -91.89414838378175 number episode from 10: 71 avegar over 10 episode: -93.933 avegare return across last 100 episodes: -93.933 state values: tensor(0.7408) 250
72 257 -257.0 -92.44481659324711 number episode from 10: 72 avegar over 10 episode: -93.913 avegare return across last 100 episodes: -93.913 state values: tensor(0.7403) 257
73 252 -252.0 -92.0554548309445 number episode from 10: 73 avegar over 10 episode: -93.888 avegare return across last 100 episodes: -93.888 state values: tensor(0.7309) 252
74 248 -248.0 -91.72956676235256 number episode from 10: 74 avegar over 10 episode: -93.859 avegare return across last 100 episodes: -93.859 state values: tensor(0.7447) 248
75 245 -245.0 -91.47640754278069 number episode from 10: 75 avegar over 10 episode: -93.828 avegare return across last 100 episodes: -93.828 state values: tensor(0.7447) 245
76 1000 -1000.0 -99.99568287525881 number episode from 10: 76 avegar over 10 episode: -93.908 avegare return across last 100 episodes: -93.908 state values: tensor(0.9551) 1000
77 250 -250.0 -91.89414838378175 number episode from 10: 77 avegar over 10 episode: -93.882 avegare return across last 100 episodes: -93.882 state values: tensor(0.7425) 250
78 250 -250.0 -91.89414838378175 number episode from 10: 78 avegar over 10 episode: -93.857 avegare return across last 100 episodes: -93.857 state values: tensor(0.7406) 250
79 252 -252.0 -92.0554548309445 number episode from 10: 79 avegar over 10 episode: -93.834 avegare return across last 100 episodes: -93.834 state values: tensor(0.7418) 252
80 255 -255.0 -92.29141576701062 number episode from 10: 80 avegar over 10 episode: -93.815 avegare return across last 100 episodes: -93.815 state values: tensor(0.7451) 255
81 256 -256.0 -92.36850160934051 number episode from 10: 81 avegar over 10 episode: -93.798 avegare return across last 100 episodes: -93.798 state values: tensor(0.7475) 256
82 282 -282.0 -94.12341697204958 number episode from 10: 82 avegar over 10 episode: -93.802 avegare return across last 100 episodes: -93.802 state values: tensor(0.7736) 282
83 247 -247.0 -91.64602703267936 number episode from 10: 83 avegar over 10 episode: -93.776 avegare return across last 100 episodes: -93.776 state values: tensor(0.7452) 247
84 260 -260.0 -92.66921309561108 number episode from 10: 84 avegar over 10 episode: -93.763 avegare return across last 100 episodes: -93.763 state values: tensor(0.7410) 260
85 245 -245.0 -91.47640754278069 number episode from 10: 85 avegar over 10 episode: -93.736 avegare return across last 100 episodes: -93.736 state values: tensor(0.7434) 245
86 256 -256.0 -92.36850160934051 number episode from 10: 86 avegar over 10 episode: -93.721 avegare return across last 100 episodes: -93.721 state values: tensor(0.7393) 256
87 250 -250.0 -91.89414838378175 number episode from 10: 87 avegar over 10 episode: -93.7 avegare return across last 100 episodes: -93.7 state values: tensor(0.7396) 250
88 244 -244.0 -91.39031064927343 number episode from 10: 88 avegar over 10 episode: -93.674 avegare return across last 100 episodes: -93.674 state values: tensor(0.7389) 244
89 247 -247.0 -91.64602703267936 number episode from 10: 89 avegar over 10 episode: -93.651 avegare return across last 100 episodes: -93.651 state values: tensor(0.7435) 247
90 269 -269.0 -93.3031997252135 number episode from 10: 90 avegar over 10 episode: -93.648 avegare return across last 100 episodes: -93.648 state values: tensor(0.7575) 269
91 253 -253.0 -92.13490028263506 number episode from 10: 91 avegar over 10 episode: -93.631 avegare return across last 100 episodes: -93.631 state values: tensor(0.7402) 253
92 254 -254.0 -92.21355127980871 number episode from 10: 92 avegar over 10 episode: -93.616 avegare return across last 100 episodes: -93.616 state values: tensor(0.7343) 254
93 257 -257.0 -92.44481659324711 number episode from 10: 93 avegar over 10 episode: -93.603 avegare return across last 100 episodes: -93.603 state values: tensor(0.7393) 257
94 246 -246.0 -91.56164346735288 number episode from 10: 94 avegar over 10 episode: -93.582 avegare return across last 100 episodes: -93.582 state values: tensor(0.7418) 246
95 998 -998.0 -99.99559522013959 number episode from 10: 95 avegar over 10 episode: -93.649 avegare return across last 100 episodes: -93.649 state values: tensor(0.9277) 998
96 244 -244.0 -91.39031064927343 number episode from 10: 96 avegar over 10 episode: -93.625 avegare return across last 100 episodes: -93.625 state values: tensor(0.7386) 244
97 259 -259.0 -92.5951647430415 number episode from 10: 97 avegar over 10 episode: -93.615 avegare return across last 100 episodes: -93.615 state values: tensor(0.7443) 259
98 246 -246.0 -91.56164346735288 number episode from 10: 98 avegar over 10 episode: -93.594 avegare return across last 100 episodes: -93.594 state values: tensor(0.7431) 246
99 1000 -1000.0 -99.99568287525881 number episode from 10: 99 avegar over 10 episode: -93.658 avegare return across last 100 episodes: -93.658 state values: tensor(0.9559) 1000
100 246 -246.0 -91.56164346735288 number episode from 10: 100 avegar over 10 episode: -93.637 avegare return across last 100 episodes: -93.584 state values: tensor(0.7398) 246
101 256 -256.0 -92.36850160934051 number episode from 10: 101 avegar over 10 episode: -93.625 avegare return across last 100 episodes: -93.564 state values: tensor(0.7495) 256
102 254 -254.0 -92.21355127980871 number episode from 10: 102 avegar over 10 episode: -93.611 avegare return across last 100 episodes: -93.565 state values: tensor(0.7410) 254
103 1000 -1000.0 -99.99568287525881 number episode from 10: 103 avegar over 10 episode: -93.673 avegare return across last 100 episodes: -93.641 state values: tensor(0.9543) 1000
104 278 -278.0 -93.88235744602936 number episode from 10: 104 avegar over 10 episode: -93.675 avegare return across last 100 episodes: -93.637 state values: tensor(0.7713) 278
105 278 -278.0 -93.88235744602936 number episode from 10: 105 avegar over 10 episode: -93.677 avegare return across last 100 episodes: -93.657 state values: tensor(0.7710) 278
106 247 -247.0 -91.64602703267936 number episode from 10: 106 avegar over 10 episode: -93.658 avegare return across last 100 episodes: -93.634 state values: tensor(0.7424) 247
107 244 -244.0 -91.39031064927343 number episode from 10: 107 avegar over 10 episode: -93.637 avegare return across last 100 episodes: -93.612 state values: tensor(0.7381) 244
108 248 -248.0 -91.72956676235256 number episode from 10: 108 avegar over 10 episode: -93.619 avegare return across last 100 episodes: -93.589 state values: tensor(0.7402) 248
109 254 -254.0 -92.21355127980871 number episode from 10: 109 avegar over 10 episode: -93.606 avegare return across last 100 episodes: -93.594 state values: tensor(0.7470) 254
110 275 -275.0 -93.69509547678535 number episode from 10: 110 avegar over 10 episode: -93.607 avegare return across last 100 episodes: -93.592 state values: tensor(0.7675) 275
111 253 -253.0 -92.13490028263506 number episode from 10: 111 avegar over 10 episode: -93.594 avegare return across last 100 episodes: -93.589 state values: tensor(0.7410) 253
112 283 -283.0 -94.18218280232908 number episode from 10: 112 avegar over 10 episode: -93.599 avegare return across last 100 episodes: -93.532 state values: tensor(0.7685) 283
113 250 -250.0 -91.89414838378175 number episode from 10: 113 avegar over 10 episode: -93.584 avegare return across last 100 episodes: -93.515 state values: tensor(0.7393) 250
114 247 -247.0 -91.64602703267936 number episode from 10: 114 avegar over 10 episode: -93.567 avegare return across last 100 episodes: -93.455 state values: tensor(0.7364) 247
115 279 -279.0 -93.94353387156906 number episode from 10: 115 avegar over 10 episode: -93.571 avegare return across last 100 episodes: -93.451 state values: tensor(0.7717) 279
116 247 -247.0 -91.64602703267936 number episode from 10: 116 avegar over 10 episode: -93.554 avegare return across last 100 episodes: -93.446 state values: tensor(0.7425) 247
117 251 -251.0 -91.97520689994394 number episode from 10: 117 avegar over 10 episode: -93.541 avegare return across last 100 episodes: -93.366 state values: tensor(0.7418) 251
118 244 -244.0 -91.39031064927343 number episode from 10: 118 avegar over 10 episode: -93.523 avegare return across last 100 episodes: -93.352 state values: tensor(0.7345) 244
119 251 -251.0 -91.97520689994394 number episode from 10: 119 avegar over 10 episode: -93.51 avegare return across last 100 episodes: -93.356 state values: tensor(0.7473) 251
120 243 -243.0 -91.30334409017519 number episode from 10: 120 avegar over 10 episode: -93.492 avegare return across last 100 episodes: -93.289 state values: tensor(0.7318) 243
121 256 -256.0 -92.36850160934051 number episode from 10: 121 avegar over 10 episode: -93.482 avegare return across last 100 episodes: -93.294 state values: tensor(0.7418) 256
122 251 -251.0 -91.97520689994394 number episode from 10: 122 avegar over 10 episode: -93.47 avegare return across last 100 episodes: -93.299 state values: tensor(0.7355) 251
123 241 -241.0 -91.12676674846973 number episode from 10: 123 avegar over 10 episode: -93.451 avegare return across last 100 episodes: -93.267 state values: tensor(0.7347) 241
124 252 -252.0 -92.0554548309445 number episode from 10: 124 avegar over 10 episode: -93.44 avegare return across last 100 episodes: -93.188 state values: tensor(0.7386) 252
125 276 -276.0 -93.7581445220175 number episode from 10: 125 avegar over 10 episode: -93.443 avegare return across last 100 episodes: -93.21 state values: tensor(0.7697) 276
126 245 -245.0 -91.47640754278069 number episode from 10: 126 avegar over 10 episode: -93.427 avegare return across last 100 episodes: -93.184 state values: tensor(0.7367) 245
127 253 -253.0 -92.13490028263506 number episode from 10: 127 avegar over 10 episode: -93.417 avegare return across last 100 episodes: -93.177 state values: tensor(0.7459) 253
128 254 -254.0 -92.21355127980871 number episode from 10: 128 avegar over 10 episode: -93.408 avegare return across last 100 episodes: -93.099 state values: tensor(0.7378) 254
129 277 -277.0 -93.82056307679733 number episode from 10: 129 avegar over 10 episode: -93.411 avegare return across last 100 episodes: -93.12 state values: tensor(0.7692) 277
130 255 -255.0 -92.29141576701062 number episode from 10: 130 avegar over 10 episode: -93.402 avegare return across last 100 episodes: -93.043 state values: tensor(0.7466) 255
131 281 -281.0 -94.06405754752483 number episode from 10: 131 avegar over 10 episode: -93.407 avegare return across last 100 episodes: -93.065 state values: tensor(0.7735) 281
132 281 -281.0 -94.06405754752483 number episode from 10: 132 avegar over 10 episode: -93.412 avegare return across last 100 episodes: -93.085 state values: tensor(0.7666) 281
133 1000 -1000.0 -99.99568287525881 number episode from 10: 133 avegar over 10 episode: -93.461 avegare return across last 100 episodes: -93.161 state values: tensor(0.9542) 1000
134 247 -247.0 -91.64602703267936 number episode from 10: 134 avegar over 10 episode: -93.448 avegare return across last 100 episodes: -93.16 state values: tensor(0.7418) 247
135 283 -283.0 -94.18218280232908 number episode from 10: 135 avegar over 10 episode: -93.453 avegare return across last 100 episodes: -93.17 state values: tensor(0.7735) 283
136 272 -272.0 -93.50210139017494 number episode from 10: 136 avegar over 10 episode: -93.454 avegare return across last 100 episodes: -93.191 state values: tensor(0.7658) 272
137 277 -277.0 -93.82056307679733 number episode from 10: 137 avegar over 10 episode: -93.456 avegare return across last 100 episodes: -93.129 state values: tensor(0.7656) 277
138 249 -249.0 -91.81227109472904 number episode from 10: 138 avegar over 10 episode: -93.445 avegare return across last 100 episodes: -93.128 state values: tensor(0.7432) 249
139 270 -270.0 -93.37016772796137 number episode from 10: 139 avegar over 10 episode: -93.444 avegare return across last 100 episodes: -93.142 state values: tensor(0.7569) 270
140 267 -267.0 -93.16722755352873 number episode from 10: 140 avegar over 10 episode: -93.442 avegare return across last 100 episodes: -93.073 state values: tensor(0.7570) 267
141 256 -256.0 -92.36850160934051 number episode from 10: 141 avegar over 10 episode: -93.435 avegare return across last 100 episodes: -93.08 state values: tensor(0.7386) 256
142 252 -252.0 -92.0554548309445 number episode from 10: 142 avegar over 10 episode: -93.425 avegare return across last 100 episodes: -93.072 state values: tensor(0.7348) 252
143 249 -249.0 -91.81227109472904 number episode from 10: 143 avegar over 10 episode: -93.414 avegare return across last 100 episodes: -93.071 state values: tensor(0.7361) 249
144 252 -252.0 -92.0554548309445 number episode from 10: 144 avegar over 10 episode: -93.404 avegare return across last 100 episodes: -93.077 state values: tensor(0.7357) 252
145 277 -277.0 -93.82056307679733 number episode from 10: 145 avegar over 10 episode: -93.407 avegare return across last 100 episodes: -93.095 state values: tensor(0.7707) 277
146 282 -282.0 -94.12341697204958 number episode from 10: 146 avegar over 10 episode: -93.412 avegare return across last 100 episodes: -93.122 state values: tensor(0.7727) 282
147 275 -275.0 -93.69509547678535 number episode from 10: 147 avegar over 10 episode: -93.414 avegare return across last 100 episodes: -93.133 state values: tensor(0.7704) 275
148 267 -267.0 -93.16722755352873 number episode from 10: 148 avegar over 10 episode: -93.412 avegare return across last 100 episodes: -93.148 state values: tensor(0.7566) 267
149 252 -252.0 -92.0554548309445 number episode from 10: 149 avegar over 10 episode: -93.403 avegare return across last 100 episodes: -93.068 state values: tensor(0.7393) 252
150 265 -265.0 -93.0284945959889 number episode from 10: 150 avegar over 10 episode: -93.401 avegare return across last 100 episodes: -93.082 state values: tensor(0.7550) 265
151 1000 -1000.0 -99.99568287525881 number episode from 10: 151 avegar over 10 episode: -93.444 avegare return across last 100 episodes: -93.155 state values: tensor(0.9498) 1000
152 275 -275.0 -93.69509547678535 number episode from 10: 152 avegar over 10 episode: -93.446 avegare return across last 100 episodes: -93.173 state values: tensor(0.7605) 275
153 249 -249.0 -91.81227109472904 number episode from 10: 153 avegar over 10 episode: -93.435 avegare return across last 100 episodes: -93.154 state values: tensor(0.7374) 249
154 246 -246.0 -91.56164346735288 number episode from 10: 154 avegar over 10 episode: -93.423 avegare return across last 100 episodes: -93.153 state values: tensor(0.7408) 246
155 271 -271.0 -93.43646605068176 number episode from 10: 155 avegar over 10 episode: -93.423 avegare return across last 100 episodes: -93.15 state values: tensor(0.7581) 271
156 244 -244.0 -91.39031064927343 number episode from 10: 156 avegar over 10 episode: -93.41 avegare return across last 100 episodes: -93.146 state values: tensor(0.7373) 244
157 252 -252.0 -92.0554548309445 number episode from 10: 157 avegar over 10 episode: -93.402 avegare return across last 100 episodes: -93.152 state values: tensor(0.7470) 252
158 251 -251.0 -91.97520689994394 number episode from 10: 158 avegar over 10 episode: -93.393 avegare return across last 100 episodes: -93.155 state values: tensor(0.7469) 251
159 246 -246.0 -91.56164346735288 number episode from 10: 159 avegar over 10 episode: -93.381 avegare return across last 100 episodes: -93.07 state values: tensor(0.7355) 246
160 247 -247.0 -91.64602703267936 number episode from 10: 160 avegar over 10 episode: -93.37 avegare return across last 100 episodes: -93.073 state values: tensor(0.7425) 247
161 240 -240.0 -91.03713812976741 number episode from 10: 161 avegar over 10 episode: -93.356 avegare return across last 100 episodes: -92.983 state values: tensor(0.7310) 240
162 1000 -1000.0 -99.99568287525881 number episode from 10: 162 avegar over 10 episode: -93.397 avegare return across last 100 episodes: -93.049 state values: tensor(0.9548) 1000
163 278 -278.0 -93.88235744602936 number episode from 10: 163 avegar over 10 episode: -93.4 avegare return across last 100 episodes: -92.988 state values: tensor(0.7715) 278
164 261 -261.0 -92.74252096465497 number episode from 10: 164 avegar over 10 episode: -93.396 avegare return across last 100 episodes: -92.995 state values: tensor(0.7502) 261
165 248 -248.0 -91.72956676235256 number episode from 10: 165 avegar over 10 episode: -93.386 avegare return across last 100 episodes: -92.974 state values: tensor(0.7387) 248
166 283 -283.0 -94.18218280232908 number episode from 10: 166 avegar over 10 episode: -93.391 avegare return across last 100 episodes: -92.916 state values: tensor(0.7750) 283
167 250 -250.0 -91.89414838378175 number episode from 10: 167 avegar over 10 episode: -93.382 avegare return across last 100 episodes: -92.919 state values: tensor(0.7445) 250
168 1000 -1000.0 -99.99568287525881 number episode from 10: 168 avegar over 10 episode: -93.421 avegare return across last 100 episodes: -93.003 state values: tensor(0.9562) 1000
169 243 -243.0 -91.30334409017519 number episode from 10: 169 avegar over 10 episode: -93.408 avegare return across last 100 episodes: -92.997 state values: tensor(0.7369) 243
170 275 -275.0 -93.69509547678535 number episode from 10: 170 avegar over 10 episode: -93.41 avegare return across last 100 episodes: -93.018 state values: tensor(0.7671) 275
171 254 -254.0 -92.21355127980871 number episode from 10: 171 avegar over 10 episode: -93.403 avegare return across last 100 episodes: -93.021 state values: tensor(0.7340) 254
172 252 -252.0 -92.0554548309445 number episode from 10: 172 avegar over 10 episode: -93.395 avegare return across last 100 episodes: -93.017 state values: tensor(0.7449) 252
173 256 -256.0 -92.36850160934051 number episode from 10: 173 avegar over 10 episode: -93.389 avegare return across last 100 episodes: -93.02 state values: tensor(0.7435) 256
174 266 -266.0 -93.09820965002902 number episode from 10: 174 avegar over 10 episode: -93.388 avegare return across last 100 episodes: -93.034 state values: tensor(0.7557) 266
175 1000 -1000.0 -99.99568287525881 number episode from 10: 175 avegar over 10 episode: -93.425 avegare return across last 100 episodes: -93.119 state values: tensor(0.9543) 1000
176 251 -251.0 -91.97520689994394 number episode from 10: 176 avegar over 10 episode: -93.417 avegare return across last 100 episodes: -93.039 state values: tensor(0.7453) 251
177 1000 -1000.0 -99.99568287525881 number episode from 10: 177 avegar over 10 episode: -93.454 avegare return across last 100 episodes: -93.12 state values: tensor(0.9508) 1000
178 277 -277.0 -93.82056307679733 number episode from 10: 178 avegar over 10 episode: -93.456 avegare return across last 100 episodes: -93.139 state values: tensor(0.7689) 277
179 275 -275.0 -93.69509547678535 number episode from 10: 179 avegar over 10 episode: -93.457 avegare return across last 100 episodes: -93.156 state values: tensor(0.7662) 275
180 246 -246.0 -91.56164346735288 number episode from 10: 180 avegar over 10 episode: -93.447 avegare return across last 100 episodes: -93.148 state values: tensor(0.7420) 246
181 261 -261.0 -92.74252096465497 number episode from 10: 181 avegar over 10 episode: -93.443 avegare return across last 100 episodes: -93.152 state values: tensor(0.7524) 261
182 248 -248.0 -91.72956676235256 number episode from 10: 182 avegar over 10 episode: -93.434 avegare return across last 100 episodes: -93.128 state values: tensor(0.7429) 248
183 272 -272.0 -93.50210139017494 number episode from 10: 183 avegar over 10 episode: -93.434 avegare return across last 100 episodes: -93.147 state values: tensor(0.7595) 272
184 253 -253.0 -92.13490028263506 number episode from 10: 184 avegar over 10 episode: -93.427 avegare return across last 100 episodes: -93.141 state values: tensor(0.7408) 253
185 246 -246.0 -91.56164346735288 number episode from 10: 185 avegar over 10 episode: -93.417 avegare return across last 100 episodes: -93.142 state values: tensor(0.7449) 246
186 1000 -1000.0 -99.99568287525881 number episode from 10: 186 avegar over 10 episode: -93.452 avegare return across last 100 episodes: -93.219 state values: tensor(0.9546) 1000
187 245 -245.0 -91.47640754278069 number episode from 10: 187 avegar over 10 episode: -93.442 avegare return across last 100 episodes: -93.214 state values: tensor(0.7419) 245
188 259 -259.0 -92.5951647430415 number episode from 10: 188 avegar over 10 episode: -93.437 avegare return across last 100 episodes: -93.226 state values: tensor(0.7501) 259
189 252 -252.0 -92.0554548309445 number episode from 10: 189 avegar over 10 episode: -93.43 avegare return across last 100 episodes: -93.231 state values: tensor(0.7410) 252
190 276 -276.0 -93.7581445220175 number episode from 10: 190 avegar over 10 episode: -93.432 avegare return across last 100 episodes: -93.235 state values: tensor(0.7690) 276
191 253 -253.0 -92.13490028263506 number episode from 10: 191 avegar over 10 episode: -93.425 avegare return across last 100 episodes: -93.235 state values: tensor(0.7468) 253
192 247 -247.0 -91.64602703267936 number episode from 10: 192 avegar over 10 episode: -93.416 avegare return across last 100 episodes: -93.229 state values: tensor(0.7403) 247
193 388 -388.0 -97.97485789211497 number episode from 10: 193 avegar over 10 episode: -93.439 avegare return across last 100 episodes: -93.285 state values: tensor(0.7747) 388
194 284 -284.0 -94.24036097430579 number episode from 10: 194 avegar over 10 episode: -93.443 avegare return across last 100 episodes: -93.311 state values: tensor(0.7710) 284
195 257 -257.0 -92.44481659324711 number episode from 10: 195 avegar over 10 episode: -93.438 avegare return across last 100 episodes: -93.236 state values: tensor(0.7403) 257
196 245 -245.0 -91.47640754278069 number episode from 10: 196 avegar over 10 episode: -93.428 avegare return across last 100 episodes: -93.237 state values: tensor(0.7398) 245
197 252 -252.0 -92.0554548309445 number episode from 10: 197 avegar over 10 episode: -93.421 avegare return across last 100 episodes: -93.231 state values: tensor(0.7444) 252
198 244 -244.0 -91.39031064927343 number episode from 10: 198 avegar over 10 episode: -93.411 avegare return across last 100 episodes: -93.23 state values: tensor(0.7374) 244
199 258 -258.0 -92.52036842731464 number episode from 10: 199 avegar over 10 episode: -93.407 avegare return across last 100 episodes: -93.155 state values: tensor(0.7523) 258
200 253 -253.0 -92.13490028263506 number episode from 10: 200 avegar over 10 episode: -93.4 avegare return across last 100 episodes: -93.161 state values: tensor(0.7344) 253
load offline data!!!!!
mem_cntr: 50000 ; mem_size: 50000
nn.learn_nn_feature_fqi FQI:  998
nn.learn_nn_feature_fqi FQI:  1998
nn.learn_nn_feature_fqi FQI:  2998
nn.learn_nn_feature_fqi FQI:  3998
nn.learn_nn_feature_fqi FQI:  4998
nn.learn_nn_feature_fqi FQI:  5998
nn.learn_nn_feature_fqi FQI:  6998
nn.learn_nn_feature_fqi FQI:  7998
nn.learn_nn_feature_fqi FQI:  8998
nn.learn_nn_feature_fqi FQI:  9998
nn.learn_nn_feature_fqi FQI:  10998
nn.learn_nn_feature_fqi FQI:  11998
nn.learn_nn_feature_fqi FQI:  12998
nn.learn_nn_feature_fqi FQI:  13998
nn.learn_nn_feature_fqi FQI:  14998
nn.learn_nn_feature_fqi FQI:  15998
nn.learn_nn_feature_fqi FQI:  16998
nn.learn_nn_feature_fqi FQI:  17998
nn.learn_nn_feature_fqi FQI:  18998
nn.learn_nn_feature_fqi FQI:  19998
nn.learn_nn_feature_fqi FQI:  20998
nn.learn_nn_feature_fqi FQI:  21998
nn.learn_nn_feature_fqi FQI:  22998
nn.learn_nn_feature_fqi FQI:  23998
nn.learn_nn_feature_fqi FQI:  24998
nn.learn_nn_feature_fqi FQI:  25998
nn.learn_nn_feature_fqi FQI:  26998
nn.learn_nn_feature_fqi FQI:  27998
nn.learn_nn_feature_fqi FQI:  28998
nn.learn_nn_feature_fqi FQI:  29998
nn.learn_nn_feature_fqi FQI:  30998
nn.learn_nn_feature_fqi FQI:  31998
nn.learn_nn_feature_fqi FQI:  32998
nn.learn_nn_feature_fqi FQI:  33998
nn.learn_nn_feature_fqi FQI:  34998
nn.learn_nn_feature_fqi FQI:  35998
nn.learn_nn_feature_fqi FQI:  36998
nn.learn_nn_feature_fqi FQI:  37998
nn.learn_nn_feature_fqi FQI:  38998
nn.learn_nn_feature_fqi FQI:  39998
nn.learn_nn_feature_fqi FQI:  40998
nn.learn_nn_feature_fqi FQI:  41998
nn.learn_nn_feature_fqi FQI:  42998
nn.learn_nn_feature_fqi FQI:  43998
nn.learn_nn_feature_fqi FQI:  44998
nn.learn_nn_feature_fqi FQI:  45998
nn.learn_nn_feature_fqi FQI:  46998
nn.learn_nn_feature_fqi FQI:  47998
nn.learn_nn_feature_fqi FQI:  48998
nn.learn_nn_feature_fqi FQI:  49998
nn.learn_nn_feature_fqi FQI:  50998
nn.learn_nn_feature_fqi FQI:  51998
nn.learn_nn_feature_fqi FQI:  52998
nn.learn_nn_feature_fqi FQI:  53998
nn.learn_nn_feature_fqi FQI:  54998
nn.learn_nn_feature_fqi FQI:  55998
nn.learn_nn_feature_fqi FQI:  56998
nn.learn_nn_feature_fqi FQI:  57998
nn.learn_nn_feature_fqi FQI:  58998
nn.learn_nn_feature_fqi FQI:  59998
nn.learn_nn_feature_fqi FQI:  60998
nn.learn_nn_feature_fqi FQI:  61998
nn.learn_nn_feature_fqi FQI:  62998
nn.learn_nn_feature_fqi FQI:  63998
nn.learn_nn_feature_fqi FQI:  64998
nn.learn_nn_feature_fqi FQI:  65998
nn.learn_nn_feature_fqi FQI:  66998
nn.learn_nn_feature_fqi FQI:  67998
nn.learn_nn_feature_fqi FQI:  68998
nn.learn_nn_feature_fqi FQI:  69998
nn.learn_nn_feature_fqi FQI:  70998
nn.learn_nn_feature_fqi FQI:  71998
nn.learn_nn_feature_fqi FQI:  72998
nn.learn_nn_feature_fqi FQI:  73998
nn.learn_nn_feature_fqi FQI:  74998
nn.learn_nn_feature_fqi FQI:  75998
nn.learn_nn_feature_fqi FQI:  76998
nn.learn_nn_feature_fqi FQI:  77998
nn.learn_nn_feature_fqi FQI:  78998
nn.learn_nn_feature_fqi FQI:  79998
nn.learn_nn_feature_fqi FQI:  80998
nn.learn_nn_feature_fqi FQI:  81998
nn.learn_nn_feature_fqi FQI:  82998
nn.learn_nn_feature_fqi FQI:  83998
nn.learn_nn_feature_fqi FQI:  84998
nn.learn_nn_feature_fqi FQI:  85998
nn.learn_nn_feature_fqi FQI:  86998
nn.learn_nn_feature_fqi FQI:  87998
nn.learn_nn_feature_fqi FQI:  88998
nn.learn_nn_feature_fqi FQI:  89998
nn.learn_nn_feature_fqi FQI:  90998
nn.learn_nn_feature_fqi FQI:  91998
nn.learn_nn_feature_fqi FQI:  92998
nn.learn_nn_feature_fqi FQI:  93998
nn.learn_nn_feature_fqi FQI:  94998
nn.learn_nn_feature_fqi FQI:  95998
nn.learn_nn_feature_fqi FQI:  96998
nn.learn_nn_feature_fqi FQI:  97998
nn.learn_nn_feature_fqi FQI:  98998
nn.learn_nn_feature_fqi FQI:  99998
nn.learn_nn_feature_fqi FQI:  100998
nn.learn_nn_feature_fqi FQI:  101998
nn.learn_nn_feature_fqi FQI:  102998
nn.learn_nn_feature_fqi FQI:  103998
nn.learn_nn_feature_fqi FQI:  104998
nn.learn_nn_feature_fqi FQI:  105998
nn.learn_nn_feature_fqi FQI:  106998
nn.learn_nn_feature_fqi FQI:  107998
nn.learn_nn_feature_fqi FQI:  108998
nn.learn_nn_feature_fqi FQI:  109998
nn.learn_nn_feature_fqi FQI:  110998
nn.learn_nn_feature_fqi FQI:  111998
nn.learn_nn_feature_fqi FQI:  112998
nn.learn_nn_feature_fqi FQI:  113998
nn.learn_nn_feature_fqi FQI:  114998
nn.learn_nn_feature_fqi FQI:  115998
nn.learn_nn_feature_fqi FQI:  116998
nn.learn_nn_feature_fqi FQI:  117998
nn.learn_nn_feature_fqi FQI:  118998
nn.learn_nn_feature_fqi FQI:  119998
nn.learn_nn_feature_fqi FQI:  120998
nn.learn_nn_feature_fqi FQI:  121998
nn.learn_nn_feature_fqi FQI:  122998
nn.learn_nn_feature_fqi FQI:  123998
nn.learn_nn_feature_fqi FQI:  124998
nn.learn_nn_feature_fqi FQI:  125998
nn.learn_nn_feature_fqi FQI:  126998
nn.learn_nn_feature_fqi FQI:  127998
nn.learn_nn_feature_fqi FQI:  128998
nn.learn_nn_feature_fqi FQI:  129998
nn.learn_nn_feature_fqi FQI:  130998
nn.learn_nn_feature_fqi FQI:  131998
nn.learn_nn_feature_fqi FQI:  132998
nn.learn_nn_feature_fqi FQI:  133998
nn.learn_nn_feature_fqi FQI:  134998
nn.learn_nn_feature_fqi FQI:  135998
nn.learn_nn_feature_fqi FQI:  136998
nn.learn_nn_feature_fqi FQI:  137998
nn.learn_nn_feature_fqi FQI:  138998
nn.learn_nn_feature_fqi FQI:  139998
nn.learn_nn_feature_fqi FQI:  140998
nn.learn_nn_feature_fqi FQI:  141998
nn.learn_nn_feature_fqi FQI:  142998
nn.learn_nn_feature_fqi FQI:  143998
nn.learn_nn_feature_fqi FQI:  144998
nn.learn_nn_feature_fqi FQI:  145998
nn.learn_nn_feature_fqi FQI:  146998
nn.learn_nn_feature_fqi FQI:  147998
nn.learn_nn_feature_fqi FQI:  148998
nn.learn_nn_feature_fqi FQI:  149998
nn.learn_nn_feature_fqi FQI:  150998
nn.learn_nn_feature_fqi FQI:  151998
nn.learn_nn_feature_fqi FQI:  152998
nn.learn_nn_feature_fqi FQI:  153998
nn.learn_nn_feature_fqi FQI:  154998
nn.learn_nn_feature_fqi FQI:  155998
0 1001 -1000.0 -98.99572604650622 number episode from 10: 0 avegar over 10 episode: -98.996 avegare return across last 100 episodes: -98.996 state values: tensor(0.5374) 1000
1 1000 -1000.0 -99.99568287525881 number episode from 10: 1 avegar over 10 episode: -99.496 avegare return across last 100 episodes: -99.496 state values: tensor(0.5316) 1000
2 1000 -1000.0 -99.99568287525881 number episode from 10: 2 avegar over 10 episode: -99.662 avegare return across last 100 episodes: -99.662 state values: tensor(0.5472) 1000
3 1000 -1000.0 -99.99568287525881 number episode from 10: 3 avegar over 10 episode: -99.746 avegare return across last 100 episodes: -99.746 state values: tensor(0.5396) 1000
4 1000 -1000.0 -99.99568287525881 number episode from 10: 4 avegar over 10 episode: -99.796 avegare return across last 100 episodes: -99.796 state values: tensor(0.5319) 1000
5 1000 -1000.0 -99.99568287525881 number episode from 10: 5 avegar over 10 episode: -99.829 avegare return across last 100 episodes: -99.829 state values: tensor(0.5408) 1000
6 1000 -1000.0 -99.99568287525881 number episode from 10: 6 avegar over 10 episode: -99.853 avegare return across last 100 episodes: -99.853 state values: tensor(0.5546) 1000
7 1000 -1000.0 -99.99568287525881 number episode from 10: 7 avegar over 10 episode: -99.871 avegare return across last 100 episodes: -99.871 state values: tensor(0.5372) 1000
8 1000 -1000.0 -99.99568287525881 number episode from 10: 8 avegar over 10 episode: -99.885 avegare return across last 100 episodes: -99.885 state values: tensor(0.5376) 1000
9 1000 -1000.0 -99.99568287525881 number episode from 10: 9 avegar over 10 episode: -99.896 avegare return across last 100 episodes: -99.896 state values: tensor(0.5306) 1000
10 1000 -1000.0 -99.99568287525881 number episode from 10: 10 avegar over 10 episode: -99.905 avegare return across last 100 episodes: -99.905 state values: tensor(0.5434) 1000
11 1000 -1000.0 -99.99568287525881 number episode from 10: 11 avegar over 10 episode: -99.912 avegare return across last 100 episodes: -99.912 state values: tensor(0.5350) 1000
12 1000 -1000.0 -99.99568287525881 number episode from 10: 12 avegar over 10 episode: -99.919 avegare return across last 100 episodes: -99.919 state values: tensor(0.5337) 1000
13 1000 -1000.0 -99.99568287525881 number episode from 10: 13 avegar over 10 episode: -99.924 avegare return across last 100 episodes: -99.924 state values: tensor(0.5335) 1000
14 1000 -1000.0 -99.99568287525881 number episode from 10: 14 avegar over 10 episode: -99.929 avegare return across last 100 episodes: -99.929 state values: tensor(0.5448) 1000
15 1000 -1000.0 -99.99568287525881 number episode from 10: 15 avegar over 10 episode: -99.933 avegare return across last 100 episodes: -99.933 state values: tensor(0.5352) 1000
16 1000 -1000.0 -99.99568287525881 number episode from 10: 16 avegar over 10 episode: -99.937 avegare return across last 100 episodes: -99.937 state values: tensor(0.5306) 1000
17 1000 -1000.0 -99.99568287525881 number episode from 10: 17 avegar over 10 episode: -99.94 avegare return across last 100 episodes: -99.94 state values: tensor(0.5388) 1000
18 1000 -1000.0 -99.99568287525881 number episode from 10: 18 avegar over 10 episode: -99.943 avegare return across last 100 episodes: -99.943 state values: tensor(0.5360) 1000
19 1000 -1000.0 -99.99568287525881 number episode from 10: 19 avegar over 10 episode: -99.946 avegare return across last 100 episodes: -99.946 state values: tensor(0.5460) 1000
20 1000 -1000.0 -99.99568287525881 number episode from 10: 20 avegar over 10 episode: -99.948 avegare return across last 100 episodes: -99.948 state values: tensor(0.5346) 1000
21 1000 -1000.0 -99.99568287525881 number episode from 10: 21 avegar over 10 episode: -99.95 avegare return across last 100 episodes: -99.95 state values: tensor(0.5352) 1000
22 1000 -1000.0 -99.99568287525881 number episode from 10: 22 avegar over 10 episode: -99.952 avegare return across last 100 episodes: -99.952 state values: tensor(0.5352) 1000
23 1000 -1000.0 -99.99568287525881 number episode from 10: 23 avegar over 10 episode: -99.954 avegare return across last 100 episodes: -99.954 state values: tensor(0.5363) 1000
24 1000 -1000.0 -99.99568287525881 number episode from 10: 24 avegar over 10 episode: -99.956 avegare return across last 100 episodes: -99.956 state values: tensor(0.5332) 1000
25 1000 -1000.0 -99.99568287525881 number episode from 10: 25 avegar over 10 episode: -99.957 avegare return across last 100 episodes: -99.957 state values: tensor(0.5311) 1000
26 1000 -1000.0 -99.99568287525881 number episode from 10: 26 avegar over 10 episode: -99.959 avegare return across last 100 episodes: -99.959 state values: tensor(0.5475) 1000
27 1000 -1000.0 -99.99568287525881 number episode from 10: 27 avegar over 10 episode: -99.96 avegare return across last 100 episodes: -99.96 state values: tensor(0.5322) 1000
28 1000 -1000.0 -99.99568287525881 number episode from 10: 28 avegar over 10 episode: -99.961 avegare return across last 100 episodes: -99.961 state values: tensor(0.5345) 1000
29 1000 -1000.0 -99.99568287525881 number episode from 10: 29 avegar over 10 episode: -99.962 avegare return across last 100 episodes: -99.962 state values: tensor(0.5313) 1000
30 1000 -1000.0 -99.99568287525881 number episode from 10: 30 avegar over 10 episode: -99.963 avegare return across last 100 episodes: -99.963 state values: tensor(0.5317) 1000
31 1000 -1000.0 -99.99568287525881 number episode from 10: 31 avegar over 10 episode: -99.964 avegare return across last 100 episodes: -99.964 state values: tensor(0.5318) 1000
32 1000 -1000.0 -99.99568287525881 number episode from 10: 32 avegar over 10 episode: -99.965 avegare return across last 100 episodes: -99.965 state values: tensor(0.5514) 1000
33 1000 -1000.0 -99.99568287525881 number episode from 10: 33 avegar over 10 episode: -99.966 avegare return across last 100 episodes: -99.966 state values: tensor(0.5305) 1000
34 1000 -1000.0 -99.99568287525881 number episode from 10: 34 avegar over 10 episode: -99.967 avegare return across last 100 episodes: -99.967 state values: tensor(0.7198) 1000
35 1000 -1000.0 -99.99568287525881 number episode from 10: 35 avegar over 10 episode: -99.968 avegare return across last 100 episodes: -99.968 state values: tensor(0.5319) 1000
36 1000 -1000.0 -99.99568287525881 number episode from 10: 36 avegar over 10 episode: -99.969 avegare return across last 100 episodes: -99.969 state values: tensor(0.5308) 1000
37 1000 -1000.0 -99.99568287525881 number episode from 10: 37 avegar over 10 episode: -99.969 avegare return across last 100 episodes: -99.969 state values: tensor(0.5313) 1000
38 1000 -1000.0 -99.99568287525881 number episode from 10: 38 avegar over 10 episode: -99.97 avegare return across last 100 episodes: -99.97 state values: tensor(0.5312) 1000
39 1000 -1000.0 -99.99568287525881 number episode from 10: 39 avegar over 10 episode: -99.971 avegare return across last 100 episodes: -99.971 state values: tensor(0.5333) 1000
40 1000 -1000.0 -99.99568287525881 number episode from 10: 40 avegar over 10 episode: -99.971 avegare return across last 100 episodes: -99.971 state values: tensor(0.5314) 1000
41 1000 -1000.0 -99.99568287525881 number episode from 10: 41 avegar over 10 episode: -99.972 avegare return across last 100 episodes: -99.972 state values: tensor(0.5334) 1000
42 1000 -1000.0 -99.99568287525881 number episode from 10: 42 avegar over 10 episode: -99.972 avegare return across last 100 episodes: -99.972 state values: tensor(0.5347) 1000
43 1000 -1000.0 -99.99568287525881 number episode from 10: 43 avegar over 10 episode: -99.973 avegare return across last 100 episodes: -99.973 state values: tensor(0.5324) 1000
44 1000 -1000.0 -99.99568287525881 number episode from 10: 44 avegar over 10 episode: -99.973 avegare return across last 100 episodes: -99.973 state values: tensor(0.5328) 1000
45 1000 -1000.0 -99.99568287525881 number episode from 10: 45 avegar over 10 episode: -99.974 avegare return across last 100 episodes: -99.974 state values: tensor(0.5322) 1000
46 1000 -1000.0 -99.99568287525881 number episode from 10: 46 avegar over 10 episode: -99.974 avegare return across last 100 episodes: -99.974 state values: tensor(0.5375) 1000
47 1000 -1000.0 -99.99568287525881 number episode from 10: 47 avegar over 10 episode: -99.975 avegare return across last 100 episodes: -99.975 state values: tensor(0.5326) 1000
48 1000 -1000.0 -99.99568287525881 number episode from 10: 48 avegar over 10 episode: -99.975 avegare return across last 100 episodes: -99.975 state values: tensor(0.5397) 1000
49 1000 -1000.0 -99.99568287525881 number episode from 10: 49 avegar over 10 episode: -99.976 avegare return across last 100 episodes: -99.976 state values: tensor(0.5307) 1000
50 1000 -1000.0 -99.99568287525881 number episode from 10: 50 avegar over 10 episode: -99.976 avegare return across last 100 episodes: -99.976 state values: tensor(0.5314) 1000
51 1000 -1000.0 -99.99568287525881 number episode from 10: 51 avegar over 10 episode: -99.976 avegare return across last 100 episodes: -99.976 state values: tensor(0.5308) 1000
52 1000 -1000.0 -99.99568287525881 number episode from 10: 52 avegar over 10 episode: -99.977 avegare return across last 100 episodes: -99.977 state values: tensor(0.5307) 1000
53 1000 -1000.0 -99.99568287525881 number episode from 10: 53 avegar over 10 episode: -99.977 avegare return across last 100 episodes: -99.977 state values: tensor(0.5532) 1000
54 1000 -1000.0 -99.99568287525881 number episode from 10: 54 avegar over 10 episode: -99.978 avegare return across last 100 episodes: -99.978 state values: tensor(0.5314) 1000
55 1000 -1000.0 -99.99568287525881 number episode from 10: 55 avegar over 10 episode: -99.978 avegare return across last 100 episodes: -99.978 state values: tensor(0.5364) 1000
56 1000 -1000.0 -99.99568287525881 number episode from 10: 56 avegar over 10 episode: -99.978 avegare return across last 100 episodes: -99.978 state values: tensor(0.5351) 1000
57 1000 -1000.0 -99.99568287525881 number episode from 10: 57 avegar over 10 episode: -99.978 avegare return across last 100 episodes: -99.978 state values: tensor(0.5416) 1000
58 1000 -1000.0 -99.99568287525881 number episode from 10: 58 avegar over 10 episode: -99.979 avegare return across last 100 episodes: -99.979 state values: tensor(0.5333) 1000
59 1000 -1000.0 -99.99568287525881 number episode from 10: 59 avegar over 10 episode: -99.979 avegare return across last 100 episodes: -99.979 state values: tensor(0.5368) 1000
60 1000 -1000.0 -99.99568287525881 number episode from 10: 60 avegar over 10 episode: -99.979 avegare return across last 100 episodes: -99.979 state values: tensor(0.5477) 1000
61 1000 -1000.0 -99.99568287525881 number episode from 10: 61 avegar over 10 episode: -99.98 avegare return across last 100 episodes: -99.98 state values: tensor(0.5579) 1000
62 1000 -1000.0 -99.99568287525881 number episode from 10: 62 avegar over 10 episode: -99.98 avegare return across last 100 episodes: -99.98 state values: tensor(0.5313) 1000
63 1000 -1000.0 -99.99568287525881 number episode from 10: 63 avegar over 10 episode: -99.98 avegare return across last 100 episodes: -99.98 state values: tensor(0.5495) 1000
64 1000 -1000.0 -99.99568287525881 number episode from 10: 64 avegar over 10 episode: -99.98 avegare return across last 100 episodes: -99.98 state values: tensor(0.5323) 1000
65 1000 -1000.0 -99.99568287525881 number episode from 10: 65 avegar over 10 episode: -99.981 avegare return across last 100 episodes: -99.981 state values: tensor(0.5466) 1000
66 1000 -1000.0 -99.99568287525881 number episode from 10: 66 avegar over 10 episode: -99.981 avegare return across last 100 episodes: -99.981 state values: tensor(0.5429) 1000
67 1000 -1000.0 -99.99568287525881 number episode from 10: 67 avegar over 10 episode: -99.981 avegare return across last 100 episodes: -99.981 state values: tensor(0.5426) 1000
68 1000 -1000.0 -99.99568287525881 number episode from 10: 68 avegar over 10 episode: -99.981 avegare return across last 100 episodes: -99.981 state values: tensor(0.5304) 1000
69 1000 -1000.0 -99.99568287525881 number episode from 10: 69 avegar over 10 episode: -99.981 avegare return across last 100 episodes: -99.981 state values: tensor(0.5352) 1000
70 1000 -1000.0 -99.99568287525881 number episode from 10: 70 avegar over 10 episode: -99.982 avegare return across last 100 episodes: -99.982 state values: tensor(0.5431) 1000
71 1000 -1000.0 -99.99568287525881 number episode from 10: 71 avegar over 10 episode: -99.982 avegare return across last 100 episodes: -99.982 state values: tensor(0.5304) 1000
72 1000 -1000.0 -99.99568287525881 number episode from 10: 72 avegar over 10 episode: -99.982 avegare return across last 100 episodes: -99.982 state values: tensor(0.5384) 1000
73 1000 -1000.0 -99.99568287525881 number episode from 10: 73 avegar over 10 episode: -99.982 avegare return across last 100 episodes: -99.982 state values: tensor(0.5426) 1000
74 1000 -1000.0 -99.99568287525881 number episode from 10: 74 avegar over 10 episode: -99.982 avegare return across last 100 episodes: -99.982 state values: tensor(0.5372) 1000
75 1000 -1000.0 -99.99568287525881 number episode from 10: 75 avegar over 10 episode: -99.983 avegare return across last 100 episodes: -99.983 state values: tensor(0.5315) 1000
76 1000 -1000.0 -99.99568287525881 number episode from 10: 76 avegar over 10 episode: -99.983 avegare return across last 100 episodes: -99.983 state values: tensor(0.5373) 1000
77 1000 -1000.0 -99.99568287525881 number episode from 10: 77 avegar over 10 episode: -99.983 avegare return across last 100 episodes: -99.983 state values: tensor(0.5332) 1000
78 1000 -1000.0 -99.99568287525881 number episode from 10: 78 avegar over 10 episode: -99.983 avegare return across last 100 episodes: -99.983 state values: tensor(0.5315) 1000
79 1000 -1000.0 -99.99568287525881 number episode from 10: 79 avegar over 10 episode: -99.983 avegare return across last 100 episodes: -99.983 state values: tensor(0.5357) 1000
80 1000 -1000.0 -99.99568287525881 number episode from 10: 80 avegar over 10 episode: -99.983 avegare return across last 100 episodes: -99.983 state values: tensor(0.5448) 1000
81 1000 -1000.0 -99.99568287525881 number episode from 10: 81 avegar over 10 episode: -99.983 avegare return across last 100 episodes: -99.983 state values: tensor(0.5388) 1000
82 1000 -1000.0 -99.99568287525881 number episode from 10: 82 avegar over 10 episode: -99.984 avegare return across last 100 episodes: -99.984 state values: tensor(0.6865) 1000
83 1000 -1000.0 -99.99568287525881 number episode from 10: 83 avegar over 10 episode: -99.984 avegare return across last 100 episodes: -99.984 state values: tensor(0.5807) 1000
84 1000 -1000.0 -99.99568287525881 number episode from 10: 84 avegar over 10 episode: -99.984 avegare return across last 100 episodes: -99.984 state values: tensor(0.5391) 1000
85 1000 -1000.0 -99.99568287525881 number episode from 10: 85 avegar over 10 episode: -99.984 avegare return across last 100 episodes: -99.984 state values: tensor(0.5347) 1000
86 1000 -1000.0 -99.99568287525881 number episode from 10: 86 avegar over 10 episode: -99.984 avegare return across last 100 episodes: -99.984 state values: tensor(0.5326) 1000
87 1000 -1000.0 -99.99568287525881 number episode from 10: 87 avegar over 10 episode: -99.984 avegare return across last 100 episodes: -99.984 state values: tensor(0.5323) 1000
88 1000 -1000.0 -99.99568287525881 number episode from 10: 88 avegar over 10 episode: -99.984 avegare return across last 100 episodes: -99.984 state values: tensor(0.5581) 1000
89 1000 -1000.0 -99.99568287525881 number episode from 10: 89 avegar over 10 episode: -99.985 avegare return across last 100 episodes: -99.985 state values: tensor(0.5380) 1000
90 1000 -1000.0 -99.99568287525881 number episode from 10: 90 avegar over 10 episode: -99.985 avegare return across last 100 episodes: -99.985 state values: tensor(0.5345) 1000
91 1000 -1000.0 -99.99568287525881 number episode from 10: 91 avegar over 10 episode: -99.985 avegare return across last 100 episodes: -99.985 state values: tensor(0.5407) 1000
92 1000 -1000.0 -99.99568287525881 number episode from 10: 92 avegar over 10 episode: -99.985 avegare return across last 100 episodes: -99.985 state values: tensor(0.5561) 1000
93 1000 -1000.0 -99.99568287525881 number episode from 10: 93 avegar over 10 episode: -99.985 avegare return across last 100 episodes: -99.985 state values: tensor(0.5331) 1000
94 1000 -1000.0 -99.99568287525881 number episode from 10: 94 avegar over 10 episode: -99.985 avegare return across last 100 episodes: -99.985 state values: tensor(0.5306) 1000
95 1000 -1000.0 -99.99568287525881 number episode from 10: 95 avegar over 10 episode: -99.985 avegare return across last 100 episodes: -99.985 state values: tensor(0.5339) 1000
96 1000 -1000.0 -99.99568287525881 number episode from 10: 96 avegar over 10 episode: -99.985 avegare return across last 100 episodes: -99.985 state values: tensor(0.5515) 1000
97 1000 -1000.0 -99.99568287525881 number episode from 10: 97 avegar over 10 episode: -99.985 avegare return across last 100 episodes: -99.985 state values: tensor(0.5500) 1000
98 1000 -1000.0 -99.99568287525881 number episode from 10: 98 avegar over 10 episode: -99.986 avegare return across last 100 episodes: -99.986 state values: tensor(0.5313) 1000
99 1000 -1000.0 -99.99568287525881 number episode from 10: 99 avegar over 10 episode: -99.986 avegare return across last 100 episodes: -99.986 state values: tensor(0.5316) 1000
100 1000 -1000.0 -99.99568287525881 number episode from 10: 100 avegar over 10 episode: -99.986 avegare return across last 100 episodes: -99.996 state values: tensor(0.5364) 1000
101 1000 -1000.0 -99.99568287525881 number episode from 10: 101 avegar over 10 episode: -99.986 avegare return across last 100 episodes: -99.996 state values: tensor(0.5436) 1000
102 1000 -1000.0 -99.99568287525881 number episode from 10: 102 avegar over 10 episode: -99.986 avegare return across last 100 episodes: -99.996 state values: tensor(0.5375) 1000
103 1000 -1000.0 -99.99568287525881 number episode from 10: 103 avegar over 10 episode: -99.986 avegare return across last 100 episodes: -99.996 state values: tensor(0.6244) 1000
104 1000 -1000.0 -99.99568287525881 number episode from 10: 104 avegar over 10 episode: -99.986 avegare return across last 100 episodes: -99.996 state values: tensor(0.5428) 1000
105 1000 -1000.0 -99.99568287525881 number episode from 10: 105 avegar over 10 episode: -99.986 avegare return across last 100 episodes: -99.996 state values: tensor(0.5315) 1000
106 1000 -1000.0 -99.99568287525881 number episode from 10: 106 avegar over 10 episode: -99.986 avegare return across last 100 episodes: -99.996 state values: tensor(0.5416) 1000
107 1000 -1000.0 -99.99568287525881 number episode from 10: 107 avegar over 10 episode: -99.986 avegare return across last 100 episodes: -99.996 state values: tensor(0.5368) 1000
108 1000 -1000.0 -99.99568287525881 number episode from 10: 108 avegar over 10 episode: -99.987 avegare return across last 100 episodes: -99.996 state values: tensor(0.5383) 1000
109 1000 -1000.0 -99.99568287525881 number episode from 10: 109 avegar over 10 episode: -99.987 avegare return across last 100 episodes: -99.996 state values: tensor(0.5558) 1000
110 1000 -1000.0 -99.99568287525881 number episode from 10: 110 avegar over 10 episode: -99.987 avegare return across last 100 episodes: -99.996 state values: tensor(0.5416) 1000
111 1000 -1000.0 -99.99568287525881 number episode from 10: 111 avegar over 10 episode: -99.987 avegare return across last 100 episodes: -99.996 state values: tensor(0.5425) 1000
112 1000 -1000.0 -99.99568287525881 number episode from 10: 112 avegar over 10 episode: -99.987 avegare return across last 100 episodes: -99.996 state values: tensor(0.5942) 1000
113 1000 -1000.0 -99.99568287525881 number episode from 10: 113 avegar over 10 episode: -99.987 avegare return across last 100 episodes: -99.996 state values: tensor(0.6721) 1000
114 1000 -1000.0 -99.99568287525881 number episode from 10: 114 avegar over 10 episode: -99.987 avegare return across last 100 episodes: -99.996 state values: tensor(0.6434) 1000
115 1000 -1000.0 -99.99568287525881 number episode from 10: 115 avegar over 10 episode: -99.987 avegare return across last 100 episodes: -99.996 state values: tensor(0.5317) 1000
116 1000 -1000.0 -99.99568287525881 number episode from 10: 116 avegar over 10 episode: -99.987 avegare return across last 100 episodes: -99.996 state values: tensor(0.5379) 1000
117 1000 -1000.0 -99.99568287525881 number episode from 10: 117 avegar over 10 episode: -99.987 avegare return across last 100 episodes: -99.996 state values: tensor(0.5306) 1000
118 1000 -1000.0 -99.99568287525881 number episode from 10: 118 avegar over 10 episode: -99.987 avegare return across last 100 episodes: -99.996 state values: tensor(0.5310) 1000
119 1000 -1000.0 -99.99568287525881 number episode from 10: 119 avegar over 10 episode: -99.987 avegare return across last 100 episodes: -99.996 state values: tensor(0.5320) 1000
120 1000 -1000.0 -99.99568287525881 number episode from 10: 120 avegar over 10 episode: -99.987 avegare return across last 100 episodes: -99.996 state values: tensor(0.5346) 1000
121 1000 -1000.0 -99.99568287525881 number episode from 10: 121 avegar over 10 episode: -99.987 avegare return across last 100 episodes: -99.996 state values: tensor(0.6880) 1000
122 1000 -1000.0 -99.99568287525881 number episode from 10: 122 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.5552) 1000
123 1000 -1000.0 -99.99568287525881 number episode from 10: 123 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.5316) 1000
124 1000 -1000.0 -99.99568287525881 number episode from 10: 124 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.5357) 1000
125 1000 -1000.0 -99.99568287525881 number episode from 10: 125 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.5351) 1000
126 1000 -1000.0 -99.99568287525881 number episode from 10: 126 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.5307) 1000
127 1000 -1000.0 -99.99568287525881 number episode from 10: 127 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.5773) 1000
128 1000 -1000.0 -99.99568287525881 number episode from 10: 128 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.5309) 1000
129 1000 -1000.0 -99.99568287525881 number episode from 10: 129 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.5336) 1000
130 1000 -1000.0 -99.99568287525881 number episode from 10: 130 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.5308) 1000
131 1000 -1000.0 -99.99568287525881 number episode from 10: 131 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.5374) 1000
132 1000 -1000.0 -99.99568287525881 number episode from 10: 132 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.5309) 1000
133 1000 -1000.0 -99.99568287525881 number episode from 10: 133 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.5312) 1000
134 1000 -1000.0 -99.99568287525881 number episode from 10: 134 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.5364) 1000
135 1000 -1000.0 -99.99568287525881 number episode from 10: 135 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.5330) 1000
136 1000 -1000.0 -99.99568287525881 number episode from 10: 136 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.5468) 1000
137 1000 -1000.0 -99.99568287525881 number episode from 10: 137 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.5311) 1000
138 1000 -1000.0 -99.99568287525881 number episode from 10: 138 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.5381) 1000
139 1000 -1000.0 -99.99568287525881 number episode from 10: 139 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.5341) 1000
140 1000 -1000.0 -99.99568287525881 number episode from 10: 140 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.5488) 1000
141 1000 -1000.0 -99.99568287525881 number episode from 10: 141 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.5324) 1000
142 1000 -1000.0 -99.99568287525881 number episode from 10: 142 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.5333) 1000
143 1000 -1000.0 -99.99568287525881 number episode from 10: 143 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.5315) 1000
144 1000 -1000.0 -99.99568287525881 number episode from 10: 144 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.5323) 1000
145 1000 -1000.0 -99.99568287525881 number episode from 10: 145 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.5551) 1000
146 1000 -1000.0 -99.99568287525881 number episode from 10: 146 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.5342) 1000
147 1000 -1000.0 -99.99568287525881 number episode from 10: 147 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.5513) 1000
148 1000 -1000.0 -99.99568287525881 number episode from 10: 148 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.5366) 1000
149 1000 -1000.0 -99.99568287525881 number episode from 10: 149 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.5312) 1000
150 1000 -1000.0 -99.99568287525881 number episode from 10: 150 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.5317) 1000
151 1000 -1000.0 -99.99568287525881 number episode from 10: 151 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.5492) 1000
152 1000 -1000.0 -99.99568287525881 number episode from 10: 152 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.5475) 1000
153 1000 -1000.0 -99.99568287525881 number episode from 10: 153 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.5313) 1000
154 1000 -1000.0 -99.99568287525881 number episode from 10: 154 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.5407) 1000
155 1000 -1000.0 -99.99568287525881 number episode from 10: 155 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.5344) 1000
156 1000 -1000.0 -99.99568287525881 number episode from 10: 156 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.5406) 1000
157 1000 -1000.0 -99.99568287525881 number episode from 10: 157 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.5362) 1000
158 1000 -1000.0 -99.99568287525881 number episode from 10: 158 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.5409) 1000
159 1000 -1000.0 -99.99568287525881 number episode from 10: 159 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.5340) 1000
160 1000 -1000.0 -99.99568287525881 number episode from 10: 160 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.5334) 1000
161 1000 -1000.0 -99.99568287525881 number episode from 10: 161 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.5377) 1000
162 1000 -1000.0 -99.99568287525881 number episode from 10: 162 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.6875) 1000
163 1000 -1000.0 -99.99568287525881 number episode from 10: 163 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.5318) 1000
164 1000 -1000.0 -99.99568287525881 number episode from 10: 164 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.5362) 1000
165 1000 -1000.0 -99.99568287525881 number episode from 10: 165 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.5473) 1000
166 1000 -1000.0 -99.99568287525881 number episode from 10: 166 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.5407) 1000
167 1000 -1000.0 -99.99568287525881 number episode from 10: 167 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.5403) 1000
168 1000 -1000.0 -99.99568287525881 number episode from 10: 168 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.5316) 1000
169 1000 -1000.0 -99.99568287525881 number episode from 10: 169 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.5450) 1000
170 1000 -1000.0 -99.99568287525881 number episode from 10: 170 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.5476) 1000
171 1000 -1000.0 -99.99568287525881 number episode from 10: 171 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.5341) 1000
172 1000 -1000.0 -99.99568287525881 number episode from 10: 172 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.5314) 1000
173 1000 -1000.0 -99.99568287525881 number episode from 10: 173 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.5309) 1000
174 1000 -1000.0 -99.99568287525881 number episode from 10: 174 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.5322) 1000
175 1000 -1000.0 -99.99568287525881 number episode from 10: 175 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.5331) 1000
176 1000 -1000.0 -99.99568287525881 number episode from 10: 176 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.5384) 1000
177 1000 -1000.0 -99.99568287525881 number episode from 10: 177 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.5334) 1000
178 1000 -1000.0 -99.99568287525881 number episode from 10: 178 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.5340) 1000
179 1000 -1000.0 -99.99568287525881 number episode from 10: 179 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.5311) 1000
180 1000 -1000.0 -99.99568287525881 number episode from 10: 180 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.5324) 1000
181 1000 -1000.0 -99.99568287525881 number episode from 10: 181 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.5460) 1000
182 1000 -1000.0 -99.99568287525881 number episode from 10: 182 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.6110) 1000
183 1000 -1000.0 -99.99568287525881 number episode from 10: 183 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.5387) 1000
184 1000 -1000.0 -99.99568287525881 number episode from 10: 184 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.5349) 1000
185 1000 -1000.0 -99.99568287525881 number episode from 10: 185 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.5309) 1000
186 1000 -1000.0 -99.99568287525881 number episode from 10: 186 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.5349) 1000
187 1000 -1000.0 -99.99568287525881 number episode from 10: 187 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.5314) 1000
188 1000 -1000.0 -99.99568287525881 number episode from 10: 188 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.5432) 1000
189 1000 -1000.0 -99.99568287525881 number episode from 10: 189 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.5337) 1000
190 1000 -1000.0 -99.99568287525881 number episode from 10: 190 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.5309) 1000
191 1000 -1000.0 -99.99568287525881 number episode from 10: 191 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.5422) 1000
192 1000 -1000.0 -99.99568287525881 number episode from 10: 192 avegar over 10 episode: -99.991 avegare return across last 100 episodes: -99.996 state values: tensor(0.5347) 1000
193 1000 -1000.0 -99.99568287525881 number episode from 10: 193 avegar over 10 episode: -99.991 avegare return across last 100 episodes: -99.996 state values: tensor(0.5350) 1000
194 1000 -1000.0 -99.99568287525881 number episode from 10: 194 avegar over 10 episode: -99.991 avegare return across last 100 episodes: -99.996 state values: tensor(0.5332) 1000
195 1000 -1000.0 -99.99568287525881 number episode from 10: 195 avegar over 10 episode: -99.991 avegare return across last 100 episodes: -99.996 state values: tensor(0.5338) 1000
196 1000 -1000.0 -99.99568287525881 number episode from 10: 196 avegar over 10 episode: -99.991 avegare return across last 100 episodes: -99.996 state values: tensor(0.5323) 1000
197 1000 -1000.0 -99.99568287525881 number episode from 10: 197 avegar over 10 episode: -99.991 avegare return across last 100 episodes: -99.996 state values: tensor(0.5326) 1000
198 1000 -1000.0 -99.99568287525881 number episode from 10: 198 avegar over 10 episode: -99.991 avegare return across last 100 episodes: -99.996 state values: tensor(0.5310) 1000
199 1000 -1000.0 -99.99568287525881 number episode from 10: 199 avegar over 10 episode: -99.991 avegare return across last 100 episodes: -99.996 state values: tensor(0.5550) 1000
200 1000 -1000.0 -99.99568287525881 number episode from 10: 200 avegar over 10 episode: -99.991 avegare return across last 100 episodes: -99.996 state values: tensor(0.5444) 1000
load offline data!!!!!
mem_cntr: 50000 ; mem_size: 50000
nn.learn_nn_feature_fqi FQI:  998
nn.learn_nn_feature_fqi FQI:  1998
nn.learn_nn_feature_fqi FQI:  2998
nn.learn_nn_feature_fqi FQI:  3998
nn.learn_nn_feature_fqi FQI:  4998
nn.learn_nn_feature_fqi FQI:  5998
nn.learn_nn_feature_fqi FQI:  6998
nn.learn_nn_feature_fqi FQI:  7998
nn.learn_nn_feature_fqi FQI:  8998
nn.learn_nn_feature_fqi FQI:  9998
nn.learn_nn_feature_fqi FQI:  10998
nn.learn_nn_feature_fqi FQI:  11998
nn.learn_nn_feature_fqi FQI:  12998
nn.learn_nn_feature_fqi FQI:  13998
nn.learn_nn_feature_fqi FQI:  14998
nn.learn_nn_feature_fqi FQI:  15998
nn.learn_nn_feature_fqi FQI:  16998
nn.learn_nn_feature_fqi FQI:  17998
nn.learn_nn_feature_fqi FQI:  18998
nn.learn_nn_feature_fqi FQI:  19998
nn.learn_nn_feature_fqi FQI:  20998
nn.learn_nn_feature_fqi FQI:  21998
nn.learn_nn_feature_fqi FQI:  22998
nn.learn_nn_feature_fqi FQI:  23998
nn.learn_nn_feature_fqi FQI:  24998
nn.learn_nn_feature_fqi FQI:  25998
nn.learn_nn_feature_fqi FQI:  26998
nn.learn_nn_feature_fqi FQI:  27998
nn.learn_nn_feature_fqi FQI:  28998
nn.learn_nn_feature_fqi FQI:  29998
nn.learn_nn_feature_fqi FQI:  30998
nn.learn_nn_feature_fqi FQI:  31998
nn.learn_nn_feature_fqi FQI:  32998
nn.learn_nn_feature_fqi FQI:  33998
nn.learn_nn_feature_fqi FQI:  34998
nn.learn_nn_feature_fqi FQI:  35998
nn.learn_nn_feature_fqi FQI:  36998
nn.learn_nn_feature_fqi FQI:  37998
nn.learn_nn_feature_fqi FQI:  38998
nn.learn_nn_feature_fqi FQI:  39998
nn.learn_nn_feature_fqi FQI:  40998
nn.learn_nn_feature_fqi FQI:  41998
nn.learn_nn_feature_fqi FQI:  42998
nn.learn_nn_feature_fqi FQI:  43998
nn.learn_nn_feature_fqi FQI:  44998
nn.learn_nn_feature_fqi FQI:  45998
nn.learn_nn_feature_fqi FQI:  46998
nn.learn_nn_feature_fqi FQI:  47998
nn.learn_nn_feature_fqi FQI:  48998
nn.learn_nn_feature_fqi FQI:  49998
nn.learn_nn_feature_fqi FQI:  50998
nn.learn_nn_feature_fqi FQI:  51998
nn.learn_nn_feature_fqi FQI:  52998
nn.learn_nn_feature_fqi FQI:  53998
nn.learn_nn_feature_fqi FQI:  54998
nn.learn_nn_feature_fqi FQI:  55998
nn.learn_nn_feature_fqi FQI:  56998
nn.learn_nn_feature_fqi FQI:  57998
nn.learn_nn_feature_fqi FQI:  58998
nn.learn_nn_feature_fqi FQI:  59998
nn.learn_nn_feature_fqi FQI:  60998
nn.learn_nn_feature_fqi FQI:  61998
nn.learn_nn_feature_fqi FQI:  62998
nn.learn_nn_feature_fqi FQI:  63998
nn.learn_nn_feature_fqi FQI:  64998
nn.learn_nn_feature_fqi FQI:  65998
nn.learn_nn_feature_fqi FQI:  66998
nn.learn_nn_feature_fqi FQI:  67998
nn.learn_nn_feature_fqi FQI:  68998
nn.learn_nn_feature_fqi FQI:  69998
nn.learn_nn_feature_fqi FQI:  70998
nn.learn_nn_feature_fqi FQI:  71998
nn.learn_nn_feature_fqi FQI:  72998
nn.learn_nn_feature_fqi FQI:  73998
nn.learn_nn_feature_fqi FQI:  74998
nn.learn_nn_feature_fqi FQI:  75998
nn.learn_nn_feature_fqi FQI:  76998
nn.learn_nn_feature_fqi FQI:  77998
nn.learn_nn_feature_fqi FQI:  78998
nn.learn_nn_feature_fqi FQI:  79998
nn.learn_nn_feature_fqi FQI:  80998
nn.learn_nn_feature_fqi FQI:  81998
nn.learn_nn_feature_fqi FQI:  82998
nn.learn_nn_feature_fqi FQI:  83998
nn.learn_nn_feature_fqi FQI:  84998
nn.learn_nn_feature_fqi FQI:  85998
nn.learn_nn_feature_fqi FQI:  86998
nn.learn_nn_feature_fqi FQI:  87998
nn.learn_nn_feature_fqi FQI:  88998
nn.learn_nn_feature_fqi FQI:  89998
nn.learn_nn_feature_fqi FQI:  90998
nn.learn_nn_feature_fqi FQI:  91998
nn.learn_nn_feature_fqi FQI:  92998
nn.learn_nn_feature_fqi FQI:  93998
nn.learn_nn_feature_fqi FQI:  94998
nn.learn_nn_feature_fqi FQI:  95998
nn.learn_nn_feature_fqi FQI:  96998
nn.learn_nn_feature_fqi FQI:  97998
nn.learn_nn_feature_fqi FQI:  98998
nn.learn_nn_feature_fqi FQI:  99998
nn.learn_nn_feature_fqi FQI:  100998
nn.learn_nn_feature_fqi FQI:  101998
nn.learn_nn_feature_fqi FQI:  102998
nn.learn_nn_feature_fqi FQI:  103998
nn.learn_nn_feature_fqi FQI:  104998
nn.learn_nn_feature_fqi FQI:  105998
nn.learn_nn_feature_fqi FQI:  106998
nn.learn_nn_feature_fqi FQI:  107998
nn.learn_nn_feature_fqi FQI:  108998
nn.learn_nn_feature_fqi FQI:  109998
nn.learn_nn_feature_fqi FQI:  110998
nn.learn_nn_feature_fqi FQI:  111998
nn.learn_nn_feature_fqi FQI:  112998
nn.learn_nn_feature_fqi FQI:  113998
nn.learn_nn_feature_fqi FQI:  114998
nn.learn_nn_feature_fqi FQI:  115998
nn.learn_nn_feature_fqi FQI:  116998
nn.learn_nn_feature_fqi FQI:  117998
nn.learn_nn_feature_fqi FQI:  118998
nn.learn_nn_feature_fqi FQI:  119998
nn.learn_nn_feature_fqi FQI:  120998
nn.learn_nn_feature_fqi FQI:  121998
nn.learn_nn_feature_fqi FQI:  122998
nn.learn_nn_feature_fqi FQI:  123998
nn.learn_nn_feature_fqi FQI:  124998
nn.learn_nn_feature_fqi FQI:  125998
nn.learn_nn_feature_fqi FQI:  126998
nn.learn_nn_feature_fqi FQI:  127998
nn.learn_nn_feature_fqi FQI:  128998
nn.learn_nn_feature_fqi FQI:  129998
nn.learn_nn_feature_fqi FQI:  130998
nn.learn_nn_feature_fqi FQI:  131998
nn.learn_nn_feature_fqi FQI:  132998
nn.learn_nn_feature_fqi FQI:  133998
nn.learn_nn_feature_fqi FQI:  134998
nn.learn_nn_feature_fqi FQI:  135998
nn.learn_nn_feature_fqi FQI:  136998
nn.learn_nn_feature_fqi FQI:  137998
nn.learn_nn_feature_fqi FQI:  138998
nn.learn_nn_feature_fqi FQI:  139998
nn.learn_nn_feature_fqi FQI:  140998
nn.learn_nn_feature_fqi FQI:  141998
nn.learn_nn_feature_fqi FQI:  142998
nn.learn_nn_feature_fqi FQI:  143998
nn.learn_nn_feature_fqi FQI:  144998
nn.learn_nn_feature_fqi FQI:  145998
nn.learn_nn_feature_fqi FQI:  146998
nn.learn_nn_feature_fqi FQI:  147998
nn.learn_nn_feature_fqi FQI:  148998
nn.learn_nn_feature_fqi FQI:  149998
nn.learn_nn_feature_fqi FQI:  150998
nn.learn_nn_feature_fqi FQI:  151998
nn.learn_nn_feature_fqi FQI:  152998
nn.learn_nn_feature_fqi FQI:  153998
nn.learn_nn_feature_fqi FQI:  154998
nn.learn_nn_feature_fqi FQI:  155998
0 164 -163.0 -79.76146871060318 number episode from 10: 0 avegar over 10 episode: -79.761 avegare return across last 100 episodes: -79.761 state values: tensor(0.7639) 163
1 199 -199.0 -86.46669950929667 number episode from 10: 1 avegar over 10 episode: -83.114 avegare return across last 100 episodes: -83.114 state values: tensor(0.7209) 199
2 199 -199.0 -86.46669950929667 number episode from 10: 2 avegar over 10 episode: -84.232 avegare return across last 100 episodes: -84.232 state values: tensor(0.7262) 199
3 1000 -1000.0 -99.99568287525881 number episode from 10: 3 avegar over 10 episode: -88.173 avegare return across last 100 episodes: -88.173 state values: tensor(0.5750) 1000
4 323 -323.0 -96.1080445982371 number episode from 10: 4 avegar over 10 episode: -89.76 avegare return across last 100 episodes: -89.76 state values: tensor(0.7682) 323
5 199 -199.0 -86.46669950929667 number episode from 10: 5 avegar over 10 episode: -89.211 avegare return across last 100 episodes: -89.211 state values: tensor(0.7240) 199
6 293 -293.0 -94.73847041074846 number episode from 10: 6 avegar over 10 episode: -90.001 avegare return across last 100 episodes: -90.001 state values: tensor(0.7828) 293
7 345 -345.0 -96.88008949682511 number episode from 10: 7 avegar over 10 episode: -90.86 avegare return across last 100 episodes: -90.86 state values: tensor(0.7865) 345
8 166 -166.0 -81.14431548326218 number episode from 10: 8 avegar over 10 episode: -89.781 avegare return across last 100 episodes: -89.781 state values: tensor(0.7581) 166
9 167 -167.0 -81.33287232842956 number episode from 10: 9 avegar over 10 episode: -88.936 avegare return across last 100 episodes: -88.936 state values: tensor(0.7710) 167
10 258 -258.0 -92.52036842731464 number episode from 10: 10 avegar over 10 episode: -89.262 avegare return across last 100 episodes: -89.262 state values: tensor(0.7657) 258
11 176 -176.0 -82.94725691104124 number episode from 10: 11 avegar over 10 episode: -88.736 avegare return across last 100 episodes: -88.736 state values: tensor(0.7586) 176
12 199 -199.0 -86.46669950929667 number episode from 10: 12 avegar over 10 episode: -88.561 avegare return across last 100 episodes: -88.561 state values: tensor(0.7277) 199
13 285 -285.0 -94.29795736456273 number episode from 10: 13 avegar over 10 episode: -88.971 avegare return across last 100 episodes: -88.971 state values: tensor(0.7899) 285
14 322 -322.0 -96.06873191741121 number episode from 10: 14 avegar over 10 episode: -89.444 avegare return across last 100 episodes: -89.444 state values: tensor(0.7669) 322
15 337 -337.0 -96.61888004123486 number episode from 10: 15 avegar over 10 episode: -89.893 avegare return across last 100 episodes: -89.893 state values: tensor(0.8136) 337
16 164 -164.0 -80.76146871060318 number episode from 10: 16 avegar over 10 episode: -89.355 avegare return across last 100 episodes: -89.355 state values: tensor(0.7488) 164
17 245 -245.0 -91.47640754278069 number episode from 10: 17 avegar over 10 episode: -89.473 avegare return across last 100 episodes: -89.473 state values: tensor(0.7648) 245
18 202 -202.0 -86.86865206717106 number episode from 10: 18 avegar over 10 episode: -89.336 avegare return across last 100 episodes: -89.336 state values: tensor(0.7214) 202
19 301 -301.0 -95.14495148694262 number episode from 10: 19 avegar over 10 episode: -89.627 avegare return across last 100 episodes: -89.627 state values: tensor(0.7396) 301
20 164 -164.0 -80.76146871060318 number episode from 10: 20 avegar over 10 episode: -89.204 avegare return across last 100 episodes: -89.204 state values: tensor(0.7563) 164
21 164 -164.0 -80.76146871060318 number episode from 10: 21 avegar over 10 episode: -88.821 avegare return across last 100 episodes: -88.821 state values: tensor(0.7650) 164
22 198 -198.0 -86.32999950434008 number episode from 10: 22 avegar over 10 episode: -88.712 avegare return across last 100 episodes: -88.712 state values: tensor(0.7290) 198
23 987 -987.0 -99.9950803175901 number episode from 10: 23 avegar over 10 episode: -89.183 avegare return across last 100 episodes: -89.183 state values: tensor(0.6325) 987
24 320 -320.0 -95.98891125131233 number episode from 10: 24 avegar over 10 episode: -89.455 avegare return across last 100 episodes: -89.455 state values: tensor(0.7573) 320
25 287 -287.0 -94.41142801300794 number episode from 10: 25 avegar over 10 episode: -89.645 avegare return across last 100 episodes: -89.645 state values: tensor(0.7960) 287
26 200 -200.0 -86.6020325142037 number episode from 10: 26 avegar over 10 episode: -89.533 avegare return across last 100 episodes: -89.533 state values: tensor(0.7205) 200
27 169 -169.0 -81.7043481690938 number episode from 10: 27 avegar over 10 episode: -89.253 avegare return across last 100 episodes: -89.253 state values: tensor(0.7711) 169
28 202 -202.0 -86.86865206717106 number episode from 10: 28 avegar over 10 episode: -89.171 avegare return across last 100 episodes: -89.171 state values: tensor(0.7221) 202
29 199 -199.0 -86.46669950929667 number episode from 10: 29 avegar over 10 episode: -89.081 avegare return across last 100 episodes: -89.081 state values: tensor(0.7259) 199
30 163 -163.0 -80.56714011172039 number episode from 10: 30 avegar over 10 episode: -88.806 avegare return across last 100 episodes: -88.806 state values: tensor(0.7617) 163
31 201 -201.0 -86.73601218906167 number episode from 10: 31 avegar over 10 episode: -88.741 avegare return across last 100 episodes: -88.741 state values: tensor(0.7241) 201
32 314 -314.0 -95.73959286211226 number episode from 10: 32 avegar over 10 episode: -88.953 avegare return across last 100 episodes: -88.953 state values: tensor(0.7643) 314
33 169 -169.0 -81.7043481690938 number episode from 10: 33 avegar over 10 episode: -88.74 avegare return across last 100 episodes: -88.74 state values: tensor(0.7763) 169
34 224 -224.0 -89.47350981516395 number episode from 10: 34 avegar over 10 episode: -88.761 avegare return across last 100 episodes: -88.761 state values: tensor(0.8032) 224
35 166 -166.0 -81.14431548326218 number episode from 10: 35 avegar over 10 episode: -88.55 avegare return across last 100 episodes: -88.55 state values: tensor(0.7652) 166
36 641 -641.0 -99.84072055379644 number episode from 10: 36 avegar over 10 episode: -88.855 avegare return across last 100 episodes: -88.855 state values: tensor(0.6529) 641
37 312 -312.0 -95.65308933997781 number episode from 10: 37 avegar over 10 episode: -89.034 avegare return across last 100 episodes: -89.034 state values: tensor(0.7580) 312
38 278 -278.0 -93.88235744602936 number episode from 10: 38 avegar over 10 episode: -89.158 avegare return across last 100 episodes: -89.158 state values: tensor(0.7838) 278
39 212 -212.0 -88.12424430884558 number episode from 10: 39 avegar over 10 episode: -89.132 avegare return across last 100 episodes: -89.132 state values: tensor(0.7170) 212
40 167 -167.0 -81.33287232842956 number episode from 10: 40 avegar over 10 episode: -88.942 avegare return across last 100 episodes: -88.942 state values: tensor(0.7715) 167
41 167 -167.0 -81.33287232842956 number episode from 10: 41 avegar over 10 episode: -88.761 avegare return across last 100 episodes: -88.761 state values: tensor(0.7721) 167
42 167 -167.0 -81.33287232842956 number episode from 10: 42 avegar over 10 episode: -88.588 avegare return across last 100 episodes: -88.588 state values: tensor(0.7710) 167
43 310 -310.0 -95.56482944595226 number episode from 10: 43 avegar over 10 episode: -88.747 avegare return across last 100 episodes: -88.747 state values: tensor(0.7625) 310
44 166 -166.0 -81.14431548326218 number episode from 10: 44 avegar over 10 episode: -88.578 avegare return across last 100 episodes: -88.578 state values: tensor(0.7666) 166
45 176 -176.0 -82.94725691104124 number episode from 10: 45 avegar over 10 episode: -88.455 avegare return across last 100 episodes: -88.455 state values: tensor(0.7605) 176
46 344 -344.0 -96.84857524931829 number episode from 10: 46 avegar over 10 episode: -88.634 avegare return across last 100 episodes: -88.634 state values: tensor(0.7355) 344
47 266 -266.0 -93.09820965002902 number episode from 10: 47 avegar over 10 episode: -88.727 avegare return across last 100 episodes: -88.727 state values: tensor(0.7647) 266
48 1000 -1000.0 -99.99568287525881 number episode from 10: 48 avegar over 10 episode: -88.957 avegare return across last 100 episodes: -88.957 state values: tensor(0.5749) 1000
49 202 -202.0 -86.86865206717106 number episode from 10: 49 avegar over 10 episode: -88.915 avegare return across last 100 episodes: -88.915 state values: tensor(0.7262) 202
50 201 -201.0 -86.73601218906167 number episode from 10: 50 avegar over 10 episode: -88.872 avegare return across last 100 episodes: -88.872 state values: tensor(0.7207) 201
51 342 -342.0 -96.78458856169604 number episode from 10: 51 avegar over 10 episode: -89.025 avegare return across last 100 episodes: -89.025 state values: tensor(0.7780) 342
52 278 -278.0 -93.88235744602936 number episode from 10: 52 avegar over 10 episode: -89.116 avegare return across last 100 episodes: -89.116 state values: tensor(0.7829) 278
53 164 -164.0 -80.76146871060318 number episode from 10: 53 avegar over 10 episode: -88.961 avegare return across last 100 episodes: -88.961 state values: tensor(0.7602) 164
54 165 -165.0 -80.95385402349714 number episode from 10: 54 avegar over 10 episode: -88.816 avegare return across last 100 episodes: -88.816 state values: tensor(0.7663) 165
55 166 -166.0 -81.14431548326218 number episode from 10: 55 avegar over 10 episode: -88.679 avegare return across last 100 episodes: -88.679 state values: tensor(0.7687) 166
56 336 -336.0 -96.58472731437865 number episode from 10: 56 avegar over 10 episode: -88.818 avegare return across last 100 episodes: -88.818 state values: tensor(0.7789) 336
57 174 -174.0 -82.60101715237347 number episode from 10: 57 avegar over 10 episode: -88.71 avegare return across last 100 episodes: -88.71 state values: tensor(0.7555) 174
58 165 -165.0 -80.95385402349714 number episode from 10: 58 avegar over 10 episode: -88.579 avegare return across last 100 episodes: -88.579 state values: tensor(0.7530) 165
59 167 -167.0 -81.33287232842956 number episode from 10: 59 avegar over 10 episode: -88.458 avegare return across last 100 episodes: -88.458 state values: tensor(0.7711) 167
60 214 -214.0 -88.36057184709955 number episode from 10: 60 avegar over 10 episode: -88.457 avegare return across last 100 episodes: -88.457 state values: tensor(0.7356) 214
61 279 -279.0 -93.94353387156906 number episode from 10: 61 avegar over 10 episode: -88.545 avegare return across last 100 episodes: -88.545 state values: tensor(0.7839) 279
62 201 -201.0 -86.73601218906167 number episode from 10: 62 avegar over 10 episode: -88.516 avegare return across last 100 episodes: -88.516 state values: tensor(0.7212) 201
63 165 -165.0 -80.95385402349714 number episode from 10: 63 avegar over 10 episode: -88.398 avegare return across last 100 episodes: -88.398 state values: tensor(0.7624) 165
64 709 -709.0 -99.91958205523798 number episode from 10: 64 avegar over 10 episode: -88.575 avegare return across last 100 episodes: -88.575 state values: tensor(0.6556) 709
65 810 -810.0 -99.97085878708431 number episode from 10: 65 avegar over 10 episode: -88.748 avegare return across last 100 episodes: -88.748 state values: tensor(0.6216) 810
66 166 -166.0 -81.14431548326218 number episode from 10: 66 avegar over 10 episode: -88.635 avegare return across last 100 episodes: -88.635 state values: tensor(0.7538) 166
67 1000 -1000.0 -99.99568287525881 number episode from 10: 67 avegar over 10 episode: -88.802 avegare return across last 100 episodes: -88.802 state values: tensor(0.6149) 1000
68 830 -830.0 -99.97616519978622 number episode from 10: 68 avegar over 10 episode: -88.964 avegare return across last 100 episodes: -88.964 state values: tensor(0.6494) 830
69 300 -300.0 -95.09591059287133 number episode from 10: 69 avegar over 10 episode: -89.051 avegare return across last 100 episodes: -89.051 state values: tensor(0.7457) 300
70 164 -164.0 -80.76146871060318 number episode from 10: 70 avegar over 10 episode: -88.934 avegare return across last 100 episodes: -88.934 state values: tensor(0.7644) 164
71 279 -279.0 -93.94353387156906 number episode from 10: 71 avegar over 10 episode: -89.004 avegare return across last 100 episodes: -89.004 state values: tensor(0.7794) 279
72 200 -200.0 -86.6020325142037 number episode from 10: 72 avegar over 10 episode: -88.971 avegare return across last 100 episodes: -88.971 state values: tensor(0.7266) 200
73 302 -302.0 -95.1935019720732 number episode from 10: 73 avegar over 10 episode: -89.055 avegare return across last 100 episodes: -89.055 state values: tensor(0.7516) 302
74 1000 -1000.0 -99.99568287525881 number episode from 10: 74 avegar over 10 episode: -89.201 avegare return across last 100 episodes: -89.201 state values: tensor(0.6287) 1000
75 166 -166.0 -81.14431548326218 number episode from 10: 75 avegar over 10 episode: -89.095 avegare return across last 100 episodes: -89.095 state values: tensor(0.7705) 166
76 301 -301.0 -95.14495148694262 number episode from 10: 76 avegar over 10 episode: -89.174 avegare return across last 100 episodes: -89.174 state values: tensor(0.7523) 301
77 275 -275.0 -93.69509547678535 number episode from 10: 77 avegar over 10 episode: -89.232 avegare return across last 100 episodes: -89.232 state values: tensor(0.7785) 275
78 164 -164.0 -80.76146871060318 number episode from 10: 78 avegar over 10 episode: -89.124 avegare return across last 100 episodes: -89.124 state values: tensor(0.7643) 164
79 310 -310.0 -95.56482944595226 number episode from 10: 79 avegar over 10 episode: -89.205 avegare return across last 100 episodes: -89.205 state values: tensor(0.7599) 310
80 165 -165.0 -80.95385402349714 number episode from 10: 80 avegar over 10 episode: -89.103 avegare return across last 100 episodes: -89.103 state values: tensor(0.7662) 165
81 236 -236.0 -90.66947834789299 number episode from 10: 81 avegar over 10 episode: -89.122 avegare return across last 100 episodes: -89.122 state values: tensor(0.7510) 236
82 200 -200.0 -86.6020325142037 number episode from 10: 82 avegar over 10 episode: -89.092 avegare return across last 100 episodes: -89.092 state values: tensor(0.7206) 200
83 259 -259.0 -92.5951647430415 number episode from 10: 83 avegar over 10 episode: -89.133 avegare return across last 100 episodes: -89.133 state values: tensor(0.7664) 259
84 644 -644.0 -99.84545131262814 number episode from 10: 84 avegar over 10 episode: -89.26 avegare return across last 100 episodes: -89.26 state values: tensor(0.6287) 644
85 577 -577.0 -99.696954888429 number episode from 10: 85 avegar over 10 episode: -89.381 avegare return across last 100 episodes: -89.381 state values: tensor(0.6584) 577
86 1000 -1000.0 -99.99568287525881 number episode from 10: 86 avegar over 10 episode: -89.503 avegare return across last 100 episodes: -89.503 state values: tensor(0.5748) 1000
87 253 -253.0 -92.13490028263506 number episode from 10: 87 avegar over 10 episode: -89.533 avegare return across last 100 episodes: -89.533 state values: tensor(0.7695) 253
88 164 -164.0 -80.76146871060318 number episode from 10: 88 avegar over 10 episode: -89.434 avegare return across last 100 episodes: -89.434 state values: tensor(0.7634) 164
89 166 -166.0 -81.14431548326218 number episode from 10: 89 avegar over 10 episode: -89.342 avegare return across last 100 episodes: -89.342 state values: tensor(0.7526) 166
90 167 -167.0 -81.33287232842956 number episode from 10: 90 avegar over 10 episode: -89.254 avegare return across last 100 episodes: -89.254 state values: tensor(0.7716) 167
91 165 -165.0 -80.95385402349714 number episode from 10: 91 avegar over 10 episode: -89.164 avegare return across last 100 episodes: -89.164 state values: tensor(0.7533) 165
92 167 -167.0 -81.33287232842956 number episode from 10: 92 avegar over 10 episode: -89.08 avegare return across last 100 episodes: -89.08 state values: tensor(0.7539) 167
93 167 -167.0 -81.33287232842956 number episode from 10: 93 avegar over 10 episode: -88.997 avegare return across last 100 episodes: -88.997 state values: tensor(0.7713) 167
94 199 -199.0 -86.46669950929667 number episode from 10: 94 avegar over 10 episode: -88.971 avegare return across last 100 episodes: -88.971 state values: tensor(0.7281) 199
95 290 -290.0 -94.57741418959358 number episode from 10: 95 avegar over 10 episode: -89.029 avegare return across last 100 episodes: -89.029 state values: tensor(0.7939) 290
96 201 -201.0 -86.73601218906167 number episode from 10: 96 avegar over 10 episode: -89.005 avegare return across last 100 episodes: -89.005 state values: tensor(0.7216) 201
97 293 -293.0 -94.73847041074846 number episode from 10: 97 avegar over 10 episode: -89.064 avegare return across last 100 episodes: -89.064 state values: tensor(0.8055) 293
98 892 -892.0 -99.98721815399118 number episode from 10: 98 avegar over 10 episode: -89.174 avegare return across last 100 episodes: -89.174 state values: tensor(0.6410) 892
99 167 -167.0 -81.33287232842956 number episode from 10: 99 avegar over 10 episode: -89.096 avegare return across last 100 episodes: -89.096 state values: tensor(0.7719) 167
100 789 -789.0 -99.96401110291572 number episode from 10: 100 avegar over 10 episode: -89.203 avegare return across last 100 episodes: -89.298 state values: tensor(0.6386) 789
101 167 -167.0 -81.33287232842956 number episode from 10: 101 avegar over 10 episode: -89.126 avegare return across last 100 episodes: -89.247 state values: tensor(0.7473) 167
102 219 -219.0 -88.93101964006571 number episode from 10: 102 avegar over 10 episode: -89.124 avegare return across last 100 episodes: -89.271 state values: tensor(0.7382) 219
103 576 -576.0 -99.69389382669597 number episode from 10: 103 avegar over 10 episode: -89.226 avegare return across last 100 episodes: -89.268 state values: tensor(0.6814) 576
104 164 -164.0 -80.76146871060318 number episode from 10: 104 avegar over 10 episode: -89.145 avegare return across last 100 episodes: -89.115 state values: tensor(0.7590) 164
105 165 -165.0 -80.95385402349714 number episode from 10: 105 avegar over 10 episode: -89.068 avegare return across last 100 episodes: -89.06 state values: tensor(0.7554) 165
106 268 -268.0 -93.23555527799344 number episode from 10: 106 avegar over 10 episode: -89.107 avegare return across last 100 episodes: -89.045 state values: tensor(0.7682) 268
107 315 -315.0 -95.78219693349114 number episode from 10: 107 avegar over 10 episode: -89.169 avegare return across last 100 episodes: -89.034 state values: tensor(0.7532) 315
108 338 -338.0 -96.6526912408225 number episode from 10: 108 avegar over 10 episode: -89.238 avegare return across last 100 episodes: -89.189 state values: tensor(0.7497) 338
109 165 -165.0 -80.95385402349714 number episode from 10: 109 avegar over 10 episode: -89.162 avegare return across last 100 episodes: -89.185 state values: tensor(0.7674) 165
110 789 -789.0 -99.96401110291572 number episode from 10: 110 avegar over 10 episode: -89.26 avegare return across last 100 episodes: -89.259 state values: tensor(0.6503) 789
111 176 -176.0 -82.94725691104124 number episode from 10: 111 avegar over 10 episode: -89.203 avegare return across last 100 episodes: -89.259 state values: tensor(0.7583) 176
112 168 -168.0 -81.51954360514526 number episode from 10: 112 avegar over 10 episode: -89.135 avegare return across last 100 episodes: -89.21 state values: tensor(0.7706) 168
113 182 -182.0 -83.94518088891023 number episode from 10: 113 avegar over 10 episode: -89.09 avegare return across last 100 episodes: -89.106 state values: tensor(0.7667) 182
114 247 -247.0 -91.64602703267936 number episode from 10: 114 avegar over 10 episode: -89.112 avegare return across last 100 episodes: -89.062 state values: tensor(0.7682) 247
115 277 -277.0 -93.82056307679733 number episode from 10: 115 avegar over 10 episode: -89.152 avegare return across last 100 episodes: -89.034 state values: tensor(0.7820) 277
116 201 -201.0 -86.73601218906167 number episode from 10: 116 avegar over 10 episode: -89.132 avegare return across last 100 episodes: -89.094 state values: tensor(0.7264) 201
117 216 -216.0 -88.59219646734226 number episode from 10: 117 avegar over 10 episode: -89.127 avegare return across last 100 episodes: -89.065 state values: tensor(0.8046) 216
118 164 -164.0 -80.76146871060318 number episode from 10: 118 avegar over 10 episode: -89.057 avegare return across last 100 episodes: -89.004 state values: tensor(0.7570) 164
119 283 -283.0 -94.18218280232908 number episode from 10: 119 avegar over 10 episode: -89.1 avegare return across last 100 episodes: -88.994 state values: tensor(0.7872) 283
120 185 -185.0 -84.4220250713287 number episode from 10: 120 avegar over 10 episode: -89.061 avegare return across last 100 episodes: -89.031 state values: tensor(0.7700) 185
121 163 -163.0 -80.56714011172039 number episode from 10: 121 avegar over 10 episode: -88.991 avegare return across last 100 episodes: -89.029 state values: tensor(0.7597) 163
122 166 -166.0 -81.14431548326218 number episode from 10: 122 avegar over 10 episode: -88.928 avegare return across last 100 episodes: -88.977 state values: tensor(0.7461) 166
123 317 -317.0 -95.86613121451465 number episode from 10: 123 avegar over 10 episode: -88.984 avegare return across last 100 episodes: -88.936 state values: tensor(0.7636) 317
124 163 -163.0 -80.56714011172039 number episode from 10: 124 avegar over 10 episode: -88.916 avegare return across last 100 episodes: -88.782 state values: tensor(0.7541) 163
125 189 -189.0 -85.0358594396383 number episode from 10: 125 avegar over 10 episode: -88.885 avegare return across last 100 episodes: -88.688 state values: tensor(0.7761) 189
126 323 -323.0 -96.1080445982371 number episode from 10: 126 avegar over 10 episode: -88.942 avegare return across last 100 episodes: -88.783 state values: tensor(0.7621) 323
127 669 -669.0 -99.87978872989507 number episode from 10: 127 avegar over 10 episode: -89.028 avegare return across last 100 episodes: -88.965 state values: tensor(0.6677) 669
128 201 -201.0 -86.73601218906167 number episode from 10: 128 avegar over 10 episode: -89.01 avegare return across last 100 episodes: -88.963 state values: tensor(0.7181) 201
129 164 -164.0 -80.76146871060318 number episode from 10: 129 avegar over 10 episode: -88.947 avegare return across last 100 episodes: -88.906 state values: tensor(0.7643) 164
130 372 -372.0 -97.62155895848959 number episode from 10: 130 avegar over 10 episode: -89.013 avegare return across last 100 episodes: -89.077 state values: tensor(0.7311) 372
131 167 -167.0 -81.33287232842956 number episode from 10: 131 avegar over 10 episode: -88.955 avegare return across last 100 episodes: -89.023 state values: tensor(0.7705) 167
132 167 -167.0 -81.33287232842956 number episode from 10: 132 avegar over 10 episode: -88.897 avegare return across last 100 episodes: -88.879 state values: tensor(0.7579) 167
133 164 -164.0 -80.76146871060318 number episode from 10: 133 avegar over 10 episode: -88.837 avegare return across last 100 episodes: -88.869 state values: tensor(0.7608) 164
134 267 -267.0 -93.16722755352873 number episode from 10: 134 avegar over 10 episode: -88.869 avegare return across last 100 episodes: -88.906 state values: tensor(0.7764) 267
135 278 -278.0 -93.88235744602936 number episode from 10: 135 avegar over 10 episode: -88.905 avegare return across last 100 episodes: -89.034 state values: tensor(0.7847) 278
136 527 -527.0 -99.49910401228738 number episode from 10: 136 avegar over 10 episode: -88.983 avegare return across last 100 episodes: -89.03 state values: tensor(0.6713) 527
137 955 -955.0 -99.99321404710464 number episode from 10: 137 avegar over 10 episode: -89.063 avegare return across last 100 episodes: -89.074 state values: tensor(0.6367) 955
138 201 -201.0 -86.73601218906167 number episode from 10: 138 avegar over 10 episode: -89.046 avegare return across last 100 episodes: -89.002 state values: tensor(0.7268) 201
139 275 -275.0 -93.69509547678535 number episode from 10: 139 avegar over 10 episode: -89.079 avegare return across last 100 episodes: -89.058 state values: tensor(0.7836) 275
140 165 -165.0 -80.95385402349714 number episode from 10: 140 avegar over 10 episode: -89.021 avegare return across last 100 episodes: -89.054 state values: tensor(0.7679) 165
141 202 -202.0 -86.86865206717106 number episode from 10: 141 avegar over 10 episode: -89.006 avegare return across last 100 episodes: -89.109 state values: tensor(0.7245) 202
142 198 -198.0 -86.32999950434008 number episode from 10: 142 avegar over 10 episode: -88.988 avegare return across last 100 episodes: -89.159 state values: tensor(0.7287) 198
143 611 -611.0 -99.78467031796413 number episode from 10: 143 avegar over 10 episode: -89.063 avegare return across last 100 episodes: -89.202 state values: tensor(0.6742) 611
144 167 -167.0 -81.33287232842956 number episode from 10: 144 avegar over 10 episode: -89.009 avegare return across last 100 episodes: -89.203 state values: tensor(0.7734) 167
145 280 -280.0 -94.00409853285336 number episode from 10: 145 avegar over 10 episode: -89.043 avegare return across last 100 episodes: -89.314 state values: tensor(0.7878) 280
146 1000 -1000.0 -99.99568287525881 number episode from 10: 146 avegar over 10 episode: -89.118 avegare return across last 100 episodes: -89.345 state values: tensor(0.5958) 1000
147 163 -163.0 -80.56714011172039 number episode from 10: 147 avegar over 10 episode: -89.06 avegare return across last 100 episodes: -89.22 state values: tensor(0.7600) 163
148 163 -163.0 -80.56714011172039 number episode from 10: 148 avegar over 10 episode: -89.003 avegare return across last 100 episodes: -89.026 state values: tensor(0.7639) 163
149 166 -166.0 -81.14431548326218 number episode from 10: 149 avegar over 10 episode: -88.951 avegare return across last 100 episodes: -88.969 state values: tensor(0.7458) 166
150 300 -300.0 -95.09591059287133 number episode from 10: 150 avegar over 10 episode: -88.991 avegare return across last 100 episodes: -89.052 state values: tensor(0.8040) 300
151 166 -166.0 -81.14431548326218 number episode from 10: 151 avegar over 10 episode: -88.94 avegare return across last 100 episodes: -88.896 state values: tensor(0.7690) 166
152 769 -769.0 -99.95599878735594 number episode from 10: 152 avegar over 10 episode: -89.012 avegare return across last 100 episodes: -88.957 state values: tensor(0.6518) 769
153 219 -219.0 -88.93101964006571 number episode from 10: 153 avegar over 10 episode: -89.011 avegare return across last 100 episodes: -89.038 state values: tensor(0.8056) 219
154 176 -176.0 -82.94725691104124 number episode from 10: 154 avegar over 10 episode: -88.972 avegare return across last 100 episodes: -89.058 state values: tensor(0.7571) 176
155 207 -207.0 -87.51221877410474 number episode from 10: 155 avegar over 10 episode: -88.963 avegare return across last 100 episodes: -89.122 state values: tensor(0.7238) 207
156 315 -315.0 -95.78219693349114 number episode from 10: 156 avegar over 10 episode: -89.006 avegare return across last 100 episodes: -89.114 state values: tensor(0.7637) 315
157 305 -305.0 -95.33625977000064 number episode from 10: 157 avegar over 10 episode: -89.046 avegare return across last 100 episodes: -89.241 state values: tensor(0.8013) 305
158 221 -221.0 -89.1512923492284 number episode from 10: 158 avegar over 10 episode: -89.047 avegare return across last 100 episodes: -89.323 state values: tensor(0.7365) 221
159 201 -201.0 -86.73601218906167 number episode from 10: 159 avegar over 10 episode: -89.033 avegare return across last 100 episodes: -89.377 state values: tensor(0.7224) 201
160 273 -273.0 -93.5670803762732 number episode from 10: 160 avegar over 10 episode: -89.061 avegare return across last 100 episodes: -89.429 state values: tensor(0.7784) 273
161 254 -254.0 -92.21355127980871 number episode from 10: 161 avegar over 10 episode: -89.08 avegare return across last 100 episodes: -89.412 state values: tensor(0.7777) 254
162 164 -164.0 -80.76146871060318 number episode from 10: 162 avegar over 10 episode: -89.029 avegare return across last 100 episodes: -89.352 state values: tensor(0.7661) 164
163 862 -862.0 -99.98272023853355 number episode from 10: 163 avegar over 10 episode: -89.096 avegare return across last 100 episodes: -89.543 state values: tensor(0.6489) 862
164 200 -200.0 -86.6020325142037 number episode from 10: 164 avegar over 10 episode: -89.081 avegare return across last 100 episodes: -89.409 state values: tensor(0.7176) 200
165 163 -163.0 -80.56714011172039 number episode from 10: 165 avegar over 10 episode: -89.03 avegare return across last 100 episodes: -89.215 state values: tensor(0.7626) 163
166 274 -274.0 -93.63140957251046 number episode from 10: 166 avegar over 10 episode: -89.057 avegare return across last 100 episodes: -89.34 state values: tensor(0.7770) 274
167 212 -212.0 -88.12424430884558 number episode from 10: 167 avegar over 10 episode: -89.052 avegare return across last 100 episodes: -89.221 state values: tensor(0.7198) 212
168 164 -164.0 -80.76146871060318 number episode from 10: 168 avegar over 10 episode: -89.002 avegare return across last 100 episodes: -89.029 state values: tensor(0.7564) 164
169 165 -165.0 -80.95385402349714 number episode from 10: 169 avegar over 10 episode: -88.955 avegare return across last 100 episodes: -88.888 state values: tensor(0.7535) 165
170 166 -166.0 -81.14431548326218 number episode from 10: 170 avegar over 10 episode: -88.909 avegare return across last 100 episodes: -88.892 state values: tensor(0.7696) 166
171 339 -339.0 -96.68616432841428 number episode from 10: 171 avegar over 10 episode: -88.955 avegare return across last 100 episodes: -88.919 state values: tensor(0.7762) 339
172 199 -199.0 -86.46669950929667 number episode from 10: 172 avegar over 10 episode: -88.94 avegare return across last 100 episodes: -88.918 state values: tensor(0.7273) 199
173 412 -412.0 -98.40889011380645 number episode from 10: 173 avegar over 10 episode: -88.995 avegare return across last 100 episodes: -88.95 state values: tensor(0.7101) 412
174 1000 -1000.0 -99.99568287525881 number episode from 10: 174 avegar over 10 episode: -89.058 avegare return across last 100 episodes: -88.95 state values: tensor(0.5893) 1000
175 166 -166.0 -81.14431548326218 number episode from 10: 175 avegar over 10 episode: -89.013 avegare return across last 100 episodes: -88.95 state values: tensor(0.7695) 166
176 164 -164.0 -80.76146871060318 number episode from 10: 176 avegar over 10 episode: -88.966 avegare return across last 100 episodes: -88.806 state values: tensor(0.7643) 164
177 187 -187.0 -84.73202677240926 number episode from 10: 177 avegar over 10 episode: -88.942 avegare return across last 100 episodes: -88.716 state values: tensor(0.7563) 187
178 1000 -1000.0 -99.99568287525881 number episode from 10: 178 avegar over 10 episode: -89.004 avegare return across last 100 episodes: -88.909 state values: tensor(0.5747) 1000
179 223 -223.0 -89.36718163147874 number episode from 10: 179 avegar over 10 episode: -89.006 avegare return across last 100 episodes: -88.847 state values: tensor(0.7325) 223
180 512 -512.0 -99.4176023231336 number episode from 10: 180 avegar over 10 episode: -89.064 avegare return across last 100 episodes: -89.031 state values: tensor(0.6700) 512
181 163 -163.0 -80.56714011172039 number episode from 10: 181 avegar over 10 episode: -89.017 avegare return across last 100 episodes: -88.93 state values: tensor(0.7564) 163
182 168 -168.0 -81.51954360514526 number episode from 10: 182 avegar over 10 episode: -88.976 avegare return across last 100 episodes: -88.88 state values: tensor(0.7727) 168
183 873 -873.0 -99.9845287685346 number episode from 10: 183 avegar over 10 episode: -89.036 avegare return across last 100 episodes: -88.954 state values: tensor(0.6428) 873
184 334 -334.0 -96.51538344493281 number episode from 10: 184 avegar over 10 episode: -89.076 avegare return across last 100 episodes: -88.92 state values: tensor(0.7414) 334
185 164 -164.0 -80.76146871060318 number episode from 10: 185 avegar over 10 episode: -89.031 avegare return across last 100 episodes: -88.731 state values: tensor(0.7632) 164
186 441 -441.0 -98.81116709402107 number episode from 10: 186 avegar over 10 episode: -89.084 avegare return across last 100 episodes: -88.719 state values: tensor(0.7123) 441
187 301 -301.0 -95.14495148694262 number episode from 10: 187 avegar over 10 episode: -89.116 avegare return across last 100 episodes: -88.749 state values: tensor(0.8029) 301
188 654 -654.0 -99.86022893742476 number episode from 10: 188 avegar over 10 episode: -89.173 avegare return across last 100 episodes: -88.94 state values: tensor(0.6514) 654
189 341 -341.0 -96.75210965827883 number episode from 10: 189 avegar over 10 episode: -89.213 avegare return across last 100 episodes: -89.096 state values: tensor(0.7330) 341
190 164 -164.0 -80.76146871060318 number episode from 10: 190 avegar over 10 episode: -89.168 avegare return across last 100 episodes: -89.09 state values: tensor(0.7645) 164
191 275 -275.0 -93.69509547678535 number episode from 10: 191 avegar over 10 episode: -89.192 avegare return across last 100 episodes: -89.218 state values: tensor(0.7803) 275
192 323 -323.0 -96.1080445982371 number episode from 10: 192 avegar over 10 episode: -89.228 avegare return across last 100 episodes: -89.366 state values: tensor(0.7697) 323
193 989 -989.0 -99.99517821927004 number episode from 10: 193 avegar over 10 episode: -89.283 avegare return across last 100 episodes: -89.552 state values: tensor(0.6324) 989
194 202 -202.0 -86.86865206717106 number episode from 10: 194 avegar over 10 episode: -89.271 avegare return across last 100 episodes: -89.556 state values: tensor(0.7220) 202
195 202 -202.0 -86.86865206717106 number episode from 10: 195 avegar over 10 episode: -89.259 avegare return across last 100 episodes: -89.479 state values: tensor(0.7191) 202
196 284 -284.0 -94.24036097430579 number episode from 10: 196 avegar over 10 episode: -89.284 avegare return across last 100 episodes: -89.554 state values: tensor(0.7853) 284
197 338 -338.0 -96.6526912408225 number episode from 10: 197 avegar over 10 episode: -89.321 avegare return across last 100 episodes: -89.573 state values: tensor(0.7710) 338
198 329 -329.0 -96.33580124688622 number episode from 10: 198 avegar over 10 episode: -89.356 avegare return across last 100 episodes: -89.537 state values: tensor(0.7723) 329
199 335 -335.0 -96.55022961048348 number episode from 10: 199 avegar over 10 episode: -89.392 avegare return across last 100 episodes: -89.689 state values: tensor(0.7795) 335
200 167 -167.0 -81.33287232842956 number episode from 10: 200 avegar over 10 episode: -89.352 avegare return across last 100 episodes: -89.503 state values: tensor(0.7720) 167
load offline data!!!!!
mem_cntr: 50000 ; mem_size: 50000
nn.learn_nn_feature_fqi FQI:  998
nn.learn_nn_feature_fqi FQI:  1998
nn.learn_nn_feature_fqi FQI:  2998
nn.learn_nn_feature_fqi FQI:  3998
nn.learn_nn_feature_fqi FQI:  4998
nn.learn_nn_feature_fqi FQI:  5998
nn.learn_nn_feature_fqi FQI:  6998
nn.learn_nn_feature_fqi FQI:  7998
nn.learn_nn_feature_fqi FQI:  8998
nn.learn_nn_feature_fqi FQI:  9998
nn.learn_nn_feature_fqi FQI:  10998
nn.learn_nn_feature_fqi FQI:  11998
nn.learn_nn_feature_fqi FQI:  12998
nn.learn_nn_feature_fqi FQI:  13998
nn.learn_nn_feature_fqi FQI:  14998
nn.learn_nn_feature_fqi FQI:  15998
nn.learn_nn_feature_fqi FQI:  16998
nn.learn_nn_feature_fqi FQI:  17998
nn.learn_nn_feature_fqi FQI:  18998
nn.learn_nn_feature_fqi FQI:  19998
nn.learn_nn_feature_fqi FQI:  20998
nn.learn_nn_feature_fqi FQI:  21998
nn.learn_nn_feature_fqi FQI:  22998
nn.learn_nn_feature_fqi FQI:  23998
nn.learn_nn_feature_fqi FQI:  24998
nn.learn_nn_feature_fqi FQI:  25998
nn.learn_nn_feature_fqi FQI:  26998
nn.learn_nn_feature_fqi FQI:  27998
nn.learn_nn_feature_fqi FQI:  28998
nn.learn_nn_feature_fqi FQI:  29998
nn.learn_nn_feature_fqi FQI:  30998
nn.learn_nn_feature_fqi FQI:  31998
nn.learn_nn_feature_fqi FQI:  32998
nn.learn_nn_feature_fqi FQI:  33998
nn.learn_nn_feature_fqi FQI:  34998
nn.learn_nn_feature_fqi FQI:  35998
nn.learn_nn_feature_fqi FQI:  36998
nn.learn_nn_feature_fqi FQI:  37998
nn.learn_nn_feature_fqi FQI:  38998
nn.learn_nn_feature_fqi FQI:  39998
nn.learn_nn_feature_fqi FQI:  40998
nn.learn_nn_feature_fqi FQI:  41998
nn.learn_nn_feature_fqi FQI:  42998
nn.learn_nn_feature_fqi FQI:  43998
nn.learn_nn_feature_fqi FQI:  44998
nn.learn_nn_feature_fqi FQI:  45998
nn.learn_nn_feature_fqi FQI:  46998
nn.learn_nn_feature_fqi FQI:  47998
nn.learn_nn_feature_fqi FQI:  48998
nn.learn_nn_feature_fqi FQI:  49998
nn.learn_nn_feature_fqi FQI:  50998
nn.learn_nn_feature_fqi FQI:  51998
nn.learn_nn_feature_fqi FQI:  52998
nn.learn_nn_feature_fqi FQI:  53998
nn.learn_nn_feature_fqi FQI:  54998
nn.learn_nn_feature_fqi FQI:  55998
nn.learn_nn_feature_fqi FQI:  56998
nn.learn_nn_feature_fqi FQI:  57998
nn.learn_nn_feature_fqi FQI:  58998
nn.learn_nn_feature_fqi FQI:  59998
nn.learn_nn_feature_fqi FQI:  60998
nn.learn_nn_feature_fqi FQI:  61998
nn.learn_nn_feature_fqi FQI:  62998
nn.learn_nn_feature_fqi FQI:  63998
nn.learn_nn_feature_fqi FQI:  64998
nn.learn_nn_feature_fqi FQI:  65998
nn.learn_nn_feature_fqi FQI:  66998
nn.learn_nn_feature_fqi FQI:  67998
nn.learn_nn_feature_fqi FQI:  68998
nn.learn_nn_feature_fqi FQI:  69998
nn.learn_nn_feature_fqi FQI:  70998
nn.learn_nn_feature_fqi FQI:  71998
nn.learn_nn_feature_fqi FQI:  72998
nn.learn_nn_feature_fqi FQI:  73998
nn.learn_nn_feature_fqi FQI:  74998
nn.learn_nn_feature_fqi FQI:  75998
nn.learn_nn_feature_fqi FQI:  76998
nn.learn_nn_feature_fqi FQI:  77998
nn.learn_nn_feature_fqi FQI:  78998
nn.learn_nn_feature_fqi FQI:  79998
nn.learn_nn_feature_fqi FQI:  80998
nn.learn_nn_feature_fqi FQI:  81998
nn.learn_nn_feature_fqi FQI:  82998
nn.learn_nn_feature_fqi FQI:  83998
nn.learn_nn_feature_fqi FQI:  84998
nn.learn_nn_feature_fqi FQI:  85998
nn.learn_nn_feature_fqi FQI:  86998
nn.learn_nn_feature_fqi FQI:  87998
nn.learn_nn_feature_fqi FQI:  88998
nn.learn_nn_feature_fqi FQI:  89998
nn.learn_nn_feature_fqi FQI:  90998
nn.learn_nn_feature_fqi FQI:  91998
nn.learn_nn_feature_fqi FQI:  92998
nn.learn_nn_feature_fqi FQI:  93998
nn.learn_nn_feature_fqi FQI:  94998
nn.learn_nn_feature_fqi FQI:  95998
nn.learn_nn_feature_fqi FQI:  96998
nn.learn_nn_feature_fqi FQI:  97998
nn.learn_nn_feature_fqi FQI:  98998
nn.learn_nn_feature_fqi FQI:  99998
nn.learn_nn_feature_fqi FQI:  100998
nn.learn_nn_feature_fqi FQI:  101998
nn.learn_nn_feature_fqi FQI:  102998
nn.learn_nn_feature_fqi FQI:  103998
nn.learn_nn_feature_fqi FQI:  104998
nn.learn_nn_feature_fqi FQI:  105998
nn.learn_nn_feature_fqi FQI:  106998
nn.learn_nn_feature_fqi FQI:  107998
nn.learn_nn_feature_fqi FQI:  108998
nn.learn_nn_feature_fqi FQI:  109998
nn.learn_nn_feature_fqi FQI:  110998
nn.learn_nn_feature_fqi FQI:  111998
nn.learn_nn_feature_fqi FQI:  112998
nn.learn_nn_feature_fqi FQI:  113998
nn.learn_nn_feature_fqi FQI:  114998
nn.learn_nn_feature_fqi FQI:  115998
nn.learn_nn_feature_fqi FQI:  116998
nn.learn_nn_feature_fqi FQI:  117998
nn.learn_nn_feature_fqi FQI:  118998
nn.learn_nn_feature_fqi FQI:  119998
nn.learn_nn_feature_fqi FQI:  120998
nn.learn_nn_feature_fqi FQI:  121998
nn.learn_nn_feature_fqi FQI:  122998
nn.learn_nn_feature_fqi FQI:  123998
nn.learn_nn_feature_fqi FQI:  124998
nn.learn_nn_feature_fqi FQI:  125998
nn.learn_nn_feature_fqi FQI:  126998
nn.learn_nn_feature_fqi FQI:  127998
nn.learn_nn_feature_fqi FQI:  128998
nn.learn_nn_feature_fqi FQI:  129998
nn.learn_nn_feature_fqi FQI:  130998
nn.learn_nn_feature_fqi FQI:  131998
nn.learn_nn_feature_fqi FQI:  132998
nn.learn_nn_feature_fqi FQI:  133998
nn.learn_nn_feature_fqi FQI:  134998
nn.learn_nn_feature_fqi FQI:  135998
nn.learn_nn_feature_fqi FQI:  136998
nn.learn_nn_feature_fqi FQI:  137998
nn.learn_nn_feature_fqi FQI:  138998
nn.learn_nn_feature_fqi FQI:  139998
nn.learn_nn_feature_fqi FQI:  140998
nn.learn_nn_feature_fqi FQI:  141998
nn.learn_nn_feature_fqi FQI:  142998
nn.learn_nn_feature_fqi FQI:  143998
nn.learn_nn_feature_fqi FQI:  144998
nn.learn_nn_feature_fqi FQI:  145998
nn.learn_nn_feature_fqi FQI:  146998
nn.learn_nn_feature_fqi FQI:  147998
nn.learn_nn_feature_fqi FQI:  148998
nn.learn_nn_feature_fqi FQI:  149998
nn.learn_nn_feature_fqi FQI:  150998
nn.learn_nn_feature_fqi FQI:  151998
nn.learn_nn_feature_fqi FQI:  152998
nn.learn_nn_feature_fqi FQI:  153998
nn.learn_nn_feature_fqi FQI:  154998
nn.learn_nn_feature_fqi FQI:  155998
0 1001 -1000.0 -98.99572604650622 number episode from 10: 0 avegar over 10 episode: -98.996 avegare return across last 100 episodes: -98.996 state values: tensor(0.6839) 1000
1 1000 -1000.0 -99.99568287525881 number episode from 10: 1 avegar over 10 episode: -99.496 avegare return across last 100 episodes: -99.496 state values: tensor(0.6844) 1000
2 1000 -1000.0 -99.99568287525881 number episode from 10: 2 avegar over 10 episode: -99.662 avegare return across last 100 episodes: -99.662 state values: tensor(0.6830) 1000
3 1000 -1000.0 -99.99568287525881 number episode from 10: 3 avegar over 10 episode: -99.746 avegare return across last 100 episodes: -99.746 state values: tensor(0.6720) 1000
4 1000 -1000.0 -99.99568287525881 number episode from 10: 4 avegar over 10 episode: -99.796 avegare return across last 100 episodes: -99.796 state values: tensor(0.6827) 1000
5 1000 -1000.0 -99.99568287525881 number episode from 10: 5 avegar over 10 episode: -99.829 avegare return across last 100 episodes: -99.829 state values: tensor(0.6738) 1000
6 1000 -1000.0 -99.99568287525881 number episode from 10: 6 avegar over 10 episode: -99.853 avegare return across last 100 episodes: -99.853 state values: tensor(0.6720) 1000
7 1000 -1000.0 -99.99568287525881 number episode from 10: 7 avegar over 10 episode: -99.871 avegare return across last 100 episodes: -99.871 state values: tensor(0.6835) 1000
8 1000 -1000.0 -99.99568287525881 number episode from 10: 8 avegar over 10 episode: -99.885 avegare return across last 100 episodes: -99.885 state values: tensor(0.6834) 1000
9 1000 -1000.0 -99.99568287525881 number episode from 10: 9 avegar over 10 episode: -99.896 avegare return across last 100 episodes: -99.896 state values: tensor(0.6828) 1000
10 1000 -1000.0 -99.99568287525881 number episode from 10: 10 avegar over 10 episode: -99.905 avegare return across last 100 episodes: -99.905 state values: tensor(0.6848) 1000
11 1000 -1000.0 -99.99568287525881 number episode from 10: 11 avegar over 10 episode: -99.912 avegare return across last 100 episodes: -99.912 state values: tensor(0.6718) 1000
12 1000 -1000.0 -99.99568287525881 number episode from 10: 12 avegar over 10 episode: -99.919 avegare return across last 100 episodes: -99.919 state values: tensor(0.6831) 1000
13 1000 -1000.0 -99.99568287525881 number episode from 10: 13 avegar over 10 episode: -99.924 avegare return across last 100 episodes: -99.924 state values: tensor(0.6845) 1000
14 1000 -1000.0 -99.99568287525881 number episode from 10: 14 avegar over 10 episode: -99.929 avegare return across last 100 episodes: -99.929 state values: tensor(0.6718) 1000
15 1000 -1000.0 -99.99568287525881 number episode from 10: 15 avegar over 10 episode: -99.933 avegare return across last 100 episodes: -99.933 state values: tensor(0.6837) 1000
16 1000 -1000.0 -99.99568287525881 number episode from 10: 16 avegar over 10 episode: -99.937 avegare return across last 100 episodes: -99.937 state values: tensor(0.6807) 1000
17 1000 -1000.0 -99.99568287525881 number episode from 10: 17 avegar over 10 episode: -99.94 avegare return across last 100 episodes: -99.94 state values: tensor(0.6838) 1000
18 1000 -1000.0 -99.99568287525881 number episode from 10: 18 avegar over 10 episode: -99.943 avegare return across last 100 episodes: -99.943 state values: tensor(0.6719) 1000
19 1000 -1000.0 -99.99568287525881 number episode from 10: 19 avegar over 10 episode: -99.946 avegare return across last 100 episodes: -99.946 state values: tensor(0.6846) 1000
20 1000 -1000.0 -99.99568287525881 number episode from 10: 20 avegar over 10 episode: -99.948 avegare return across last 100 episodes: -99.948 state values: tensor(0.6841) 1000
21 1000 -1000.0 -99.99568287525881 number episode from 10: 21 avegar over 10 episode: -99.95 avegare return across last 100 episodes: -99.95 state values: tensor(0.6723) 1000
22 1000 -1000.0 -99.99568287525881 number episode from 10: 22 avegar over 10 episode: -99.952 avegare return across last 100 episodes: -99.952 state values: tensor(0.6829) 1000
23 1000 -1000.0 -99.99568287525881 number episode from 10: 23 avegar over 10 episode: -99.954 avegare return across last 100 episodes: -99.954 state values: tensor(0.6718) 1000
24 1000 -1000.0 -99.99568287525881 number episode from 10: 24 avegar over 10 episode: -99.956 avegare return across last 100 episodes: -99.956 state values: tensor(0.6835) 1000
25 1000 -1000.0 -99.99568287525881 number episode from 10: 25 avegar over 10 episode: -99.957 avegare return across last 100 episodes: -99.957 state values: tensor(0.6834) 1000
26 1000 -1000.0 -99.99568287525881 number episode from 10: 26 avegar over 10 episode: -99.959 avegare return across last 100 episodes: -99.959 state values: tensor(0.6827) 1000
27 1000 -1000.0 -99.99568287525881 number episode from 10: 27 avegar over 10 episode: -99.96 avegare return across last 100 episodes: -99.96 state values: tensor(0.6719) 1000
28 1000 -1000.0 -99.99568287525881 number episode from 10: 28 avegar over 10 episode: -99.961 avegare return across last 100 episodes: -99.961 state values: tensor(0.6823) 1000
29 1000 -1000.0 -99.99568287525881 number episode from 10: 29 avegar over 10 episode: -99.962 avegare return across last 100 episodes: -99.962 state values: tensor(0.6853) 1000
30 1000 -1000.0 -99.99568287525881 number episode from 10: 30 avegar over 10 episode: -99.963 avegare return across last 100 episodes: -99.963 state values: tensor(0.6770) 1000
31 1000 -1000.0 -99.99568287525881 number episode from 10: 31 avegar over 10 episode: -99.964 avegare return across last 100 episodes: -99.964 state values: tensor(0.6849) 1000
32 1000 -1000.0 -99.99568287525881 number episode from 10: 32 avegar over 10 episode: -99.965 avegare return across last 100 episodes: -99.965 state values: tensor(0.6715) 1000
33 1000 -1000.0 -99.99568287525881 number episode from 10: 33 avegar over 10 episode: -99.966 avegare return across last 100 episodes: -99.966 state values: tensor(0.6833) 1000
34 1000 -1000.0 -99.99568287525881 number episode from 10: 34 avegar over 10 episode: -99.967 avegare return across last 100 episodes: -99.967 state values: tensor(0.6828) 1000
35 1000 -1000.0 -99.99568287525881 number episode from 10: 35 avegar over 10 episode: -99.968 avegare return across last 100 episodes: -99.968 state values: tensor(0.6842) 1000
36 1000 -1000.0 -99.99568287525881 number episode from 10: 36 avegar over 10 episode: -99.969 avegare return across last 100 episodes: -99.969 state values: tensor(0.6834) 1000
37 1000 -1000.0 -99.99568287525881 number episode from 10: 37 avegar over 10 episode: -99.969 avegare return across last 100 episodes: -99.969 state values: tensor(0.6840) 1000
38 1000 -1000.0 -99.99568287525881 number episode from 10: 38 avegar over 10 episode: -99.97 avegare return across last 100 episodes: -99.97 state values: tensor(0.6827) 1000
39 1000 -1000.0 -99.99568287525881 number episode from 10: 39 avegar over 10 episode: -99.971 avegare return across last 100 episodes: -99.971 state values: tensor(0.6720) 1000
40 1000 -1000.0 -99.99568287525881 number episode from 10: 40 avegar over 10 episode: -99.971 avegare return across last 100 episodes: -99.971 state values: tensor(0.6840) 1000
41 1000 -1000.0 -99.99568287525881 number episode from 10: 41 avegar over 10 episode: -99.972 avegare return across last 100 episodes: -99.972 state values: tensor(0.6830) 1000
42 1000 -1000.0 -99.99568287525881 number episode from 10: 42 avegar over 10 episode: -99.972 avegare return across last 100 episodes: -99.972 state values: tensor(0.6719) 1000
43 1000 -1000.0 -99.99568287525881 number episode from 10: 43 avegar over 10 episode: -99.973 avegare return across last 100 episodes: -99.973 state values: tensor(0.6837) 1000
44 1000 -1000.0 -99.99568287525881 number episode from 10: 44 avegar over 10 episode: -99.973 avegare return across last 100 episodes: -99.973 state values: tensor(0.6716) 1000
45 1000 -1000.0 -99.99568287525881 number episode from 10: 45 avegar over 10 episode: -99.974 avegare return across last 100 episodes: -99.974 state values: tensor(0.6788) 1000
46 1000 -1000.0 -99.99568287525881 number episode from 10: 46 avegar over 10 episode: -99.974 avegare return across last 100 episodes: -99.974 state values: tensor(0.6835) 1000
47 1000 -1000.0 -99.99568287525881 number episode from 10: 47 avegar over 10 episode: -99.975 avegare return across last 100 episodes: -99.975 state values: tensor(0.6846) 1000
48 1000 -1000.0 -99.99568287525881 number episode from 10: 48 avegar over 10 episode: -99.975 avegare return across last 100 episodes: -99.975 state values: tensor(0.6847) 1000
49 1000 -1000.0 -99.99568287525881 number episode from 10: 49 avegar over 10 episode: -99.976 avegare return across last 100 episodes: -99.976 state values: tensor(0.6844) 1000
50 1000 -1000.0 -99.99568287525881 number episode from 10: 50 avegar over 10 episode: -99.976 avegare return across last 100 episodes: -99.976 state values: tensor(0.6835) 1000
51 1000 -1000.0 -99.99568287525881 number episode from 10: 51 avegar over 10 episode: -99.976 avegare return across last 100 episodes: -99.976 state values: tensor(0.6836) 1000
52 1000 -1000.0 -99.99568287525881 number episode from 10: 52 avegar over 10 episode: -99.977 avegare return across last 100 episodes: -99.977 state values: tensor(0.6830) 1000
53 1000 -1000.0 -99.99568287525881 number episode from 10: 53 avegar over 10 episode: -99.977 avegare return across last 100 episodes: -99.977 state values: tensor(0.6795) 1000
54 1000 -1000.0 -99.99568287525881 number episode from 10: 54 avegar over 10 episode: -99.978 avegare return across last 100 episodes: -99.978 state values: tensor(0.6834) 1000
55 1000 -1000.0 -99.99568287525881 number episode from 10: 55 avegar over 10 episode: -99.978 avegare return across last 100 episodes: -99.978 state values: tensor(0.6849) 1000
56 1000 -1000.0 -99.99568287525881 number episode from 10: 56 avegar over 10 episode: -99.978 avegare return across last 100 episodes: -99.978 state values: tensor(0.6842) 1000
57 1000 -1000.0 -99.99568287525881 number episode from 10: 57 avegar over 10 episode: -99.978 avegare return across last 100 episodes: -99.978 state values: tensor(0.6822) 1000
58 1000 -1000.0 -99.99568287525881 number episode from 10: 58 avegar over 10 episode: -99.979 avegare return across last 100 episodes: -99.979 state values: tensor(0.6837) 1000
59 1000 -1000.0 -99.99568287525881 number episode from 10: 59 avegar over 10 episode: -99.979 avegare return across last 100 episodes: -99.979 state values: tensor(0.6827) 1000
60 1000 -1000.0 -99.99568287525881 number episode from 10: 60 avegar over 10 episode: -99.979 avegare return across last 100 episodes: -99.979 state values: tensor(0.6838) 1000
61 1000 -1000.0 -99.99568287525881 number episode from 10: 61 avegar over 10 episode: -99.98 avegare return across last 100 episodes: -99.98 state values: tensor(0.6718) 1000
62 1000 -1000.0 -99.99568287525881 number episode from 10: 62 avegar over 10 episode: -99.98 avegare return across last 100 episodes: -99.98 state values: tensor(0.6826) 1000
63 1000 -1000.0 -99.99568287525881 number episode from 10: 63 avegar over 10 episode: -99.98 avegare return across last 100 episodes: -99.98 state values: tensor(0.6719) 1000
64 1000 -1000.0 -99.99568287525881 number episode from 10: 64 avegar over 10 episode: -99.98 avegare return across last 100 episodes: -99.98 state values: tensor(0.6842) 1000
65 1000 -1000.0 -99.99568287525881 number episode from 10: 65 avegar over 10 episode: -99.981 avegare return across last 100 episodes: -99.981 state values: tensor(0.6847) 1000
66 1000 -1000.0 -99.99568287525881 number episode from 10: 66 avegar over 10 episode: -99.981 avegare return across last 100 episodes: -99.981 state values: tensor(0.6833) 1000
67 1000 -1000.0 -99.99568287525881 number episode from 10: 67 avegar over 10 episode: -99.981 avegare return across last 100 episodes: -99.981 state values: tensor(0.6842) 1000
68 1000 -1000.0 -99.99568287525881 number episode from 10: 68 avegar over 10 episode: -99.981 avegare return across last 100 episodes: -99.981 state values: tensor(0.6843) 1000
69 1000 -1000.0 -99.99568287525881 number episode from 10: 69 avegar over 10 episode: -99.981 avegare return across last 100 episodes: -99.981 state values: tensor(0.6844) 1000
70 1000 -1000.0 -99.99568287525881 number episode from 10: 70 avegar over 10 episode: -99.982 avegare return across last 100 episodes: -99.982 state values: tensor(0.6718) 1000
71 1000 -1000.0 -99.99568287525881 number episode from 10: 71 avegar over 10 episode: -99.982 avegare return across last 100 episodes: -99.982 state values: tensor(0.6831) 1000
72 1000 -1000.0 -99.99568287525881 number episode from 10: 72 avegar over 10 episode: -99.982 avegare return across last 100 episodes: -99.982 state values: tensor(0.6849) 1000
73 1000 -1000.0 -99.99568287525881 number episode from 10: 73 avegar over 10 episode: -99.982 avegare return across last 100 episodes: -99.982 state values: tensor(0.6848) 1000
74 1000 -1000.0 -99.99568287525881 number episode from 10: 74 avegar over 10 episode: -99.982 avegare return across last 100 episodes: -99.982 state values: tensor(0.6826) 1000
75 1000 -1000.0 -99.99568287525881 number episode from 10: 75 avegar over 10 episode: -99.983 avegare return across last 100 episodes: -99.983 state values: tensor(0.6842) 1000
76 1000 -1000.0 -99.99568287525881 number episode from 10: 76 avegar over 10 episode: -99.983 avegare return across last 100 episodes: -99.983 state values: tensor(0.6822) 1000
77 1000 -1000.0 -99.99568287525881 number episode from 10: 77 avegar over 10 episode: -99.983 avegare return across last 100 episodes: -99.983 state values: tensor(0.6833) 1000
78 1000 -1000.0 -99.99568287525881 number episode from 10: 78 avegar over 10 episode: -99.983 avegare return across last 100 episodes: -99.983 state values: tensor(0.6830) 1000
79 1000 -1000.0 -99.99568287525881 number episode from 10: 79 avegar over 10 episode: -99.983 avegare return across last 100 episodes: -99.983 state values: tensor(0.6843) 1000
80 1000 -1000.0 -99.99568287525881 number episode from 10: 80 avegar over 10 episode: -99.983 avegare return across last 100 episodes: -99.983 state values: tensor(0.6715) 1000
81 1000 -1000.0 -99.99568287525881 number episode from 10: 81 avegar over 10 episode: -99.983 avegare return across last 100 episodes: -99.983 state values: tensor(0.6829) 1000
82 1000 -1000.0 -99.99568287525881 number episode from 10: 82 avegar over 10 episode: -99.984 avegare return across last 100 episodes: -99.984 state values: tensor(0.6833) 1000
83 1000 -1000.0 -99.99568287525881 number episode from 10: 83 avegar over 10 episode: -99.984 avegare return across last 100 episodes: -99.984 state values: tensor(0.6824) 1000
84 1000 -1000.0 -99.99568287525881 number episode from 10: 84 avegar over 10 episode: -99.984 avegare return across last 100 episodes: -99.984 state values: tensor(0.6838) 1000
85 1000 -1000.0 -99.99568287525881 number episode from 10: 85 avegar over 10 episode: -99.984 avegare return across last 100 episodes: -99.984 state values: tensor(0.6822) 1000
86 1000 -1000.0 -99.99568287525881 number episode from 10: 86 avegar over 10 episode: -99.984 avegare return across last 100 episodes: -99.984 state values: tensor(0.6827) 1000
87 1000 -1000.0 -99.99568287525881 number episode from 10: 87 avegar over 10 episode: -99.984 avegare return across last 100 episodes: -99.984 state values: tensor(0.6801) 1000
88 1000 -1000.0 -99.99568287525881 number episode from 10: 88 avegar over 10 episode: -99.984 avegare return across last 100 episodes: -99.984 state values: tensor(0.6814) 1000
89 1000 -1000.0 -99.99568287525881 number episode from 10: 89 avegar over 10 episode: -99.985 avegare return across last 100 episodes: -99.985 state values: tensor(0.6842) 1000
90 1000 -1000.0 -99.99568287525881 number episode from 10: 90 avegar over 10 episode: -99.985 avegare return across last 100 episodes: -99.985 state values: tensor(0.6717) 1000
91 1000 -1000.0 -99.99568287525881 number episode from 10: 91 avegar over 10 episode: -99.985 avegare return across last 100 episodes: -99.985 state values: tensor(0.6719) 1000
92 1000 -1000.0 -99.99568287525881 number episode from 10: 92 avegar over 10 episode: -99.985 avegare return across last 100 episodes: -99.985 state values: tensor(0.6827) 1000
93 1000 -1000.0 -99.99568287525881 number episode from 10: 93 avegar over 10 episode: -99.985 avegare return across last 100 episodes: -99.985 state values: tensor(0.6772) 1000
94 1000 -1000.0 -99.99568287525881 number episode from 10: 94 avegar over 10 episode: -99.985 avegare return across last 100 episodes: -99.985 state values: tensor(0.6843) 1000
95 1000 -1000.0 -99.99568287525881 number episode from 10: 95 avegar over 10 episode: -99.985 avegare return across last 100 episodes: -99.985 state values: tensor(0.6836) 1000
96 1000 -1000.0 -99.99568287525881 number episode from 10: 96 avegar over 10 episode: -99.985 avegare return across last 100 episodes: -99.985 state values: tensor(0.6718) 1000
97 1000 -1000.0 -99.99568287525881 number episode from 10: 97 avegar over 10 episode: -99.985 avegare return across last 100 episodes: -99.985 state values: tensor(0.6722) 1000
98 1000 -1000.0 -99.99568287525881 number episode from 10: 98 avegar over 10 episode: -99.986 avegare return across last 100 episodes: -99.986 state values: tensor(0.6829) 1000
99 1000 -1000.0 -99.99568287525881 number episode from 10: 99 avegar over 10 episode: -99.986 avegare return across last 100 episodes: -99.986 state values: tensor(0.6847) 1000
100 1000 -1000.0 -99.99568287525881 number episode from 10: 100 avegar over 10 episode: -99.986 avegare return across last 100 episodes: -99.996 state values: tensor(0.6828) 1000
101 1000 -1000.0 -99.99568287525881 number episode from 10: 101 avegar over 10 episode: -99.986 avegare return across last 100 episodes: -99.996 state values: tensor(0.6840) 1000
102 1000 -1000.0 -99.99568287525881 number episode from 10: 102 avegar over 10 episode: -99.986 avegare return across last 100 episodes: -99.996 state values: tensor(0.6831) 1000
103 1000 -1000.0 -99.99568287525881 number episode from 10: 103 avegar over 10 episode: -99.986 avegare return across last 100 episodes: -99.996 state values: tensor(0.6832) 1000
104 1000 -1000.0 -99.99568287525881 number episode from 10: 104 avegar over 10 episode: -99.986 avegare return across last 100 episodes: -99.996 state values: tensor(0.6842) 1000
105 1000 -1000.0 -99.99568287525881 number episode from 10: 105 avegar over 10 episode: -99.986 avegare return across last 100 episodes: -99.996 state values: tensor(0.6716) 1000
106 1000 -1000.0 -99.99568287525881 number episode from 10: 106 avegar over 10 episode: -99.986 avegare return across last 100 episodes: -99.996 state values: tensor(0.6788) 1000
107 1000 -1000.0 -99.99568287525881 number episode from 10: 107 avegar over 10 episode: -99.986 avegare return across last 100 episodes: -99.996 state values: tensor(0.6834) 1000
108 1000 -1000.0 -99.99568287525881 number episode from 10: 108 avegar over 10 episode: -99.987 avegare return across last 100 episodes: -99.996 state values: tensor(0.6744) 1000
109 1000 -1000.0 -99.99568287525881 number episode from 10: 109 avegar over 10 episode: -99.987 avegare return across last 100 episodes: -99.996 state values: tensor(0.6720) 1000
110 1000 -1000.0 -99.99568287525881 number episode from 10: 110 avegar over 10 episode: -99.987 avegare return across last 100 episodes: -99.996 state values: tensor(0.6826) 1000
111 1000 -1000.0 -99.99568287525881 number episode from 10: 111 avegar over 10 episode: -99.987 avegare return across last 100 episodes: -99.996 state values: tensor(0.6856) 1000
112 1000 -1000.0 -99.99568287525881 number episode from 10: 112 avegar over 10 episode: -99.987 avegare return across last 100 episodes: -99.996 state values: tensor(0.6848) 1000
113 1000 -1000.0 -99.99568287525881 number episode from 10: 113 avegar over 10 episode: -99.987 avegare return across last 100 episodes: -99.996 state values: tensor(0.6719) 1000
114 1000 -1000.0 -99.99568287525881 number episode from 10: 114 avegar over 10 episode: -99.987 avegare return across last 100 episodes: -99.996 state values: tensor(0.6829) 1000
115 1000 -1000.0 -99.99568287525881 number episode from 10: 115 avegar over 10 episode: -99.987 avegare return across last 100 episodes: -99.996 state values: tensor(0.6845) 1000
116 1000 -1000.0 -99.99568287525881 number episode from 10: 116 avegar over 10 episode: -99.987 avegare return across last 100 episodes: -99.996 state values: tensor(0.6777) 1000
117 1000 -1000.0 -99.99568287525881 number episode from 10: 117 avegar over 10 episode: -99.987 avegare return across last 100 episodes: -99.996 state values: tensor(0.6838) 1000
118 1000 -1000.0 -99.99568287525881 number episode from 10: 118 avegar over 10 episode: -99.987 avegare return across last 100 episodes: -99.996 state values: tensor(0.6822) 1000
119 1000 -1000.0 -99.99568287525881 number episode from 10: 119 avegar over 10 episode: -99.987 avegare return across last 100 episodes: -99.996 state values: tensor(0.6721) 1000
120 1000 -1000.0 -99.99568287525881 number episode from 10: 120 avegar over 10 episode: -99.987 avegare return across last 100 episodes: -99.996 state values: tensor(0.6715) 1000
121 1000 -1000.0 -99.99568287525881 number episode from 10: 121 avegar over 10 episode: -99.987 avegare return across last 100 episodes: -99.996 state values: tensor(0.6836) 1000
122 1000 -1000.0 -99.99568287525881 number episode from 10: 122 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.6828) 1000
123 1000 -1000.0 -99.99568287525881 number episode from 10: 123 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.6842) 1000
124 1000 -1000.0 -99.99568287525881 number episode from 10: 124 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.6847) 1000
125 1000 -1000.0 -99.99568287525881 number episode from 10: 125 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.6826) 1000
126 1000 -1000.0 -99.99568287525881 number episode from 10: 126 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.6852) 1000
127 1000 -1000.0 -99.99568287525881 number episode from 10: 127 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.6833) 1000
128 1000 -1000.0 -99.99568287525881 number episode from 10: 128 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.6826) 1000
129 1000 -1000.0 -99.99568287525881 number episode from 10: 129 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.6851) 1000
130 1000 -1000.0 -99.99568287525881 number episode from 10: 130 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.6831) 1000
131 1000 -1000.0 -99.99568287525881 number episode from 10: 131 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.6836) 1000
132 1000 -1000.0 -99.99568287525881 number episode from 10: 132 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.6748) 1000
133 1000 -1000.0 -99.99568287525881 number episode from 10: 133 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.6826) 1000
134 1000 -1000.0 -99.99568287525881 number episode from 10: 134 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.6832) 1000
135 1000 -1000.0 -99.99568287525881 number episode from 10: 135 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.6837) 1000
136 1000 -1000.0 -99.99568287525881 number episode from 10: 136 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.6849) 1000
137 1000 -1000.0 -99.99568287525881 number episode from 10: 137 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.6720) 1000
138 1000 -1000.0 -99.99568287525881 number episode from 10: 138 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.6850) 1000
139 1000 -1000.0 -99.99568287525881 number episode from 10: 139 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.6827) 1000
140 1000 -1000.0 -99.99568287525881 number episode from 10: 140 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.6827) 1000
141 1000 -1000.0 -99.99568287525881 number episode from 10: 141 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.6818) 1000
142 1000 -1000.0 -99.99568287525881 number episode from 10: 142 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.6841) 1000
143 1000 -1000.0 -99.99568287525881 number episode from 10: 143 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.6828) 1000
144 1000 -1000.0 -99.99568287525881 number episode from 10: 144 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.6718) 1000
145 1000 -1000.0 -99.99568287525881 number episode from 10: 145 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.6719) 1000
146 1000 -1000.0 -99.99568287525881 number episode from 10: 146 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.6850) 1000
147 1000 -1000.0 -99.99568287525881 number episode from 10: 147 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.6845) 1000
148 1000 -1000.0 -99.99568287525881 number episode from 10: 148 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.6852) 1000
149 1000 -1000.0 -99.99568287525881 number episode from 10: 149 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.6718) 1000
150 1000 -1000.0 -99.99568287525881 number episode from 10: 150 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.6830) 1000
151 1000 -1000.0 -99.99568287525881 number episode from 10: 151 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.6831) 1000
152 1000 -1000.0 -99.99568287525881 number episode from 10: 152 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.6844) 1000
153 1000 -1000.0 -99.99568287525881 number episode from 10: 153 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.6825) 1000
154 1000 -1000.0 -99.99568287525881 number episode from 10: 154 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.6825) 1000
155 1000 -1000.0 -99.99568287525881 number episode from 10: 155 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.6775) 1000
156 1000 -1000.0 -99.99568287525881 number episode from 10: 156 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.6759) 1000
157 1000 -1000.0 -99.99568287525881 number episode from 10: 157 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.6717) 1000
158 1000 -1000.0 -99.99568287525881 number episode from 10: 158 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.6826) 1000
159 1000 -1000.0 -99.99568287525881 number episode from 10: 159 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.6716) 1000
160 1000 -1000.0 -99.99568287525881 number episode from 10: 160 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.6827) 1000
161 1000 -1000.0 -99.99568287525881 number episode from 10: 161 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.6845) 1000
162 1000 -1000.0 -99.99568287525881 number episode from 10: 162 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.6827) 1000
163 1000 -1000.0 -99.99568287525881 number episode from 10: 163 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.6718) 1000
164 1000 -1000.0 -99.99568287525881 number episode from 10: 164 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.6835) 1000
165 1000 -1000.0 -99.99568287525881 number episode from 10: 165 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.6722) 1000
166 1000 -1000.0 -99.99568287525881 number episode from 10: 166 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.6836) 1000
167 1000 -1000.0 -99.99568287525881 number episode from 10: 167 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.6717) 1000
168 1000 -1000.0 -99.99568287525881 number episode from 10: 168 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.6838) 1000
169 1000 -1000.0 -99.99568287525881 number episode from 10: 169 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.6785) 1000
170 1000 -1000.0 -99.99568287525881 number episode from 10: 170 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.6736) 1000
171 1000 -1000.0 -99.99568287525881 number episode from 10: 171 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.6839) 1000
172 1000 -1000.0 -99.99568287525881 number episode from 10: 172 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.6843) 1000
173 1000 -1000.0 -99.99568287525881 number episode from 10: 173 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.6718) 1000
174 1000 -1000.0 -99.99568287525881 number episode from 10: 174 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.6828) 1000
175 1000 -1000.0 -99.99568287525881 number episode from 10: 175 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.6832) 1000
176 1000 -1000.0 -99.99568287525881 number episode from 10: 176 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.6851) 1000
177 1000 -1000.0 -99.99568287525881 number episode from 10: 177 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.6839) 1000
178 1000 -1000.0 -99.99568287525881 number episode from 10: 178 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.6830) 1000
179 1000 -1000.0 -99.99568287525881 number episode from 10: 179 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.6830) 1000
180 1000 -1000.0 -99.99568287525881 number episode from 10: 180 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.6844) 1000
181 1000 -1000.0 -99.99568287525881 number episode from 10: 181 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.6830) 1000
182 1000 -1000.0 -99.99568287525881 number episode from 10: 182 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.6718) 1000
183 1000 -1000.0 -99.99568287525881 number episode from 10: 183 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.6717) 1000
184 1000 -1000.0 -99.99568287525881 number episode from 10: 184 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.6716) 1000
185 1000 -1000.0 -99.99568287525881 number episode from 10: 185 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.6843) 1000
186 1000 -1000.0 -99.99568287525881 number episode from 10: 186 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.6850) 1000
187 1000 -1000.0 -99.99568287525881 number episode from 10: 187 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.6733) 1000
188 1000 -1000.0 -99.99568287525881 number episode from 10: 188 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.6839) 1000
189 1000 -1000.0 -99.99568287525881 number episode from 10: 189 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.6823) 1000
190 1000 -1000.0 -99.99568287525881 number episode from 10: 190 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.6825) 1000
191 1000 -1000.0 -99.99568287525881 number episode from 10: 191 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.6718) 1000
192 1000 -1000.0 -99.99568287525881 number episode from 10: 192 avegar over 10 episode: -99.991 avegare return across last 100 episodes: -99.996 state values: tensor(0.6719) 1000
193 1000 -1000.0 -99.99568287525881 number episode from 10: 193 avegar over 10 episode: -99.991 avegare return across last 100 episodes: -99.996 state values: tensor(0.6826) 1000
194 1000 -1000.0 -99.99568287525881 number episode from 10: 194 avegar over 10 episode: -99.991 avegare return across last 100 episodes: -99.996 state values: tensor(0.6822) 1000
195 1000 -1000.0 -99.99568287525881 number episode from 10: 195 avegar over 10 episode: -99.991 avegare return across last 100 episodes: -99.996 state values: tensor(0.6740) 1000
196 1000 -1000.0 -99.99568287525881 number episode from 10: 196 avegar over 10 episode: -99.991 avegare return across last 100 episodes: -99.996 state values: tensor(0.6835) 1000
197 1000 -1000.0 -99.99568287525881 number episode from 10: 197 avegar over 10 episode: -99.991 avegare return across last 100 episodes: -99.996 state values: tensor(0.6828) 1000
198 1000 -1000.0 -99.99568287525881 number episode from 10: 198 avegar over 10 episode: -99.991 avegare return across last 100 episodes: -99.996 state values: tensor(0.6827) 1000
199 1000 -1000.0 -99.99568287525881 number episode from 10: 199 avegar over 10 episode: -99.991 avegare return across last 100 episodes: -99.996 state values: tensor(0.6823) 1000
200 1000 -1000.0 -99.99568287525881 number episode from 10: 200 avegar over 10 episode: -99.991 avegare return across last 100 episodes: -99.996 state values: tensor(0.6838) 1000
load offline data!!!!!
mem_cntr: 50000 ; mem_size: 50000
nn.learn_nn_feature_fqi FQI:  998
nn.learn_nn_feature_fqi FQI:  1998
nn.learn_nn_feature_fqi FQI:  2998
nn.learn_nn_feature_fqi FQI:  3998
nn.learn_nn_feature_fqi FQI:  4998
nn.learn_nn_feature_fqi FQI:  5998
nn.learn_nn_feature_fqi FQI:  6998
nn.learn_nn_feature_fqi FQI:  7998
nn.learn_nn_feature_fqi FQI:  8998
nn.learn_nn_feature_fqi FQI:  9998
nn.learn_nn_feature_fqi FQI:  10998
nn.learn_nn_feature_fqi FQI:  11998
nn.learn_nn_feature_fqi FQI:  12998
nn.learn_nn_feature_fqi FQI:  13998
nn.learn_nn_feature_fqi FQI:  14998
nn.learn_nn_feature_fqi FQI:  15998
nn.learn_nn_feature_fqi FQI:  16998
nn.learn_nn_feature_fqi FQI:  17998
nn.learn_nn_feature_fqi FQI:  18998
nn.learn_nn_feature_fqi FQI:  19998
nn.learn_nn_feature_fqi FQI:  20998
nn.learn_nn_feature_fqi FQI:  21998
nn.learn_nn_feature_fqi FQI:  22998
nn.learn_nn_feature_fqi FQI:  23998
nn.learn_nn_feature_fqi FQI:  24998
nn.learn_nn_feature_fqi FQI:  25998
nn.learn_nn_feature_fqi FQI:  26998
nn.learn_nn_feature_fqi FQI:  27998
nn.learn_nn_feature_fqi FQI:  28998
nn.learn_nn_feature_fqi FQI:  29998
nn.learn_nn_feature_fqi FQI:  30998
nn.learn_nn_feature_fqi FQI:  31998
nn.learn_nn_feature_fqi FQI:  32998
nn.learn_nn_feature_fqi FQI:  33998
nn.learn_nn_feature_fqi FQI:  34998
nn.learn_nn_feature_fqi FQI:  35998
nn.learn_nn_feature_fqi FQI:  36998
nn.learn_nn_feature_fqi FQI:  37998
nn.learn_nn_feature_fqi FQI:  38998
nn.learn_nn_feature_fqi FQI:  39998
nn.learn_nn_feature_fqi FQI:  40998
nn.learn_nn_feature_fqi FQI:  41998
nn.learn_nn_feature_fqi FQI:  42998
nn.learn_nn_feature_fqi FQI:  43998
nn.learn_nn_feature_fqi FQI:  44998
nn.learn_nn_feature_fqi FQI:  45998
nn.learn_nn_feature_fqi FQI:  46998
nn.learn_nn_feature_fqi FQI:  47998
nn.learn_nn_feature_fqi FQI:  48998
nn.learn_nn_feature_fqi FQI:  49998
nn.learn_nn_feature_fqi FQI:  50998
nn.learn_nn_feature_fqi FQI:  51998
nn.learn_nn_feature_fqi FQI:  52998
nn.learn_nn_feature_fqi FQI:  53998
nn.learn_nn_feature_fqi FQI:  54998
nn.learn_nn_feature_fqi FQI:  55998
nn.learn_nn_feature_fqi FQI:  56998
nn.learn_nn_feature_fqi FQI:  57998
nn.learn_nn_feature_fqi FQI:  58998
nn.learn_nn_feature_fqi FQI:  59998
nn.learn_nn_feature_fqi FQI:  60998
nn.learn_nn_feature_fqi FQI:  61998
nn.learn_nn_feature_fqi FQI:  62998
nn.learn_nn_feature_fqi FQI:  63998
nn.learn_nn_feature_fqi FQI:  64998
nn.learn_nn_feature_fqi FQI:  65998
nn.learn_nn_feature_fqi FQI:  66998
nn.learn_nn_feature_fqi FQI:  67998
nn.learn_nn_feature_fqi FQI:  68998
nn.learn_nn_feature_fqi FQI:  69998
nn.learn_nn_feature_fqi FQI:  70998
nn.learn_nn_feature_fqi FQI:  71998
nn.learn_nn_feature_fqi FQI:  72998
nn.learn_nn_feature_fqi FQI:  73998
nn.learn_nn_feature_fqi FQI:  74998
nn.learn_nn_feature_fqi FQI:  75998
nn.learn_nn_feature_fqi FQI:  76998
nn.learn_nn_feature_fqi FQI:  77998
nn.learn_nn_feature_fqi FQI:  78998
nn.learn_nn_feature_fqi FQI:  79998
nn.learn_nn_feature_fqi FQI:  80998
nn.learn_nn_feature_fqi FQI:  81998
nn.learn_nn_feature_fqi FQI:  82998
nn.learn_nn_feature_fqi FQI:  83998
nn.learn_nn_feature_fqi FQI:  84998
nn.learn_nn_feature_fqi FQI:  85998
nn.learn_nn_feature_fqi FQI:  86998
nn.learn_nn_feature_fqi FQI:  87998
nn.learn_nn_feature_fqi FQI:  88998
nn.learn_nn_feature_fqi FQI:  89998
nn.learn_nn_feature_fqi FQI:  90998
nn.learn_nn_feature_fqi FQI:  91998
nn.learn_nn_feature_fqi FQI:  92998
nn.learn_nn_feature_fqi FQI:  93998
nn.learn_nn_feature_fqi FQI:  94998
nn.learn_nn_feature_fqi FQI:  95998
nn.learn_nn_feature_fqi FQI:  96998
nn.learn_nn_feature_fqi FQI:  97998
nn.learn_nn_feature_fqi FQI:  98998
nn.learn_nn_feature_fqi FQI:  99998
nn.learn_nn_feature_fqi FQI:  100998
nn.learn_nn_feature_fqi FQI:  101998
nn.learn_nn_feature_fqi FQI:  102998
nn.learn_nn_feature_fqi FQI:  103998
nn.learn_nn_feature_fqi FQI:  104998
nn.learn_nn_feature_fqi FQI:  105998
nn.learn_nn_feature_fqi FQI:  106998
nn.learn_nn_feature_fqi FQI:  107998
nn.learn_nn_feature_fqi FQI:  108998
nn.learn_nn_feature_fqi FQI:  109998
nn.learn_nn_feature_fqi FQI:  110998
nn.learn_nn_feature_fqi FQI:  111998
nn.learn_nn_feature_fqi FQI:  112998
nn.learn_nn_feature_fqi FQI:  113998
nn.learn_nn_feature_fqi FQI:  114998
nn.learn_nn_feature_fqi FQI:  115998
nn.learn_nn_feature_fqi FQI:  116998
nn.learn_nn_feature_fqi FQI:  117998
nn.learn_nn_feature_fqi FQI:  118998
nn.learn_nn_feature_fqi FQI:  119998
nn.learn_nn_feature_fqi FQI:  120998
nn.learn_nn_feature_fqi FQI:  121998
nn.learn_nn_feature_fqi FQI:  122998
nn.learn_nn_feature_fqi FQI:  123998
nn.learn_nn_feature_fqi FQI:  124998
nn.learn_nn_feature_fqi FQI:  125998
nn.learn_nn_feature_fqi FQI:  126998
nn.learn_nn_feature_fqi FQI:  127998
nn.learn_nn_feature_fqi FQI:  128998
nn.learn_nn_feature_fqi FQI:  129998
nn.learn_nn_feature_fqi FQI:  130998
nn.learn_nn_feature_fqi FQI:  131998
nn.learn_nn_feature_fqi FQI:  132998
nn.learn_nn_feature_fqi FQI:  133998
nn.learn_nn_feature_fqi FQI:  134998
nn.learn_nn_feature_fqi FQI:  135998
nn.learn_nn_feature_fqi FQI:  136998
nn.learn_nn_feature_fqi FQI:  137998
nn.learn_nn_feature_fqi FQI:  138998
nn.learn_nn_feature_fqi FQI:  139998
nn.learn_nn_feature_fqi FQI:  140998
nn.learn_nn_feature_fqi FQI:  141998
nn.learn_nn_feature_fqi FQI:  142998
nn.learn_nn_feature_fqi FQI:  143998
nn.learn_nn_feature_fqi FQI:  144998
nn.learn_nn_feature_fqi FQI:  145998
nn.learn_nn_feature_fqi FQI:  146998
nn.learn_nn_feature_fqi FQI:  147998
nn.learn_nn_feature_fqi FQI:  148998
nn.learn_nn_feature_fqi FQI:  149998
nn.learn_nn_feature_fqi FQI:  150998
nn.learn_nn_feature_fqi FQI:  151998
nn.learn_nn_feature_fqi FQI:  152998
nn.learn_nn_feature_fqi FQI:  153998
nn.learn_nn_feature_fqi FQI:  154998
nn.learn_nn_feature_fqi FQI:  155998
0 1001 -1000.0 -98.99572604650622 number episode from 10: 0 avegar over 10 episode: -98.996 avegare return across last 100 episodes: -98.996 state values: tensor(0.5716) 1000
1 1000 -1000.0 -99.99568287525881 number episode from 10: 1 avegar over 10 episode: -99.496 avegare return across last 100 episodes: -99.496 state values: tensor(0.5716) 1000
2 1000 -1000.0 -99.99568287525881 number episode from 10: 2 avegar over 10 episode: -99.662 avegare return across last 100 episodes: -99.662 state values: tensor(0.5718) 1000
3 1000 -1000.0 -99.99568287525881 number episode from 10: 3 avegar over 10 episode: -99.746 avegare return across last 100 episodes: -99.746 state values: tensor(0.5718) 1000
4 1000 -1000.0 -99.99568287525881 number episode from 10: 4 avegar over 10 episode: -99.796 avegare return across last 100 episodes: -99.796 state values: tensor(0.5716) 1000
5 1000 -1000.0 -99.99568287525881 number episode from 10: 5 avegar over 10 episode: -99.829 avegare return across last 100 episodes: -99.829 state values: tensor(0.5715) 1000
6 1000 -1000.0 -99.99568287525881 number episode from 10: 6 avegar over 10 episode: -99.853 avegare return across last 100 episodes: -99.853 state values: tensor(0.5718) 1000
7 1000 -1000.0 -99.99568287525881 number episode from 10: 7 avegar over 10 episode: -99.871 avegare return across last 100 episodes: -99.871 state values: tensor(0.5716) 1000
8 1000 -1000.0 -99.99568287525881 number episode from 10: 8 avegar over 10 episode: -99.885 avegare return across last 100 episodes: -99.885 state values: tensor(0.5717) 1000
9 1000 -1000.0 -99.99568287525881 number episode from 10: 9 avegar over 10 episode: -99.896 avegare return across last 100 episodes: -99.896 state values: tensor(0.5716) 1000
10 1000 -1000.0 -99.99568287525881 number episode from 10: 10 avegar over 10 episode: -99.905 avegare return across last 100 episodes: -99.905 state values: tensor(0.5716) 1000
11 1000 -1000.0 -99.99568287525881 number episode from 10: 11 avegar over 10 episode: -99.912 avegare return across last 100 episodes: -99.912 state values: tensor(0.5716) 1000
12 1000 -1000.0 -99.99568287525881 number episode from 10: 12 avegar over 10 episode: -99.919 avegare return across last 100 episodes: -99.919 state values: tensor(0.5718) 1000
13 1000 -1000.0 -99.99568287525881 number episode from 10: 13 avegar over 10 episode: -99.924 avegare return across last 100 episodes: -99.924 state values: tensor(0.5716) 1000
14 1000 -1000.0 -99.99568287525881 number episode from 10: 14 avegar over 10 episode: -99.929 avegare return across last 100 episodes: -99.929 state values: tensor(0.5724) 1000
15 1000 -1000.0 -99.99568287525881 number episode from 10: 15 avegar over 10 episode: -99.933 avegare return across last 100 episodes: -99.933 state values: tensor(0.5716) 1000
16 1000 -1000.0 -99.99568287525881 number episode from 10: 16 avegar over 10 episode: -99.937 avegare return across last 100 episodes: -99.937 state values: tensor(0.5717) 1000
17 1000 -1000.0 -99.99568287525881 number episode from 10: 17 avegar over 10 episode: -99.94 avegare return across last 100 episodes: -99.94 state values: tensor(0.5715) 1000
18 1000 -1000.0 -99.99568287525881 number episode from 10: 18 avegar over 10 episode: -99.943 avegare return across last 100 episodes: -99.943 state values: tensor(0.5719) 1000
19 1000 -1000.0 -99.99568287525881 number episode from 10: 19 avegar over 10 episode: -99.946 avegare return across last 100 episodes: -99.946 state values: tensor(0.5715) 1000
20 1000 -1000.0 -99.99568287525881 number episode from 10: 20 avegar over 10 episode: -99.948 avegare return across last 100 episodes: -99.948 state values: tensor(0.5717) 1000
21 1000 -1000.0 -99.99568287525881 number episode from 10: 21 avegar over 10 episode: -99.95 avegare return across last 100 episodes: -99.95 state values: tensor(0.5720) 1000
22 1000 -1000.0 -99.99568287525881 number episode from 10: 22 avegar over 10 episode: -99.952 avegare return across last 100 episodes: -99.952 state values: tensor(0.5716) 1000
23 1000 -1000.0 -99.99568287525881 number episode from 10: 23 avegar over 10 episode: -99.954 avegare return across last 100 episodes: -99.954 state values: tensor(0.5717) 1000
24 1000 -1000.0 -99.99568287525881 number episode from 10: 24 avegar over 10 episode: -99.956 avegare return across last 100 episodes: -99.956 state values: tensor(0.5716) 1000
25 1000 -1000.0 -99.99568287525881 number episode from 10: 25 avegar over 10 episode: -99.957 avegare return across last 100 episodes: -99.957 state values: tensor(0.5717) 1000
26 1000 -1000.0 -99.99568287525881 number episode from 10: 26 avegar over 10 episode: -99.959 avegare return across last 100 episodes: -99.959 state values: tensor(0.5723) 1000
27 1000 -1000.0 -99.99568287525881 number episode from 10: 27 avegar over 10 episode: -99.96 avegare return across last 100 episodes: -99.96 state values: tensor(0.5717) 1000
28 1000 -1000.0 -99.99568287525881 number episode from 10: 28 avegar over 10 episode: -99.961 avegare return across last 100 episodes: -99.961 state values: tensor(0.5717) 1000
29 1000 -1000.0 -99.99568287525881 number episode from 10: 29 avegar over 10 episode: -99.962 avegare return across last 100 episodes: -99.962 state values: tensor(0.5716) 1000
30 1000 -1000.0 -99.99568287525881 number episode from 10: 30 avegar over 10 episode: -99.963 avegare return across last 100 episodes: -99.963 state values: tensor(0.5715) 1000
31 1000 -1000.0 -99.99568287525881 number episode from 10: 31 avegar over 10 episode: -99.964 avegare return across last 100 episodes: -99.964 state values: tensor(0.5716) 1000
32 1000 -1000.0 -99.99568287525881 number episode from 10: 32 avegar over 10 episode: -99.965 avegare return across last 100 episodes: -99.965 state values: tensor(0.5716) 1000
33 1000 -1000.0 -99.99568287525881 number episode from 10: 33 avegar over 10 episode: -99.966 avegare return across last 100 episodes: -99.966 state values: tensor(0.5725) 1000
34 1000 -1000.0 -99.99568287525881 number episode from 10: 34 avegar over 10 episode: -99.967 avegare return across last 100 episodes: -99.967 state values: tensor(0.5716) 1000
35 1000 -1000.0 -99.99568287525881 number episode from 10: 35 avegar over 10 episode: -99.968 avegare return across last 100 episodes: -99.968 state values: tensor(0.5725) 1000
36 1000 -1000.0 -99.99568287525881 number episode from 10: 36 avegar over 10 episode: -99.969 avegare return across last 100 episodes: -99.969 state values: tensor(0.5715) 1000
37 1000 -1000.0 -99.99568287525881 number episode from 10: 37 avegar over 10 episode: -99.969 avegare return across last 100 episodes: -99.969 state values: tensor(0.5715) 1000
38 1000 -1000.0 -99.99568287525881 number episode from 10: 38 avegar over 10 episode: -99.97 avegare return across last 100 episodes: -99.97 state values: tensor(0.5716) 1000
39 1000 -1000.0 -99.99568287525881 number episode from 10: 39 avegar over 10 episode: -99.971 avegare return across last 100 episodes: -99.971 state values: tensor(0.5717) 1000
40 1000 -1000.0 -99.99568287525881 number episode from 10: 40 avegar over 10 episode: -99.971 avegare return across last 100 episodes: -99.971 state values: tensor(0.5723) 1000
41 1000 -1000.0 -99.99568287525881 number episode from 10: 41 avegar over 10 episode: -99.972 avegare return across last 100 episodes: -99.972 state values: tensor(0.5715) 1000
42 1000 -1000.0 -99.99568287525881 number episode from 10: 42 avegar over 10 episode: -99.972 avegare return across last 100 episodes: -99.972 state values: tensor(0.5719) 1000
43 1000 -1000.0 -99.99568287525881 number episode from 10: 43 avegar over 10 episode: -99.973 avegare return across last 100 episodes: -99.973 state values: tensor(0.5716) 1000
44 1000 -1000.0 -99.99568287525881 number episode from 10: 44 avegar over 10 episode: -99.973 avegare return across last 100 episodes: -99.973 state values: tensor(0.5716) 1000
45 1000 -1000.0 -99.99568287525881 number episode from 10: 45 avegar over 10 episode: -99.974 avegare return across last 100 episodes: -99.974 state values: tensor(0.5725) 1000
46 1000 -1000.0 -99.99568287525881 number episode from 10: 46 avegar over 10 episode: -99.974 avegare return across last 100 episodes: -99.974 state values: tensor(0.5716) 1000
47 1000 -1000.0 -99.99568287525881 number episode from 10: 47 avegar over 10 episode: -99.975 avegare return across last 100 episodes: -99.975 state values: tensor(0.5717) 1000
48 1000 -1000.0 -99.99568287525881 number episode from 10: 48 avegar over 10 episode: -99.975 avegare return across last 100 episodes: -99.975 state values: tensor(0.5716) 1000
49 1000 -1000.0 -99.99568287525881 number episode from 10: 49 avegar over 10 episode: -99.976 avegare return across last 100 episodes: -99.976 state values: tensor(0.5715) 1000
50 1000 -1000.0 -99.99568287525881 number episode from 10: 50 avegar over 10 episode: -99.976 avegare return across last 100 episodes: -99.976 state values: tensor(0.5716) 1000
51 1000 -1000.0 -99.99568287525881 number episode from 10: 51 avegar over 10 episode: -99.976 avegare return across last 100 episodes: -99.976 state values: tensor(0.5717) 1000
52 1000 -1000.0 -99.99568287525881 number episode from 10: 52 avegar over 10 episode: -99.977 avegare return across last 100 episodes: -99.977 state values: tensor(0.5719) 1000
53 1000 -1000.0 -99.99568287525881 number episode from 10: 53 avegar over 10 episode: -99.977 avegare return across last 100 episodes: -99.977 state values: tensor(0.5717) 1000
54 1000 -1000.0 -99.99568287525881 number episode from 10: 54 avegar over 10 episode: -99.978 avegare return across last 100 episodes: -99.978 state values: tensor(0.5716) 1000
55 1000 -1000.0 -99.99568287525881 number episode from 10: 55 avegar over 10 episode: -99.978 avegare return across last 100 episodes: -99.978 state values: tensor(0.5725) 1000
56 1000 -1000.0 -99.99568287525881 number episode from 10: 56 avegar over 10 episode: -99.978 avegare return across last 100 episodes: -99.978 state values: tensor(0.5717) 1000
57 1000 -1000.0 -99.99568287525881 number episode from 10: 57 avegar over 10 episode: -99.978 avegare return across last 100 episodes: -99.978 state values: tensor(0.5716) 1000
58 1000 -1000.0 -99.99568287525881 number episode from 10: 58 avegar over 10 episode: -99.979 avegare return across last 100 episodes: -99.979 state values: tensor(0.5715) 1000
59 1000 -1000.0 -99.99568287525881 number episode from 10: 59 avegar over 10 episode: -99.979 avegare return across last 100 episodes: -99.979 state values: tensor(0.5717) 1000
60 1000 -1000.0 -99.99568287525881 number episode from 10: 60 avegar over 10 episode: -99.979 avegare return across last 100 episodes: -99.979 state values: tensor(0.5724) 1000
61 1000 -1000.0 -99.99568287525881 number episode from 10: 61 avegar over 10 episode: -99.98 avegare return across last 100 episodes: -99.98 state values: tensor(0.5718) 1000
62 1000 -1000.0 -99.99568287525881 number episode from 10: 62 avegar over 10 episode: -99.98 avegare return across last 100 episodes: -99.98 state values: tensor(0.5718) 1000
63 1000 -1000.0 -99.99568287525881 number episode from 10: 63 avegar over 10 episode: -99.98 avegare return across last 100 episodes: -99.98 state values: tensor(0.5720) 1000
64 1000 -1000.0 -99.99568287525881 number episode from 10: 64 avegar over 10 episode: -99.98 avegare return across last 100 episodes: -99.98 state values: tensor(0.5717) 1000
65 1000 -1000.0 -99.99568287525881 number episode from 10: 65 avegar over 10 episode: -99.981 avegare return across last 100 episodes: -99.981 state values: tensor(0.5716) 1000
66 1000 -1000.0 -99.99568287525881 number episode from 10: 66 avegar over 10 episode: -99.981 avegare return across last 100 episodes: -99.981 state values: tensor(0.5717) 1000
67 1000 -1000.0 -99.99568287525881 number episode from 10: 67 avegar over 10 episode: -99.981 avegare return across last 100 episodes: -99.981 state values: tensor(0.5716) 1000
68 1000 -1000.0 -99.99568287525881 number episode from 10: 68 avegar over 10 episode: -99.981 avegare return across last 100 episodes: -99.981 state values: tensor(0.5717) 1000
69 1000 -1000.0 -99.99568287525881 number episode from 10: 69 avegar over 10 episode: -99.981 avegare return across last 100 episodes: -99.981 state values: tensor(0.5718) 1000
70 1000 -1000.0 -99.99568287525881 number episode from 10: 70 avegar over 10 episode: -99.982 avegare return across last 100 episodes: -99.982 state values: tensor(0.5719) 1000
71 1000 -1000.0 -99.99568287525881 number episode from 10: 71 avegar over 10 episode: -99.982 avegare return across last 100 episodes: -99.982 state values: tensor(0.5723) 1000
72 1000 -1000.0 -99.99568287525881 number episode from 10: 72 avegar over 10 episode: -99.982 avegare return across last 100 episodes: -99.982 state values: tensor(0.5723) 1000
73 1000 -1000.0 -99.99568287525881 number episode from 10: 73 avegar over 10 episode: -99.982 avegare return across last 100 episodes: -99.982 state values: tensor(0.5716) 1000
74 1000 -1000.0 -99.99568287525881 number episode from 10: 74 avegar over 10 episode: -99.982 avegare return across last 100 episodes: -99.982 state values: tensor(0.5717) 1000
75 1000 -1000.0 -99.99568287525881 number episode from 10: 75 avegar over 10 episode: -99.983 avegare return across last 100 episodes: -99.983 state values: tensor(0.5717) 1000
76 1000 -1000.0 -99.99568287525881 number episode from 10: 76 avegar over 10 episode: -99.983 avegare return across last 100 episodes: -99.983 state values: tensor(0.5716) 1000
77 1000 -1000.0 -99.99568287525881 number episode from 10: 77 avegar over 10 episode: -99.983 avegare return across last 100 episodes: -99.983 state values: tensor(0.5719) 1000
78 1000 -1000.0 -99.99568287525881 number episode from 10: 78 avegar over 10 episode: -99.983 avegare return across last 100 episodes: -99.983 state values: tensor(0.5723) 1000
79 1000 -1000.0 -99.99568287525881 number episode from 10: 79 avegar over 10 episode: -99.983 avegare return across last 100 episodes: -99.983 state values: tensor(0.5716) 1000
80 1000 -1000.0 -99.99568287525881 number episode from 10: 80 avegar over 10 episode: -99.983 avegare return across last 100 episodes: -99.983 state values: tensor(0.5718) 1000
81 1000 -1000.0 -99.99568287525881 number episode from 10: 81 avegar over 10 episode: -99.983 avegare return across last 100 episodes: -99.983 state values: tensor(0.5716) 1000
82 1000 -1000.0 -99.99568287525881 number episode from 10: 82 avegar over 10 episode: -99.984 avegare return across last 100 episodes: -99.984 state values: tensor(0.5716) 1000
83 1000 -1000.0 -99.99568287525881 number episode from 10: 83 avegar over 10 episode: -99.984 avegare return across last 100 episodes: -99.984 state values: tensor(0.5716) 1000
84 1000 -1000.0 -99.99568287525881 number episode from 10: 84 avegar over 10 episode: -99.984 avegare return across last 100 episodes: -99.984 state values: tensor(0.5715) 1000
85 1000 -1000.0 -99.99568287525881 number episode from 10: 85 avegar over 10 episode: -99.984 avegare return across last 100 episodes: -99.984 state values: tensor(0.5720) 1000
86 1000 -1000.0 -99.99568287525881 number episode from 10: 86 avegar over 10 episode: -99.984 avegare return across last 100 episodes: -99.984 state values: tensor(0.5719) 1000
87 1000 -1000.0 -99.99568287525881 number episode from 10: 87 avegar over 10 episode: -99.984 avegare return across last 100 episodes: -99.984 state values: tensor(0.5719) 1000
88 1000 -1000.0 -99.99568287525881 number episode from 10: 88 avegar over 10 episode: -99.984 avegare return across last 100 episodes: -99.984 state values: tensor(0.5717) 1000
89 1000 -1000.0 -99.99568287525881 number episode from 10: 89 avegar over 10 episode: -99.985 avegare return across last 100 episodes: -99.985 state values: tensor(0.5723) 1000
90 1000 -1000.0 -99.99568287525881 number episode from 10: 90 avegar over 10 episode: -99.985 avegare return across last 100 episodes: -99.985 state values: tensor(0.5724) 1000
91 1000 -1000.0 -99.99568287525881 number episode from 10: 91 avegar over 10 episode: -99.985 avegare return across last 100 episodes: -99.985 state values: tensor(0.5715) 1000
92 1000 -1000.0 -99.99568287525881 number episode from 10: 92 avegar over 10 episode: -99.985 avegare return across last 100 episodes: -99.985 state values: tensor(0.5724) 1000
93 1000 -1000.0 -99.99568287525881 number episode from 10: 93 avegar over 10 episode: -99.985 avegare return across last 100 episodes: -99.985 state values: tensor(0.5720) 1000
94 1000 -1000.0 -99.99568287525881 number episode from 10: 94 avegar over 10 episode: -99.985 avegare return across last 100 episodes: -99.985 state values: tensor(0.5715) 1000
95 1000 -1000.0 -99.99568287525881 number episode from 10: 95 avegar over 10 episode: -99.985 avegare return across last 100 episodes: -99.985 state values: tensor(0.5715) 1000
96 1000 -1000.0 -99.99568287525881 number episode from 10: 96 avegar over 10 episode: -99.985 avegare return across last 100 episodes: -99.985 state values: tensor(0.5717) 1000
97 1000 -1000.0 -99.99568287525881 number episode from 10: 97 avegar over 10 episode: -99.985 avegare return across last 100 episodes: -99.985 state values: tensor(0.5715) 1000
98 1000 -1000.0 -99.99568287525881 number episode from 10: 98 avegar over 10 episode: -99.986 avegare return across last 100 episodes: -99.986 state values: tensor(0.5715) 1000
99 1000 -1000.0 -99.99568287525881 number episode from 10: 99 avegar over 10 episode: -99.986 avegare return across last 100 episodes: -99.986 state values: tensor(0.5715) 1000
100 1000 -1000.0 -99.99568287525881 number episode from 10: 100 avegar over 10 episode: -99.986 avegare return across last 100 episodes: -99.996 state values: tensor(0.5715) 1000
101 1000 -1000.0 -99.99568287525881 number episode from 10: 101 avegar over 10 episode: -99.986 avegare return across last 100 episodes: -99.996 state values: tensor(0.5716) 1000
102 1000 -1000.0 -99.99568287525881 number episode from 10: 102 avegar over 10 episode: -99.986 avegare return across last 100 episodes: -99.996 state values: tensor(0.5719) 1000
103 1000 -1000.0 -99.99568287525881 number episode from 10: 103 avegar over 10 episode: -99.986 avegare return across last 100 episodes: -99.996 state values: tensor(0.5718) 1000
104 1000 -1000.0 -99.99568287525881 number episode from 10: 104 avegar over 10 episode: -99.986 avegare return across last 100 episodes: -99.996 state values: tensor(0.5718) 1000
105 1000 -1000.0 -99.99568287525881 number episode from 10: 105 avegar over 10 episode: -99.986 avegare return across last 100 episodes: -99.996 state values: tensor(0.5717) 1000
106 1000 -1000.0 -99.99568287525881 number episode from 10: 106 avegar over 10 episode: -99.986 avegare return across last 100 episodes: -99.996 state values: tensor(0.5715) 1000
107 1000 -1000.0 -99.99568287525881 number episode from 10: 107 avegar over 10 episode: -99.986 avegare return across last 100 episodes: -99.996 state values: tensor(0.5719) 1000
108 1000 -1000.0 -99.99568287525881 number episode from 10: 108 avegar over 10 episode: -99.987 avegare return across last 100 episodes: -99.996 state values: tensor(0.5718) 1000
109 1000 -1000.0 -99.99568287525881 number episode from 10: 109 avegar over 10 episode: -99.987 avegare return across last 100 episodes: -99.996 state values: tensor(0.5717) 1000
110 1000 -1000.0 -99.99568287525881 number episode from 10: 110 avegar over 10 episode: -99.987 avegare return across last 100 episodes: -99.996 state values: tensor(0.5715) 1000
111 1000 -1000.0 -99.99568287525881 number episode from 10: 111 avegar over 10 episode: -99.987 avegare return across last 100 episodes: -99.996 state values: tensor(0.5720) 1000
112 1000 -1000.0 -99.99568287525881 number episode from 10: 112 avegar over 10 episode: -99.987 avegare return across last 100 episodes: -99.996 state values: tensor(0.5724) 1000
113 1000 -1000.0 -99.99568287525881 number episode from 10: 113 avegar over 10 episode: -99.987 avegare return across last 100 episodes: -99.996 state values: tensor(0.5715) 1000
114 1000 -1000.0 -99.99568287525881 number episode from 10: 114 avegar over 10 episode: -99.987 avegare return across last 100 episodes: -99.996 state values: tensor(0.5716) 1000
115 1000 -1000.0 -99.99568287525881 number episode from 10: 115 avegar over 10 episode: -99.987 avegare return across last 100 episodes: -99.996 state values: tensor(0.5717) 1000
116 1000 -1000.0 -99.99568287525881 number episode from 10: 116 avegar over 10 episode: -99.987 avegare return across last 100 episodes: -99.996 state values: tensor(0.5723) 1000
117 1000 -1000.0 -99.99568287525881 number episode from 10: 117 avegar over 10 episode: -99.987 avegare return across last 100 episodes: -99.996 state values: tensor(0.5720) 1000
118 1000 -1000.0 -99.99568287525881 number episode from 10: 118 avegar over 10 episode: -99.987 avegare return across last 100 episodes: -99.996 state values: tensor(0.5717) 1000
119 1000 -1000.0 -99.99568287525881 number episode from 10: 119 avegar over 10 episode: -99.987 avegare return across last 100 episodes: -99.996 state values: tensor(0.5715) 1000
120 1000 -1000.0 -99.99568287525881 number episode from 10: 120 avegar over 10 episode: -99.987 avegare return across last 100 episodes: -99.996 state values: tensor(0.5717) 1000
121 1000 -1000.0 -99.99568287525881 number episode from 10: 121 avegar over 10 episode: -99.987 avegare return across last 100 episodes: -99.996 state values: tensor(0.5715) 1000
122 1000 -1000.0 -99.99568287525881 number episode from 10: 122 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.5715) 1000
123 1000 -1000.0 -99.99568287525881 number episode from 10: 123 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.5715) 1000
124 1000 -1000.0 -99.99568287525881 number episode from 10: 124 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.5716) 1000
125 1000 -1000.0 -99.99568287525881 number episode from 10: 125 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.5716) 1000
126 1000 -1000.0 -99.99568287525881 number episode from 10: 126 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.5723) 1000
127 1000 -1000.0 -99.99568287525881 number episode from 10: 127 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.5720) 1000
128 1000 -1000.0 -99.99568287525881 number episode from 10: 128 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.5716) 1000
129 1000 -1000.0 -99.99568287525881 number episode from 10: 129 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.5716) 1000
130 1000 -1000.0 -99.99568287525881 number episode from 10: 130 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.5718) 1000
131 1000 -1000.0 -99.99568287525881 number episode from 10: 131 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.5716) 1000
132 1000 -1000.0 -99.99568287525881 number episode from 10: 132 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.5715) 1000
133 1000 -1000.0 -99.99568287525881 number episode from 10: 133 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.5715) 1000
134 1000 -1000.0 -99.99568287525881 number episode from 10: 134 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.5719) 1000
135 1000 -1000.0 -99.99568287525881 number episode from 10: 135 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.5715) 1000
136 1000 -1000.0 -99.99568287525881 number episode from 10: 136 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.5716) 1000
137 1000 -1000.0 -99.99568287525881 number episode from 10: 137 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.5715) 1000
138 1000 -1000.0 -99.99568287525881 number episode from 10: 138 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.5716) 1000
139 1000 -1000.0 -99.99568287525881 number episode from 10: 139 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.5716) 1000
140 1000 -1000.0 -99.99568287525881 number episode from 10: 140 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.5716) 1000
141 1000 -1000.0 -99.99568287525881 number episode from 10: 141 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.5718) 1000
142 1000 -1000.0 -99.99568287525881 number episode from 10: 142 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.5717) 1000
143 1000 -1000.0 -99.99568287525881 number episode from 10: 143 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.5717) 1000
144 1000 -1000.0 -99.99568287525881 number episode from 10: 144 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.5717) 1000
145 1000 -1000.0 -99.99568287525881 number episode from 10: 145 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.5717) 1000
146 1000 -1000.0 -99.99568287525881 number episode from 10: 146 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.5716) 1000
147 1000 -1000.0 -99.99568287525881 number episode from 10: 147 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.5716) 1000
148 1000 -1000.0 -99.99568287525881 number episode from 10: 148 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.5716) 1000
149 1000 -1000.0 -99.99568287525881 number episode from 10: 149 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.5715) 1000
150 1000 -1000.0 -99.99568287525881 number episode from 10: 150 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.5716) 1000
151 1000 -1000.0 -99.99568287525881 number episode from 10: 151 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.5716) 1000
152 1000 -1000.0 -99.99568287525881 number episode from 10: 152 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.5716) 1000
153 1000 -1000.0 -99.99568287525881 number episode from 10: 153 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.5719) 1000
154 1000 -1000.0 -99.99568287525881 number episode from 10: 154 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.5716) 1000
155 1000 -1000.0 -99.99568287525881 number episode from 10: 155 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.5718) 1000
156 1000 -1000.0 -99.99568287525881 number episode from 10: 156 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.5720) 1000
157 1000 -1000.0 -99.99568287525881 number episode from 10: 157 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.5719) 1000
158 1000 -1000.0 -99.99568287525881 number episode from 10: 158 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.5724) 1000
159 1000 -1000.0 -99.99568287525881 number episode from 10: 159 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.5717) 1000
160 1000 -1000.0 -99.99568287525881 number episode from 10: 160 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.5716) 1000
161 1000 -1000.0 -99.99568287525881 number episode from 10: 161 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.5720) 1000
162 1000 -1000.0 -99.99568287525881 number episode from 10: 162 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.5716) 1000
163 1000 -1000.0 -99.99568287525881 number episode from 10: 163 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.5716) 1000
164 1000 -1000.0 -99.99568287525881 number episode from 10: 164 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.5717) 1000
165 1000 -1000.0 -99.99568287525881 number episode from 10: 165 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.5719) 1000
166 1000 -1000.0 -99.99568287525881 number episode from 10: 166 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.5717) 1000
167 1000 -1000.0 -99.99568287525881 number episode from 10: 167 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.5719) 1000
168 1000 -1000.0 -99.99568287525881 number episode from 10: 168 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.5718) 1000
169 1000 -1000.0 -99.99568287525881 number episode from 10: 169 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.5720) 1000
170 1000 -1000.0 -99.99568287525881 number episode from 10: 170 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.5724) 1000
171 1000 -1000.0 -99.99568287525881 number episode from 10: 171 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.5719) 1000
172 1000 -1000.0 -99.99568287525881 number episode from 10: 172 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.5716) 1000
173 1000 -1000.0 -99.99568287525881 number episode from 10: 173 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.5716) 1000
174 1000 -1000.0 -99.99568287525881 number episode from 10: 174 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.5715) 1000
175 1000 -1000.0 -99.99568287525881 number episode from 10: 175 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.5718) 1000
176 1000 -1000.0 -99.99568287525881 number episode from 10: 176 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.5715) 1000
177 1000 -1000.0 -99.99568287525881 number episode from 10: 177 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.5718) 1000
178 1000 -1000.0 -99.99568287525881 number episode from 10: 178 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.5720) 1000
179 1000 -1000.0 -99.99568287525881 number episode from 10: 179 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.5716) 1000
180 1000 -1000.0 -99.99568287525881 number episode from 10: 180 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.5716) 1000
181 1000 -1000.0 -99.99568287525881 number episode from 10: 181 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.5718) 1000
182 1000 -1000.0 -99.99568287525881 number episode from 10: 182 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.5715) 1000
183 1000 -1000.0 -99.99568287525881 number episode from 10: 183 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.5725) 1000
184 1000 -1000.0 -99.99568287525881 number episode from 10: 184 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.5716) 1000
185 1000 -1000.0 -99.99568287525881 number episode from 10: 185 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.5715) 1000
186 1000 -1000.0 -99.99568287525881 number episode from 10: 186 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.5715) 1000
187 1000 -1000.0 -99.99568287525881 number episode from 10: 187 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.5717) 1000
188 1000 -1000.0 -99.99568287525881 number episode from 10: 188 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.5717) 1000
189 1000 -1000.0 -99.99568287525881 number episode from 10: 189 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.5716) 1000
190 1000 -1000.0 -99.99568287525881 number episode from 10: 190 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.5716) 1000
191 1000 -1000.0 -99.99568287525881 number episode from 10: 191 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.5715) 1000
192 1000 -1000.0 -99.99568287525881 number episode from 10: 192 avegar over 10 episode: -99.991 avegare return across last 100 episodes: -99.996 state values: tensor(0.5720) 1000
193 1000 -1000.0 -99.99568287525881 number episode from 10: 193 avegar over 10 episode: -99.991 avegare return across last 100 episodes: -99.996 state values: tensor(0.5717) 1000
194 1000 -1000.0 -99.99568287525881 number episode from 10: 194 avegar over 10 episode: -99.991 avegare return across last 100 episodes: -99.996 state values: tensor(0.5716) 1000
195 1000 -1000.0 -99.99568287525881 number episode from 10: 195 avegar over 10 episode: -99.991 avegare return across last 100 episodes: -99.996 state values: tensor(0.5717) 1000
196 1000 -1000.0 -99.99568287525881 number episode from 10: 196 avegar over 10 episode: -99.991 avegare return across last 100 episodes: -99.996 state values: tensor(0.5716) 1000
197 1000 -1000.0 -99.99568287525881 number episode from 10: 197 avegar over 10 episode: -99.991 avegare return across last 100 episodes: -99.996 state values: tensor(0.5719) 1000
198 1000 -1000.0 -99.99568287525881 number episode from 10: 198 avegar over 10 episode: -99.991 avegare return across last 100 episodes: -99.996 state values: tensor(0.5717) 1000
199 1000 -1000.0 -99.99568287525881 number episode from 10: 199 avegar over 10 episode: -99.991 avegare return across last 100 episodes: -99.996 state values: tensor(0.5719) 1000
200 1000 -1000.0 -99.99568287525881 number episode from 10: 200 avegar over 10 episode: -99.991 avegare return across last 100 episodes: -99.996 state values: tensor(0.5717) 1000
load offline data!!!!!
mem_cntr: 50000 ; mem_size: 50000
nn.learn_nn_feature_fqi FQI:  998
nn.learn_nn_feature_fqi FQI:  1998
nn.learn_nn_feature_fqi FQI:  2998
nn.learn_nn_feature_fqi FQI:  3998
nn.learn_nn_feature_fqi FQI:  4998
nn.learn_nn_feature_fqi FQI:  5998
nn.learn_nn_feature_fqi FQI:  6998
nn.learn_nn_feature_fqi FQI:  7998
nn.learn_nn_feature_fqi FQI:  8998
nn.learn_nn_feature_fqi FQI:  9998
nn.learn_nn_feature_fqi FQI:  10998
nn.learn_nn_feature_fqi FQI:  11998
nn.learn_nn_feature_fqi FQI:  12998
nn.learn_nn_feature_fqi FQI:  13998
nn.learn_nn_feature_fqi FQI:  14998
nn.learn_nn_feature_fqi FQI:  15998
nn.learn_nn_feature_fqi FQI:  16998
nn.learn_nn_feature_fqi FQI:  17998
nn.learn_nn_feature_fqi FQI:  18998
nn.learn_nn_feature_fqi FQI:  19998
nn.learn_nn_feature_fqi FQI:  20998
nn.learn_nn_feature_fqi FQI:  21998
nn.learn_nn_feature_fqi FQI:  22998
nn.learn_nn_feature_fqi FQI:  23998
nn.learn_nn_feature_fqi FQI:  24998
nn.learn_nn_feature_fqi FQI:  25998
nn.learn_nn_feature_fqi FQI:  26998
nn.learn_nn_feature_fqi FQI:  27998
nn.learn_nn_feature_fqi FQI:  28998
nn.learn_nn_feature_fqi FQI:  29998
nn.learn_nn_feature_fqi FQI:  30998
nn.learn_nn_feature_fqi FQI:  31998
nn.learn_nn_feature_fqi FQI:  32998
nn.learn_nn_feature_fqi FQI:  33998
nn.learn_nn_feature_fqi FQI:  34998
nn.learn_nn_feature_fqi FQI:  35998
nn.learn_nn_feature_fqi FQI:  36998
nn.learn_nn_feature_fqi FQI:  37998
nn.learn_nn_feature_fqi FQI:  38998
nn.learn_nn_feature_fqi FQI:  39998
nn.learn_nn_feature_fqi FQI:  40998
nn.learn_nn_feature_fqi FQI:  41998
nn.learn_nn_feature_fqi FQI:  42998
nn.learn_nn_feature_fqi FQI:  43998
nn.learn_nn_feature_fqi FQI:  44998
nn.learn_nn_feature_fqi FQI:  45998
nn.learn_nn_feature_fqi FQI:  46998
nn.learn_nn_feature_fqi FQI:  47998
nn.learn_nn_feature_fqi FQI:  48998
nn.learn_nn_feature_fqi FQI:  49998
nn.learn_nn_feature_fqi FQI:  50998
nn.learn_nn_feature_fqi FQI:  51998
nn.learn_nn_feature_fqi FQI:  52998
nn.learn_nn_feature_fqi FQI:  53998
nn.learn_nn_feature_fqi FQI:  54998
nn.learn_nn_feature_fqi FQI:  55998
nn.learn_nn_feature_fqi FQI:  56998
nn.learn_nn_feature_fqi FQI:  57998
nn.learn_nn_feature_fqi FQI:  58998
nn.learn_nn_feature_fqi FQI:  59998
nn.learn_nn_feature_fqi FQI:  60998
nn.learn_nn_feature_fqi FQI:  61998
nn.learn_nn_feature_fqi FQI:  62998
nn.learn_nn_feature_fqi FQI:  63998
nn.learn_nn_feature_fqi FQI:  64998
nn.learn_nn_feature_fqi FQI:  65998
nn.learn_nn_feature_fqi FQI:  66998
nn.learn_nn_feature_fqi FQI:  67998
nn.learn_nn_feature_fqi FQI:  68998
nn.learn_nn_feature_fqi FQI:  69998
nn.learn_nn_feature_fqi FQI:  70998
nn.learn_nn_feature_fqi FQI:  71998
nn.learn_nn_feature_fqi FQI:  72998
nn.learn_nn_feature_fqi FQI:  73998
nn.learn_nn_feature_fqi FQI:  74998
nn.learn_nn_feature_fqi FQI:  75998
nn.learn_nn_feature_fqi FQI:  76998
nn.learn_nn_feature_fqi FQI:  77998
nn.learn_nn_feature_fqi FQI:  78998
nn.learn_nn_feature_fqi FQI:  79998
nn.learn_nn_feature_fqi FQI:  80998
nn.learn_nn_feature_fqi FQI:  81998
nn.learn_nn_feature_fqi FQI:  82998
nn.learn_nn_feature_fqi FQI:  83998
nn.learn_nn_feature_fqi FQI:  84998
nn.learn_nn_feature_fqi FQI:  85998
nn.learn_nn_feature_fqi FQI:  86998
nn.learn_nn_feature_fqi FQI:  87998
nn.learn_nn_feature_fqi FQI:  88998
nn.learn_nn_feature_fqi FQI:  89998
nn.learn_nn_feature_fqi FQI:  90998
nn.learn_nn_feature_fqi FQI:  91998
nn.learn_nn_feature_fqi FQI:  92998
nn.learn_nn_feature_fqi FQI:  93998
nn.learn_nn_feature_fqi FQI:  94998
nn.learn_nn_feature_fqi FQI:  95998
nn.learn_nn_feature_fqi FQI:  96998
nn.learn_nn_feature_fqi FQI:  97998
nn.learn_nn_feature_fqi FQI:  98998
nn.learn_nn_feature_fqi FQI:  99998
nn.learn_nn_feature_fqi FQI:  100998
nn.learn_nn_feature_fqi FQI:  101998
nn.learn_nn_feature_fqi FQI:  102998
nn.learn_nn_feature_fqi FQI:  103998
nn.learn_nn_feature_fqi FQI:  104998
nn.learn_nn_feature_fqi FQI:  105998
nn.learn_nn_feature_fqi FQI:  106998
nn.learn_nn_feature_fqi FQI:  107998
nn.learn_nn_feature_fqi FQI:  108998
nn.learn_nn_feature_fqi FQI:  109998
nn.learn_nn_feature_fqi FQI:  110998
nn.learn_nn_feature_fqi FQI:  111998
nn.learn_nn_feature_fqi FQI:  112998
nn.learn_nn_feature_fqi FQI:  113998
nn.learn_nn_feature_fqi FQI:  114998
nn.learn_nn_feature_fqi FQI:  115998
nn.learn_nn_feature_fqi FQI:  116998
nn.learn_nn_feature_fqi FQI:  117998
nn.learn_nn_feature_fqi FQI:  118998
nn.learn_nn_feature_fqi FQI:  119998
nn.learn_nn_feature_fqi FQI:  120998
nn.learn_nn_feature_fqi FQI:  121998
nn.learn_nn_feature_fqi FQI:  122998
nn.learn_nn_feature_fqi FQI:  123998
nn.learn_nn_feature_fqi FQI:  124998
nn.learn_nn_feature_fqi FQI:  125998
nn.learn_nn_feature_fqi FQI:  126998
nn.learn_nn_feature_fqi FQI:  127998
nn.learn_nn_feature_fqi FQI:  128998
nn.learn_nn_feature_fqi FQI:  129998
nn.learn_nn_feature_fqi FQI:  130998
nn.learn_nn_feature_fqi FQI:  131998
nn.learn_nn_feature_fqi FQI:  132998
nn.learn_nn_feature_fqi FQI:  133998
nn.learn_nn_feature_fqi FQI:  134998
nn.learn_nn_feature_fqi FQI:  135998
nn.learn_nn_feature_fqi FQI:  136998
nn.learn_nn_feature_fqi FQI:  137998
nn.learn_nn_feature_fqi FQI:  138998
nn.learn_nn_feature_fqi FQI:  139998
nn.learn_nn_feature_fqi FQI:  140998
nn.learn_nn_feature_fqi FQI:  141998
nn.learn_nn_feature_fqi FQI:  142998
nn.learn_nn_feature_fqi FQI:  143998
nn.learn_nn_feature_fqi FQI:  144998
nn.learn_nn_feature_fqi FQI:  145998
nn.learn_nn_feature_fqi FQI:  146998
nn.learn_nn_feature_fqi FQI:  147998
nn.learn_nn_feature_fqi FQI:  148998
nn.learn_nn_feature_fqi FQI:  149998
nn.learn_nn_feature_fqi FQI:  150998
nn.learn_nn_feature_fqi FQI:  151998
nn.learn_nn_feature_fqi FQI:  152998
nn.learn_nn_feature_fqi FQI:  153998
nn.learn_nn_feature_fqi FQI:  154998
nn.learn_nn_feature_fqi FQI:  155998
0 1001 -1000.0 -98.99572604650622 number episode from 10: 0 avegar over 10 episode: -98.996 avegare return across last 100 episodes: -98.996 state values: tensor(0.5227) 1000
1 1000 -1000.0 -99.99568287525881 number episode from 10: 1 avegar over 10 episode: -99.496 avegare return across last 100 episodes: -99.496 state values: tensor(0.5229) 1000
2 1000 -1000.0 -99.99568287525881 number episode from 10: 2 avegar over 10 episode: -99.662 avegare return across last 100 episodes: -99.662 state values: tensor(0.5272) 1000
3 1000 -1000.0 -99.99568287525881 number episode from 10: 3 avegar over 10 episode: -99.746 avegare return across last 100 episodes: -99.746 state values: tensor(0.5229) 1000
4 1000 -1000.0 -99.99568287525881 number episode from 10: 4 avegar over 10 episode: -99.796 avegare return across last 100 episodes: -99.796 state values: tensor(0.5232) 1000
5 1000 -1000.0 -99.99568287525881 number episode from 10: 5 avegar over 10 episode: -99.829 avegare return across last 100 episodes: -99.829 state values: tensor(0.5231) 1000
6 1000 -1000.0 -99.99568287525881 number episode from 10: 6 avegar over 10 episode: -99.853 avegare return across last 100 episodes: -99.853 state values: tensor(0.5230) 1000
7 1000 -1000.0 -99.99568287525881 number episode from 10: 7 avegar over 10 episode: -99.871 avegare return across last 100 episodes: -99.871 state values: tensor(0.5229) 1000
8 1000 -1000.0 -99.99568287525881 number episode from 10: 8 avegar over 10 episode: -99.885 avegare return across last 100 episodes: -99.885 state values: tensor(0.5231) 1000
9 1000 -1000.0 -99.99568287525881 number episode from 10: 9 avegar over 10 episode: -99.896 avegare return across last 100 episodes: -99.896 state values: tensor(0.5231) 1000
10 1000 -1000.0 -99.99568287525881 number episode from 10: 10 avegar over 10 episode: -99.905 avegare return across last 100 episodes: -99.905 state values: tensor(0.5223) 1000
11 1000 -1000.0 -99.99568287525881 number episode from 10: 11 avegar over 10 episode: -99.912 avegare return across last 100 episodes: -99.912 state values: tensor(0.5245) 1000
12 1000 -1000.0 -99.99568287525881 number episode from 10: 12 avegar over 10 episode: -99.919 avegare return across last 100 episodes: -99.919 state values: tensor(0.5231) 1000
13 1000 -1000.0 -99.99568287525881 number episode from 10: 13 avegar over 10 episode: -99.924 avegare return across last 100 episodes: -99.924 state values: tensor(0.5227) 1000
14 1000 -1000.0 -99.99568287525881 number episode from 10: 14 avegar over 10 episode: -99.929 avegare return across last 100 episodes: -99.929 state values: tensor(0.5304) 1000
15 1000 -1000.0 -99.99568287525881 number episode from 10: 15 avegar over 10 episode: -99.933 avegare return across last 100 episodes: -99.933 state values: tensor(0.5229) 1000
16 1000 -1000.0 -99.99568287525881 number episode from 10: 16 avegar over 10 episode: -99.937 avegare return across last 100 episodes: -99.937 state values: tensor(0.5230) 1000
17 1000 -1000.0 -99.99568287525881 number episode from 10: 17 avegar over 10 episode: -99.94 avegare return across last 100 episodes: -99.94 state values: tensor(0.5231) 1000
18 1000 -1000.0 -99.99568287525881 number episode from 10: 18 avegar over 10 episode: -99.943 avegare return across last 100 episodes: -99.943 state values: tensor(0.5231) 1000
19 1000 -1000.0 -99.99568287525881 number episode from 10: 19 avegar over 10 episode: -99.946 avegare return across last 100 episodes: -99.946 state values: tensor(0.5230) 1000
20 1000 -1000.0 -99.99568287525881 number episode from 10: 20 avegar over 10 episode: -99.948 avegare return across last 100 episodes: -99.948 state values: tensor(0.5230) 1000
21 1000 -1000.0 -99.99568287525881 number episode from 10: 21 avegar over 10 episode: -99.95 avegare return across last 100 episodes: -99.95 state values: tensor(0.5229) 1000
22 1000 -1000.0 -99.99568287525881 number episode from 10: 22 avegar over 10 episode: -99.952 avegare return across last 100 episodes: -99.952 state values: tensor(0.5232) 1000
23 1000 -1000.0 -99.99568287525881 number episode from 10: 23 avegar over 10 episode: -99.954 avegare return across last 100 episodes: -99.954 state values: tensor(0.5233) 1000
24 1000 -1000.0 -99.99568287525881 number episode from 10: 24 avegar over 10 episode: -99.956 avegare return across last 100 episodes: -99.956 state values: tensor(0.5295) 1000
25 1000 -1000.0 -99.99568287525881 number episode from 10: 25 avegar over 10 episode: -99.957 avegare return across last 100 episodes: -99.957 state values: tensor(0.5229) 1000
26 1000 -1000.0 -99.99568287525881 number episode from 10: 26 avegar over 10 episode: -99.959 avegare return across last 100 episodes: -99.959 state values: tensor(0.5233) 1000
27 1000 -1000.0 -99.99568287525881 number episode from 10: 27 avegar over 10 episode: -99.96 avegare return across last 100 episodes: -99.96 state values: tensor(0.5228) 1000
28 1000 -1000.0 -99.99568287525881 number episode from 10: 28 avegar over 10 episode: -99.961 avegare return across last 100 episodes: -99.961 state values: tensor(0.5231) 1000
29 1000 -1000.0 -99.99568287525881 number episode from 10: 29 avegar over 10 episode: -99.962 avegare return across last 100 episodes: -99.962 state values: tensor(0.5231) 1000
30 1000 -1000.0 -99.99568287525881 number episode from 10: 30 avegar over 10 episode: -99.963 avegare return across last 100 episodes: -99.963 state values: tensor(0.5230) 1000
31 634 -634.0 -99.82911128864384 number episode from 10: 31 avegar over 10 episode: -99.959 avegare return across last 100 episodes: -99.959 state values: tensor(0.6004) 634
32 1000 -1000.0 -99.99568287525881 number episode from 10: 32 avegar over 10 episode: -99.96 avegare return across last 100 episodes: -99.96 state values: tensor(0.5239) 1000
33 1000 -1000.0 -99.99568287525881 number episode from 10: 33 avegar over 10 episode: -99.961 avegare return across last 100 episodes: -99.961 state values: tensor(0.5230) 1000
34 1000 -1000.0 -99.99568287525881 number episode from 10: 34 avegar over 10 episode: -99.962 avegare return across last 100 episodes: -99.962 state values: tensor(0.5229) 1000
35 1000 -1000.0 -99.99568287525881 number episode from 10: 35 avegar over 10 episode: -99.963 avegare return across last 100 episodes: -99.963 state values: tensor(0.5227) 1000
36 1000 -1000.0 -99.99568287525881 number episode from 10: 36 avegar over 10 episode: -99.964 avegare return across last 100 episodes: -99.964 state values: tensor(0.5247) 1000
37 1000 -1000.0 -99.99568287525881 number episode from 10: 37 avegar over 10 episode: -99.965 avegare return across last 100 episodes: -99.965 state values: tensor(0.5230) 1000
38 1000 -1000.0 -99.99568287525881 number episode from 10: 38 avegar over 10 episode: -99.966 avegare return across last 100 episodes: -99.966 state values: tensor(0.5246) 1000
39 1000 -1000.0 -99.99568287525881 number episode from 10: 39 avegar over 10 episode: -99.967 avegare return across last 100 episodes: -99.967 state values: tensor(0.5238) 1000
40 1000 -1000.0 -99.99568287525881 number episode from 10: 40 avegar over 10 episode: -99.967 avegare return across last 100 episodes: -99.967 state values: tensor(0.5225) 1000
41 1000 -1000.0 -99.99568287525881 number episode from 10: 41 avegar over 10 episode: -99.968 avegare return across last 100 episodes: -99.968 state values: tensor(0.5229) 1000
42 1000 -1000.0 -99.99568287525881 number episode from 10: 42 avegar over 10 episode: -99.969 avegare return across last 100 episodes: -99.969 state values: tensor(0.5231) 1000
43 1000 -1000.0 -99.99568287525881 number episode from 10: 43 avegar over 10 episode: -99.969 avegare return across last 100 episodes: -99.969 state values: tensor(0.5229) 1000
44 1000 -1000.0 -99.99568287525881 number episode from 10: 44 avegar over 10 episode: -99.97 avegare return across last 100 episodes: -99.97 state values: tensor(0.5231) 1000
45 1000 -1000.0 -99.99568287525881 number episode from 10: 45 avegar over 10 episode: -99.97 avegare return across last 100 episodes: -99.97 state values: tensor(0.5259) 1000
46 1000 -1000.0 -99.99568287525881 number episode from 10: 46 avegar over 10 episode: -99.971 avegare return across last 100 episodes: -99.971 state values: tensor(0.5229) 1000
47 1000 -1000.0 -99.99568287525881 number episode from 10: 47 avegar over 10 episode: -99.971 avegare return across last 100 episodes: -99.971 state values: tensor(0.5226) 1000
48 1000 -1000.0 -99.99568287525881 number episode from 10: 48 avegar over 10 episode: -99.972 avegare return across last 100 episodes: -99.972 state values: tensor(0.5229) 1000
49 1000 -1000.0 -99.99568287525881 number episode from 10: 49 avegar over 10 episode: -99.972 avegare return across last 100 episodes: -99.972 state values: tensor(0.5231) 1000
50 1000 -1000.0 -99.99568287525881 number episode from 10: 50 avegar over 10 episode: -99.973 avegare return across last 100 episodes: -99.973 state values: tensor(0.5228) 1000
51 1000 -1000.0 -99.99568287525881 number episode from 10: 51 avegar over 10 episode: -99.973 avegare return across last 100 episodes: -99.973 state values: tensor(0.5228) 1000
52 1000 -1000.0 -99.99568287525881 number episode from 10: 52 avegar over 10 episode: -99.974 avegare return across last 100 episodes: -99.974 state values: tensor(0.5232) 1000
53 1000 -1000.0 -99.99568287525881 number episode from 10: 53 avegar over 10 episode: -99.974 avegare return across last 100 episodes: -99.974 state values: tensor(0.5214) 1000
54 1000 -1000.0 -99.99568287525881 number episode from 10: 54 avegar over 10 episode: -99.974 avegare return across last 100 episodes: -99.974 state values: tensor(0.5230) 1000
55 1000 -1000.0 -99.99568287525881 number episode from 10: 55 avegar over 10 episode: -99.975 avegare return across last 100 episodes: -99.975 state values: tensor(0.5228) 1000
56 1000 -1000.0 -99.99568287525881 number episode from 10: 56 avegar over 10 episode: -99.975 avegare return across last 100 episodes: -99.975 state values: tensor(0.5230) 1000
57 1000 -1000.0 -99.99568287525881 number episode from 10: 57 avegar over 10 episode: -99.976 avegare return across last 100 episodes: -99.976 state values: tensor(0.5233) 1000
58 1000 -1000.0 -99.99568287525881 number episode from 10: 58 avegar over 10 episode: -99.976 avegare return across last 100 episodes: -99.976 state values: tensor(0.5229) 1000
59 1000 -1000.0 -99.99568287525881 number episode from 10: 59 avegar over 10 episode: -99.976 avegare return across last 100 episodes: -99.976 state values: tensor(0.5230) 1000
60 1000 -1000.0 -99.99568287525881 number episode from 10: 60 avegar over 10 episode: -99.977 avegare return across last 100 episodes: -99.977 state values: tensor(0.5232) 1000
61 1000 -1000.0 -99.99568287525881 number episode from 10: 61 avegar over 10 episode: -99.977 avegare return across last 100 episodes: -99.977 state values: tensor(0.5228) 1000
62 1000 -1000.0 -99.99568287525881 number episode from 10: 62 avegar over 10 episode: -99.977 avegare return across last 100 episodes: -99.977 state values: tensor(0.5217) 1000
63 1000 -1000.0 -99.99568287525881 number episode from 10: 63 avegar over 10 episode: -99.977 avegare return across last 100 episodes: -99.977 state values: tensor(0.5231) 1000
64 1000 -1000.0 -99.99568287525881 number episode from 10: 64 avegar over 10 episode: -99.978 avegare return across last 100 episodes: -99.978 state values: tensor(0.5232) 1000
65 1000 -1000.0 -99.99568287525881 number episode from 10: 65 avegar over 10 episode: -99.978 avegare return across last 100 episodes: -99.978 state values: tensor(0.5233) 1000
66 1000 -1000.0 -99.99568287525881 number episode from 10: 66 avegar over 10 episode: -99.978 avegare return across last 100 episodes: -99.978 state values: tensor(0.5233) 1000
67 1000 -1000.0 -99.99568287525881 number episode from 10: 67 avegar over 10 episode: -99.979 avegare return across last 100 episodes: -99.979 state values: tensor(0.5228) 1000
68 1000 -1000.0 -99.99568287525881 number episode from 10: 68 avegar over 10 episode: -99.979 avegare return across last 100 episodes: -99.979 state values: tensor(0.5230) 1000
69 1000 -1000.0 -99.99568287525881 number episode from 10: 69 avegar over 10 episode: -99.979 avegare return across last 100 episodes: -99.979 state values: tensor(0.5230) 1000
70 1000 -1000.0 -99.99568287525881 number episode from 10: 70 avegar over 10 episode: -99.979 avegare return across last 100 episodes: -99.979 state values: tensor(0.5226) 1000
71 1000 -1000.0 -99.99568287525881 number episode from 10: 71 avegar over 10 episode: -99.979 avegare return across last 100 episodes: -99.979 state values: tensor(0.5303) 1000
72 1000 -1000.0 -99.99568287525881 number episode from 10: 72 avegar over 10 episode: -99.98 avegare return across last 100 episodes: -99.98 state values: tensor(0.5135) 1000
73 1000 -1000.0 -99.99568287525881 number episode from 10: 73 avegar over 10 episode: -99.98 avegare return across last 100 episodes: -99.98 state values: tensor(0.5227) 1000
74 1000 -1000.0 -99.99568287525881 number episode from 10: 74 avegar over 10 episode: -99.98 avegare return across last 100 episodes: -99.98 state values: tensor(0.5233) 1000
75 1000 -1000.0 -99.99568287525881 number episode from 10: 75 avegar over 10 episode: -99.98 avegare return across last 100 episodes: -99.98 state values: tensor(0.5232) 1000
76 1000 -1000.0 -99.99568287525881 number episode from 10: 76 avegar over 10 episode: -99.981 avegare return across last 100 episodes: -99.981 state values: tensor(0.5141) 1000
77 1000 -1000.0 -99.99568287525881 number episode from 10: 77 avegar over 10 episode: -99.981 avegare return across last 100 episodes: -99.981 state values: tensor(0.5246) 1000
78 1000 -1000.0 -99.99568287525881 number episode from 10: 78 avegar over 10 episode: -99.981 avegare return across last 100 episodes: -99.981 state values: tensor(0.5229) 1000
79 1000 -1000.0 -99.99568287525881 number episode from 10: 79 avegar over 10 episode: -99.981 avegare return across last 100 episodes: -99.981 state values: tensor(0.5228) 1000
80 1000 -1000.0 -99.99568287525881 number episode from 10: 80 avegar over 10 episode: -99.981 avegare return across last 100 episodes: -99.981 state values: tensor(0.5232) 1000
81 1000 -1000.0 -99.99568287525881 number episode from 10: 81 avegar over 10 episode: -99.981 avegare return across last 100 episodes: -99.981 state values: tensor(0.5229) 1000
82 1000 -1000.0 -99.99568287525881 number episode from 10: 82 avegar over 10 episode: -99.982 avegare return across last 100 episodes: -99.982 state values: tensor(0.5229) 1000
83 1000 -1000.0 -99.99568287525881 number episode from 10: 83 avegar over 10 episode: -99.982 avegare return across last 100 episodes: -99.982 state values: tensor(0.5230) 1000
84 1000 -1000.0 -99.99568287525881 number episode from 10: 84 avegar over 10 episode: -99.982 avegare return across last 100 episodes: -99.982 state values: tensor(0.5230) 1000
85 1000 -1000.0 -99.99568287525881 number episode from 10: 85 avegar over 10 episode: -99.982 avegare return across last 100 episodes: -99.982 state values: tensor(0.5229) 1000
86 1000 -1000.0 -99.99568287525881 number episode from 10: 86 avegar over 10 episode: -99.982 avegare return across last 100 episodes: -99.982 state values: tensor(0.5276) 1000
87 1000 -1000.0 -99.99568287525881 number episode from 10: 87 avegar over 10 episode: -99.982 avegare return across last 100 episodes: -99.982 state values: tensor(0.5233) 1000
88 1000 -1000.0 -99.99568287525881 number episode from 10: 88 avegar over 10 episode: -99.983 avegare return across last 100 episodes: -99.983 state values: tensor(0.5230) 1000
89 1000 -1000.0 -99.99568287525881 number episode from 10: 89 avegar over 10 episode: -99.983 avegare return across last 100 episodes: -99.983 state values: tensor(0.5230) 1000
90 1000 -1000.0 -99.99568287525881 number episode from 10: 90 avegar over 10 episode: -99.983 avegare return across last 100 episodes: -99.983 state values: tensor(0.5232) 1000
91 1000 -1000.0 -99.99568287525881 number episode from 10: 91 avegar over 10 episode: -99.983 avegare return across last 100 episodes: -99.983 state values: tensor(0.5218) 1000
92 1000 -1000.0 -99.99568287525881 number episode from 10: 92 avegar over 10 episode: -99.983 avegare return across last 100 episodes: -99.983 state values: tensor(0.5228) 1000
93 1000 -1000.0 -99.99568287525881 number episode from 10: 93 avegar over 10 episode: -99.983 avegare return across last 100 episodes: -99.983 state values: tensor(0.5229) 1000
94 1000 -1000.0 -99.99568287525881 number episode from 10: 94 avegar over 10 episode: -99.983 avegare return across last 100 episodes: -99.983 state values: tensor(0.5232) 1000
95 1000 -1000.0 -99.99568287525881 number episode from 10: 95 avegar over 10 episode: -99.984 avegare return across last 100 episodes: -99.984 state values: tensor(0.5224) 1000
96 1000 -1000.0 -99.99568287525881 number episode from 10: 96 avegar over 10 episode: -99.984 avegare return across last 100 episodes: -99.984 state values: tensor(0.5231) 1000
97 1000 -1000.0 -99.99568287525881 number episode from 10: 97 avegar over 10 episode: -99.984 avegare return across last 100 episodes: -99.984 state values: tensor(0.5229) 1000
98 1000 -1000.0 -99.99568287525881 number episode from 10: 98 avegar over 10 episode: -99.984 avegare return across last 100 episodes: -99.984 state values: tensor(0.5231) 1000
99 1000 -1000.0 -99.99568287525881 number episode from 10: 99 avegar over 10 episode: -99.984 avegare return across last 100 episodes: -99.984 state values: tensor(0.5228) 1000
100 1000 -1000.0 -99.99568287525881 number episode from 10: 100 avegar over 10 episode: -99.984 avegare return across last 100 episodes: -99.994 state values: tensor(0.5261) 1000
101 1000 -1000.0 -99.99568287525881 number episode from 10: 101 avegar over 10 episode: -99.984 avegare return across last 100 episodes: -99.994 state values: tensor(0.5231) 1000
102 1000 -1000.0 -99.99568287525881 number episode from 10: 102 avegar over 10 episode: -99.984 avegare return across last 100 episodes: -99.994 state values: tensor(0.5229) 1000
103 1000 -1000.0 -99.99568287525881 number episode from 10: 103 avegar over 10 episode: -99.984 avegare return across last 100 episodes: -99.994 state values: tensor(0.5232) 1000
104 1000 -1000.0 -99.99568287525881 number episode from 10: 104 avegar over 10 episode: -99.985 avegare return across last 100 episodes: -99.994 state values: tensor(0.5229) 1000
105 1000 -1000.0 -99.99568287525881 number episode from 10: 105 avegar over 10 episode: -99.985 avegare return across last 100 episodes: -99.994 state values: tensor(0.5231) 1000
106 1000 -1000.0 -99.99568287525881 number episode from 10: 106 avegar over 10 episode: -99.985 avegare return across last 100 episodes: -99.994 state values: tensor(0.5228) 1000
107 1000 -1000.0 -99.99568287525881 number episode from 10: 107 avegar over 10 episode: -99.985 avegare return across last 100 episodes: -99.994 state values: tensor(0.5230) 1000
108 1000 -1000.0 -99.99568287525881 number episode from 10: 108 avegar over 10 episode: -99.985 avegare return across last 100 episodes: -99.994 state values: tensor(0.5233) 1000
109 1000 -1000.0 -99.99568287525881 number episode from 10: 109 avegar over 10 episode: -99.985 avegare return across last 100 episodes: -99.994 state values: tensor(0.5236) 1000
110 1000 -1000.0 -99.99568287525881 number episode from 10: 110 avegar over 10 episode: -99.985 avegare return across last 100 episodes: -99.994 state values: tensor(0.5241) 1000
111 1000 -1000.0 -99.99568287525881 number episode from 10: 111 avegar over 10 episode: -99.985 avegare return across last 100 episodes: -99.994 state values: tensor(0.5232) 1000
112 1000 -1000.0 -99.99568287525881 number episode from 10: 112 avegar over 10 episode: -99.985 avegare return across last 100 episodes: -99.994 state values: tensor(0.5229) 1000
113 1000 -1000.0 -99.99568287525881 number episode from 10: 113 avegar over 10 episode: -99.985 avegare return across last 100 episodes: -99.994 state values: tensor(0.5228) 1000
114 1000 -1000.0 -99.99568287525881 number episode from 10: 114 avegar over 10 episode: -99.986 avegare return across last 100 episodes: -99.994 state values: tensor(0.5230) 1000
115 1000 -1000.0 -99.99568287525881 number episode from 10: 115 avegar over 10 episode: -99.986 avegare return across last 100 episodes: -99.994 state values: tensor(0.5231) 1000
116 1000 -1000.0 -99.99568287525881 number episode from 10: 116 avegar over 10 episode: -99.986 avegare return across last 100 episodes: -99.994 state values: tensor(0.5231) 1000
117 1000 -1000.0 -99.99568287525881 number episode from 10: 117 avegar over 10 episode: -99.986 avegare return across last 100 episodes: -99.994 state values: tensor(0.5231) 1000
118 1000 -1000.0 -99.99568287525881 number episode from 10: 118 avegar over 10 episode: -99.986 avegare return across last 100 episodes: -99.994 state values: tensor(0.5229) 1000
119 1000 -1000.0 -99.99568287525881 number episode from 10: 119 avegar over 10 episode: -99.986 avegare return across last 100 episodes: -99.994 state values: tensor(0.5225) 1000
120 1000 -1000.0 -99.99568287525881 number episode from 10: 120 avegar over 10 episode: -99.986 avegare return across last 100 episodes: -99.994 state values: tensor(0.5239) 1000
121 1000 -1000.0 -99.99568287525881 number episode from 10: 121 avegar over 10 episode: -99.986 avegare return across last 100 episodes: -99.994 state values: tensor(0.5238) 1000
122 1000 -1000.0 -99.99568287525881 number episode from 10: 122 avegar over 10 episode: -99.986 avegare return across last 100 episodes: -99.994 state values: tensor(0.5228) 1000
123 1000 -1000.0 -99.99568287525881 number episode from 10: 123 avegar over 10 episode: -99.986 avegare return across last 100 episodes: -99.994 state values: tensor(0.5226) 1000
124 1000 -1000.0 -99.99568287525881 number episode from 10: 124 avegar over 10 episode: -99.986 avegare return across last 100 episodes: -99.994 state values: tensor(0.5245) 1000
125 1000 -1000.0 -99.99568287525881 number episode from 10: 125 avegar over 10 episode: -99.986 avegare return across last 100 episodes: -99.994 state values: tensor(0.5232) 1000
126 784 -784.0 -99.96215638945111 number episode from 10: 126 avegar over 10 episode: -99.986 avegare return across last 100 episodes: -99.994 state values: tensor(0.6014) 784
127 1000 -1000.0 -99.99568287525881 number episode from 10: 127 avegar over 10 episode: -99.986 avegare return across last 100 episodes: -99.994 state values: tensor(0.5229) 1000
128 1000 -1000.0 -99.99568287525881 number episode from 10: 128 avegar over 10 episode: -99.986 avegare return across last 100 episodes: -99.994 state values: tensor(0.5233) 1000
129 1000 -1000.0 -99.99568287525881 number episode from 10: 129 avegar over 10 episode: -99.986 avegare return across last 100 episodes: -99.994 state values: tensor(0.5231) 1000
130 1000 -1000.0 -99.99568287525881 number episode from 10: 130 avegar over 10 episode: -99.987 avegare return across last 100 episodes: -99.994 state values: tensor(0.5230) 1000
131 1000 -1000.0 -99.99568287525881 number episode from 10: 131 avegar over 10 episode: -99.987 avegare return across last 100 episodes: -99.995 state values: tensor(0.5228) 1000
132 1000 -1000.0 -99.99568287525881 number episode from 10: 132 avegar over 10 episode: -99.987 avegare return across last 100 episodes: -99.995 state values: tensor(0.5232) 1000
133 1000 -1000.0 -99.99568287525881 number episode from 10: 133 avegar over 10 episode: -99.987 avegare return across last 100 episodes: -99.995 state values: tensor(0.5232) 1000
134 1000 -1000.0 -99.99568287525881 number episode from 10: 134 avegar over 10 episode: -99.987 avegare return across last 100 episodes: -99.995 state values: tensor(0.5229) 1000
135 1000 -1000.0 -99.99568287525881 number episode from 10: 135 avegar over 10 episode: -99.987 avegare return across last 100 episodes: -99.995 state values: tensor(0.5232) 1000
136 1000 -1000.0 -99.99568287525881 number episode from 10: 136 avegar over 10 episode: -99.987 avegare return across last 100 episodes: -99.995 state values: tensor(0.5227) 1000
137 1000 -1000.0 -99.99568287525881 number episode from 10: 137 avegar over 10 episode: -99.987 avegare return across last 100 episodes: -99.995 state values: tensor(0.5233) 1000
138 1000 -1000.0 -99.99568287525881 number episode from 10: 138 avegar over 10 episode: -99.987 avegare return across last 100 episodes: -99.995 state values: tensor(0.5212) 1000
139 1000 -1000.0 -99.99568287525881 number episode from 10: 139 avegar over 10 episode: -99.987 avegare return across last 100 episodes: -99.995 state values: tensor(0.5231) 1000
140 1000 -1000.0 -99.99568287525881 number episode from 10: 140 avegar over 10 episode: -99.987 avegare return across last 100 episodes: -99.995 state values: tensor(0.5232) 1000
141 1000 -1000.0 -99.99568287525881 number episode from 10: 141 avegar over 10 episode: -99.987 avegare return across last 100 episodes: -99.995 state values: tensor(0.5231) 1000
142 1000 -1000.0 -99.99568287525881 number episode from 10: 142 avegar over 10 episode: -99.987 avegare return across last 100 episodes: -99.995 state values: tensor(0.5230) 1000
143 1000 -1000.0 -99.99568287525881 number episode from 10: 143 avegar over 10 episode: -99.987 avegare return across last 100 episodes: -99.995 state values: tensor(0.5228) 1000
144 1000 -1000.0 -99.99568287525881 number episode from 10: 144 avegar over 10 episode: -99.987 avegare return across last 100 episodes: -99.995 state values: tensor(0.5230) 1000
145 1000 -1000.0 -99.99568287525881 number episode from 10: 145 avegar over 10 episode: -99.987 avegare return across last 100 episodes: -99.995 state values: tensor(0.5232) 1000
146 1000 -1000.0 -99.99568287525881 number episode from 10: 146 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.995 state values: tensor(0.5229) 1000
147 1000 -1000.0 -99.99568287525881 number episode from 10: 147 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.995 state values: tensor(0.5229) 1000
148 1000 -1000.0 -99.99568287525881 number episode from 10: 148 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.995 state values: tensor(0.5232) 1000
149 1000 -1000.0 -99.99568287525881 number episode from 10: 149 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.995 state values: tensor(0.5230) 1000
150 1000 -1000.0 -99.99568287525881 number episode from 10: 150 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.995 state values: tensor(0.5227) 1000
151 1000 -1000.0 -99.99568287525881 number episode from 10: 151 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.995 state values: tensor(0.5239) 1000
152 1000 -1000.0 -99.99568287525881 number episode from 10: 152 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.995 state values: tensor(0.5229) 1000
153 1000 -1000.0 -99.99568287525881 number episode from 10: 153 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.995 state values: tensor(0.5233) 1000
154 1000 -1000.0 -99.99568287525881 number episode from 10: 154 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.995 state values: tensor(0.5235) 1000
155 1000 -1000.0 -99.99568287525881 number episode from 10: 155 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.995 state values: tensor(0.5232) 1000
156 1000 -1000.0 -99.99568287525881 number episode from 10: 156 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.995 state values: tensor(0.5230) 1000
157 1000 -1000.0 -99.99568287525881 number episode from 10: 157 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.995 state values: tensor(0.5164) 1000
158 1000 -1000.0 -99.99568287525881 number episode from 10: 158 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.995 state values: tensor(0.5232) 1000
159 1000 -1000.0 -99.99568287525881 number episode from 10: 159 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.995 state values: tensor(0.5231) 1000
160 1000 -1000.0 -99.99568287525881 number episode from 10: 160 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.995 state values: tensor(0.5234) 1000
161 1000 -1000.0 -99.99568287525881 number episode from 10: 161 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.995 state values: tensor(0.5230) 1000
162 1000 -1000.0 -99.99568287525881 number episode from 10: 162 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.995 state values: tensor(0.5226) 1000
163 1000 -1000.0 -99.99568287525881 number episode from 10: 163 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.995 state values: tensor(0.5229) 1000
164 1000 -1000.0 -99.99568287525881 number episode from 10: 164 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.995 state values: tensor(0.5229) 1000
165 1000 -1000.0 -99.99568287525881 number episode from 10: 165 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.995 state values: tensor(0.5229) 1000
166 1000 -1000.0 -99.99568287525881 number episode from 10: 166 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.995 state values: tensor(0.5229) 1000
167 1000 -1000.0 -99.99568287525881 number episode from 10: 167 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.995 state values: tensor(0.5232) 1000
168 1000 -1000.0 -99.99568287525881 number episode from 10: 168 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.995 state values: tensor(0.5231) 1000
169 1000 -1000.0 -99.99568287525881 number episode from 10: 169 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.995 state values: tensor(0.5230) 1000
170 1000 -1000.0 -99.99568287525881 number episode from 10: 170 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.995 state values: tensor(0.5229) 1000
171 1000 -1000.0 -99.99568287525881 number episode from 10: 171 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.995 state values: tensor(0.5231) 1000
172 1000 -1000.0 -99.99568287525881 number episode from 10: 172 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.995 state values: tensor(0.5230) 1000
173 1000 -1000.0 -99.99568287525881 number episode from 10: 173 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.995 state values: tensor(0.5232) 1000
174 1000 -1000.0 -99.99568287525881 number episode from 10: 174 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.995 state values: tensor(0.5232) 1000
175 1000 -1000.0 -99.99568287525881 number episode from 10: 175 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.995 state values: tensor(0.5228) 1000
176 1000 -1000.0 -99.99568287525881 number episode from 10: 176 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.995 state values: tensor(0.5234) 1000
177 1000 -1000.0 -99.99568287525881 number episode from 10: 177 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.995 state values: tensor(0.5230) 1000
178 1000 -1000.0 -99.99568287525881 number episode from 10: 178 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.995 state values: tensor(0.5248) 1000
179 1000 -1000.0 -99.99568287525881 number episode from 10: 179 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.995 state values: tensor(0.5230) 1000
180 1000 -1000.0 -99.99568287525881 number episode from 10: 180 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.995 state values: tensor(0.5235) 1000
181 1000 -1000.0 -99.99568287525881 number episode from 10: 181 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.995 state values: tensor(0.5236) 1000
182 1000 -1000.0 -99.99568287525881 number episode from 10: 182 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.995 state values: tensor(0.5228) 1000
183 1000 -1000.0 -99.99568287525881 number episode from 10: 183 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.995 state values: tensor(0.5232) 1000
184 1000 -1000.0 -99.99568287525881 number episode from 10: 184 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.995 state values: tensor(0.5228) 1000
185 1000 -1000.0 -99.99568287525881 number episode from 10: 185 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.995 state values: tensor(0.5229) 1000
186 1000 -1000.0 -99.99568287525881 number episode from 10: 186 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.995 state values: tensor(0.5238) 1000
187 1000 -1000.0 -99.99568287525881 number episode from 10: 187 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.995 state values: tensor(0.5259) 1000
188 1000 -1000.0 -99.99568287525881 number episode from 10: 188 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.995 state values: tensor(0.5229) 1000
189 1000 -1000.0 -99.99568287525881 number episode from 10: 189 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.995 state values: tensor(0.5232) 1000
190 1000 -1000.0 -99.99568287525881 number episode from 10: 190 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.995 state values: tensor(0.5230) 1000
191 1000 -1000.0 -99.99568287525881 number episode from 10: 191 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.995 state values: tensor(0.5232) 1000
192 1000 -1000.0 -99.99568287525881 number episode from 10: 192 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.995 state values: tensor(0.5229) 1000
193 1000 -1000.0 -99.99568287525881 number episode from 10: 193 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.995 state values: tensor(0.5231) 1000
194 1000 -1000.0 -99.99568287525881 number episode from 10: 194 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.995 state values: tensor(0.5231) 1000
195 1000 -1000.0 -99.99568287525881 number episode from 10: 195 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.995 state values: tensor(0.5233) 1000
196 1000 -1000.0 -99.99568287525881 number episode from 10: 196 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.995 state values: tensor(0.5230) 1000
197 1000 -1000.0 -99.99568287525881 number episode from 10: 197 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.995 state values: tensor(0.5231) 1000
198 786 -786.0 -99.96290947730104 number episode from 10: 198 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.995 state values: tensor(0.5929) 786
199 1000 -1000.0 -99.99568287525881 number episode from 10: 199 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.995 state values: tensor(0.5229) 1000
200 1000 -1000.0 -99.99568287525881 number episode from 10: 200 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.995 state values: tensor(0.5226) 1000
load offline data!!!!!
mem_cntr: 50000 ; mem_size: 50000
nn.learn_nn_feature_fqi FQI:  998
nn.learn_nn_feature_fqi FQI:  1998
nn.learn_nn_feature_fqi FQI:  2998
nn.learn_nn_feature_fqi FQI:  3998
nn.learn_nn_feature_fqi FQI:  4998
nn.learn_nn_feature_fqi FQI:  5998
nn.learn_nn_feature_fqi FQI:  6998
nn.learn_nn_feature_fqi FQI:  7998
nn.learn_nn_feature_fqi FQI:  8998
nn.learn_nn_feature_fqi FQI:  9998
nn.learn_nn_feature_fqi FQI:  10998
nn.learn_nn_feature_fqi FQI:  11998
nn.learn_nn_feature_fqi FQI:  12998
nn.learn_nn_feature_fqi FQI:  13998
nn.learn_nn_feature_fqi FQI:  14998
nn.learn_nn_feature_fqi FQI:  15998
nn.learn_nn_feature_fqi FQI:  16998
nn.learn_nn_feature_fqi FQI:  17998
nn.learn_nn_feature_fqi FQI:  18998
nn.learn_nn_feature_fqi FQI:  19998
nn.learn_nn_feature_fqi FQI:  20998
nn.learn_nn_feature_fqi FQI:  21998
nn.learn_nn_feature_fqi FQI:  22998
nn.learn_nn_feature_fqi FQI:  23998
nn.learn_nn_feature_fqi FQI:  24998
nn.learn_nn_feature_fqi FQI:  25998
nn.learn_nn_feature_fqi FQI:  26998
nn.learn_nn_feature_fqi FQI:  27998
nn.learn_nn_feature_fqi FQI:  28998
nn.learn_nn_feature_fqi FQI:  29998
nn.learn_nn_feature_fqi FQI:  30998
nn.learn_nn_feature_fqi FQI:  31998
nn.learn_nn_feature_fqi FQI:  32998
nn.learn_nn_feature_fqi FQI:  33998
nn.learn_nn_feature_fqi FQI:  34998
nn.learn_nn_feature_fqi FQI:  35998
nn.learn_nn_feature_fqi FQI:  36998
nn.learn_nn_feature_fqi FQI:  37998
nn.learn_nn_feature_fqi FQI:  38998
nn.learn_nn_feature_fqi FQI:  39998
nn.learn_nn_feature_fqi FQI:  40998
nn.learn_nn_feature_fqi FQI:  41998
nn.learn_nn_feature_fqi FQI:  42998
nn.learn_nn_feature_fqi FQI:  43998
nn.learn_nn_feature_fqi FQI:  44998
nn.learn_nn_feature_fqi FQI:  45998
nn.learn_nn_feature_fqi FQI:  46998
nn.learn_nn_feature_fqi FQI:  47998
nn.learn_nn_feature_fqi FQI:  48998
nn.learn_nn_feature_fqi FQI:  49998
nn.learn_nn_feature_fqi FQI:  50998
nn.learn_nn_feature_fqi FQI:  51998
nn.learn_nn_feature_fqi FQI:  52998
nn.learn_nn_feature_fqi FQI:  53998
nn.learn_nn_feature_fqi FQI:  54998
nn.learn_nn_feature_fqi FQI:  55998
nn.learn_nn_feature_fqi FQI:  56998
nn.learn_nn_feature_fqi FQI:  57998
nn.learn_nn_feature_fqi FQI:  58998
nn.learn_nn_feature_fqi FQI:  59998
nn.learn_nn_feature_fqi FQI:  60998
nn.learn_nn_feature_fqi FQI:  61998
nn.learn_nn_feature_fqi FQI:  62998
nn.learn_nn_feature_fqi FQI:  63998
nn.learn_nn_feature_fqi FQI:  64998
nn.learn_nn_feature_fqi FQI:  65998
nn.learn_nn_feature_fqi FQI:  66998
nn.learn_nn_feature_fqi FQI:  67998
nn.learn_nn_feature_fqi FQI:  68998
nn.learn_nn_feature_fqi FQI:  69998
nn.learn_nn_feature_fqi FQI:  70998
nn.learn_nn_feature_fqi FQI:  71998
nn.learn_nn_feature_fqi FQI:  72998
nn.learn_nn_feature_fqi FQI:  73998
nn.learn_nn_feature_fqi FQI:  74998
nn.learn_nn_feature_fqi FQI:  75998
nn.learn_nn_feature_fqi FQI:  76998
nn.learn_nn_feature_fqi FQI:  77998
nn.learn_nn_feature_fqi FQI:  78998
nn.learn_nn_feature_fqi FQI:  79998
nn.learn_nn_feature_fqi FQI:  80998
nn.learn_nn_feature_fqi FQI:  81998
nn.learn_nn_feature_fqi FQI:  82998
nn.learn_nn_feature_fqi FQI:  83998
nn.learn_nn_feature_fqi FQI:  84998
nn.learn_nn_feature_fqi FQI:  85998
nn.learn_nn_feature_fqi FQI:  86998
nn.learn_nn_feature_fqi FQI:  87998
nn.learn_nn_feature_fqi FQI:  88998
nn.learn_nn_feature_fqi FQI:  89998
nn.learn_nn_feature_fqi FQI:  90998
nn.learn_nn_feature_fqi FQI:  91998
nn.learn_nn_feature_fqi FQI:  92998
nn.learn_nn_feature_fqi FQI:  93998
nn.learn_nn_feature_fqi FQI:  94998
nn.learn_nn_feature_fqi FQI:  95998
nn.learn_nn_feature_fqi FQI:  96998
nn.learn_nn_feature_fqi FQI:  97998
nn.learn_nn_feature_fqi FQI:  98998
nn.learn_nn_feature_fqi FQI:  99998
nn.learn_nn_feature_fqi FQI:  100998
nn.learn_nn_feature_fqi FQI:  101998
nn.learn_nn_feature_fqi FQI:  102998
nn.learn_nn_feature_fqi FQI:  103998
nn.learn_nn_feature_fqi FQI:  104998
nn.learn_nn_feature_fqi FQI:  105998
nn.learn_nn_feature_fqi FQI:  106998
nn.learn_nn_feature_fqi FQI:  107998
nn.learn_nn_feature_fqi FQI:  108998
nn.learn_nn_feature_fqi FQI:  109998
nn.learn_nn_feature_fqi FQI:  110998
nn.learn_nn_feature_fqi FQI:  111998
nn.learn_nn_feature_fqi FQI:  112998
nn.learn_nn_feature_fqi FQI:  113998
nn.learn_nn_feature_fqi FQI:  114998
nn.learn_nn_feature_fqi FQI:  115998
nn.learn_nn_feature_fqi FQI:  116998
nn.learn_nn_feature_fqi FQI:  117998
nn.learn_nn_feature_fqi FQI:  118998
nn.learn_nn_feature_fqi FQI:  119998
nn.learn_nn_feature_fqi FQI:  120998
nn.learn_nn_feature_fqi FQI:  121998
nn.learn_nn_feature_fqi FQI:  122998
nn.learn_nn_feature_fqi FQI:  123998
nn.learn_nn_feature_fqi FQI:  124998
nn.learn_nn_feature_fqi FQI:  125998
nn.learn_nn_feature_fqi FQI:  126998
nn.learn_nn_feature_fqi FQI:  127998
nn.learn_nn_feature_fqi FQI:  128998
nn.learn_nn_feature_fqi FQI:  129998
nn.learn_nn_feature_fqi FQI:  130998
nn.learn_nn_feature_fqi FQI:  131998
nn.learn_nn_feature_fqi FQI:  132998
nn.learn_nn_feature_fqi FQI:  133998
nn.learn_nn_feature_fqi FQI:  134998
nn.learn_nn_feature_fqi FQI:  135998
nn.learn_nn_feature_fqi FQI:  136998
nn.learn_nn_feature_fqi FQI:  137998
nn.learn_nn_feature_fqi FQI:  138998
nn.learn_nn_feature_fqi FQI:  139998
nn.learn_nn_feature_fqi FQI:  140998
nn.learn_nn_feature_fqi FQI:  141998
nn.learn_nn_feature_fqi FQI:  142998
nn.learn_nn_feature_fqi FQI:  143998
nn.learn_nn_feature_fqi FQI:  144998
nn.learn_nn_feature_fqi FQI:  145998
nn.learn_nn_feature_fqi FQI:  146998
nn.learn_nn_feature_fqi FQI:  147998
nn.learn_nn_feature_fqi FQI:  148998
nn.learn_nn_feature_fqi FQI:  149998
nn.learn_nn_feature_fqi FQI:  150998
nn.learn_nn_feature_fqi FQI:  151998
nn.learn_nn_feature_fqi FQI:  152998
nn.learn_nn_feature_fqi FQI:  153998
nn.learn_nn_feature_fqi FQI:  154998
nn.learn_nn_feature_fqi FQI:  155998
0 1001 -1000.0 -98.99572604650622 number episode from 10: 0 avegar over 10 episode: -98.996 avegare return across last 100 episodes: -98.996 state values: tensor(0.6288) 1000
1 1000 -1000.0 -99.99568287525881 number episode from 10: 1 avegar over 10 episode: -99.496 avegare return across last 100 episodes: -99.496 state values: tensor(0.6288) 1000
2 1000 -1000.0 -99.99568287525881 number episode from 10: 2 avegar over 10 episode: -99.662 avegare return across last 100 episodes: -99.662 state values: tensor(0.6297) 1000
3 1000 -1000.0 -99.99568287525881 number episode from 10: 3 avegar over 10 episode: -99.746 avegare return across last 100 episodes: -99.746 state values: tensor(0.6289) 1000
4 1000 -1000.0 -99.99568287525881 number episode from 10: 4 avegar over 10 episode: -99.796 avegare return across last 100 episodes: -99.796 state values: tensor(0.6282) 1000
5 1000 -1000.0 -99.99568287525881 number episode from 10: 5 avegar over 10 episode: -99.829 avegare return across last 100 episodes: -99.829 state values: tensor(0.6290) 1000
6 1000 -1000.0 -99.99568287525881 number episode from 10: 6 avegar over 10 episode: -99.853 avegare return across last 100 episodes: -99.853 state values: tensor(0.6280) 1000
7 1000 -1000.0 -99.99568287525881 number episode from 10: 7 avegar over 10 episode: -99.871 avegare return across last 100 episodes: -99.871 state values: tensor(0.6283) 1000
8 1000 -1000.0 -99.99568287525881 number episode from 10: 8 avegar over 10 episode: -99.885 avegare return across last 100 episodes: -99.885 state values: tensor(0.6297) 1000
9 1000 -1000.0 -99.99568287525881 number episode from 10: 9 avegar over 10 episode: -99.896 avegare return across last 100 episodes: -99.896 state values: tensor(0.6284) 1000
10 1000 -1000.0 -99.99568287525881 number episode from 10: 10 avegar over 10 episode: -99.905 avegare return across last 100 episodes: -99.905 state values: tensor(0.6280) 1000
11 1000 -1000.0 -99.99568287525881 number episode from 10: 11 avegar over 10 episode: -99.912 avegare return across last 100 episodes: -99.912 state values: tensor(0.6283) 1000
12 1000 -1000.0 -99.99568287525881 number episode from 10: 12 avegar over 10 episode: -99.919 avegare return across last 100 episodes: -99.919 state values: tensor(0.6287) 1000
13 1000 -1000.0 -99.99568287525881 number episode from 10: 13 avegar over 10 episode: -99.924 avegare return across last 100 episodes: -99.924 state values: tensor(0.6294) 1000
14 1000 -1000.0 -99.99568287525881 number episode from 10: 14 avegar over 10 episode: -99.929 avegare return across last 100 episodes: -99.929 state values: tensor(0.6280) 1000
15 1000 -1000.0 -99.99568287525881 number episode from 10: 15 avegar over 10 episode: -99.933 avegare return across last 100 episodes: -99.933 state values: tensor(0.6278) 1000
16 1000 -1000.0 -99.99568287525881 number episode from 10: 16 avegar over 10 episode: -99.937 avegare return across last 100 episodes: -99.937 state values: tensor(0.6289) 1000
17 1000 -1000.0 -99.99568287525881 number episode from 10: 17 avegar over 10 episode: -99.94 avegare return across last 100 episodes: -99.94 state values: tensor(0.6284) 1000
18 1000 -1000.0 -99.99568287525881 number episode from 10: 18 avegar over 10 episode: -99.943 avegare return across last 100 episodes: -99.943 state values: tensor(0.6292) 1000
19 1000 -1000.0 -99.99568287525881 number episode from 10: 19 avegar over 10 episode: -99.946 avegare return across last 100 episodes: -99.946 state values: tensor(0.6295) 1000
20 1000 -1000.0 -99.99568287525881 number episode from 10: 20 avegar over 10 episode: -99.948 avegare return across last 100 episodes: -99.948 state values: tensor(0.6292) 1000
21 1000 -1000.0 -99.99568287525881 number episode from 10: 21 avegar over 10 episode: -99.95 avegare return across last 100 episodes: -99.95 state values: tensor(0.6269) 1000
22 1000 -1000.0 -99.99568287525881 number episode from 10: 22 avegar over 10 episode: -99.952 avegare return across last 100 episodes: -99.952 state values: tensor(0.6284) 1000
23 1000 -1000.0 -99.99568287525881 number episode from 10: 23 avegar over 10 episode: -99.954 avegare return across last 100 episodes: -99.954 state values: tensor(0.6286) 1000
24 1000 -1000.0 -99.99568287525881 number episode from 10: 24 avegar over 10 episode: -99.956 avegare return across last 100 episodes: -99.956 state values: tensor(0.6295) 1000
25 1000 -1000.0 -99.99568287525881 number episode from 10: 25 avegar over 10 episode: -99.957 avegare return across last 100 episodes: -99.957 state values: tensor(0.6292) 1000
26 1000 -1000.0 -99.99568287525881 number episode from 10: 26 avegar over 10 episode: -99.959 avegare return across last 100 episodes: -99.959 state values: tensor(0.6284) 1000
27 1000 -1000.0 -99.99568287525881 number episode from 10: 27 avegar over 10 episode: -99.96 avegare return across last 100 episodes: -99.96 state values: tensor(0.6273) 1000
28 1000 -1000.0 -99.99568287525881 number episode from 10: 28 avegar over 10 episode: -99.961 avegare return across last 100 episodes: -99.961 state values: tensor(0.6287) 1000
29 1000 -1000.0 -99.99568287525881 number episode from 10: 29 avegar over 10 episode: -99.962 avegare return across last 100 episodes: -99.962 state values: tensor(0.6290) 1000
30 1000 -1000.0 -99.99568287525881 number episode from 10: 30 avegar over 10 episode: -99.963 avegare return across last 100 episodes: -99.963 state values: tensor(0.6286) 1000
31 1000 -1000.0 -99.99568287525881 number episode from 10: 31 avegar over 10 episode: -99.964 avegare return across last 100 episodes: -99.964 state values: tensor(0.6292) 1000
32 1000 -1000.0 -99.99568287525881 number episode from 10: 32 avegar over 10 episode: -99.965 avegare return across last 100 episodes: -99.965 state values: tensor(0.6288) 1000
33 1000 -1000.0 -99.99568287525881 number episode from 10: 33 avegar over 10 episode: -99.966 avegare return across last 100 episodes: -99.966 state values: tensor(0.6291) 1000
34 1000 -1000.0 -99.99568287525881 number episode from 10: 34 avegar over 10 episode: -99.967 avegare return across last 100 episodes: -99.967 state values: tensor(0.6293) 1000
35 1000 -1000.0 -99.99568287525881 number episode from 10: 35 avegar over 10 episode: -99.968 avegare return across last 100 episodes: -99.968 state values: tensor(0.6281) 1000
36 1000 -1000.0 -99.99568287525881 number episode from 10: 36 avegar over 10 episode: -99.969 avegare return across last 100 episodes: -99.969 state values: tensor(0.6288) 1000
37 1000 -1000.0 -99.99568287525881 number episode from 10: 37 avegar over 10 episode: -99.969 avegare return across last 100 episodes: -99.969 state values: tensor(0.6278) 1000
38 1000 -1000.0 -99.99568287525881 number episode from 10: 38 avegar over 10 episode: -99.97 avegare return across last 100 episodes: -99.97 state values: tensor(0.6294) 1000
39 1000 -1000.0 -99.99568287525881 number episode from 10: 39 avegar over 10 episode: -99.971 avegare return across last 100 episodes: -99.971 state values: tensor(0.6282) 1000
40 1000 -1000.0 -99.99568287525881 number episode from 10: 40 avegar over 10 episode: -99.971 avegare return across last 100 episodes: -99.971 state values: tensor(0.6287) 1000
41 1000 -1000.0 -99.99568287525881 number episode from 10: 41 avegar over 10 episode: -99.972 avegare return across last 100 episodes: -99.972 state values: tensor(0.6288) 1000
42 1000 -1000.0 -99.99568287525881 number episode from 10: 42 avegar over 10 episode: -99.972 avegare return across last 100 episodes: -99.972 state values: tensor(0.6294) 1000
43 1000 -1000.0 -99.99568287525881 number episode from 10: 43 avegar over 10 episode: -99.973 avegare return across last 100 episodes: -99.973 state values: tensor(0.6293) 1000
44 1000 -1000.0 -99.99568287525881 number episode from 10: 44 avegar over 10 episode: -99.973 avegare return across last 100 episodes: -99.973 state values: tensor(0.6294) 1000
45 1000 -1000.0 -99.99568287525881 number episode from 10: 45 avegar over 10 episode: -99.974 avegare return across last 100 episodes: -99.974 state values: tensor(0.6271) 1000
46 1000 -1000.0 -99.99568287525881 number episode from 10: 46 avegar over 10 episode: -99.974 avegare return across last 100 episodes: -99.974 state values: tensor(0.6274) 1000
47 1000 -1000.0 -99.99568287525881 number episode from 10: 47 avegar over 10 episode: -99.975 avegare return across last 100 episodes: -99.975 state values: tensor(0.6280) 1000
48 1000 -1000.0 -99.99568287525881 number episode from 10: 48 avegar over 10 episode: -99.975 avegare return across last 100 episodes: -99.975 state values: tensor(0.6299) 1000
49 1000 -1000.0 -99.99568287525881 number episode from 10: 49 avegar over 10 episode: -99.976 avegare return across last 100 episodes: -99.976 state values: tensor(0.6289) 1000
50 1000 -1000.0 -99.99568287525881 number episode from 10: 50 avegar over 10 episode: -99.976 avegare return across last 100 episodes: -99.976 state values: tensor(0.6288) 1000
51 1000 -1000.0 -99.99568287525881 number episode from 10: 51 avegar over 10 episode: -99.976 avegare return across last 100 episodes: -99.976 state values: tensor(0.6284) 1000
52 1000 -1000.0 -99.99568287525881 number episode from 10: 52 avegar over 10 episode: -99.977 avegare return across last 100 episodes: -99.977 state values: tensor(0.6282) 1000
53 1000 -1000.0 -99.99568287525881 number episode from 10: 53 avegar over 10 episode: -99.977 avegare return across last 100 episodes: -99.977 state values: tensor(0.6290) 1000
54 1000 -1000.0 -99.99568287525881 number episode from 10: 54 avegar over 10 episode: -99.978 avegare return across last 100 episodes: -99.978 state values: tensor(0.6295) 1000
55 1000 -1000.0 -99.99568287525881 number episode from 10: 55 avegar over 10 episode: -99.978 avegare return across last 100 episodes: -99.978 state values: tensor(0.6289) 1000
56 1000 -1000.0 -99.99568287525881 number episode from 10: 56 avegar over 10 episode: -99.978 avegare return across last 100 episodes: -99.978 state values: tensor(0.6269) 1000
57 1000 -1000.0 -99.99568287525881 number episode from 10: 57 avegar over 10 episode: -99.978 avegare return across last 100 episodes: -99.978 state values: tensor(0.6282) 1000
58 1000 -1000.0 -99.99568287525881 number episode from 10: 58 avegar over 10 episode: -99.979 avegare return across last 100 episodes: -99.979 state values: tensor(0.6292) 1000
59 1000 -1000.0 -99.99568287525881 number episode from 10: 59 avegar over 10 episode: -99.979 avegare return across last 100 episodes: -99.979 state values: tensor(0.6290) 1000
60 1000 -1000.0 -99.99568287525881 number episode from 10: 60 avegar over 10 episode: -99.979 avegare return across last 100 episodes: -99.979 state values: tensor(0.6285) 1000
61 1000 -1000.0 -99.99568287525881 number episode from 10: 61 avegar over 10 episode: -99.98 avegare return across last 100 episodes: -99.98 state values: tensor(0.6293) 1000
62 1000 -1000.0 -99.99568287525881 number episode from 10: 62 avegar over 10 episode: -99.98 avegare return across last 100 episodes: -99.98 state values: tensor(0.6285) 1000
63 1000 -1000.0 -99.99568287525881 number episode from 10: 63 avegar over 10 episode: -99.98 avegare return across last 100 episodes: -99.98 state values: tensor(0.6287) 1000
64 1000 -1000.0 -99.99568287525881 number episode from 10: 64 avegar over 10 episode: -99.98 avegare return across last 100 episodes: -99.98 state values: tensor(0.6274) 1000
65 1000 -1000.0 -99.99568287525881 number episode from 10: 65 avegar over 10 episode: -99.981 avegare return across last 100 episodes: -99.981 state values: tensor(0.6286) 1000
66 1000 -1000.0 -99.99568287525881 number episode from 10: 66 avegar over 10 episode: -99.981 avegare return across last 100 episodes: -99.981 state values: tensor(0.6277) 1000
67 1000 -1000.0 -99.99568287525881 number episode from 10: 67 avegar over 10 episode: -99.981 avegare return across last 100 episodes: -99.981 state values: tensor(0.6291) 1000
68 1000 -1000.0 -99.99568287525881 number episode from 10: 68 avegar over 10 episode: -99.981 avegare return across last 100 episodes: -99.981 state values: tensor(0.6275) 1000
69 1000 -1000.0 -99.99568287525881 number episode from 10: 69 avegar over 10 episode: -99.981 avegare return across last 100 episodes: -99.981 state values: tensor(0.6265) 1000
70 1000 -1000.0 -99.99568287525881 number episode from 10: 70 avegar over 10 episode: -99.982 avegare return across last 100 episodes: -99.982 state values: tensor(0.6287) 1000
71 1000 -1000.0 -99.99568287525881 number episode from 10: 71 avegar over 10 episode: -99.982 avegare return across last 100 episodes: -99.982 state values: tensor(0.6285) 1000
72 1000 -1000.0 -99.99568287525881 number episode from 10: 72 avegar over 10 episode: -99.982 avegare return across last 100 episodes: -99.982 state values: tensor(0.6279) 1000
73 1000 -1000.0 -99.99568287525881 number episode from 10: 73 avegar over 10 episode: -99.982 avegare return across last 100 episodes: -99.982 state values: tensor(0.6284) 1000
74 1000 -1000.0 -99.99568287525881 number episode from 10: 74 avegar over 10 episode: -99.982 avegare return across last 100 episodes: -99.982 state values: tensor(0.6289) 1000
75 1000 -1000.0 -99.99568287525881 number episode from 10: 75 avegar over 10 episode: -99.983 avegare return across last 100 episodes: -99.983 state values: tensor(0.6284) 1000
76 1000 -1000.0 -99.99568287525881 number episode from 10: 76 avegar over 10 episode: -99.983 avegare return across last 100 episodes: -99.983 state values: tensor(0.6291) 1000
77 1000 -1000.0 -99.99568287525881 number episode from 10: 77 avegar over 10 episode: -99.983 avegare return across last 100 episodes: -99.983 state values: tensor(0.6296) 1000
78 1000 -1000.0 -99.99568287525881 number episode from 10: 78 avegar over 10 episode: -99.983 avegare return across last 100 episodes: -99.983 state values: tensor(0.6290) 1000
79 1000 -1000.0 -99.99568287525881 number episode from 10: 79 avegar over 10 episode: -99.983 avegare return across last 100 episodes: -99.983 state values: tensor(0.6287) 1000
80 1000 -1000.0 -99.99568287525881 number episode from 10: 80 avegar over 10 episode: -99.983 avegare return across last 100 episodes: -99.983 state values: tensor(0.6287) 1000
81 1000 -1000.0 -99.99568287525881 number episode from 10: 81 avegar over 10 episode: -99.983 avegare return across last 100 episodes: -99.983 state values: tensor(0.6276) 1000
82 1000 -1000.0 -99.99568287525881 number episode from 10: 82 avegar over 10 episode: -99.984 avegare return across last 100 episodes: -99.984 state values: tensor(0.6286) 1000
83 1000 -1000.0 -99.99568287525881 number episode from 10: 83 avegar over 10 episode: -99.984 avegare return across last 100 episodes: -99.984 state values: tensor(0.6284) 1000
84 1000 -1000.0 -99.99568287525881 number episode from 10: 84 avegar over 10 episode: -99.984 avegare return across last 100 episodes: -99.984 state values: tensor(0.6287) 1000
85 1000 -1000.0 -99.99568287525881 number episode from 10: 85 avegar over 10 episode: -99.984 avegare return across last 100 episodes: -99.984 state values: tensor(0.6297) 1000
86 1000 -1000.0 -99.99568287525881 number episode from 10: 86 avegar over 10 episode: -99.984 avegare return across last 100 episodes: -99.984 state values: tensor(0.6285) 1000
87 1000 -1000.0 -99.99568287525881 number episode from 10: 87 avegar over 10 episode: -99.984 avegare return across last 100 episodes: -99.984 state values: tensor(0.6279) 1000
88 1000 -1000.0 -99.99568287525881 number episode from 10: 88 avegar over 10 episode: -99.984 avegare return across last 100 episodes: -99.984 state values: tensor(0.6295) 1000
89 1000 -1000.0 -99.99568287525881 number episode from 10: 89 avegar over 10 episode: -99.985 avegare return across last 100 episodes: -99.985 state values: tensor(0.6285) 1000
90 1000 -1000.0 -99.99568287525881 number episode from 10: 90 avegar over 10 episode: -99.985 avegare return across last 100 episodes: -99.985 state values: tensor(0.6282) 1000
91 1000 -1000.0 -99.99568287525881 number episode from 10: 91 avegar over 10 episode: -99.985 avegare return across last 100 episodes: -99.985 state values: tensor(0.6286) 1000
92 1000 -1000.0 -99.99568287525881 number episode from 10: 92 avegar over 10 episode: -99.985 avegare return across last 100 episodes: -99.985 state values: tensor(0.6293) 1000
93 1000 -1000.0 -99.99568287525881 number episode from 10: 93 avegar over 10 episode: -99.985 avegare return across last 100 episodes: -99.985 state values: tensor(0.6277) 1000
94 1000 -1000.0 -99.99568287525881 number episode from 10: 94 avegar over 10 episode: -99.985 avegare return across last 100 episodes: -99.985 state values: tensor(0.6288) 1000
95 1000 -1000.0 -99.99568287525881 number episode from 10: 95 avegar over 10 episode: -99.985 avegare return across last 100 episodes: -99.985 state values: tensor(0.6291) 1000
96 1000 -1000.0 -99.99568287525881 number episode from 10: 96 avegar over 10 episode: -99.985 avegare return across last 100 episodes: -99.985 state values: tensor(0.6291) 1000
97 1000 -1000.0 -99.99568287525881 number episode from 10: 97 avegar over 10 episode: -99.985 avegare return across last 100 episodes: -99.985 state values: tensor(0.6281) 1000
98 1000 -1000.0 -99.99568287525881 number episode from 10: 98 avegar over 10 episode: -99.986 avegare return across last 100 episodes: -99.986 state values: tensor(0.6280) 1000
99 1000 -1000.0 -99.99568287525881 number episode from 10: 99 avegar over 10 episode: -99.986 avegare return across last 100 episodes: -99.986 state values: tensor(0.6293) 1000
100 1000 -1000.0 -99.99568287525881 number episode from 10: 100 avegar over 10 episode: -99.986 avegare return across last 100 episodes: -99.996 state values: tensor(0.6290) 1000
101 1000 -1000.0 -99.99568287525881 number episode from 10: 101 avegar over 10 episode: -99.986 avegare return across last 100 episodes: -99.996 state values: tensor(0.6292) 1000
102 1000 -1000.0 -99.99568287525881 number episode from 10: 102 avegar over 10 episode: -99.986 avegare return across last 100 episodes: -99.996 state values: tensor(0.6286) 1000
103 1000 -1000.0 -99.99568287525881 number episode from 10: 103 avegar over 10 episode: -99.986 avegare return across last 100 episodes: -99.996 state values: tensor(0.6280) 1000
104 1000 -1000.0 -99.99568287525881 number episode from 10: 104 avegar over 10 episode: -99.986 avegare return across last 100 episodes: -99.996 state values: tensor(0.6280) 1000
105 1000 -1000.0 -99.99568287525881 number episode from 10: 105 avegar over 10 episode: -99.986 avegare return across last 100 episodes: -99.996 state values: tensor(0.6282) 1000
106 1000 -1000.0 -99.99568287525881 number episode from 10: 106 avegar over 10 episode: -99.986 avegare return across last 100 episodes: -99.996 state values: tensor(0.6290) 1000
107 1000 -1000.0 -99.99568287525881 number episode from 10: 107 avegar over 10 episode: -99.986 avegare return across last 100 episodes: -99.996 state values: tensor(0.6283) 1000
108 1000 -1000.0 -99.99568287525881 number episode from 10: 108 avegar over 10 episode: -99.987 avegare return across last 100 episodes: -99.996 state values: tensor(0.6282) 1000
109 1000 -1000.0 -99.99568287525881 number episode from 10: 109 avegar over 10 episode: -99.987 avegare return across last 100 episodes: -99.996 state values: tensor(0.6290) 1000
110 1000 -1000.0 -99.99568287525881 number episode from 10: 110 avegar over 10 episode: -99.987 avegare return across last 100 episodes: -99.996 state values: tensor(0.6290) 1000
111 1000 -1000.0 -99.99568287525881 number episode from 10: 111 avegar over 10 episode: -99.987 avegare return across last 100 episodes: -99.996 state values: tensor(0.6286) 1000
112 1000 -1000.0 -99.99568287525881 number episode from 10: 112 avegar over 10 episode: -99.987 avegare return across last 100 episodes: -99.996 state values: tensor(0.6281) 1000
113 1000 -1000.0 -99.99568287525881 number episode from 10: 113 avegar over 10 episode: -99.987 avegare return across last 100 episodes: -99.996 state values: tensor(0.6291) 1000
114 1000 -1000.0 -99.99568287525881 number episode from 10: 114 avegar over 10 episode: -99.987 avegare return across last 100 episodes: -99.996 state values: tensor(0.6285) 1000
115 1000 -1000.0 -99.99568287525881 number episode from 10: 115 avegar over 10 episode: -99.987 avegare return across last 100 episodes: -99.996 state values: tensor(0.6266) 1000
116 1000 -1000.0 -99.99568287525881 number episode from 10: 116 avegar over 10 episode: -99.987 avegare return across last 100 episodes: -99.996 state values: tensor(0.6289) 1000
117 1000 -1000.0 -99.99568287525881 number episode from 10: 117 avegar over 10 episode: -99.987 avegare return across last 100 episodes: -99.996 state values: tensor(0.6289) 1000
118 1000 -1000.0 -99.99568287525881 number episode from 10: 118 avegar over 10 episode: -99.987 avegare return across last 100 episodes: -99.996 state values: tensor(0.6288) 1000
119 1000 -1000.0 -99.99568287525881 number episode from 10: 119 avegar over 10 episode: -99.987 avegare return across last 100 episodes: -99.996 state values: tensor(0.6278) 1000
120 1000 -1000.0 -99.99568287525881 number episode from 10: 120 avegar over 10 episode: -99.987 avegare return across last 100 episodes: -99.996 state values: tensor(0.6277) 1000
121 1000 -1000.0 -99.99568287525881 number episode from 10: 121 avegar over 10 episode: -99.987 avegare return across last 100 episodes: -99.996 state values: tensor(0.6294) 1000
122 1000 -1000.0 -99.99568287525881 number episode from 10: 122 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.6290) 1000
123 1000 -1000.0 -99.99568287525881 number episode from 10: 123 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.6293) 1000
124 1000 -1000.0 -99.99568287525881 number episode from 10: 124 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.6285) 1000
125 1000 -1000.0 -99.99568287525881 number episode from 10: 125 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.6284) 1000
126 1000 -1000.0 -99.99568287525881 number episode from 10: 126 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.6294) 1000
127 1000 -1000.0 -99.99568287525881 number episode from 10: 127 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.6284) 1000
128 1000 -1000.0 -99.99568287525881 number episode from 10: 128 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.6292) 1000
129 1000 -1000.0 -99.99568287525881 number episode from 10: 129 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.6290) 1000
130 1000 -1000.0 -99.99568287525881 number episode from 10: 130 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.6279) 1000
131 1000 -1000.0 -99.99568287525881 number episode from 10: 131 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.6288) 1000
132 1000 -1000.0 -99.99568287525881 number episode from 10: 132 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.6289) 1000
133 1000 -1000.0 -99.99568287525881 number episode from 10: 133 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.6295) 1000
134 1000 -1000.0 -99.99568287525881 number episode from 10: 134 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.6297) 1000
135 1000 -1000.0 -99.99568287525881 number episode from 10: 135 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.6286) 1000
136 1000 -1000.0 -99.99568287525881 number episode from 10: 136 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.6290) 1000
137 1000 -1000.0 -99.99568287525881 number episode from 10: 137 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.6283) 1000
138 1000 -1000.0 -99.99568287525881 number episode from 10: 138 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.6286) 1000
139 1000 -1000.0 -99.99568287525881 number episode from 10: 139 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.6281) 1000
140 1000 -1000.0 -99.99568287525881 number episode from 10: 140 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.6290) 1000
141 1000 -1000.0 -99.99568287525881 number episode from 10: 141 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.6290) 1000
142 1000 -1000.0 -99.99568287525881 number episode from 10: 142 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.6292) 1000
143 1000 -1000.0 -99.99568287525881 number episode from 10: 143 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.6286) 1000
144 1000 -1000.0 -99.99568287525881 number episode from 10: 144 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.6288) 1000
145 1000 -1000.0 -99.99568287525881 number episode from 10: 145 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.6282) 1000
146 1000 -1000.0 -99.99568287525881 number episode from 10: 146 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.6279) 1000
147 1000 -1000.0 -99.99568287525881 number episode from 10: 147 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.6295) 1000
148 1000 -1000.0 -99.99568287525881 number episode from 10: 148 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.6273) 1000
149 1000 -1000.0 -99.99568287525881 number episode from 10: 149 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.6289) 1000
150 1000 -1000.0 -99.99568287525881 number episode from 10: 150 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.6285) 1000
151 1000 -1000.0 -99.99568287525881 number episode from 10: 151 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.6287) 1000
152 1000 -1000.0 -99.99568287525881 number episode from 10: 152 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.6292) 1000
153 1000 -1000.0 -99.99568287525881 number episode from 10: 153 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.6293) 1000
154 1000 -1000.0 -99.99568287525881 number episode from 10: 154 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.6282) 1000
155 1000 -1000.0 -99.99568287525881 number episode from 10: 155 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.6286) 1000
156 1000 -1000.0 -99.99568287525881 number episode from 10: 156 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.6291) 1000
157 1000 -1000.0 -99.99568287525881 number episode from 10: 157 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.6295) 1000
158 1000 -1000.0 -99.99568287525881 number episode from 10: 158 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.6283) 1000
159 1000 -1000.0 -99.99568287525881 number episode from 10: 159 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.6284) 1000
160 1000 -1000.0 -99.99568287525881 number episode from 10: 160 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.6290) 1000
161 1000 -1000.0 -99.99568287525881 number episode from 10: 161 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.6285) 1000
162 1000 -1000.0 -99.99568287525881 number episode from 10: 162 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.6287) 1000
163 1000 -1000.0 -99.99568287525881 number episode from 10: 163 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.6285) 1000
164 1000 -1000.0 -99.99568287525881 number episode from 10: 164 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.6281) 1000
165 1000 -1000.0 -99.99568287525881 number episode from 10: 165 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.6277) 1000
166 1000 -1000.0 -99.99568287525881 number episode from 10: 166 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.6290) 1000
167 1000 -1000.0 -99.99568287525881 number episode from 10: 167 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.6299) 1000
168 1000 -1000.0 -99.99568287525881 number episode from 10: 168 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.6289) 1000
169 1000 -1000.0 -99.99568287525881 number episode from 10: 169 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.6268) 1000
170 1000 -1000.0 -99.99568287525881 number episode from 10: 170 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.6295) 1000
171 1000 -1000.0 -99.99568287525881 number episode from 10: 171 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.6290) 1000
172 1000 -1000.0 -99.99568287525881 number episode from 10: 172 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.6289) 1000
173 1000 -1000.0 -99.99568287525881 number episode from 10: 173 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.6284) 1000
174 1000 -1000.0 -99.99568287525881 number episode from 10: 174 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.6281) 1000
175 1000 -1000.0 -99.99568287525881 number episode from 10: 175 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.6293) 1000
176 1000 -1000.0 -99.99568287525881 number episode from 10: 176 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.6280) 1000
177 1000 -1000.0 -99.99568287525881 number episode from 10: 177 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.6296) 1000
178 1000 -1000.0 -99.99568287525881 number episode from 10: 178 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.6288) 1000
179 1000 -1000.0 -99.99568287525881 number episode from 10: 179 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.6272) 1000
180 1000 -1000.0 -99.99568287525881 number episode from 10: 180 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.6280) 1000
181 1000 -1000.0 -99.99568287525881 number episode from 10: 181 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.6291) 1000
182 1000 -1000.0 -99.99568287525881 number episode from 10: 182 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.6284) 1000
183 1000 -1000.0 -99.99568287525881 number episode from 10: 183 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.6268) 1000
184 1000 -1000.0 -99.99568287525881 number episode from 10: 184 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.6279) 1000
185 1000 -1000.0 -99.99568287525881 number episode from 10: 185 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.6294) 1000
186 1000 -1000.0 -99.99568287525881 number episode from 10: 186 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.6273) 1000
187 1000 -1000.0 -99.99568287525881 number episode from 10: 187 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.6283) 1000
188 1000 -1000.0 -99.99568287525881 number episode from 10: 188 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.6283) 1000
189 1000 -1000.0 -99.99568287525881 number episode from 10: 189 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.6285) 1000
190 1000 -1000.0 -99.99568287525881 number episode from 10: 190 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.6280) 1000
191 1000 -1000.0 -99.99568287525881 number episode from 10: 191 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.6275) 1000
192 1000 -1000.0 -99.99568287525881 number episode from 10: 192 avegar over 10 episode: -99.991 avegare return across last 100 episodes: -99.996 state values: tensor(0.6280) 1000
193 1000 -1000.0 -99.99568287525881 number episode from 10: 193 avegar over 10 episode: -99.991 avegare return across last 100 episodes: -99.996 state values: tensor(0.6271) 1000
194 1000 -1000.0 -99.99568287525881 number episode from 10: 194 avegar over 10 episode: -99.991 avegare return across last 100 episodes: -99.996 state values: tensor(0.6293) 1000
195 1000 -1000.0 -99.99568287525881 number episode from 10: 195 avegar over 10 episode: -99.991 avegare return across last 100 episodes: -99.996 state values: tensor(0.6283) 1000
196 1000 -1000.0 -99.99568287525881 number episode from 10: 196 avegar over 10 episode: -99.991 avegare return across last 100 episodes: -99.996 state values: tensor(0.6285) 1000
197 1000 -1000.0 -99.99568287525881 number episode from 10: 197 avegar over 10 episode: -99.991 avegare return across last 100 episodes: -99.996 state values: tensor(0.6286) 1000
198 1000 -1000.0 -99.99568287525881 number episode from 10: 198 avegar over 10 episode: -99.991 avegare return across last 100 episodes: -99.996 state values: tensor(0.6296) 1000
199 1000 -1000.0 -99.99568287525881 number episode from 10: 199 avegar over 10 episode: -99.991 avegare return across last 100 episodes: -99.996 state values: tensor(0.6284) 1000
200 1000 -1000.0 -99.99568287525881 number episode from 10: 200 avegar over 10 episode: -99.991 avegare return across last 100 episodes: -99.996 state values: tensor(0.6291) 1000
load offline data!!!!!
mem_cntr: 50000 ; mem_size: 50000
nn.learn_nn_feature_fqi FQI:  998
nn.learn_nn_feature_fqi FQI:  1998
nn.learn_nn_feature_fqi FQI:  2998
nn.learn_nn_feature_fqi FQI:  3998
nn.learn_nn_feature_fqi FQI:  4998
nn.learn_nn_feature_fqi FQI:  5998
nn.learn_nn_feature_fqi FQI:  6998
nn.learn_nn_feature_fqi FQI:  7998
nn.learn_nn_feature_fqi FQI:  8998
nn.learn_nn_feature_fqi FQI:  9998
nn.learn_nn_feature_fqi FQI:  10998
nn.learn_nn_feature_fqi FQI:  11998
nn.learn_nn_feature_fqi FQI:  12998
nn.learn_nn_feature_fqi FQI:  13998
nn.learn_nn_feature_fqi FQI:  14998
nn.learn_nn_feature_fqi FQI:  15998
nn.learn_nn_feature_fqi FQI:  16998
nn.learn_nn_feature_fqi FQI:  17998
nn.learn_nn_feature_fqi FQI:  18998
nn.learn_nn_feature_fqi FQI:  19998
nn.learn_nn_feature_fqi FQI:  20998
nn.learn_nn_feature_fqi FQI:  21998
nn.learn_nn_feature_fqi FQI:  22998
nn.learn_nn_feature_fqi FQI:  23998
nn.learn_nn_feature_fqi FQI:  24998
nn.learn_nn_feature_fqi FQI:  25998
nn.learn_nn_feature_fqi FQI:  26998
nn.learn_nn_feature_fqi FQI:  27998
nn.learn_nn_feature_fqi FQI:  28998
nn.learn_nn_feature_fqi FQI:  29998
nn.learn_nn_feature_fqi FQI:  30998
nn.learn_nn_feature_fqi FQI:  31998
nn.learn_nn_feature_fqi FQI:  32998
nn.learn_nn_feature_fqi FQI:  33998
nn.learn_nn_feature_fqi FQI:  34998
nn.learn_nn_feature_fqi FQI:  35998
nn.learn_nn_feature_fqi FQI:  36998
nn.learn_nn_feature_fqi FQI:  37998
nn.learn_nn_feature_fqi FQI:  38998
nn.learn_nn_feature_fqi FQI:  39998
nn.learn_nn_feature_fqi FQI:  40998
nn.learn_nn_feature_fqi FQI:  41998
nn.learn_nn_feature_fqi FQI:  42998
nn.learn_nn_feature_fqi FQI:  43998
nn.learn_nn_feature_fqi FQI:  44998
nn.learn_nn_feature_fqi FQI:  45998
nn.learn_nn_feature_fqi FQI:  46998
nn.learn_nn_feature_fqi FQI:  47998
nn.learn_nn_feature_fqi FQI:  48998
nn.learn_nn_feature_fqi FQI:  49998
nn.learn_nn_feature_fqi FQI:  50998
nn.learn_nn_feature_fqi FQI:  51998
nn.learn_nn_feature_fqi FQI:  52998
nn.learn_nn_feature_fqi FQI:  53998
nn.learn_nn_feature_fqi FQI:  54998
nn.learn_nn_feature_fqi FQI:  55998
nn.learn_nn_feature_fqi FQI:  56998
nn.learn_nn_feature_fqi FQI:  57998
nn.learn_nn_feature_fqi FQI:  58998
nn.learn_nn_feature_fqi FQI:  59998
nn.learn_nn_feature_fqi FQI:  60998
nn.learn_nn_feature_fqi FQI:  61998
nn.learn_nn_feature_fqi FQI:  62998
nn.learn_nn_feature_fqi FQI:  63998
nn.learn_nn_feature_fqi FQI:  64998
nn.learn_nn_feature_fqi FQI:  65998
nn.learn_nn_feature_fqi FQI:  66998
nn.learn_nn_feature_fqi FQI:  67998
nn.learn_nn_feature_fqi FQI:  68998
nn.learn_nn_feature_fqi FQI:  69998
nn.learn_nn_feature_fqi FQI:  70998
nn.learn_nn_feature_fqi FQI:  71998
nn.learn_nn_feature_fqi FQI:  72998
nn.learn_nn_feature_fqi FQI:  73998
nn.learn_nn_feature_fqi FQI:  74998
nn.learn_nn_feature_fqi FQI:  75998
nn.learn_nn_feature_fqi FQI:  76998
nn.learn_nn_feature_fqi FQI:  77998
nn.learn_nn_feature_fqi FQI:  78998
nn.learn_nn_feature_fqi FQI:  79998
nn.learn_nn_feature_fqi FQI:  80998
nn.learn_nn_feature_fqi FQI:  81998
nn.learn_nn_feature_fqi FQI:  82998
nn.learn_nn_feature_fqi FQI:  83998
nn.learn_nn_feature_fqi FQI:  84998
nn.learn_nn_feature_fqi FQI:  85998
nn.learn_nn_feature_fqi FQI:  86998
nn.learn_nn_feature_fqi FQI:  87998
nn.learn_nn_feature_fqi FQI:  88998
nn.learn_nn_feature_fqi FQI:  89998
nn.learn_nn_feature_fqi FQI:  90998
nn.learn_nn_feature_fqi FQI:  91998
nn.learn_nn_feature_fqi FQI:  92998
nn.learn_nn_feature_fqi FQI:  93998
nn.learn_nn_feature_fqi FQI:  94998
nn.learn_nn_feature_fqi FQI:  95998
nn.learn_nn_feature_fqi FQI:  96998
nn.learn_nn_feature_fqi FQI:  97998
nn.learn_nn_feature_fqi FQI:  98998
nn.learn_nn_feature_fqi FQI:  99998
nn.learn_nn_feature_fqi FQI:  100998
nn.learn_nn_feature_fqi FQI:  101998
nn.learn_nn_feature_fqi FQI:  102998
nn.learn_nn_feature_fqi FQI:  103998
nn.learn_nn_feature_fqi FQI:  104998
nn.learn_nn_feature_fqi FQI:  105998
nn.learn_nn_feature_fqi FQI:  106998
nn.learn_nn_feature_fqi FQI:  107998
nn.learn_nn_feature_fqi FQI:  108998
nn.learn_nn_feature_fqi FQI:  109998
nn.learn_nn_feature_fqi FQI:  110998
nn.learn_nn_feature_fqi FQI:  111998
nn.learn_nn_feature_fqi FQI:  112998
nn.learn_nn_feature_fqi FQI:  113998
nn.learn_nn_feature_fqi FQI:  114998
nn.learn_nn_feature_fqi FQI:  115998
nn.learn_nn_feature_fqi FQI:  116998
nn.learn_nn_feature_fqi FQI:  117998
nn.learn_nn_feature_fqi FQI:  118998
nn.learn_nn_feature_fqi FQI:  119998
nn.learn_nn_feature_fqi FQI:  120998
nn.learn_nn_feature_fqi FQI:  121998
nn.learn_nn_feature_fqi FQI:  122998
nn.learn_nn_feature_fqi FQI:  123998
nn.learn_nn_feature_fqi FQI:  124998
nn.learn_nn_feature_fqi FQI:  125998
nn.learn_nn_feature_fqi FQI:  126998
nn.learn_nn_feature_fqi FQI:  127998
nn.learn_nn_feature_fqi FQI:  128998
nn.learn_nn_feature_fqi FQI:  129998
nn.learn_nn_feature_fqi FQI:  130998
nn.learn_nn_feature_fqi FQI:  131998
nn.learn_nn_feature_fqi FQI:  132998
nn.learn_nn_feature_fqi FQI:  133998
nn.learn_nn_feature_fqi FQI:  134998
nn.learn_nn_feature_fqi FQI:  135998
nn.learn_nn_feature_fqi FQI:  136998
nn.learn_nn_feature_fqi FQI:  137998
nn.learn_nn_feature_fqi FQI:  138998
nn.learn_nn_feature_fqi FQI:  139998
nn.learn_nn_feature_fqi FQI:  140998
nn.learn_nn_feature_fqi FQI:  141998
nn.learn_nn_feature_fqi FQI:  142998
nn.learn_nn_feature_fqi FQI:  143998
nn.learn_nn_feature_fqi FQI:  144998
nn.learn_nn_feature_fqi FQI:  145998
nn.learn_nn_feature_fqi FQI:  146998
nn.learn_nn_feature_fqi FQI:  147998
nn.learn_nn_feature_fqi FQI:  148998
nn.learn_nn_feature_fqi FQI:  149998
nn.learn_nn_feature_fqi FQI:  150998
nn.learn_nn_feature_fqi FQI:  151998
nn.learn_nn_feature_fqi FQI:  152998
nn.learn_nn_feature_fqi FQI:  153998
nn.learn_nn_feature_fqi FQI:  154998
nn.learn_nn_feature_fqi FQI:  155998
0 1001 -1000.0 -98.99572604650622 number episode from 10: 0 avegar over 10 episode: -98.996 avegare return across last 100 episodes: -98.996 state values: tensor(0.3862) 1000
1 1000 -1000.0 -99.99568287525881 number episode from 10: 1 avegar over 10 episode: -99.496 avegare return across last 100 episodes: -99.496 state values: tensor(0.3856) 1000
2 1000 -1000.0 -99.99568287525881 number episode from 10: 2 avegar over 10 episode: -99.662 avegare return across last 100 episodes: -99.662 state values: tensor(0.3978) 1000
3 1000 -1000.0 -99.99568287525881 number episode from 10: 3 avegar over 10 episode: -99.746 avegare return across last 100 episodes: -99.746 state values: tensor(0.4048) 1000
4 1000 -1000.0 -99.99568287525881 number episode from 10: 4 avegar over 10 episode: -99.796 avegare return across last 100 episodes: -99.796 state values: tensor(0.3951) 1000
5 1000 -1000.0 -99.99568287525881 number episode from 10: 5 avegar over 10 episode: -99.829 avegare return across last 100 episodes: -99.829 state values: tensor(0.3938) 1000
6 1000 -1000.0 -99.99568287525881 number episode from 10: 6 avegar over 10 episode: -99.853 avegare return across last 100 episodes: -99.853 state values: tensor(0.3831) 1000
7 1000 -1000.0 -99.99568287525881 number episode from 10: 7 avegar over 10 episode: -99.871 avegare return across last 100 episodes: -99.871 state values: tensor(0.3885) 1000
8 1000 -1000.0 -99.99568287525881 number episode from 10: 8 avegar over 10 episode: -99.885 avegare return across last 100 episodes: -99.885 state values: tensor(0.3938) 1000
9 1000 -1000.0 -99.99568287525881 number episode from 10: 9 avegar over 10 episode: -99.896 avegare return across last 100 episodes: -99.896 state values: tensor(0.3848) 1000
10 1000 -1000.0 -99.99568287525881 number episode from 10: 10 avegar over 10 episode: -99.905 avegare return across last 100 episodes: -99.905 state values: tensor(0.3849) 1000
11 1000 -1000.0 -99.99568287525881 number episode from 10: 11 avegar over 10 episode: -99.912 avegare return across last 100 episodes: -99.912 state values: tensor(0.3835) 1000
12 1000 -1000.0 -99.99568287525881 number episode from 10: 12 avegar over 10 episode: -99.919 avegare return across last 100 episodes: -99.919 state values: tensor(0.3882) 1000
13 1000 -1000.0 -99.99568287525881 number episode from 10: 13 avegar over 10 episode: -99.924 avegare return across last 100 episodes: -99.924 state values: tensor(0.3934) 1000
14 1000 -1000.0 -99.99568287525881 number episode from 10: 14 avegar over 10 episode: -99.929 avegare return across last 100 episodes: -99.929 state values: tensor(0.3833) 1000
15 1000 -1000.0 -99.99568287525881 number episode from 10: 15 avegar over 10 episode: -99.933 avegare return across last 100 episodes: -99.933 state values: tensor(0.4043) 1000
16 1000 -1000.0 -99.99568287525881 number episode from 10: 16 avegar over 10 episode: -99.937 avegare return across last 100 episodes: -99.937 state values: tensor(0.3982) 1000
17 1000 -1000.0 -99.99568287525881 number episode from 10: 17 avegar over 10 episode: -99.94 avegare return across last 100 episodes: -99.94 state values: tensor(0.4110) 1000
18 1000 -1000.0 -99.99568287525881 number episode from 10: 18 avegar over 10 episode: -99.943 avegare return across last 100 episodes: -99.943 state values: tensor(0.3835) 1000
19 1000 -1000.0 -99.99568287525881 number episode from 10: 19 avegar over 10 episode: -99.946 avegare return across last 100 episodes: -99.946 state values: tensor(0.3855) 1000
20 1000 -1000.0 -99.99568287525881 number episode from 10: 20 avegar over 10 episode: -99.948 avegare return across last 100 episodes: -99.948 state values: tensor(0.3838) 1000
21 1000 -1000.0 -99.99568287525881 number episode from 10: 21 avegar over 10 episode: -99.95 avegare return across last 100 episodes: -99.95 state values: tensor(0.4057) 1000
22 1000 -1000.0 -99.99568287525881 number episode from 10: 22 avegar over 10 episode: -99.952 avegare return across last 100 episodes: -99.952 state values: tensor(0.3831) 1000
23 1000 -1000.0 -99.99568287525881 number episode from 10: 23 avegar over 10 episode: -99.954 avegare return across last 100 episodes: -99.954 state values: tensor(0.3936) 1000
24 1000 -1000.0 -99.99568287525881 number episode from 10: 24 avegar over 10 episode: -99.956 avegare return across last 100 episodes: -99.956 state values: tensor(0.3825) 1000
25 1000 -1000.0 -99.99568287525881 number episode from 10: 25 avegar over 10 episode: -99.957 avegare return across last 100 episodes: -99.957 state values: tensor(0.3939) 1000
26 1000 -1000.0 -99.99568287525881 number episode from 10: 26 avegar over 10 episode: -99.959 avegare return across last 100 episodes: -99.959 state values: tensor(0.3859) 1000
27 1000 -1000.0 -99.99568287525881 number episode from 10: 27 avegar over 10 episode: -99.96 avegare return across last 100 episodes: -99.96 state values: tensor(0.3836) 1000
28 1000 -1000.0 -99.99568287525881 number episode from 10: 28 avegar over 10 episode: -99.961 avegare return across last 100 episodes: -99.961 state values: tensor(0.3885) 1000
29 1000 -1000.0 -99.99568287525881 number episode from 10: 29 avegar over 10 episode: -99.962 avegare return across last 100 episodes: -99.962 state values: tensor(0.3827) 1000
30 1000 -1000.0 -99.99568287525881 number episode from 10: 30 avegar over 10 episode: -99.963 avegare return across last 100 episodes: -99.963 state values: tensor(0.3950) 1000
31 1000 -1000.0 -99.99568287525881 number episode from 10: 31 avegar over 10 episode: -99.964 avegare return across last 100 episodes: -99.964 state values: tensor(0.3879) 1000
32 1000 -1000.0 -99.99568287525881 number episode from 10: 32 avegar over 10 episode: -99.965 avegare return across last 100 episodes: -99.965 state values: tensor(0.3825) 1000
33 1000 -1000.0 -99.99568287525881 number episode from 10: 33 avegar over 10 episode: -99.966 avegare return across last 100 episodes: -99.966 state values: tensor(0.3919) 1000
34 1000 -1000.0 -99.99568287525881 number episode from 10: 34 avegar over 10 episode: -99.967 avegare return across last 100 episodes: -99.967 state values: tensor(0.3951) 1000
35 1000 -1000.0 -99.99568287525881 number episode from 10: 35 avegar over 10 episode: -99.968 avegare return across last 100 episodes: -99.968 state values: tensor(0.3882) 1000
36 1000 -1000.0 -99.99568287525881 number episode from 10: 36 avegar over 10 episode: -99.969 avegare return across last 100 episodes: -99.969 state values: tensor(0.3848) 1000
37 1000 -1000.0 -99.99568287525881 number episode from 10: 37 avegar over 10 episode: -99.969 avegare return across last 100 episodes: -99.969 state values: tensor(0.3830) 1000
38 1000 -1000.0 -99.99568287525881 number episode from 10: 38 avegar over 10 episode: -99.97 avegare return across last 100 episodes: -99.97 state values: tensor(0.3931) 1000
39 1000 -1000.0 -99.99568287525881 number episode from 10: 39 avegar over 10 episode: -99.971 avegare return across last 100 episodes: -99.971 state values: tensor(0.3954) 1000
40 1000 -1000.0 -99.99568287525881 number episode from 10: 40 avegar over 10 episode: -99.971 avegare return across last 100 episodes: -99.971 state values: tensor(0.3992) 1000
41 1000 -1000.0 -99.99568287525881 number episode from 10: 41 avegar over 10 episode: -99.972 avegare return across last 100 episodes: -99.972 state values: tensor(0.3843) 1000
42 1000 -1000.0 -99.99568287525881 number episode from 10: 42 avegar over 10 episode: -99.972 avegare return across last 100 episodes: -99.972 state values: tensor(0.4048) 1000
43 1000 -1000.0 -99.99568287525881 number episode from 10: 43 avegar over 10 episode: -99.973 avegare return across last 100 episodes: -99.973 state values: tensor(0.3998) 1000
44 1000 -1000.0 -99.99568287525881 number episode from 10: 44 avegar over 10 episode: -99.973 avegare return across last 100 episodes: -99.973 state values: tensor(0.3966) 1000
45 1000 -1000.0 -99.99568287525881 number episode from 10: 45 avegar over 10 episode: -99.974 avegare return across last 100 episodes: -99.974 state values: tensor(0.3830) 1000
46 1000 -1000.0 -99.99568287525881 number episode from 10: 46 avegar over 10 episode: -99.974 avegare return across last 100 episodes: -99.974 state values: tensor(0.4037) 1000
47 1000 -1000.0 -99.99568287525881 number episode from 10: 47 avegar over 10 episode: -99.975 avegare return across last 100 episodes: -99.975 state values: tensor(0.3854) 1000
48 1000 -1000.0 -99.99568287525881 number episode from 10: 48 avegar over 10 episode: -99.975 avegare return across last 100 episodes: -99.975 state values: tensor(0.3837) 1000
49 1000 -1000.0 -99.99568287525881 number episode from 10: 49 avegar over 10 episode: -99.976 avegare return across last 100 episodes: -99.976 state values: tensor(0.3829) 1000
50 1000 -1000.0 -99.99568287525881 number episode from 10: 50 avegar over 10 episode: -99.976 avegare return across last 100 episodes: -99.976 state values: tensor(0.3885) 1000
51 1000 -1000.0 -99.99568287525881 number episode from 10: 51 avegar over 10 episode: -99.976 avegare return across last 100 episodes: -99.976 state values: tensor(0.3886) 1000
52 1000 -1000.0 -99.99568287525881 number episode from 10: 52 avegar over 10 episode: -99.977 avegare return across last 100 episodes: -99.977 state values: tensor(0.3859) 1000
53 1000 -1000.0 -99.99568287525881 number episode from 10: 53 avegar over 10 episode: -99.977 avegare return across last 100 episodes: -99.977 state values: tensor(0.3841) 1000
54 1000 -1000.0 -99.99568287525881 number episode from 10: 54 avegar over 10 episode: -99.978 avegare return across last 100 episodes: -99.978 state values: tensor(0.3834) 1000
55 1000 -1000.0 -99.99568287525881 number episode from 10: 55 avegar over 10 episode: -99.978 avegare return across last 100 episodes: -99.978 state values: tensor(0.3925) 1000
56 1000 -1000.0 -99.99568287525881 number episode from 10: 56 avegar over 10 episode: -99.978 avegare return across last 100 episodes: -99.978 state values: tensor(0.3833) 1000
57 1000 -1000.0 -99.99568287525881 number episode from 10: 57 avegar over 10 episode: -99.978 avegare return across last 100 episodes: -99.978 state values: tensor(0.3833) 1000
58 1000 -1000.0 -99.99568287525881 number episode from 10: 58 avegar over 10 episode: -99.979 avegare return across last 100 episodes: -99.979 state values: tensor(0.3899) 1000
59 1000 -1000.0 -99.99568287525881 number episode from 10: 59 avegar over 10 episode: -99.979 avegare return across last 100 episodes: -99.979 state values: tensor(0.3886) 1000
60 1000 -1000.0 -99.99568287525881 number episode from 10: 60 avegar over 10 episode: -99.979 avegare return across last 100 episodes: -99.979 state values: tensor(0.4027) 1000
61 1000 -1000.0 -99.99568287525881 number episode from 10: 61 avegar over 10 episode: -99.98 avegare return across last 100 episodes: -99.98 state values: tensor(0.3919) 1000
62 1000 -1000.0 -99.99568287525881 number episode from 10: 62 avegar over 10 episode: -99.98 avegare return across last 100 episodes: -99.98 state values: tensor(0.3849) 1000
63 1000 -1000.0 -99.99568287525881 number episode from 10: 63 avegar over 10 episode: -99.98 avegare return across last 100 episodes: -99.98 state values: tensor(0.3825) 1000
64 1000 -1000.0 -99.99568287525881 number episode from 10: 64 avegar over 10 episode: -99.98 avegare return across last 100 episodes: -99.98 state values: tensor(0.3831) 1000
65 1000 -1000.0 -99.99568287525881 number episode from 10: 65 avegar over 10 episode: -99.981 avegare return across last 100 episodes: -99.981 state values: tensor(0.4087) 1000
66 1000 -1000.0 -99.99568287525881 number episode from 10: 66 avegar over 10 episode: -99.981 avegare return across last 100 episodes: -99.981 state values: tensor(0.3885) 1000
67 1000 -1000.0 -99.99568287525881 number episode from 10: 67 avegar over 10 episode: -99.981 avegare return across last 100 episodes: -99.981 state values: tensor(0.3834) 1000
68 1000 -1000.0 -99.99568287525881 number episode from 10: 68 avegar over 10 episode: -99.981 avegare return across last 100 episodes: -99.981 state values: tensor(0.3856) 1000
69 1000 -1000.0 -99.99568287525881 number episode from 10: 69 avegar over 10 episode: -99.981 avegare return across last 100 episodes: -99.981 state values: tensor(0.4124) 1000
70 1000 -1000.0 -99.99568287525881 number episode from 10: 70 avegar over 10 episode: -99.982 avegare return across last 100 episodes: -99.982 state values: tensor(0.3853) 1000
71 1000 -1000.0 -99.99568287525881 number episode from 10: 71 avegar over 10 episode: -99.982 avegare return across last 100 episodes: -99.982 state values: tensor(0.3937) 1000
72 1000 -1000.0 -99.99568287525881 number episode from 10: 72 avegar over 10 episode: -99.982 avegare return across last 100 episodes: -99.982 state values: tensor(0.3951) 1000
73 1000 -1000.0 -99.99568287525881 number episode from 10: 73 avegar over 10 episode: -99.982 avegare return across last 100 episodes: -99.982 state values: tensor(0.3919) 1000
74 1000 -1000.0 -99.99568287525881 number episode from 10: 74 avegar over 10 episode: -99.982 avegare return across last 100 episodes: -99.982 state values: tensor(0.3875) 1000
75 1000 -1000.0 -99.99568287525881 number episode from 10: 75 avegar over 10 episode: -99.983 avegare return across last 100 episodes: -99.983 state values: tensor(0.3854) 1000
76 1000 -1000.0 -99.99568287525881 number episode from 10: 76 avegar over 10 episode: -99.983 avegare return across last 100 episodes: -99.983 state values: tensor(0.3838) 1000
77 1000 -1000.0 -99.99568287525881 number episode from 10: 77 avegar over 10 episode: -99.983 avegare return across last 100 episodes: -99.983 state values: tensor(0.3866) 1000
78 1000 -1000.0 -99.99568287525881 number episode from 10: 78 avegar over 10 episode: -99.983 avegare return across last 100 episodes: -99.983 state values: tensor(0.3869) 1000
79 1000 -1000.0 -99.99568287525881 number episode from 10: 79 avegar over 10 episode: -99.983 avegare return across last 100 episodes: -99.983 state values: tensor(0.3867) 1000
80 1000 -1000.0 -99.99568287525881 number episode from 10: 80 avegar over 10 episode: -99.983 avegare return across last 100 episodes: -99.983 state values: tensor(0.3846) 1000
81 1000 -1000.0 -99.99568287525881 number episode from 10: 81 avegar over 10 episode: -99.983 avegare return across last 100 episodes: -99.983 state values: tensor(0.3930) 1000
82 1000 -1000.0 -99.99568287525881 number episode from 10: 82 avegar over 10 episode: -99.984 avegare return across last 100 episodes: -99.984 state values: tensor(0.3867) 1000
83 1000 -1000.0 -99.99568287525881 number episode from 10: 83 avegar over 10 episode: -99.984 avegare return across last 100 episodes: -99.984 state values: tensor(0.3844) 1000
84 1000 -1000.0 -99.99568287525881 number episode from 10: 84 avegar over 10 episode: -99.984 avegare return across last 100 episodes: -99.984 state values: tensor(0.3889) 1000
85 1000 -1000.0 -99.99568287525881 number episode from 10: 85 avegar over 10 episode: -99.984 avegare return across last 100 episodes: -99.984 state values: tensor(0.3842) 1000
86 1000 -1000.0 -99.99568287525881 number episode from 10: 86 avegar over 10 episode: -99.984 avegare return across last 100 episodes: -99.984 state values: tensor(0.3940) 1000
87 1000 -1000.0 -99.99568287525881 number episode from 10: 87 avegar over 10 episode: -99.984 avegare return across last 100 episodes: -99.984 state values: tensor(0.3856) 1000
88 1000 -1000.0 -99.99568287525881 number episode from 10: 88 avegar over 10 episode: -99.984 avegare return across last 100 episodes: -99.984 state values: tensor(0.3976) 1000
89 1000 -1000.0 -99.99568287525881 number episode from 10: 89 avegar over 10 episode: -99.985 avegare return across last 100 episodes: -99.985 state values: tensor(0.3844) 1000
90 1000 -1000.0 -99.99568287525881 number episode from 10: 90 avegar over 10 episode: -99.985 avegare return across last 100 episodes: -99.985 state values: tensor(0.4072) 1000
91 1000 -1000.0 -99.99568287525881 number episode from 10: 91 avegar over 10 episode: -99.985 avegare return across last 100 episodes: -99.985 state values: tensor(0.4119) 1000
92 1000 -1000.0 -99.99568287525881 number episode from 10: 92 avegar over 10 episode: -99.985 avegare return across last 100 episodes: -99.985 state values: tensor(0.3855) 1000
93 1000 -1000.0 -99.99568287525881 number episode from 10: 93 avegar over 10 episode: -99.985 avegare return across last 100 episodes: -99.985 state values: tensor(0.3859) 1000
94 1000 -1000.0 -99.99568287525881 number episode from 10: 94 avegar over 10 episode: -99.985 avegare return across last 100 episodes: -99.985 state values: tensor(0.3895) 1000
95 1000 -1000.0 -99.99568287525881 number episode from 10: 95 avegar over 10 episode: -99.985 avegare return across last 100 episodes: -99.985 state values: tensor(0.3893) 1000
96 1000 -1000.0 -99.99568287525881 number episode from 10: 96 avegar over 10 episode: -99.985 avegare return across last 100 episodes: -99.985 state values: tensor(0.3825) 1000
97 1000 -1000.0 -99.99568287525881 number episode from 10: 97 avegar over 10 episode: -99.985 avegare return across last 100 episodes: -99.985 state values: tensor(0.3897) 1000
98 1000 -1000.0 -99.99568287525881 number episode from 10: 98 avegar over 10 episode: -99.986 avegare return across last 100 episodes: -99.986 state values: tensor(0.3870) 1000
99 1000 -1000.0 -99.99568287525881 number episode from 10: 99 avegar over 10 episode: -99.986 avegare return across last 100 episodes: -99.986 state values: tensor(0.3832) 1000
100 1000 -1000.0 -99.99568287525881 number episode from 10: 100 avegar over 10 episode: -99.986 avegare return across last 100 episodes: -99.996 state values: tensor(0.4048) 1000
101 1000 -1000.0 -99.99568287525881 number episode from 10: 101 avegar over 10 episode: -99.986 avegare return across last 100 episodes: -99.996 state values: tensor(0.4034) 1000
102 1000 -1000.0 -99.99568287525881 number episode from 10: 102 avegar over 10 episode: -99.986 avegare return across last 100 episodes: -99.996 state values: tensor(0.3836) 1000
103 1000 -1000.0 -99.99568287525881 number episode from 10: 103 avegar over 10 episode: -99.986 avegare return across last 100 episodes: -99.996 state values: tensor(0.4024) 1000
104 1000 -1000.0 -99.99568287525881 number episode from 10: 104 avegar over 10 episode: -99.986 avegare return across last 100 episodes: -99.996 state values: tensor(0.3976) 1000
105 1000 -1000.0 -99.99568287525881 number episode from 10: 105 avegar over 10 episode: -99.986 avegare return across last 100 episodes: -99.996 state values: tensor(0.3857) 1000
106 1000 -1000.0 -99.99568287525881 number episode from 10: 106 avegar over 10 episode: -99.986 avegare return across last 100 episodes: -99.996 state values: tensor(0.3990) 1000
107 1000 -1000.0 -99.99568287525881 number episode from 10: 107 avegar over 10 episode: -99.986 avegare return across last 100 episodes: -99.996 state values: tensor(0.4014) 1000
108 1000 -1000.0 -99.99568287525881 number episode from 10: 108 avegar over 10 episode: -99.987 avegare return across last 100 episodes: -99.996 state values: tensor(0.3886) 1000
109 1000 -1000.0 -99.99568287525881 number episode from 10: 109 avegar over 10 episode: -99.987 avegare return across last 100 episodes: -99.996 state values: tensor(0.3841) 1000
110 1000 -1000.0 -99.99568287525881 number episode from 10: 110 avegar over 10 episode: -99.987 avegare return across last 100 episodes: -99.996 state values: tensor(0.3828) 1000
111 1000 -1000.0 -99.99568287525881 number episode from 10: 111 avegar over 10 episode: -99.987 avegare return across last 100 episodes: -99.996 state values: tensor(0.3825) 1000
112 1000 -1000.0 -99.99568287525881 number episode from 10: 112 avegar over 10 episode: -99.987 avegare return across last 100 episodes: -99.996 state values: tensor(0.3852) 1000
113 1000 -1000.0 -99.99568287525881 number episode from 10: 113 avegar over 10 episode: -99.987 avegare return across last 100 episodes: -99.996 state values: tensor(0.3854) 1000
114 1000 -1000.0 -99.99568287525881 number episode from 10: 114 avegar over 10 episode: -99.987 avegare return across last 100 episodes: -99.996 state values: tensor(0.3835) 1000
115 1000 -1000.0 -99.99568287525881 number episode from 10: 115 avegar over 10 episode: -99.987 avegare return across last 100 episodes: -99.996 state values: tensor(0.3853) 1000
116 1000 -1000.0 -99.99568287525881 number episode from 10: 116 avegar over 10 episode: -99.987 avegare return across last 100 episodes: -99.996 state values: tensor(0.3840) 1000
117 1000 -1000.0 -99.99568287525881 number episode from 10: 117 avegar over 10 episode: -99.987 avegare return across last 100 episodes: -99.996 state values: tensor(0.3894) 1000
118 1000 -1000.0 -99.99568287525881 number episode from 10: 118 avegar over 10 episode: -99.987 avegare return across last 100 episodes: -99.996 state values: tensor(0.3839) 1000
119 1000 -1000.0 -99.99568287525881 number episode from 10: 119 avegar over 10 episode: -99.987 avegare return across last 100 episodes: -99.996 state values: tensor(0.3863) 1000
120 1000 -1000.0 -99.99568287525881 number episode from 10: 120 avegar over 10 episode: -99.987 avegare return across last 100 episodes: -99.996 state values: tensor(0.3833) 1000
121 1000 -1000.0 -99.99568287525881 number episode from 10: 121 avegar over 10 episode: -99.987 avegare return across last 100 episodes: -99.996 state values: tensor(0.3885) 1000
122 1000 -1000.0 -99.99568287525881 number episode from 10: 122 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.3845) 1000
123 1000 -1000.0 -99.99568287525881 number episode from 10: 123 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.3826) 1000
124 1000 -1000.0 -99.99568287525881 number episode from 10: 124 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.3866) 1000
125 1000 -1000.0 -99.99568287525881 number episode from 10: 125 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.3951) 1000
126 1000 -1000.0 -99.99568287525881 number episode from 10: 126 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.3966) 1000
127 1000 -1000.0 -99.99568287525881 number episode from 10: 127 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.3843) 1000
128 1000 -1000.0 -99.99568287525881 number episode from 10: 128 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.3844) 1000
129 1000 -1000.0 -99.99568287525881 number episode from 10: 129 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.3971) 1000
130 1000 -1000.0 -99.99568287525881 number episode from 10: 130 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.3939) 1000
131 1000 -1000.0 -99.99568287525881 number episode from 10: 131 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.3827) 1000
132 1000 -1000.0 -99.99568287525881 number episode from 10: 132 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.3900) 1000
133 1000 -1000.0 -99.99568287525881 number episode from 10: 133 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.3999) 1000
134 1000 -1000.0 -99.99568287525881 number episode from 10: 134 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.4062) 1000
135 1000 -1000.0 -99.99568287525881 number episode from 10: 135 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.3908) 1000
136 1000 -1000.0 -99.99568287525881 number episode from 10: 136 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.3830) 1000
137 1000 -1000.0 -99.99568287525881 number episode from 10: 137 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.3841) 1000
138 1000 -1000.0 -99.99568287525881 number episode from 10: 138 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.4189) 1000
139 1000 -1000.0 -99.99568287525881 number episode from 10: 139 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.3845) 1000
140 1000 -1000.0 -99.99568287525881 number episode from 10: 140 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.3848) 1000
141 1000 -1000.0 -99.99568287525881 number episode from 10: 141 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.3965) 1000
142 1000 -1000.0 -99.99568287525881 number episode from 10: 142 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.3835) 1000
143 1000 -1000.0 -99.99568287525881 number episode from 10: 143 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.3845) 1000
144 1000 -1000.0 -99.99568287525881 number episode from 10: 144 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.4096) 1000
145 1000 -1000.0 -99.99568287525881 number episode from 10: 145 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.3848) 1000
146 1000 -1000.0 -99.99568287525881 number episode from 10: 146 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.3955) 1000
147 1000 -1000.0 -99.99568287525881 number episode from 10: 147 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.3829) 1000
148 1000 -1000.0 -99.99568287525881 number episode from 10: 148 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.3838) 1000
149 1000 -1000.0 -99.99568287525881 number episode from 10: 149 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.3851) 1000
150 1000 -1000.0 -99.99568287525881 number episode from 10: 150 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.3995) 1000
151 1000 -1000.0 -99.99568287525881 number episode from 10: 151 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.3846) 1000
152 1000 -1000.0 -99.99568287525881 number episode from 10: 152 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.3880) 1000
153 1000 -1000.0 -99.99568287525881 number episode from 10: 153 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.3938) 1000
154 1000 -1000.0 -99.99568287525881 number episode from 10: 154 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.4043) 1000
155 1000 -1000.0 -99.99568287525881 number episode from 10: 155 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.3863) 1000
156 1000 -1000.0 -99.99568287525881 number episode from 10: 156 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.3856) 1000
157 1000 -1000.0 -99.99568287525881 number episode from 10: 157 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.3861) 1000
158 1000 -1000.0 -99.99568287525881 number episode from 10: 158 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.3938) 1000
159 1000 -1000.0 -99.99568287525881 number episode from 10: 159 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.4022) 1000
160 1000 -1000.0 -99.99568287525881 number episode from 10: 160 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.4079) 1000
161 1000 -1000.0 -99.99568287525881 number episode from 10: 161 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.3907) 1000
162 1000 -1000.0 -99.99568287525881 number episode from 10: 162 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.3862) 1000
163 1000 -1000.0 -99.99568287525881 number episode from 10: 163 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.3940) 1000
164 1000 -1000.0 -99.99568287525881 number episode from 10: 164 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.3863) 1000
165 1000 -1000.0 -99.99568287525881 number episode from 10: 165 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.3861) 1000
166 1000 -1000.0 -99.99568287525881 number episode from 10: 166 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.4085) 1000
167 1000 -1000.0 -99.99568287525881 number episode from 10: 167 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.3834) 1000
168 1000 -1000.0 -99.99568287525881 number episode from 10: 168 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.3844) 1000
169 1000 -1000.0 -99.99568287525881 number episode from 10: 169 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.3837) 1000
170 1000 -1000.0 -99.99568287525881 number episode from 10: 170 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.3834) 1000
171 1000 -1000.0 -99.99568287525881 number episode from 10: 171 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.4068) 1000
172 1000 -1000.0 -99.99568287525881 number episode from 10: 172 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.3857) 1000
173 1000 -1000.0 -99.99568287525881 number episode from 10: 173 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.3942) 1000
174 1000 -1000.0 -99.99568287525881 number episode from 10: 174 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.3890) 1000
175 1000 -1000.0 -99.99568287525881 number episode from 10: 175 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.3891) 1000
176 1000 -1000.0 -99.99568287525881 number episode from 10: 176 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.3970) 1000
177 1000 -1000.0 -99.99568287525881 number episode from 10: 177 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.3847) 1000
178 1000 -1000.0 -99.99568287525881 number episode from 10: 178 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.3862) 1000
179 1000 -1000.0 -99.99568287525881 number episode from 10: 179 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.4048) 1000
180 1000 -1000.0 -99.99568287525881 number episode from 10: 180 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.3864) 1000
181 1000 -1000.0 -99.99568287525881 number episode from 10: 181 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.4049) 1000
182 1000 -1000.0 -99.99568287525881 number episode from 10: 182 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.3827) 1000
183 1000 -1000.0 -99.99568287525881 number episode from 10: 183 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.3824) 1000
184 1000 -1000.0 -99.99568287525881 number episode from 10: 184 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.3826) 1000
185 1000 -1000.0 -99.99568287525881 number episode from 10: 185 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.3833) 1000
186 1000 -1000.0 -99.99568287525881 number episode from 10: 186 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.3973) 1000
187 1000 -1000.0 -99.99568287525881 number episode from 10: 187 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.3916) 1000
188 1000 -1000.0 -99.99568287525881 number episode from 10: 188 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.3822) 1000
189 1000 -1000.0 -99.99568287525881 number episode from 10: 189 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.3844) 1000
190 1000 -1000.0 -99.99568287525881 number episode from 10: 190 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.3899) 1000
191 1000 -1000.0 -99.99568287525881 number episode from 10: 191 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.3929) 1000
192 1000 -1000.0 -99.99568287525881 number episode from 10: 192 avegar over 10 episode: -99.991 avegare return across last 100 episodes: -99.996 state values: tensor(0.3846) 1000
193 1000 -1000.0 -99.99568287525881 number episode from 10: 193 avegar over 10 episode: -99.991 avegare return across last 100 episodes: -99.996 state values: tensor(0.3869) 1000
194 1000 -1000.0 -99.99568287525881 number episode from 10: 194 avegar over 10 episode: -99.991 avegare return across last 100 episodes: -99.996 state values: tensor(0.3832) 1000
195 1000 -1000.0 -99.99568287525881 number episode from 10: 195 avegar over 10 episode: -99.991 avegare return across last 100 episodes: -99.996 state values: tensor(0.3883) 1000
196 1000 -1000.0 -99.99568287525881 number episode from 10: 196 avegar over 10 episode: -99.991 avegare return across last 100 episodes: -99.996 state values: tensor(0.3836) 1000
197 1000 -1000.0 -99.99568287525881 number episode from 10: 197 avegar over 10 episode: -99.991 avegare return across last 100 episodes: -99.996 state values: tensor(0.3836) 1000
198 1000 -1000.0 -99.99568287525881 number episode from 10: 198 avegar over 10 episode: -99.991 avegare return across last 100 episodes: -99.996 state values: tensor(0.3921) 1000
199 1000 -1000.0 -99.99568287525881 number episode from 10: 199 avegar over 10 episode: -99.991 avegare return across last 100 episodes: -99.996 state values: tensor(0.3957) 1000
200 1000 -1000.0 -99.99568287525881 number episode from 10: 200 avegar over 10 episode: -99.991 avegare return across last 100 episodes: -99.996 state values: tensor(0.3961) 1000
load offline data!!!!!
mem_cntr: 50000 ; mem_size: 50000
nn.learn_nn_feature_fqi FQI:  998
nn.learn_nn_feature_fqi FQI:  1998
nn.learn_nn_feature_fqi FQI:  2998
nn.learn_nn_feature_fqi FQI:  3998
nn.learn_nn_feature_fqi FQI:  4998
nn.learn_nn_feature_fqi FQI:  5998
nn.learn_nn_feature_fqi FQI:  6998
nn.learn_nn_feature_fqi FQI:  7998
nn.learn_nn_feature_fqi FQI:  8998
nn.learn_nn_feature_fqi FQI:  9998
nn.learn_nn_feature_fqi FQI:  10998
nn.learn_nn_feature_fqi FQI:  11998
nn.learn_nn_feature_fqi FQI:  12998
nn.learn_nn_feature_fqi FQI:  13998
nn.learn_nn_feature_fqi FQI:  14998
nn.learn_nn_feature_fqi FQI:  15998
nn.learn_nn_feature_fqi FQI:  16998
nn.learn_nn_feature_fqi FQI:  17998
nn.learn_nn_feature_fqi FQI:  18998
nn.learn_nn_feature_fqi FQI:  19998
nn.learn_nn_feature_fqi FQI:  20998
nn.learn_nn_feature_fqi FQI:  21998
nn.learn_nn_feature_fqi FQI:  22998
nn.learn_nn_feature_fqi FQI:  23998
nn.learn_nn_feature_fqi FQI:  24998
nn.learn_nn_feature_fqi FQI:  25998
nn.learn_nn_feature_fqi FQI:  26998
nn.learn_nn_feature_fqi FQI:  27998
nn.learn_nn_feature_fqi FQI:  28998
nn.learn_nn_feature_fqi FQI:  29998
nn.learn_nn_feature_fqi FQI:  30998
nn.learn_nn_feature_fqi FQI:  31998
nn.learn_nn_feature_fqi FQI:  32998
nn.learn_nn_feature_fqi FQI:  33998
nn.learn_nn_feature_fqi FQI:  34998
nn.learn_nn_feature_fqi FQI:  35998
nn.learn_nn_feature_fqi FQI:  36998
nn.learn_nn_feature_fqi FQI:  37998
nn.learn_nn_feature_fqi FQI:  38998
nn.learn_nn_feature_fqi FQI:  39998
nn.learn_nn_feature_fqi FQI:  40998
nn.learn_nn_feature_fqi FQI:  41998
nn.learn_nn_feature_fqi FQI:  42998
nn.learn_nn_feature_fqi FQI:  43998
nn.learn_nn_feature_fqi FQI:  44998
nn.learn_nn_feature_fqi FQI:  45998
nn.learn_nn_feature_fqi FQI:  46998
nn.learn_nn_feature_fqi FQI:  47998
nn.learn_nn_feature_fqi FQI:  48998
nn.learn_nn_feature_fqi FQI:  49998
nn.learn_nn_feature_fqi FQI:  50998
nn.learn_nn_feature_fqi FQI:  51998
nn.learn_nn_feature_fqi FQI:  52998
nn.learn_nn_feature_fqi FQI:  53998
nn.learn_nn_feature_fqi FQI:  54998
nn.learn_nn_feature_fqi FQI:  55998
nn.learn_nn_feature_fqi FQI:  56998
nn.learn_nn_feature_fqi FQI:  57998
nn.learn_nn_feature_fqi FQI:  58998
nn.learn_nn_feature_fqi FQI:  59998
nn.learn_nn_feature_fqi FQI:  60998
nn.learn_nn_feature_fqi FQI:  61998
nn.learn_nn_feature_fqi FQI:  62998
nn.learn_nn_feature_fqi FQI:  63998
nn.learn_nn_feature_fqi FQI:  64998
nn.learn_nn_feature_fqi FQI:  65998
nn.learn_nn_feature_fqi FQI:  66998
nn.learn_nn_feature_fqi FQI:  67998
nn.learn_nn_feature_fqi FQI:  68998
nn.learn_nn_feature_fqi FQI:  69998
nn.learn_nn_feature_fqi FQI:  70998
nn.learn_nn_feature_fqi FQI:  71998
nn.learn_nn_feature_fqi FQI:  72998
nn.learn_nn_feature_fqi FQI:  73998
nn.learn_nn_feature_fqi FQI:  74998
nn.learn_nn_feature_fqi FQI:  75998
nn.learn_nn_feature_fqi FQI:  76998
nn.learn_nn_feature_fqi FQI:  77998
nn.learn_nn_feature_fqi FQI:  78998
nn.learn_nn_feature_fqi FQI:  79998
nn.learn_nn_feature_fqi FQI:  80998
nn.learn_nn_feature_fqi FQI:  81998
nn.learn_nn_feature_fqi FQI:  82998
nn.learn_nn_feature_fqi FQI:  83998
nn.learn_nn_feature_fqi FQI:  84998
nn.learn_nn_feature_fqi FQI:  85998
nn.learn_nn_feature_fqi FQI:  86998
nn.learn_nn_feature_fqi FQI:  87998
nn.learn_nn_feature_fqi FQI:  88998
nn.learn_nn_feature_fqi FQI:  89998
nn.learn_nn_feature_fqi FQI:  90998
nn.learn_nn_feature_fqi FQI:  91998
nn.learn_nn_feature_fqi FQI:  92998
nn.learn_nn_feature_fqi FQI:  93998
nn.learn_nn_feature_fqi FQI:  94998
nn.learn_nn_feature_fqi FQI:  95998
nn.learn_nn_feature_fqi FQI:  96998
nn.learn_nn_feature_fqi FQI:  97998
nn.learn_nn_feature_fqi FQI:  98998
nn.learn_nn_feature_fqi FQI:  99998
nn.learn_nn_feature_fqi FQI:  100998
nn.learn_nn_feature_fqi FQI:  101998
nn.learn_nn_feature_fqi FQI:  102998
nn.learn_nn_feature_fqi FQI:  103998
nn.learn_nn_feature_fqi FQI:  104998
nn.learn_nn_feature_fqi FQI:  105998
nn.learn_nn_feature_fqi FQI:  106998
nn.learn_nn_feature_fqi FQI:  107998
nn.learn_nn_feature_fqi FQI:  108998
nn.learn_nn_feature_fqi FQI:  109998
nn.learn_nn_feature_fqi FQI:  110998
nn.learn_nn_feature_fqi FQI:  111998
nn.learn_nn_feature_fqi FQI:  112998
nn.learn_nn_feature_fqi FQI:  113998
nn.learn_nn_feature_fqi FQI:  114998
nn.learn_nn_feature_fqi FQI:  115998
nn.learn_nn_feature_fqi FQI:  116998
nn.learn_nn_feature_fqi FQI:  117998
nn.learn_nn_feature_fqi FQI:  118998
nn.learn_nn_feature_fqi FQI:  119998
nn.learn_nn_feature_fqi FQI:  120998
nn.learn_nn_feature_fqi FQI:  121998
nn.learn_nn_feature_fqi FQI:  122998
nn.learn_nn_feature_fqi FQI:  123998
nn.learn_nn_feature_fqi FQI:  124998
nn.learn_nn_feature_fqi FQI:  125998
nn.learn_nn_feature_fqi FQI:  126998
nn.learn_nn_feature_fqi FQI:  127998
nn.learn_nn_feature_fqi FQI:  128998
nn.learn_nn_feature_fqi FQI:  129998
nn.learn_nn_feature_fqi FQI:  130998
nn.learn_nn_feature_fqi FQI:  131998
nn.learn_nn_feature_fqi FQI:  132998
nn.learn_nn_feature_fqi FQI:  133998
nn.learn_nn_feature_fqi FQI:  134998
nn.learn_nn_feature_fqi FQI:  135998
nn.learn_nn_feature_fqi FQI:  136998
nn.learn_nn_feature_fqi FQI:  137998
nn.learn_nn_feature_fqi FQI:  138998
nn.learn_nn_feature_fqi FQI:  139998
nn.learn_nn_feature_fqi FQI:  140998
nn.learn_nn_feature_fqi FQI:  141998
nn.learn_nn_feature_fqi FQI:  142998
nn.learn_nn_feature_fqi FQI:  143998
nn.learn_nn_feature_fqi FQI:  144998
nn.learn_nn_feature_fqi FQI:  145998
nn.learn_nn_feature_fqi FQI:  146998
nn.learn_nn_feature_fqi FQI:  147998
nn.learn_nn_feature_fqi FQI:  148998
nn.learn_nn_feature_fqi FQI:  149998
nn.learn_nn_feature_fqi FQI:  150998
nn.learn_nn_feature_fqi FQI:  151998
nn.learn_nn_feature_fqi FQI:  152998
nn.learn_nn_feature_fqi FQI:  153998
nn.learn_nn_feature_fqi FQI:  154998
nn.learn_nn_feature_fqi FQI:  155998
0 1001 -1000.0 -98.99572604650622 number episode from 10: 0 avegar over 10 episode: -98.996 avegare return across last 100 episodes: -98.996 state values: tensor(0.6982) 1000
1 1000 -1000.0 -99.99568287525881 number episode from 10: 1 avegar over 10 episode: -99.496 avegare return across last 100 episodes: -99.496 state values: tensor(0.6990) 1000
2 1000 -1000.0 -99.99568287525881 number episode from 10: 2 avegar over 10 episode: -99.662 avegare return across last 100 episodes: -99.662 state values: tensor(0.6981) 1000
3 1000 -1000.0 -99.99568287525881 number episode from 10: 3 avegar over 10 episode: -99.746 avegare return across last 100 episodes: -99.746 state values: tensor(0.6985) 1000
4 1000 -1000.0 -99.99568287525881 number episode from 10: 4 avegar over 10 episode: -99.796 avegare return across last 100 episodes: -99.796 state values: tensor(0.6970) 1000
5 1000 -1000.0 -99.99568287525881 number episode from 10: 5 avegar over 10 episode: -99.829 avegare return across last 100 episodes: -99.829 state values: tensor(0.6982) 1000
6 1000 -1000.0 -99.99568287525881 number episode from 10: 6 avegar over 10 episode: -99.853 avegare return across last 100 episodes: -99.853 state values: tensor(0.6975) 1000
7 1000 -1000.0 -99.99568287525881 number episode from 10: 7 avegar over 10 episode: -99.871 avegare return across last 100 episodes: -99.871 state values: tensor(0.6983) 1000
8 1000 -1000.0 -99.99568287525881 number episode from 10: 8 avegar over 10 episode: -99.885 avegare return across last 100 episodes: -99.885 state values: tensor(0.6991) 1000
9 1000 -1000.0 -99.99568287525881 number episode from 10: 9 avegar over 10 episode: -99.896 avegare return across last 100 episodes: -99.896 state values: tensor(0.6986) 1000
10 1000 -1000.0 -99.99568287525881 number episode from 10: 10 avegar over 10 episode: -99.905 avegare return across last 100 episodes: -99.905 state values: tensor(0.6987) 1000
11 1000 -1000.0 -99.99568287525881 number episode from 10: 11 avegar over 10 episode: -99.912 avegare return across last 100 episodes: -99.912 state values: tensor(0.6985) 1000
12 1000 -1000.0 -99.99568287525881 number episode from 10: 12 avegar over 10 episode: -99.919 avegare return across last 100 episodes: -99.919 state values: tensor(0.6981) 1000
13 1000 -1000.0 -99.99568287525881 number episode from 10: 13 avegar over 10 episode: -99.924 avegare return across last 100 episodes: -99.924 state values: tensor(0.6973) 1000
14 1000 -1000.0 -99.99568287525881 number episode from 10: 14 avegar over 10 episode: -99.929 avegare return across last 100 episodes: -99.929 state values: tensor(0.6978) 1000
15 1000 -1000.0 -99.99568287525881 number episode from 10: 15 avegar over 10 episode: -99.933 avegare return across last 100 episodes: -99.933 state values: tensor(0.6972) 1000
16 1000 -1000.0 -99.99568287525881 number episode from 10: 16 avegar over 10 episode: -99.937 avegare return across last 100 episodes: -99.937 state values: tensor(0.6981) 1000
17 1000 -1000.0 -99.99568287525881 number episode from 10: 17 avegar over 10 episode: -99.94 avegare return across last 100 episodes: -99.94 state values: tensor(0.6980) 1000
18 1000 -1000.0 -99.99568287525881 number episode from 10: 18 avegar over 10 episode: -99.943 avegare return across last 100 episodes: -99.943 state values: tensor(0.6987) 1000
19 1000 -1000.0 -99.99568287525881 number episode from 10: 19 avegar over 10 episode: -99.946 avegare return across last 100 episodes: -99.946 state values: tensor(0.6985) 1000
20 1000 -1000.0 -99.99568287525881 number episode from 10: 20 avegar over 10 episode: -99.948 avegare return across last 100 episodes: -99.948 state values: tensor(0.6972) 1000
21 1000 -1000.0 -99.99568287525881 number episode from 10: 21 avegar over 10 episode: -99.95 avegare return across last 100 episodes: -99.95 state values: tensor(0.6983) 1000
22 1000 -1000.0 -99.99568287525881 number episode from 10: 22 avegar over 10 episode: -99.952 avegare return across last 100 episodes: -99.952 state values: tensor(0.6970) 1000
23 1000 -1000.0 -99.99568287525881 number episode from 10: 23 avegar over 10 episode: -99.954 avegare return across last 100 episodes: -99.954 state values: tensor(0.6980) 1000
24 1000 -1000.0 -99.99568287525881 number episode from 10: 24 avegar over 10 episode: -99.956 avegare return across last 100 episodes: -99.956 state values: tensor(0.6991) 1000
25 1000 -1000.0 -99.99568287525881 number episode from 10: 25 avegar over 10 episode: -99.957 avegare return across last 100 episodes: -99.957 state values: tensor(0.6988) 1000
26 1000 -1000.0 -99.99568287525881 number episode from 10: 26 avegar over 10 episode: -99.959 avegare return across last 100 episodes: -99.959 state values: tensor(0.6986) 1000
27 1000 -1000.0 -99.99568287525881 number episode from 10: 27 avegar over 10 episode: -99.96 avegare return across last 100 episodes: -99.96 state values: tensor(0.6970) 1000
28 1000 -1000.0 -99.99568287525881 number episode from 10: 28 avegar over 10 episode: -99.961 avegare return across last 100 episodes: -99.961 state values: tensor(0.6918) 1000
29 1000 -1000.0 -99.99568287525881 number episode from 10: 29 avegar over 10 episode: -99.962 avegare return across last 100 episodes: -99.962 state values: tensor(0.6984) 1000
30 1000 -1000.0 -99.99568287525881 number episode from 10: 30 avegar over 10 episode: -99.963 avegare return across last 100 episodes: -99.963 state values: tensor(0.6979) 1000
31 1000 -1000.0 -99.99568287525881 number episode from 10: 31 avegar over 10 episode: -99.964 avegare return across last 100 episodes: -99.964 state values: tensor(0.6978) 1000
32 1000 -1000.0 -99.99568287525881 number episode from 10: 32 avegar over 10 episode: -99.965 avegare return across last 100 episodes: -99.965 state values: tensor(0.6983) 1000
33 1000 -1000.0 -99.99568287525881 number episode from 10: 33 avegar over 10 episode: -99.966 avegare return across last 100 episodes: -99.966 state values: tensor(0.6969) 1000
34 1000 -1000.0 -99.99568287525881 number episode from 10: 34 avegar over 10 episode: -99.967 avegare return across last 100 episodes: -99.967 state values: tensor(0.6981) 1000
35 1000 -1000.0 -99.99568287525881 number episode from 10: 35 avegar over 10 episode: -99.968 avegare return across last 100 episodes: -99.968 state values: tensor(0.6979) 1000
36 1000 -1000.0 -99.99568287525881 number episode from 10: 36 avegar over 10 episode: -99.969 avegare return across last 100 episodes: -99.969 state values: tensor(0.6985) 1000
37 1000 -1000.0 -99.99568287525881 number episode from 10: 37 avegar over 10 episode: -99.969 avegare return across last 100 episodes: -99.969 state values: tensor(0.6977) 1000
38 1000 -1000.0 -99.99568287525881 number episode from 10: 38 avegar over 10 episode: -99.97 avegare return across last 100 episodes: -99.97 state values: tensor(0.6974) 1000
39 1000 -1000.0 -99.99568287525881 number episode from 10: 39 avegar over 10 episode: -99.971 avegare return across last 100 episodes: -99.971 state values: tensor(0.6973) 1000
40 1000 -1000.0 -99.99568287525881 number episode from 10: 40 avegar over 10 episode: -99.971 avegare return across last 100 episodes: -99.971 state values: tensor(0.6976) 1000
41 1000 -1000.0 -99.99568287525881 number episode from 10: 41 avegar over 10 episode: -99.972 avegare return across last 100 episodes: -99.972 state values: tensor(0.6977) 1000
42 1000 -1000.0 -99.99568287525881 number episode from 10: 42 avegar over 10 episode: -99.972 avegare return across last 100 episodes: -99.972 state values: tensor(0.6990) 1000
43 1000 -1000.0 -99.99568287525881 number episode from 10: 43 avegar over 10 episode: -99.973 avegare return across last 100 episodes: -99.973 state values: tensor(0.6982) 1000
44 1000 -1000.0 -99.99568287525881 number episode from 10: 44 avegar over 10 episode: -99.973 avegare return across last 100 episodes: -99.973 state values: tensor(0.6983) 1000
45 1000 -1000.0 -99.99568287525881 number episode from 10: 45 avegar over 10 episode: -99.974 avegare return across last 100 episodes: -99.974 state values: tensor(0.6983) 1000
46 1000 -1000.0 -99.99568287525881 number episode from 10: 46 avegar over 10 episode: -99.974 avegare return across last 100 episodes: -99.974 state values: tensor(0.6987) 1000
47 1000 -1000.0 -99.99568287525881 number episode from 10: 47 avegar over 10 episode: -99.975 avegare return across last 100 episodes: -99.975 state values: tensor(0.6981) 1000
48 1000 -1000.0 -99.99568287525881 number episode from 10: 48 avegar over 10 episode: -99.975 avegare return across last 100 episodes: -99.975 state values: tensor(0.6975) 1000
49 1000 -1000.0 -99.99568287525881 number episode from 10: 49 avegar over 10 episode: -99.976 avegare return across last 100 episodes: -99.976 state values: tensor(0.6982) 1000
50 1000 -1000.0 -99.99568287525881 number episode from 10: 50 avegar over 10 episode: -99.976 avegare return across last 100 episodes: -99.976 state values: tensor(0.6978) 1000
51 1000 -1000.0 -99.99568287525881 number episode from 10: 51 avegar over 10 episode: -99.976 avegare return across last 100 episodes: -99.976 state values: tensor(0.6966) 1000
52 1000 -1000.0 -99.99568287525881 number episode from 10: 52 avegar over 10 episode: -99.977 avegare return across last 100 episodes: -99.977 state values: tensor(0.6985) 1000
53 1000 -1000.0 -99.99568287525881 number episode from 10: 53 avegar over 10 episode: -99.977 avegare return across last 100 episodes: -99.977 state values: tensor(0.6980) 1000
54 1000 -1000.0 -99.99568287525881 number episode from 10: 54 avegar over 10 episode: -99.978 avegare return across last 100 episodes: -99.978 state values: tensor(0.6983) 1000
55 1000 -1000.0 -99.99568287525881 number episode from 10: 55 avegar over 10 episode: -99.978 avegare return across last 100 episodes: -99.978 state values: tensor(0.7000) 1000
56 1000 -1000.0 -99.99568287525881 number episode from 10: 56 avegar over 10 episode: -99.978 avegare return across last 100 episodes: -99.978 state values: tensor(0.6987) 1000
57 1000 -1000.0 -99.99568287525881 number episode from 10: 57 avegar over 10 episode: -99.978 avegare return across last 100 episodes: -99.978 state values: tensor(0.7001) 1000
58 1000 -1000.0 -99.99568287525881 number episode from 10: 58 avegar over 10 episode: -99.979 avegare return across last 100 episodes: -99.979 state values: tensor(0.6991) 1000
59 1000 -1000.0 -99.99568287525881 number episode from 10: 59 avegar over 10 episode: -99.979 avegare return across last 100 episodes: -99.979 state values: tensor(0.6976) 1000
60 1000 -1000.0 -99.99568287525881 number episode from 10: 60 avegar over 10 episode: -99.979 avegare return across last 100 episodes: -99.979 state values: tensor(0.6986) 1000
61 1000 -1000.0 -99.99568287525881 number episode from 10: 61 avegar over 10 episode: -99.98 avegare return across last 100 episodes: -99.98 state values: tensor(0.6973) 1000
62 1000 -1000.0 -99.99568287525881 number episode from 10: 62 avegar over 10 episode: -99.98 avegare return across last 100 episodes: -99.98 state values: tensor(0.6984) 1000
63 1000 -1000.0 -99.99568287525881 number episode from 10: 63 avegar over 10 episode: -99.98 avegare return across last 100 episodes: -99.98 state values: tensor(0.6972) 1000
64 1000 -1000.0 -99.99568287525881 number episode from 10: 64 avegar over 10 episode: -99.98 avegare return across last 100 episodes: -99.98 state values: tensor(0.6983) 1000
65 1000 -1000.0 -99.99568287525881 number episode from 10: 65 avegar over 10 episode: -99.981 avegare return across last 100 episodes: -99.981 state values: tensor(0.6968) 1000
66 1000 -1000.0 -99.99568287525881 number episode from 10: 66 avegar over 10 episode: -99.981 avegare return across last 100 episodes: -99.981 state values: tensor(0.6981) 1000
67 1000 -1000.0 -99.99568287525881 number episode from 10: 67 avegar over 10 episode: -99.981 avegare return across last 100 episodes: -99.981 state values: tensor(0.6991) 1000
68 1000 -1000.0 -99.99568287525881 number episode from 10: 68 avegar over 10 episode: -99.981 avegare return across last 100 episodes: -99.981 state values: tensor(0.6978) 1000
69 1000 -1000.0 -99.99568287525881 number episode from 10: 69 avegar over 10 episode: -99.981 avegare return across last 100 episodes: -99.981 state values: tensor(0.6984) 1000
70 1000 -1000.0 -99.99568287525881 number episode from 10: 70 avegar over 10 episode: -99.982 avegare return across last 100 episodes: -99.982 state values: tensor(0.6978) 1000
71 1000 -1000.0 -99.99568287525881 number episode from 10: 71 avegar over 10 episode: -99.982 avegare return across last 100 episodes: -99.982 state values: tensor(0.6989) 1000
72 1000 -1000.0 -99.99568287525881 number episode from 10: 72 avegar over 10 episode: -99.982 avegare return across last 100 episodes: -99.982 state values: tensor(0.6977) 1000
73 1000 -1000.0 -99.99568287525881 number episode from 10: 73 avegar over 10 episode: -99.982 avegare return across last 100 episodes: -99.982 state values: tensor(0.6979) 1000
74 1000 -1000.0 -99.99568287525881 number episode from 10: 74 avegar over 10 episode: -99.982 avegare return across last 100 episodes: -99.982 state values: tensor(0.6984) 1000
75 1000 -1000.0 -99.99568287525881 number episode from 10: 75 avegar over 10 episode: -99.983 avegare return across last 100 episodes: -99.983 state values: tensor(0.6961) 1000
76 1000 -1000.0 -99.99568287525881 number episode from 10: 76 avegar over 10 episode: -99.983 avegare return across last 100 episodes: -99.983 state values: tensor(0.6981) 1000
77 1000 -1000.0 -99.99568287525881 number episode from 10: 77 avegar over 10 episode: -99.983 avegare return across last 100 episodes: -99.983 state values: tensor(0.6974) 1000
78 1000 -1000.0 -99.99568287525881 number episode from 10: 78 avegar over 10 episode: -99.983 avegare return across last 100 episodes: -99.983 state values: tensor(0.6986) 1000
79 1000 -1000.0 -99.99568287525881 number episode from 10: 79 avegar over 10 episode: -99.983 avegare return across last 100 episodes: -99.983 state values: tensor(0.6970) 1000
80 1000 -1000.0 -99.99568287525881 number episode from 10: 80 avegar over 10 episode: -99.983 avegare return across last 100 episodes: -99.983 state values: tensor(0.6970) 1000
81 1000 -1000.0 -99.99568287525881 number episode from 10: 81 avegar over 10 episode: -99.983 avegare return across last 100 episodes: -99.983 state values: tensor(0.6977) 1000
82 1000 -1000.0 -99.99568287525881 number episode from 10: 82 avegar over 10 episode: -99.984 avegare return across last 100 episodes: -99.984 state values: tensor(0.6975) 1000
83 1000 -1000.0 -99.99568287525881 number episode from 10: 83 avegar over 10 episode: -99.984 avegare return across last 100 episodes: -99.984 state values: tensor(0.6983) 1000
84 1000 -1000.0 -99.99568287525881 number episode from 10: 84 avegar over 10 episode: -99.984 avegare return across last 100 episodes: -99.984 state values: tensor(0.6968) 1000
85 1000 -1000.0 -99.99568287525881 number episode from 10: 85 avegar over 10 episode: -99.984 avegare return across last 100 episodes: -99.984 state values: tensor(0.6981) 1000
86 1000 -1000.0 -99.99568287525881 number episode from 10: 86 avegar over 10 episode: -99.984 avegare return across last 100 episodes: -99.984 state values: tensor(0.6980) 1000
87 1000 -1000.0 -99.99568287525881 number episode from 10: 87 avegar over 10 episode: -99.984 avegare return across last 100 episodes: -99.984 state values: tensor(0.6967) 1000
88 1000 -1000.0 -99.99568287525881 number episode from 10: 88 avegar over 10 episode: -99.984 avegare return across last 100 episodes: -99.984 state values: tensor(0.6986) 1000
89 1000 -1000.0 -99.99568287525881 number episode from 10: 89 avegar over 10 episode: -99.985 avegare return across last 100 episodes: -99.985 state values: tensor(0.6989) 1000
90 1000 -1000.0 -99.99568287525881 number episode from 10: 90 avegar over 10 episode: -99.985 avegare return across last 100 episodes: -99.985 state values: tensor(0.6990) 1000
91 1000 -1000.0 -99.99568287525881 number episode from 10: 91 avegar over 10 episode: -99.985 avegare return across last 100 episodes: -99.985 state values: tensor(0.6988) 1000
92 1000 -1000.0 -99.99568287525881 number episode from 10: 92 avegar over 10 episode: -99.985 avegare return across last 100 episodes: -99.985 state values: tensor(0.6926) 1000
93 1000 -1000.0 -99.99568287525881 number episode from 10: 93 avegar over 10 episode: -99.985 avegare return across last 100 episodes: -99.985 state values: tensor(0.6979) 1000
94 1000 -1000.0 -99.99568287525881 number episode from 10: 94 avegar over 10 episode: -99.985 avegare return across last 100 episodes: -99.985 state values: tensor(0.6980) 1000
95 1000 -1000.0 -99.99568287525881 number episode from 10: 95 avegar over 10 episode: -99.985 avegare return across last 100 episodes: -99.985 state values: tensor(0.6988) 1000
96 1000 -1000.0 -99.99568287525881 number episode from 10: 96 avegar over 10 episode: -99.985 avegare return across last 100 episodes: -99.985 state values: tensor(0.6975) 1000
97 1000 -1000.0 -99.99568287525881 number episode from 10: 97 avegar over 10 episode: -99.985 avegare return across last 100 episodes: -99.985 state values: tensor(0.6985) 1000
98 1000 -1000.0 -99.99568287525881 number episode from 10: 98 avegar over 10 episode: -99.986 avegare return across last 100 episodes: -99.986 state values: tensor(0.6981) 1000
99 1000 -1000.0 -99.99568287525881 number episode from 10: 99 avegar over 10 episode: -99.986 avegare return across last 100 episodes: -99.986 state values: tensor(0.6985) 1000
100 1000 -1000.0 -99.99568287525881 number episode from 10: 100 avegar over 10 episode: -99.986 avegare return across last 100 episodes: -99.996 state values: tensor(0.6992) 1000
101 1000 -1000.0 -99.99568287525881 number episode from 10: 101 avegar over 10 episode: -99.986 avegare return across last 100 episodes: -99.996 state values: tensor(0.6981) 1000
102 1000 -1000.0 -99.99568287525881 number episode from 10: 102 avegar over 10 episode: -99.986 avegare return across last 100 episodes: -99.996 state values: tensor(0.6973) 1000
103 1000 -1000.0 -99.99568287525881 number episode from 10: 103 avegar over 10 episode: -99.986 avegare return across last 100 episodes: -99.996 state values: tensor(0.6976) 1000
104 1000 -1000.0 -99.99568287525881 number episode from 10: 104 avegar over 10 episode: -99.986 avegare return across last 100 episodes: -99.996 state values: tensor(0.6982) 1000
105 1000 -1000.0 -99.99568287525881 number episode from 10: 105 avegar over 10 episode: -99.986 avegare return across last 100 episodes: -99.996 state values: tensor(0.6981) 1000
106 1000 -1000.0 -99.99568287525881 number episode from 10: 106 avegar over 10 episode: -99.986 avegare return across last 100 episodes: -99.996 state values: tensor(0.6976) 1000
107 1000 -1000.0 -99.99568287525881 number episode from 10: 107 avegar over 10 episode: -99.986 avegare return across last 100 episodes: -99.996 state values: tensor(0.6987) 1000
108 1000 -1000.0 -99.99568287525881 number episode from 10: 108 avegar over 10 episode: -99.987 avegare return across last 100 episodes: -99.996 state values: tensor(0.6972) 1000
109 1000 -1000.0 -99.99568287525881 number episode from 10: 109 avegar over 10 episode: -99.987 avegare return across last 100 episodes: -99.996 state values: tensor(0.6970) 1000
110 1000 -1000.0 -99.99568287525881 number episode from 10: 110 avegar over 10 episode: -99.987 avegare return across last 100 episodes: -99.996 state values: tensor(0.6974) 1000
111 1000 -1000.0 -99.99568287525881 number episode from 10: 111 avegar over 10 episode: -99.987 avegare return across last 100 episodes: -99.996 state values: tensor(0.6972) 1000
112 1000 -1000.0 -99.99568287525881 number episode from 10: 112 avegar over 10 episode: -99.987 avegare return across last 100 episodes: -99.996 state values: tensor(0.6985) 1000
113 1000 -1000.0 -99.99568287525881 number episode from 10: 113 avegar over 10 episode: -99.987 avegare return across last 100 episodes: -99.996 state values: tensor(0.6970) 1000
114 1000 -1000.0 -99.99568287525881 number episode from 10: 114 avegar over 10 episode: -99.987 avegare return across last 100 episodes: -99.996 state values: tensor(0.6984) 1000
115 1000 -1000.0 -99.99568287525881 number episode from 10: 115 avegar over 10 episode: -99.987 avegare return across last 100 episodes: -99.996 state values: tensor(0.6979) 1000
116 1000 -1000.0 -99.99568287525881 number episode from 10: 116 avegar over 10 episode: -99.987 avegare return across last 100 episodes: -99.996 state values: tensor(0.6981) 1000
117 1000 -1000.0 -99.99568287525881 number episode from 10: 117 avegar over 10 episode: -99.987 avegare return across last 100 episodes: -99.996 state values: tensor(0.6983) 1000
118 1000 -1000.0 -99.99568287525881 number episode from 10: 118 avegar over 10 episode: -99.987 avegare return across last 100 episodes: -99.996 state values: tensor(0.6979) 1000
119 1000 -1000.0 -99.99568287525881 number episode from 10: 119 avegar over 10 episode: -99.987 avegare return across last 100 episodes: -99.996 state values: tensor(0.6980) 1000
120 1000 -1000.0 -99.99568287525881 number episode from 10: 120 avegar over 10 episode: -99.987 avegare return across last 100 episodes: -99.996 state values: tensor(0.6990) 1000
121 1000 -1000.0 -99.99568287525881 number episode from 10: 121 avegar over 10 episode: -99.987 avegare return across last 100 episodes: -99.996 state values: tensor(0.6980) 1000
122 1000 -1000.0 -99.99568287525881 number episode from 10: 122 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.6985) 1000
123 1000 -1000.0 -99.99568287525881 number episode from 10: 123 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.6977) 1000
124 1000 -1000.0 -99.99568287525881 number episode from 10: 124 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.6989) 1000
125 1000 -1000.0 -99.99568287525881 number episode from 10: 125 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.6985) 1000
126 1000 -1000.0 -99.99568287525881 number episode from 10: 126 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.6985) 1000
127 1000 -1000.0 -99.99568287525881 number episode from 10: 127 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.6992) 1000
128 1000 -1000.0 -99.99568287525881 number episode from 10: 128 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.6982) 1000
129 1000 -1000.0 -99.99568287525881 number episode from 10: 129 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.6984) 1000
130 1000 -1000.0 -99.99568287525881 number episode from 10: 130 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.6982) 1000
131 1000 -1000.0 -99.99568287525881 number episode from 10: 131 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.6982) 1000
132 1000 -1000.0 -99.99568287525881 number episode from 10: 132 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.6988) 1000
133 1000 -1000.0 -99.99568287525881 number episode from 10: 133 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.6981) 1000
134 1000 -1000.0 -99.99568287525881 number episode from 10: 134 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.6987) 1000
135 1000 -1000.0 -99.99568287525881 number episode from 10: 135 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.6976) 1000
136 1000 -1000.0 -99.99568287525881 number episode from 10: 136 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.6982) 1000
137 1000 -1000.0 -99.99568287525881 number episode from 10: 137 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.6992) 1000
138 1000 -1000.0 -99.99568287525881 number episode from 10: 138 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.6988) 1000
139 1000 -1000.0 -99.99568287525881 number episode from 10: 139 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.6998) 1000
140 1000 -1000.0 -99.99568287525881 number episode from 10: 140 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.6980) 1000
141 1000 -1000.0 -99.99568287525881 number episode from 10: 141 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.6980) 1000
142 1000 -1000.0 -99.99568287525881 number episode from 10: 142 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.6995) 1000
143 1000 -1000.0 -99.99568287525881 number episode from 10: 143 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.6983) 1000
144 1000 -1000.0 -99.99568287525881 number episode from 10: 144 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.6987) 1000
145 1000 -1000.0 -99.99568287525881 number episode from 10: 145 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.6983) 1000
146 1000 -1000.0 -99.99568287525881 number episode from 10: 146 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.6992) 1000
147 1000 -1000.0 -99.99568287525881 number episode from 10: 147 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.6976) 1000
148 1000 -1000.0 -99.99568287525881 number episode from 10: 148 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.6971) 1000
149 1000 -1000.0 -99.99568287525881 number episode from 10: 149 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.6978) 1000
150 1000 -1000.0 -99.99568287525881 number episode from 10: 150 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.6972) 1000
151 1000 -1000.0 -99.99568287525881 number episode from 10: 151 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.6984) 1000
152 1000 -1000.0 -99.99568287525881 number episode from 10: 152 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.6991) 1000
153 1000 -1000.0 -99.99568287525881 number episode from 10: 153 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.6984) 1000
154 1000 -1000.0 -99.99568287525881 number episode from 10: 154 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.6982) 1000
155 1000 -1000.0 -99.99568287525881 number episode from 10: 155 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.6982) 1000
156 1000 -1000.0 -99.99568287525881 number episode from 10: 156 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.6983) 1000
157 1000 -1000.0 -99.99568287525881 number episode from 10: 157 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.6980) 1000
158 1000 -1000.0 -99.99568287525881 number episode from 10: 158 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.6984) 1000
159 1000 -1000.0 -99.99568287525881 number episode from 10: 159 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.6992) 1000
160 1000 -1000.0 -99.99568287525881 number episode from 10: 160 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.6973) 1000
161 1000 -1000.0 -99.99568287525881 number episode from 10: 161 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.6986) 1000
162 1000 -1000.0 -99.99568287525881 number episode from 10: 162 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.6927) 1000
163 1000 -1000.0 -99.99568287525881 number episode from 10: 163 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.6984) 1000
164 1000 -1000.0 -99.99568287525881 number episode from 10: 164 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.6977) 1000
165 1000 -1000.0 -99.99568287525881 number episode from 10: 165 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.6919) 1000
166 1000 -1000.0 -99.99568287525881 number episode from 10: 166 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.6984) 1000
167 1000 -1000.0 -99.99568287525881 number episode from 10: 167 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.6992) 1000
168 1000 -1000.0 -99.99568287525881 number episode from 10: 168 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.6983) 1000
169 1000 -1000.0 -99.99568287525881 number episode from 10: 169 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.6974) 1000
170 1000 -1000.0 -99.99568287525881 number episode from 10: 170 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.6984) 1000
171 1000 -1000.0 -99.99568287525881 number episode from 10: 171 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.6994) 1000
172 1000 -1000.0 -99.99568287525881 number episode from 10: 172 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.6977) 1000
173 1000 -1000.0 -99.99568287525881 number episode from 10: 173 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.6986) 1000
174 1000 -1000.0 -99.99568287525881 number episode from 10: 174 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.6973) 1000
175 1000 -1000.0 -99.99568287525881 number episode from 10: 175 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.6976) 1000
176 1000 -1000.0 -99.99568287525881 number episode from 10: 176 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.6990) 1000
177 1000 -1000.0 -99.99568287525881 number episode from 10: 177 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.6979) 1000
178 1000 -1000.0 -99.99568287525881 number episode from 10: 178 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.6988) 1000
179 1000 -1000.0 -99.99568287525881 number episode from 10: 179 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.6985) 1000
180 1000 -1000.0 -99.99568287525881 number episode from 10: 180 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.6923) 1000
181 1000 -1000.0 -99.99568287525881 number episode from 10: 181 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.6986) 1000
182 1000 -1000.0 -99.99568287525881 number episode from 10: 182 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.6983) 1000
183 1000 -1000.0 -99.99568287525881 number episode from 10: 183 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.6989) 1000
184 1000 -1000.0 -99.99568287525881 number episode from 10: 184 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.6975) 1000
185 1000 -1000.0 -99.99568287525881 number episode from 10: 185 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.6967) 1000
186 1000 -1000.0 -99.99568287525881 number episode from 10: 186 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.6973) 1000
187 1000 -1000.0 -99.99568287525881 number episode from 10: 187 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.6990) 1000
188 1000 -1000.0 -99.99568287525881 number episode from 10: 188 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.6973) 1000
189 1000 -1000.0 -99.99568287525881 number episode from 10: 189 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.6972) 1000
190 1000 -1000.0 -99.99568287525881 number episode from 10: 190 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.6977) 1000
191 1000 -1000.0 -99.99568287525881 number episode from 10: 191 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.6986) 1000
192 1000 -1000.0 -99.99568287525881 number episode from 10: 192 avegar over 10 episode: -99.991 avegare return across last 100 episodes: -99.996 state values: tensor(0.6954) 1000
193 1000 -1000.0 -99.99568287525881 number episode from 10: 193 avegar over 10 episode: -99.991 avegare return across last 100 episodes: -99.996 state values: tensor(0.6986) 1000
194 1000 -1000.0 -99.99568287525881 number episode from 10: 194 avegar over 10 episode: -99.991 avegare return across last 100 episodes: -99.996 state values: tensor(0.6982) 1000
195 1000 -1000.0 -99.99568287525881 number episode from 10: 195 avegar over 10 episode: -99.991 avegare return across last 100 episodes: -99.996 state values: tensor(0.6987) 1000
196 1000 -1000.0 -99.99568287525881 number episode from 10: 196 avegar over 10 episode: -99.991 avegare return across last 100 episodes: -99.996 state values: tensor(0.6978) 1000
197 1000 -1000.0 -99.99568287525881 number episode from 10: 197 avegar over 10 episode: -99.991 avegare return across last 100 episodes: -99.996 state values: tensor(0.6989) 1000
198 1000 -1000.0 -99.99568287525881 number episode from 10: 198 avegar over 10 episode: -99.991 avegare return across last 100 episodes: -99.996 state values: tensor(0.6972) 1000
199 1000 -1000.0 -99.99568287525881 number episode from 10: 199 avegar over 10 episode: -99.991 avegare return across last 100 episodes: -99.996 state values: tensor(0.6992) 1000
200 1000 -1000.0 -99.99568287525881 number episode from 10: 200 avegar over 10 episode: -99.991 avegare return across last 100 episodes: -99.996 state values: tensor(0.6915) 1000
