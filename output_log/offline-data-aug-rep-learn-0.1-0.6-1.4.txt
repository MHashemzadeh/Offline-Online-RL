OrderedDict([('nn_lr', 0.0001), ('reg_A', 0.001), ('eps_decay_steps', 1), ('update_freq', 1000), ('data_length', 50000), ('fqi_rep', 1)])
/project/6029407/janjua/Offline-Online-RL-Augmentation/Offline-Online-RL/TTN_network.py:72: UserWarning: nn.init.xavier_uniform is now deprecated in favor of nn.init.xavier_uniform_.
  nn.init.xavier_uniform(m.weight)
Data already exists at: Data/Mountaincar_50000+.npy
offline 15 Mountaincar 50000
Parameters: OrderedDict([('nn_lr', 0.001), ('reg_A', 0.001), ('eps_decay_steps', 1), ('update_freq', 1000), ('data_length', 50000), ('fqi_rep', 1)])
Nnet params: {'loss_features': 'semi_MSTDE', 'beta1': 0.0, 'beta2': 0.99, 'eps_init': 1.0, 'eps_final': 0.01, 'num_actions': 3, 'replay_memory_size': 50000, 'replay_init_size': 5000, 'batch_size': 32, 'fqi_reg_type': 'prev', 'data_aug_type': 'ras', 'data_aug_prob': 0.1, 'random_shift_pad': 4, 'ras_alpha': 0.6, 'ras_beta': 1.4}
load offline data!!!!!
/project/6029407/janjua/Offline-Online-RL-Augmentation/Offline-Online-RL/replay_memory.py:52: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  temp = T.tensor((d.item().get('state')), dtype=T.float32)
/project/6029407/janjua/Offline-Online-RL-Augmentation/Offline-Online-RL/replay_memory.py:54: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.state_memory[:len(temp), :] = T.tensor((d.item().get('state')), dtype=T.float32)
/project/6029407/janjua/Offline-Online-RL-Augmentation/Offline-Online-RL/replay_memory.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.new_state_memory[:len(temp), :] = T.tensor((d.item().get('nstate')), dtype=T.float32)
/project/6029407/janjua/Offline-Online-RL-Augmentation/Offline-Online-RL/replay_memory.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.action_memory[:len(temp)] = T.tensor((d.item().get('action')), dtype=T.int64)
/project/6029407/janjua/Offline-Online-RL-Augmentation/Offline-Online-RL/replay_memory.py:57: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.new_action_memory[:len(temp)] = T.tensor((d.item().get('naction')), dtype=T.int64)
/project/6029407/janjua/Offline-Online-RL-Augmentation/Offline-Online-RL/replay_memory.py:58: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.reward_memory[:len(temp)] = T.tensor((d.item().get('reward')), dtype=T.float32)
/project/6029407/janjua/Offline-Online-RL-Augmentation/Offline-Online-RL/replay_memory.py:59: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.terminal_memory[:len(temp)] = T.tensor((d.item().get('done')), dtype=T.bool)
mem_cntr: 50000 ; mem_size: 50000
/project/6029407/janjua/Offline-Online-RL-Augmentation/Offline-Online-RL/replay_memory.py:249: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  temp = T.tensor((d.item().get('state')), dtype=T.float32)
/project/6029407/janjua/Offline-Online-RL-Augmentation/Offline-Online-RL/replay_memory.py:251: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.state_memory[:len(temp), :] = T.tensor((d.item().get('state')), dtype=T.float32)
/project/6029407/janjua/Offline-Online-RL-Augmentation/Offline-Online-RL/replay_memory.py:252: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.new_state_memory[:len(temp), :] = T.tensor((d.item().get('nstate')), dtype=T.float32)
/project/6029407/janjua/Offline-Online-RL-Augmentation/Offline-Online-RL/replay_memory.py:253: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.action_memory[:len(temp)] = T.tensor((d.item().get('action')), dtype=T.int64)
/project/6029407/janjua/Offline-Online-RL-Augmentation/Offline-Online-RL/replay_memory.py:254: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.new_action_memory[:len(temp)] = T.tensor((d.item().get('naction')), dtype=T.int64)
/project/6029407/janjua/Offline-Online-RL-Augmentation/Offline-Online-RL/replay_memory.py:255: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.reward_memory[:len(temp)] = T.tensor((d.item().get('reward')), dtype=T.float32)
/project/6029407/janjua/Offline-Online-RL-Augmentation/Offline-Online-RL/replay_memory.py:256: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.terminal_memory[:len(temp)] = T.tensor((d.item().get('done')), dtype=T.bool)
/project/6029407/janjua/Offline-Online-RL-Augmentation/Offline-Online-RL/mix_ttn_agent_online_offline.py:155: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  states = T.tensor(state).to(self.q_eval.device)
/project/6029407/janjua/Offline-Online-RL-Augmentation/Offline-Online-RL/mix_ttn_agent_online_offline.py:156: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  rewards = T.tensor(reward).to(self.q_eval.device)
/project/6029407/janjua/Offline-Online-RL-Augmentation/Offline-Online-RL/mix_ttn_agent_online_offline.py:157: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  dones = T.tensor(done).to(self.q_eval.device)
/project/6029407/janjua/Offline-Online-RL-Augmentation/Offline-Online-RL/mix_ttn_agent_online_offline.py:158: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  actions = T.tensor(action).to(self.q_eval.device)
/project/6029407/janjua/Offline-Online-RL-Augmentation/Offline-Online-RL/mix_ttn_agent_online_offline.py:159: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  states_ = T.tensor(new_state).to(self.q_eval.device)
/project/6029407/janjua/Offline-Online-RL-Augmentation/Offline-Online-RL/mix_ttn_agent_online_offline.py:160: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  actions_ = T.tensor(new_action).to(self.q_eval.device)
/project/6029407/janjua/Offline-Online-RL-Augmentation/Offline-Online-RL/mix_ttn_agent_online_offline.py:169: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  states = T.tensor(state).to(self.q_eval.device)
/project/6029407/janjua/Offline-Online-RL-Augmentation/Offline-Online-RL/mix_ttn_agent_online_offline.py:170: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  rewards = T.tensor(reward).to(self.q_eval.device)
/project/6029407/janjua/Offline-Online-RL-Augmentation/Offline-Online-RL/mix_ttn_agent_online_offline.py:171: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  dones = T.tensor(done).to(self.q_eval.device)
/project/6029407/janjua/Offline-Online-RL-Augmentation/Offline-Online-RL/mix_ttn_agent_online_offline.py:172: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  actions = T.tensor(action).to(self.q_eval.device)
/project/6029407/janjua/Offline-Online-RL-Augmentation/Offline-Online-RL/mix_ttn_agent_online_offline.py:173: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  states_ = T.tensor(new_state).to(self.q_eval.device)
/project/6029407/janjua/Offline-Online-RL-Augmentation/Offline-Online-RL/mix_ttn_agent_online_offline.py:174: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  actions_ = T.tensor(new_action).to(self.q_eval.device)
nn.learn_nn_feature_fqi FQI:  998
/project/6029407/janjua/Offline-Online-RL-Augmentation/Offline-Online-RL/mix_ttn_agent_online_offline.py:704: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  states_all = T.tensor(self.memory.state_memory[:mem_index, :]).to(self.q_eval.device)
/project/6029407/janjua/Offline-Online-RL-Augmentation/Offline-Online-RL/mix_ttn_agent_online_offline.py:705: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  actions_all = T.tensor(self.memory.action_memory[:mem_index]).to(self.q_eval.device)
/project/6029407/janjua/Offline-Online-RL-Augmentation/Offline-Online-RL/mix_ttn_agent_online_offline.py:706: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  rewards_all = T.tensor(self.memory.reward_memory[:mem_index]).to(self.q_eval.device)
/project/6029407/janjua/Offline-Online-RL-Augmentation/Offline-Online-RL/mix_ttn_agent_online_offline.py:707: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  states_all_ = T.tensor(self.memory.new_state_memory[:mem_index, :]).to(self.q_eval.device)
/project/6029407/janjua/Offline-Online-RL-Augmentation/Offline-Online-RL/mix_ttn_agent_online_offline.py:708: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  actions_all_ = T.tensor(self.memory.new_action_memory[:mem_index]).to(self.q_eval.device)
/project/6029407/janjua/Offline-Online-RL-Augmentation/Offline-Online-RL/mix_ttn_agent_online_offline.py:709: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  dones_all = T.tensor(self.memory.terminal_memory[:mem_index]).to(self.q_eval.device)
/project/6029407/janjua/Offline-Online-RL-Augmentation/Offline-Online-RL/mix_ttn_agent_online_offline.py:794: UserWarning: torch.lstsq is deprecated in favor of torch.linalg.lstsq and will be removed in a future PyTorch release.
torch.linalg.lstsq has reversed arguments and does not return the QR decomposition in the returned tuple (although it returns other information about the problem).
To get the qr decomposition consider using torch.linalg.qr.
The returned solution in torch.lstsq stored the residuals of the solution in the last m - n columns of the returned value whenever m > n. In torch.linalg.lstsq, the residuals in the field 'residuals' of the returned named tuple.
The unpacking of the solution, as in
X, _ = torch.lstsq(B, A).solution[:A.size(1)]
should be replaced with
X = torch.linalg.lstsq(A, B).solution (Triggered internally at  /tmp/coulombc/pytorch_build_2021-11-09_14-57-01/avx2/python3.7/pytorch/aten/src/ATen/native/BatchLinearAlgebra.cpp:3657.)
  new_weights = T.lstsq(b, A)[0]  # T.mm(A.inverse(), b) #T.lstsq(b, A)[0]  #T.mm(A.inverse(), b) #tf.matrix_solve(A, b)
nn.learn_nn_feature_fqi FQI:  1998
nn.learn_nn_feature_fqi FQI:  2998
nn.learn_nn_feature_fqi FQI:  3998
nn.learn_nn_feature_fqi FQI:  4998
nn.learn_nn_feature_fqi FQI:  5998
nn.learn_nn_feature_fqi FQI:  6998
nn.learn_nn_feature_fqi FQI:  7998
nn.learn_nn_feature_fqi FQI:  8998
nn.learn_nn_feature_fqi FQI:  9998
nn.learn_nn_feature_fqi FQI:  10998
nn.learn_nn_feature_fqi FQI:  11998
nn.learn_nn_feature_fqi FQI:  12998
nn.learn_nn_feature_fqi FQI:  13998
nn.learn_nn_feature_fqi FQI:  14998
nn.learn_nn_feature_fqi FQI:  15998
nn.learn_nn_feature_fqi FQI:  16998
nn.learn_nn_feature_fqi FQI:  17998
nn.learn_nn_feature_fqi FQI:  18998
nn.learn_nn_feature_fqi FQI:  19998
nn.learn_nn_feature_fqi FQI:  20998
nn.learn_nn_feature_fqi FQI:  21998
nn.learn_nn_feature_fqi FQI:  22998
nn.learn_nn_feature_fqi FQI:  23998
nn.learn_nn_feature_fqi FQI:  24998
nn.learn_nn_feature_fqi FQI:  25998
nn.learn_nn_feature_fqi FQI:  26998
nn.learn_nn_feature_fqi FQI:  27998
nn.learn_nn_feature_fqi FQI:  28998
nn.learn_nn_feature_fqi FQI:  29998
nn.learn_nn_feature_fqi FQI:  30998
nn.learn_nn_feature_fqi FQI:  31998
nn.learn_nn_feature_fqi FQI:  32998
nn.learn_nn_feature_fqi FQI:  33998
nn.learn_nn_feature_fqi FQI:  34998
nn.learn_nn_feature_fqi FQI:  35998
nn.learn_nn_feature_fqi FQI:  36998
nn.learn_nn_feature_fqi FQI:  37998
nn.learn_nn_feature_fqi FQI:  38998
nn.learn_nn_feature_fqi FQI:  39998
nn.learn_nn_feature_fqi FQI:  40998
nn.learn_nn_feature_fqi FQI:  41998
nn.learn_nn_feature_fqi FQI:  42998
nn.learn_nn_feature_fqi FQI:  43998
nn.learn_nn_feature_fqi FQI:  44998
nn.learn_nn_feature_fqi FQI:  45998
nn.learn_nn_feature_fqi FQI:  46998
nn.learn_nn_feature_fqi FQI:  47998
nn.learn_nn_feature_fqi FQI:  48998
nn.learn_nn_feature_fqi FQI:  49998
nn.learn_nn_feature_fqi FQI:  50998
nn.learn_nn_feature_fqi FQI:  51998
nn.learn_nn_feature_fqi FQI:  52998
nn.learn_nn_feature_fqi FQI:  53998
nn.learn_nn_feature_fqi FQI:  54998
nn.learn_nn_feature_fqi FQI:  55998
nn.learn_nn_feature_fqi FQI:  56998
nn.learn_nn_feature_fqi FQI:  57998
nn.learn_nn_feature_fqi FQI:  58998
nn.learn_nn_feature_fqi FQI:  59998
nn.learn_nn_feature_fqi FQI:  60998
nn.learn_nn_feature_fqi FQI:  61998
nn.learn_nn_feature_fqi FQI:  62998
nn.learn_nn_feature_fqi FQI:  63998
nn.learn_nn_feature_fqi FQI:  64998
nn.learn_nn_feature_fqi FQI:  65998
nn.learn_nn_feature_fqi FQI:  66998
nn.learn_nn_feature_fqi FQI:  67998
nn.learn_nn_feature_fqi FQI:  68998
nn.learn_nn_feature_fqi FQI:  69998
nn.learn_nn_feature_fqi FQI:  70998
nn.learn_nn_feature_fqi FQI:  71998
nn.learn_nn_feature_fqi FQI:  72998
nn.learn_nn_feature_fqi FQI:  73998
nn.learn_nn_feature_fqi FQI:  74998
nn.learn_nn_feature_fqi FQI:  75998
nn.learn_nn_feature_fqi FQI:  76998
nn.learn_nn_feature_fqi FQI:  77998
nn.learn_nn_feature_fqi FQI:  78998
nn.learn_nn_feature_fqi FQI:  79998
nn.learn_nn_feature_fqi FQI:  80998
nn.learn_nn_feature_fqi FQI:  81998
nn.learn_nn_feature_fqi FQI:  82998
nn.learn_nn_feature_fqi FQI:  83998
nn.learn_nn_feature_fqi FQI:  84998
nn.learn_nn_feature_fqi FQI:  85998
nn.learn_nn_feature_fqi FQI:  86998
nn.learn_nn_feature_fqi FQI:  87998
nn.learn_nn_feature_fqi FQI:  88998
nn.learn_nn_feature_fqi FQI:  89998
nn.learn_nn_feature_fqi FQI:  90998
nn.learn_nn_feature_fqi FQI:  91998
nn.learn_nn_feature_fqi FQI:  92998
nn.learn_nn_feature_fqi FQI:  93998
nn.learn_nn_feature_fqi FQI:  94998
nn.learn_nn_feature_fqi FQI:  95998
nn.learn_nn_feature_fqi FQI:  96998
nn.learn_nn_feature_fqi FQI:  97998
nn.learn_nn_feature_fqi FQI:  98998
nn.learn_nn_feature_fqi FQI:  99998
nn.learn_nn_feature_fqi FQI:  100998
nn.learn_nn_feature_fqi FQI:  101998
nn.learn_nn_feature_fqi FQI:  102998
nn.learn_nn_feature_fqi FQI:  103998
nn.learn_nn_feature_fqi FQI:  104998
nn.learn_nn_feature_fqi FQI:  105998
nn.learn_nn_feature_fqi FQI:  106998
nn.learn_nn_feature_fqi FQI:  107998
nn.learn_nn_feature_fqi FQI:  108998
nn.learn_nn_feature_fqi FQI:  109998
nn.learn_nn_feature_fqi FQI:  110998
nn.learn_nn_feature_fqi FQI:  111998
nn.learn_nn_feature_fqi FQI:  112998
nn.learn_nn_feature_fqi FQI:  113998
nn.learn_nn_feature_fqi FQI:  114998
nn.learn_nn_feature_fqi FQI:  115998
nn.learn_nn_feature_fqi FQI:  116998
nn.learn_nn_feature_fqi FQI:  117998
nn.learn_nn_feature_fqi FQI:  118998
nn.learn_nn_feature_fqi FQI:  119998
nn.learn_nn_feature_fqi FQI:  120998
nn.learn_nn_feature_fqi FQI:  121998
nn.learn_nn_feature_fqi FQI:  122998
nn.learn_nn_feature_fqi FQI:  123998
nn.learn_nn_feature_fqi FQI:  124998
nn.learn_nn_feature_fqi FQI:  125998
nn.learn_nn_feature_fqi FQI:  126998
nn.learn_nn_feature_fqi FQI:  127998
nn.learn_nn_feature_fqi FQI:  128998
nn.learn_nn_feature_fqi FQI:  129998
nn.learn_nn_feature_fqi FQI:  130998
nn.learn_nn_feature_fqi FQI:  131998
nn.learn_nn_feature_fqi FQI:  132998
nn.learn_nn_feature_fqi FQI:  133998
nn.learn_nn_feature_fqi FQI:  134998
nn.learn_nn_feature_fqi FQI:  135998
nn.learn_nn_feature_fqi FQI:  136998
nn.learn_nn_feature_fqi FQI:  137998
nn.learn_nn_feature_fqi FQI:  138998
nn.learn_nn_feature_fqi FQI:  139998
nn.learn_nn_feature_fqi FQI:  140998
nn.learn_nn_feature_fqi FQI:  141998
nn.learn_nn_feature_fqi FQI:  142998
nn.learn_nn_feature_fqi FQI:  143998
nn.learn_nn_feature_fqi FQI:  144998
nn.learn_nn_feature_fqi FQI:  145998
nn.learn_nn_feature_fqi FQI:  146998
nn.learn_nn_feature_fqi FQI:  147998
nn.learn_nn_feature_fqi FQI:  148998
nn.learn_nn_feature_fqi FQI:  149998
nn.learn_nn_feature_fqi FQI:  150998
nn.learn_nn_feature_fqi FQI:  151998
nn.learn_nn_feature_fqi FQI:  152998
nn.learn_nn_feature_fqi FQI:  153998
nn.learn_nn_feature_fqi FQI:  154998
nn.learn_nn_feature_fqi FQI:  155998
/project/6029407/janjua/Offline-Online-RL-Augmentation/Offline-Online-RL/mix_ttn_agent_online_offline.py:213: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /tmp/coulombc/pytorch_build_2021-11-09_14-57-01/avx2/python3.7/pytorch/torch/csrc/utils/tensor_new.cpp:198.)
  state = T.tensor([observation], dtype=T.float).to(self.q_eval.device)
0 201 -200.0 -85.73601218906167 number episode from 10: 0 avegar over 10 episode: -85.736 avegare return across last 100 episodes: -85.736 state values: tensor(0.6317) 200
1 213 -213.0 -88.24300186575712 number episode from 10: 1 avegar over 10 episode: -86.99 avegare return across last 100 episodes: -86.99 state values: tensor(0.6302) 213
2 203 -203.0 -86.99996554649934 number episode from 10: 2 avegar over 10 episode: -86.993 avegare return across last 100 episodes: -86.993 state values: tensor(0.6321) 203
3 206 -206.0 -87.38607956980276 number episode from 10: 3 avegar over 10 episode: -87.091 avegare return across last 100 episodes: -87.091 state values: tensor(0.6299) 206
4 207 -207.0 -87.51221877410474 number episode from 10: 4 avegar over 10 episode: -87.175 avegare return across last 100 episodes: -87.175 state values: tensor(0.6296) 207
5 200 -200.0 -86.6020325142037 number episode from 10: 5 avegar over 10 episode: -87.08 avegare return across last 100 episodes: -87.08 state values: tensor(0.6316) 200
6 204 -204.0 -87.12996589103435 number episode from 10: 6 avegar over 10 episode: -87.087 avegare return across last 100 episodes: -87.087 state values: tensor(0.6320) 204
7 202 -202.0 -86.86865206717106 number episode from 10: 7 avegar over 10 episode: -87.06 avegare return across last 100 episodes: -87.06 state values: tensor(0.6326) 202
8 204 -204.0 -87.12996589103435 number episode from 10: 8 avegar over 10 episode: -87.068 avegare return across last 100 episodes: -87.068 state values: tensor(0.6325) 204
9 174 -174.0 -82.60101715237347 number episode from 10: 9 avegar over 10 episode: -86.621 avegare return across last 100 episodes: -86.621 state values: tensor(0.6459) 174
10 209 -209.0 -87.76072562050005 number episode from 10: 10 avegar over 10 episode: -86.725 avegare return across last 100 episodes: -86.725 state values: tensor(0.6353) 209
11 203 -203.0 -86.99996554649934 number episode from 10: 11 avegar over 10 episode: -86.747 avegare return across last 100 episodes: -86.747 state values: tensor(0.6300) 203
12 199 -199.0 -86.46669950929667 number episode from 10: 12 avegar over 10 episode: -86.726 avegare return across last 100 episodes: -86.726 state values: tensor(0.6376) 199
13 208 -208.0 -87.6370965863637 number episode from 10: 13 avegar over 10 episode: -86.791 avegare return across last 100 episodes: -86.791 state values: tensor(0.6337) 208
14 211 -211.0 -88.0042871806521 number episode from 10: 14 avegar over 10 episode: -86.872 avegare return across last 100 episodes: -86.872 state values: tensor(0.6284) 211
15 210 -210.0 -87.88311836429506 number episode from 10: 15 avegar over 10 episode: -86.935 avegare return across last 100 episodes: -86.935 state values: tensor(0.6288) 210
16 193 -193.0 -85.6255062846374 number episode from 10: 16 avegar over 10 episode: -86.858 avegare return across last 100 episodes: -86.858 state values: tensor(0.6391) 193
17 207 -207.0 -87.51221877410474 number episode from 10: 17 avegar over 10 episode: -86.894 avegare return across last 100 episodes: -86.894 state values: tensor(0.6324) 207
18 207 -207.0 -87.51221877410474 number episode from 10: 18 avegar over 10 episode: -86.927 avegare return across last 100 episodes: -86.927 state values: tensor(0.6308) 207
19 210 -210.0 -87.88311836429506 number episode from 10: 19 avegar over 10 episode: -86.975 avegare return across last 100 episodes: -86.975 state values: tensor(0.6304) 210
20 198 -198.0 -86.32999950434008 number episode from 10: 20 avegar over 10 episode: -86.944 avegare return across last 100 episodes: -86.944 state values: tensor(0.6327) 198
21 217 -217.0 -88.70627450266883 number episode from 10: 21 avegar over 10 episode: -87.024 avegare return across last 100 episodes: -87.024 state values: tensor(0.6282) 217
22 213 -213.0 -88.24300186575712 number episode from 10: 22 avegar over 10 episode: -87.077 avegare return across last 100 episodes: -87.077 state values: tensor(0.6270) 213
23 201 -201.0 -86.73601218906167 number episode from 10: 23 avegar over 10 episode: -87.063 avegare return across last 100 episodes: -87.063 state values: tensor(0.6316) 201
24 196 -196.0 -86.05244312247738 number episode from 10: 24 avegar over 10 episode: -87.022 avegare return across last 100 episodes: -87.022 state values: tensor(0.6392) 196
25 209 -209.0 -87.76072562050005 number episode from 10: 25 avegar over 10 episode: -87.051 avegare return across last 100 episodes: -87.051 state values: tensor(0.6317) 209
26 213 -213.0 -88.24300186575712 number episode from 10: 26 avegar over 10 episode: -87.095 avegare return across last 100 episodes: -87.095 state values: tensor(0.6285) 213
27 214 -214.0 -88.36057184709955 number episode from 10: 27 avegar over 10 episode: -87.14 avegare return across last 100 episodes: -87.14 state values: tensor(0.6281) 214
28 199 -199.0 -86.46669950929667 number episode from 10: 28 avegar over 10 episode: -87.117 avegare return across last 100 episodes: -87.117 state values: tensor(0.6326) 199
29 211 -211.0 -88.0042871806521 number episode from 10: 29 avegar over 10 episode: -87.147 avegare return across last 100 episodes: -87.147 state values: tensor(0.6386) 211
30 209 -209.0 -87.76072562050005 number episode from 10: 30 avegar over 10 episode: -87.166 avegare return across last 100 episodes: -87.166 state values: tensor(0.6338) 209
31 203 -203.0 -86.99996554649934 number episode from 10: 31 avegar over 10 episode: -87.161 avegare return across last 100 episodes: -87.161 state values: tensor(0.6313) 203
32 214 -214.0 -88.36057184709955 number episode from 10: 32 avegar over 10 episode: -87.198 avegare return across last 100 episodes: -87.198 state values: tensor(0.6292) 214
33 206 -206.0 -87.38607956980276 number episode from 10: 33 avegar over 10 episode: -87.203 avegare return across last 100 episodes: -87.203 state values: tensor(0.6343) 206
34 201 -201.0 -86.73601218906167 number episode from 10: 34 avegar over 10 episode: -87.19 avegare return across last 100 episodes: -87.19 state values: tensor(0.6330) 201
35 206 -206.0 -87.38607956980276 number episode from 10: 35 avegar over 10 episode: -87.195 avegare return across last 100 episodes: -87.195 state values: tensor(0.6282) 206
36 210 -210.0 -87.88311836429506 number episode from 10: 36 avegar over 10 episode: -87.214 avegare return across last 100 episodes: -87.214 state values: tensor(0.6316) 210
37 216 -216.0 -88.59219646734226 number episode from 10: 37 avegar over 10 episode: -87.25 avegare return across last 100 episodes: -87.25 state values: tensor(0.6218) 216
38 200 -200.0 -86.6020325142037 number episode from 10: 38 avegar over 10 episode: -87.233 avegare return across last 100 episodes: -87.233 state values: tensor(0.6326) 200
39 201 -201.0 -86.73601218906167 number episode from 10: 39 avegar over 10 episode: -87.221 avegare return across last 100 episodes: -87.221 state values: tensor(0.6346) 201
40 202 -202.0 -86.86865206717106 number episode from 10: 40 avegar over 10 episode: -87.212 avegare return across last 100 episodes: -87.212 state values: tensor(0.6330) 202
41 211 -211.0 -88.0042871806521 number episode from 10: 41 avegar over 10 episode: -87.231 avegare return across last 100 episodes: -87.231 state values: tensor(0.6287) 211
42 209 -209.0 -87.76072562050005 number episode from 10: 42 avegar over 10 episode: -87.244 avegare return across last 100 episodes: -87.244 state values: tensor(0.6257) 209
43 207 -207.0 -87.51221877410474 number episode from 10: 43 avegar over 10 episode: -87.25 avegare return across last 100 episodes: -87.25 state values: tensor(0.6268) 207
44 210 -210.0 -87.88311836429506 number episode from 10: 44 avegar over 10 episode: -87.264 avegare return across last 100 episodes: -87.264 state values: tensor(0.6287) 210
45 204 -204.0 -87.12996589103435 number episode from 10: 45 avegar over 10 episode: -87.261 avegare return across last 100 episodes: -87.261 state values: tensor(0.6360) 204
46 209 -209.0 -87.76072562050005 number episode from 10: 46 avegar over 10 episode: -87.271 avegare return across last 100 episodes: -87.271 state values: tensor(0.6297) 209
47 200 -200.0 -86.6020325142037 number episode from 10: 47 avegar over 10 episode: -87.258 avegare return across last 100 episodes: -87.258 state values: tensor(0.6334) 200
48 198 -198.0 -86.32999950434008 number episode from 10: 48 avegar over 10 episode: -87.239 avegare return across last 100 episodes: -87.239 state values: tensor(0.6352) 198
49 211 -211.0 -88.0042871806521 number episode from 10: 49 avegar over 10 episode: -87.254 avegare return across last 100 episodes: -87.254 state values: tensor(0.6305) 211
50 207 -207.0 -87.51221877410474 number episode from 10: 50 avegar over 10 episode: -87.259 avegare return across last 100 episodes: -87.259 state values: tensor(0.6304) 207
51 197 -197.0 -86.19191869125261 number episode from 10: 51 avegar over 10 episode: -87.238 avegare return across last 100 episodes: -87.238 state values: tensor(0.6384) 197
52 212 -212.0 -88.12424430884558 number episode from 10: 52 avegar over 10 episode: -87.255 avegare return across last 100 episodes: -87.255 state values: tensor(0.6303) 212
53 210 -210.0 -87.88311836429506 number episode from 10: 53 avegar over 10 episode: -87.267 avegare return across last 100 episodes: -87.267 state values: tensor(0.6327) 210
54 199 -199.0 -86.46669950929667 number episode from 10: 54 avegar over 10 episode: -87.252 avegare return across last 100 episodes: -87.252 state values: tensor(0.6344) 199
55 211 -211.0 -88.0042871806521 number episode from 10: 55 avegar over 10 episode: -87.266 avegare return across last 100 episodes: -87.266 state values: tensor(0.6275) 211
56 201 -201.0 -86.73601218906167 number episode from 10: 56 avegar over 10 episode: -87.256 avegare return across last 100 episodes: -87.256 state values: tensor(0.6326) 201
57 204 -204.0 -87.12996589103435 number episode from 10: 57 avegar over 10 episode: -87.254 avegare return across last 100 episodes: -87.254 state values: tensor(0.6274) 204
58 208 -208.0 -87.6370965863637 number episode from 10: 58 avegar over 10 episode: -87.261 avegare return across last 100 episodes: -87.261 state values: tensor(0.6293) 208
59 199 -199.0 -86.46669950929667 number episode from 10: 59 avegar over 10 episode: -87.247 avegare return across last 100 episodes: -87.247 state values: tensor(0.6356) 199
60 208 -208.0 -87.6370965863637 number episode from 10: 60 avegar over 10 episode: -87.254 avegare return across last 100 episodes: -87.254 state values: tensor(0.6298) 208
61 210 -210.0 -87.88311836429506 number episode from 10: 61 avegar over 10 episode: -87.264 avegare return across last 100 episodes: -87.264 state values: tensor(0.6319) 210
62 200 -200.0 -86.6020325142037 number episode from 10: 62 avegar over 10 episode: -87.253 avegare return across last 100 episodes: -87.253 state values: tensor(0.6316) 200
63 207 -207.0 -87.51221877410474 number episode from 10: 63 avegar over 10 episode: -87.258 avegare return across last 100 episodes: -87.258 state values: tensor(0.6270) 207
64 205 -205.0 -87.258666232124 number episode from 10: 64 avegar over 10 episode: -87.258 avegare return across last 100 episodes: -87.258 state values: tensor(0.6395) 205
65 217 -217.0 -88.70627450266883 number episode from 10: 65 avegar over 10 episode: -87.28 avegare return across last 100 episodes: -87.28 state values: tensor(0.6305) 217
66 208 -208.0 -87.6370965863637 number episode from 10: 66 avegar over 10 episode: -87.285 avegare return across last 100 episodes: -87.285 state values: tensor(0.6347) 208
67 201 -201.0 -86.73601218906167 number episode from 10: 67 avegar over 10 episode: -87.277 avegare return across last 100 episodes: -87.277 state values: tensor(0.6338) 201
68 209 -209.0 -87.76072562050005 number episode from 10: 68 avegar over 10 episode: -87.284 avegare return across last 100 episodes: -87.284 state values: tensor(0.6310) 209
69 207 -207.0 -87.51221877410474 number episode from 10: 69 avegar over 10 episode: -87.287 avegare return across last 100 episodes: -87.287 state values: tensor(0.6305) 207
70 203 -203.0 -86.99996554649934 number episode from 10: 70 avegar over 10 episode: -87.283 avegare return across last 100 episodes: -87.283 state values: tensor(0.6351) 203
71 212 -212.0 -88.12424430884558 number episode from 10: 71 avegar over 10 episode: -87.295 avegare return across last 100 episodes: -87.295 state values: tensor(0.6284) 212
72 209 -209.0 -87.76072562050005 number episode from 10: 72 avegar over 10 episode: -87.301 avegare return across last 100 episodes: -87.301 state values: tensor(0.6351) 209
73 197 -197.0 -86.19191869125261 number episode from 10: 73 avegar over 10 episode: -87.286 avegare return across last 100 episodes: -87.286 state values: tensor(0.6352) 197
74 194 -194.0 -85.76925122179102 number episode from 10: 74 avegar over 10 episode: -87.266 avegare return across last 100 episodes: -87.266 state values: tensor(0.6353) 194
75 212 -212.0 -88.12424430884558 number episode from 10: 75 avegar over 10 episode: -87.277 avegare return across last 100 episodes: -87.277 state values: tensor(0.6302) 212
76 211 -211.0 -88.0042871806521 number episode from 10: 76 avegar over 10 episode: -87.287 avegare return across last 100 episodes: -87.287 state values: tensor(0.6316) 211
77 212 -212.0 -88.12424430884558 number episode from 10: 77 avegar over 10 episode: -87.297 avegare return across last 100 episodes: -87.297 state values: tensor(0.6288) 212
78 209 -209.0 -87.76072562050005 number episode from 10: 78 avegar over 10 episode: -87.303 avegare return across last 100 episodes: -87.303 state values: tensor(0.6299) 209
79 210 -210.0 -87.88311836429506 number episode from 10: 79 avegar over 10 episode: -87.31 avegare return across last 100 episodes: -87.31 state values: tensor(0.6306) 210
80 206 -206.0 -87.38607956980276 number episode from 10: 80 avegar over 10 episode: -87.311 avegare return across last 100 episodes: -87.311 state values: tensor(0.6288) 206
81 197 -197.0 -86.19191869125261 number episode from 10: 81 avegar over 10 episode: -87.298 avegare return across last 100 episodes: -87.298 state values: tensor(0.6347) 197
82 187 -187.0 -84.73202677240926 number episode from 10: 82 avegar over 10 episode: -87.267 avegare return across last 100 episodes: -87.267 state values: tensor(0.6460) 187
83 198 -198.0 -86.32999950434008 number episode from 10: 83 avegar over 10 episode: -87.256 avegare return across last 100 episodes: -87.256 state values: tensor(0.6351) 198
84 214 -214.0 -88.36057184709955 number episode from 10: 84 avegar over 10 episode: -87.269 avegare return across last 100 episodes: -87.269 state values: tensor(0.6300) 214
85 211 -211.0 -88.0042871806521 number episode from 10: 85 avegar over 10 episode: -87.277 avegare return across last 100 episodes: -87.277 state values: tensor(0.6308) 211
86 202 -202.0 -86.86865206717106 number episode from 10: 86 avegar over 10 episode: -87.273 avegare return across last 100 episodes: -87.273 state values: tensor(0.6331) 202
87 208 -208.0 -87.6370965863637 number episode from 10: 87 avegar over 10 episode: -87.277 avegare return across last 100 episodes: -87.277 state values: tensor(0.6314) 208
88 197 -197.0 -86.19191869125261 number episode from 10: 88 avegar over 10 episode: -87.264 avegare return across last 100 episodes: -87.264 state values: tensor(0.6361) 197
89 209 -209.0 -87.76072562050005 number episode from 10: 89 avegar over 10 episode: -87.27 avegare return across last 100 episodes: -87.27 state values: tensor(0.6306) 209
90 201 -201.0 -86.73601218906167 number episode from 10: 90 avegar over 10 episode: -87.264 avegare return across last 100 episodes: -87.264 state values: tensor(0.6310) 201
91 212 -212.0 -88.12424430884558 number episode from 10: 91 avegar over 10 episode: -87.273 avegare return across last 100 episodes: -87.273 state values: tensor(0.6332) 212
92 207 -207.0 -87.51221877410474 number episode from 10: 92 avegar over 10 episode: -87.276 avegare return across last 100 episodes: -87.276 state values: tensor(0.6319) 207
93 216 -216.0 -88.59219646734226 number episode from 10: 93 avegar over 10 episode: -87.29 avegare return across last 100 episodes: -87.29 state values: tensor(0.6275) 216
94 201 -201.0 -86.73601218906167 number episode from 10: 94 avegar over 10 episode: -87.284 avegare return across last 100 episodes: -87.284 state values: tensor(0.6324) 201
95 209 -209.0 -87.76072562050005 number episode from 10: 95 avegar over 10 episode: -87.289 avegare return across last 100 episodes: -87.289 state values: tensor(0.6326) 209
96 210 -210.0 -87.88311836429506 number episode from 10: 96 avegar over 10 episode: -87.295 avegare return across last 100 episodes: -87.295 state values: tensor(0.6334) 210
97 212 -212.0 -88.12424430884558 number episode from 10: 97 avegar over 10 episode: -87.304 avegare return across last 100 episodes: -87.304 state values: tensor(0.6265) 212
98 210 -210.0 -87.88311836429506 number episode from 10: 98 avegar over 10 episode: -87.31 avegare return across last 100 episodes: -87.31 state values: tensor(0.6350) 210
99 182 -182.0 -83.94518088891023 number episode from 10: 99 avegar over 10 episode: -87.276 avegare return across last 100 episodes: -87.276 state values: tensor(0.6406) 182
100 199 -199.0 -86.46669950929667 number episode from 10: 100 avegar over 10 episode: -87.268 avegare return across last 100 episodes: -87.283 state values: tensor(0.6374) 199
101 205 -205.0 -87.258666232124 number episode from 10: 101 avegar over 10 episode: -87.268 avegare return across last 100 episodes: -87.273 state values: tensor(0.6323) 205
102 203 -203.0 -86.99996554649934 number episode from 10: 102 avegar over 10 episode: -87.265 avegare return across last 100 episodes: -87.273 state values: tensor(0.6321) 203
103 211 -211.0 -88.0042871806521 number episode from 10: 103 avegar over 10 episode: -87.272 avegare return across last 100 episodes: -87.28 state values: tensor(0.6303) 211
104 209 -209.0 -87.76072562050005 number episode from 10: 104 avegar over 10 episode: -87.277 avegare return across last 100 episodes: -87.282 state values: tensor(0.6279) 209
105 207 -207.0 -87.51221877410474 number episode from 10: 105 avegar over 10 episode: -87.279 avegare return across last 100 episodes: -87.291 state values: tensor(0.6255) 207
106 198 -198.0 -86.32999950434008 number episode from 10: 106 avegar over 10 episode: -87.27 avegare return across last 100 episodes: -87.283 state values: tensor(0.6380) 198
107 209 -209.0 -87.76072562050005 number episode from 10: 107 avegar over 10 episode: -87.275 avegare return across last 100 episodes: -87.292 state values: tensor(0.6239) 209
108 196 -196.0 -86.05244312247738 number episode from 10: 108 avegar over 10 episode: -87.264 avegare return across last 100 episodes: -87.281 state values: tensor(0.6354) 196
109 206 -206.0 -87.38607956980276 number episode from 10: 109 avegar over 10 episode: -87.265 avegare return across last 100 episodes: -87.329 state values: tensor(0.6306) 206
110 208 -208.0 -87.6370965863637 number episode from 10: 110 avegar over 10 episode: -87.268 avegare return across last 100 episodes: -87.328 state values: tensor(0.6302) 208
111 205 -205.0 -87.258666232124 number episode from 10: 111 avegar over 10 episode: -87.268 avegare return across last 100 episodes: -87.331 state values: tensor(0.6320) 205
112 201 -201.0 -86.73601218906167 number episode from 10: 112 avegar over 10 episode: -87.263 avegare return across last 100 episodes: -87.333 state values: tensor(0.6337) 201
113 208 -208.0 -87.6370965863637 number episode from 10: 113 avegar over 10 episode: -87.267 avegare return across last 100 episodes: -87.333 state values: tensor(0.6306) 208
114 209 -209.0 -87.76072562050005 number episode from 10: 114 avegar over 10 episode: -87.271 avegare return across last 100 episodes: -87.331 state values: tensor(0.6353) 209
115 212 -212.0 -88.12424430884558 number episode from 10: 115 avegar over 10 episode: -87.278 avegare return across last 100 episodes: -87.333 state values: tensor(0.6310) 212
116 209 -209.0 -87.76072562050005 number episode from 10: 116 avegar over 10 episode: -87.282 avegare return across last 100 episodes: -87.355 state values: tensor(0.6349) 209
117 209 -209.0 -87.76072562050005 number episode from 10: 117 avegar over 10 episode: -87.286 avegare return across last 100 episodes: -87.357 state values: tensor(0.6251) 209
118 211 -211.0 -88.0042871806521 number episode from 10: 118 avegar over 10 episode: -87.293 avegare return across last 100 episodes: -87.362 state values: tensor(0.6258) 211
119 205 -205.0 -87.258666232124 number episode from 10: 119 avegar over 10 episode: -87.292 avegare return across last 100 episodes: -87.356 state values: tensor(0.6316) 205
120 213 -213.0 -88.24300186575712 number episode from 10: 120 avegar over 10 episode: -87.3 avegare return across last 100 episodes: -87.375 state values: tensor(0.6289) 213
121 212 -212.0 -88.12424430884558 number episode from 10: 121 avegar over 10 episode: -87.307 avegare return across last 100 episodes: -87.369 state values: tensor(0.6241) 212
122 205 -205.0 -87.258666232124 number episode from 10: 122 avegar over 10 episode: -87.306 avegare return across last 100 episodes: -87.359 state values: tensor(0.6361) 205
123 210 -210.0 -87.88311836429506 number episode from 10: 123 avegar over 10 episode: -87.311 avegare return across last 100 episodes: -87.371 state values: tensor(0.6327) 210
124 208 -208.0 -87.6370965863637 number episode from 10: 124 avegar over 10 episode: -87.314 avegare return across last 100 episodes: -87.387 state values: tensor(0.6324) 208
125 204 -204.0 -87.12996589103435 number episode from 10: 125 avegar over 10 episode: -87.312 avegare return across last 100 episodes: -87.38 state values: tensor(0.6345) 204
126 203 -203.0 -86.99996554649934 number episode from 10: 126 avegar over 10 episode: -87.31 avegare return across last 100 episodes: -87.368 state values: tensor(0.6302) 203
127 204 -204.0 -87.12996589103435 number episode from 10: 127 avegar over 10 episode: -87.308 avegare return across last 100 episodes: -87.355 state values: tensor(0.6318) 204
128 208 -208.0 -87.6370965863637 number episode from 10: 128 avegar over 10 episode: -87.311 avegare return across last 100 episodes: -87.367 state values: tensor(0.6264) 208
129 211 -211.0 -88.0042871806521 number episode from 10: 129 avegar over 10 episode: -87.316 avegare return across last 100 episodes: -87.367 state values: tensor(0.6300) 211
130 212 -212.0 -88.12424430884558 number episode from 10: 130 avegar over 10 episode: -87.322 avegare return across last 100 episodes: -87.371 state values: tensor(0.6307) 212
131 214 -214.0 -88.36057184709955 number episode from 10: 131 avegar over 10 episode: -87.33 avegare return across last 100 episodes: -87.384 state values: tensor(0.6250) 214
132 199 -199.0 -86.46669950929667 number episode from 10: 132 avegar over 10 episode: -87.324 avegare return across last 100 episodes: -87.365 state values: tensor(0.6358) 199
133 198 -198.0 -86.32999950434008 number episode from 10: 133 avegar over 10 episode: -87.316 avegare return across last 100 episodes: -87.355 state values: tensor(0.6382) 198
134 209 -209.0 -87.76072562050005 number episode from 10: 134 avegar over 10 episode: -87.32 avegare return across last 100 episodes: -87.365 state values: tensor(0.6330) 209
135 206 -206.0 -87.38607956980276 number episode from 10: 135 avegar over 10 episode: -87.32 avegare return across last 100 episodes: -87.365 state values: tensor(0.6349) 206
136 211 -211.0 -88.0042871806521 number episode from 10: 136 avegar over 10 episode: -87.325 avegare return across last 100 episodes: -87.366 state values: tensor(0.6284) 211
137 199 -199.0 -86.46669950929667 number episode from 10: 137 avegar over 10 episode: -87.319 avegare return across last 100 episodes: -87.345 state values: tensor(0.6340) 199
138 198 -198.0 -86.32999950434008 number episode from 10: 138 avegar over 10 episode: -87.312 avegare return across last 100 episodes: -87.342 state values: tensor(0.6352) 198
139 209 -209.0 -87.76072562050005 number episode from 10: 139 avegar over 10 episode: -87.315 avegare return across last 100 episodes: -87.353 state values: tensor(0.6266) 209
140 205 -205.0 -87.258666232124 number episode from 10: 140 avegar over 10 episode: -87.315 avegare return across last 100 episodes: -87.357 state values: tensor(0.6311) 205
141 214 -214.0 -88.36057184709955 number episode from 10: 141 avegar over 10 episode: -87.322 avegare return across last 100 episodes: -87.36 state values: tensor(0.6290) 214
142 206 -206.0 -87.38607956980276 number episode from 10: 142 avegar over 10 episode: -87.322 avegare return across last 100 episodes: -87.356 state values: tensor(0.6331) 206
143 209 -209.0 -87.76072562050005 number episode from 10: 143 avegar over 10 episode: -87.325 avegare return across last 100 episodes: -87.359 state values: tensor(0.6281) 209
144 209 -209.0 -87.76072562050005 number episode from 10: 144 avegar over 10 episode: -87.328 avegare return across last 100 episodes: -87.358 state values: tensor(0.6303) 209
145 200 -200.0 -86.6020325142037 number episode from 10: 145 avegar over 10 episode: -87.324 avegare return across last 100 episodes: -87.352 state values: tensor(0.6324) 200
146 210 -210.0 -87.88311836429506 number episode from 10: 146 avegar over 10 episode: -87.327 avegare return across last 100 episodes: -87.354 state values: tensor(0.6310) 210
147 203 -203.0 -86.99996554649934 number episode from 10: 147 avegar over 10 episode: -87.325 avegare return across last 100 episodes: -87.358 state values: tensor(0.6393) 203
148 194 -194.0 -85.76925122179102 number episode from 10: 148 avegar over 10 episode: -87.315 avegare return across last 100 episodes: -87.352 state values: tensor(0.6365) 194
149 208 -208.0 -87.6370965863637 number episode from 10: 149 avegar over 10 episode: -87.317 avegare return across last 100 episodes: -87.348 state values: tensor(0.6260) 208
150 204 -204.0 -87.12996589103435 number episode from 10: 150 avegar over 10 episode: -87.316 avegare return across last 100 episodes: -87.344 state values: tensor(0.6312) 204
151 202 -202.0 -86.86865206717106 number episode from 10: 151 avegar over 10 episode: -87.313 avegare return across last 100 episodes: -87.351 state values: tensor(0.6298) 202
152 199 -199.0 -86.46669950929667 number episode from 10: 152 avegar over 10 episode: -87.307 avegare return across last 100 episodes: -87.335 state values: tensor(0.6313) 199
153 210 -210.0 -87.88311836429506 number episode from 10: 153 avegar over 10 episode: -87.311 avegare return across last 100 episodes: -87.335 state values: tensor(0.6365) 210
154 173 -173.0 -82.4252698508823 number episode from 10: 154 avegar over 10 episode: -87.279 avegare return across last 100 episodes: -87.294 state values: tensor(0.6526) 173
155 199 -199.0 -86.46669950929667 number episode from 10: 155 avegar over 10 episode: -87.274 avegare return across last 100 episodes: -87.279 state values: tensor(0.6333) 199
156 199 -199.0 -86.46669950929667 number episode from 10: 156 avegar over 10 episode: -87.269 avegare return across last 100 episodes: -87.276 state values: tensor(0.6331) 199
157 209 -209.0 -87.76072562050005 number episode from 10: 157 avegar over 10 episode: -87.272 avegare return across last 100 episodes: -87.282 state values: tensor(0.6350) 209
158 207 -207.0 -87.51221877410474 number episode from 10: 158 avegar over 10 episode: -87.274 avegare return across last 100 episodes: -87.281 state values: tensor(0.6319) 207
159 205 -205.0 -87.258666232124 number episode from 10: 159 avegar over 10 episode: -87.274 avegare return across last 100 episodes: -87.289 state values: tensor(0.6369) 205
160 210 -210.0 -87.88311836429506 number episode from 10: 160 avegar over 10 episode: -87.277 avegare return across last 100 episodes: -87.292 state values: tensor(0.6276) 210
161 200 -200.0 -86.6020325142037 number episode from 10: 161 avegar over 10 episode: -87.273 avegare return across last 100 episodes: -87.279 state values: tensor(0.6320) 200
162 205 -205.0 -87.258666232124 number episode from 10: 162 avegar over 10 episode: -87.273 avegare return across last 100 episodes: -87.285 state values: tensor(0.6311) 205
163 210 -210.0 -87.88311836429506 number episode from 10: 163 avegar over 10 episode: -87.277 avegare return across last 100 episodes: -87.289 state values: tensor(0.6266) 210
164 209 -209.0 -87.76072562050005 number episode from 10: 164 avegar over 10 episode: -87.28 avegare return across last 100 episodes: -87.294 state values: tensor(0.6314) 209
165 203 -203.0 -86.99996554649934 number episode from 10: 165 avegar over 10 episode: -87.278 avegare return across last 100 episodes: -87.277 state values: tensor(0.6332) 203
166 201 -201.0 -86.73601218906167 number episode from 10: 166 avegar over 10 episode: -87.275 avegare return across last 100 episodes: -87.268 state values: tensor(0.6299) 201
167 209 -209.0 -87.76072562050005 number episode from 10: 167 avegar over 10 episode: -87.278 avegare return across last 100 episodes: -87.278 state values: tensor(0.6309) 209
168 201 -201.0 -86.73601218906167 number episode from 10: 168 avegar over 10 episode: -87.274 avegare return across last 100 episodes: -87.268 state values: tensor(0.6300) 201
169 198 -198.0 -86.32999950434008 number episode from 10: 169 avegar over 10 episode: -87.269 avegare return across last 100 episodes: -87.256 state values: tensor(0.6335) 198
170 197 -197.0 -86.19191869125261 number episode from 10: 170 avegar over 10 episode: -87.263 avegare return across last 100 episodes: -87.248 state values: tensor(0.6349) 197
171 203 -203.0 -86.99996554649934 number episode from 10: 171 avegar over 10 episode: -87.261 avegare return across last 100 episodes: -87.237 state values: tensor(0.6314) 203
172 207 -207.0 -87.51221877410474 number episode from 10: 172 avegar over 10 episode: -87.263 avegare return across last 100 episodes: -87.234 state values: tensor(0.6337) 207
173 198 -198.0 -86.32999950434008 number episode from 10: 173 avegar over 10 episode: -87.257 avegare return across last 100 episodes: -87.236 state values: tensor(0.6360) 198
174 208 -208.0 -87.6370965863637 number episode from 10: 174 avegar over 10 episode: -87.259 avegare return across last 100 episodes: -87.254 state values: tensor(0.6308) 208
175 210 -210.0 -87.88311836429506 number episode from 10: 175 avegar over 10 episode: -87.263 avegare return across last 100 episodes: -87.252 state values: tensor(0.6301) 210
176 207 -207.0 -87.51221877410474 number episode from 10: 176 avegar over 10 episode: -87.264 avegare return across last 100 episodes: -87.247 state values: tensor(0.6302) 207
177 209 -209.0 -87.76072562050005 number episode from 10: 177 avegar over 10 episode: -87.267 avegare return across last 100 episodes: -87.243 state values: tensor(0.6334) 209
178 214 -214.0 -88.36057184709955 number episode from 10: 178 avegar over 10 episode: -87.273 avegare return across last 100 episodes: -87.249 state values: tensor(0.6223) 214
179 201 -201.0 -86.73601218906167 number episode from 10: 179 avegar over 10 episode: -87.27 avegare return across last 100 episodes: -87.238 state values: tensor(0.6326) 201
180 203 -203.0 -86.99996554649934 number episode from 10: 180 avegar over 10 episode: -87.269 avegare return across last 100 episodes: -87.234 state values: tensor(0.6323) 203
181 202 -202.0 -86.86865206717106 number episode from 10: 181 avegar over 10 episode: -87.267 avegare return across last 100 episodes: -87.241 state values: tensor(0.6332) 202
182 208 -208.0 -87.6370965863637 number episode from 10: 182 avegar over 10 episode: -87.269 avegare return across last 100 episodes: -87.27 state values: tensor(0.6270) 208
183 197 -197.0 -86.19191869125261 number episode from 10: 183 avegar over 10 episode: -87.263 avegare return across last 100 episodes: -87.269 state values: tensor(0.6365) 197
184 202 -202.0 -86.86865206717106 number episode from 10: 184 avegar over 10 episode: -87.261 avegare return across last 100 episodes: -87.254 state values: tensor(0.6318) 202
185 211 -211.0 -88.0042871806521 number episode from 10: 185 avegar over 10 episode: -87.265 avegare return across last 100 episodes: -87.254 state values: tensor(0.6291) 211
186 207 -207.0 -87.51221877410474 number episode from 10: 186 avegar over 10 episode: -87.266 avegare return across last 100 episodes: -87.26 state values: tensor(0.6303) 207
187 209 -209.0 -87.76072562050005 number episode from 10: 187 avegar over 10 episode: -87.269 avegare return across last 100 episodes: -87.261 state values: tensor(0.6353) 209
188 198 -198.0 -86.32999950434008 number episode from 10: 188 avegar over 10 episode: -87.264 avegare return across last 100 episodes: -87.263 state values: tensor(0.6331) 198
189 207 -207.0 -87.51221877410474 number episode from 10: 189 avegar over 10 episode: -87.265 avegare return across last 100 episodes: -87.26 state values: tensor(0.6337) 207
190 214 -214.0 -88.36057184709955 number episode from 10: 190 avegar over 10 episode: -87.271 avegare return across last 100 episodes: -87.276 state values: tensor(0.6271) 214
191 200 -200.0 -86.6020325142037 number episode from 10: 191 avegar over 10 episode: -87.267 avegare return across last 100 episodes: -87.261 state values: tensor(0.6316) 200
192 202 -202.0 -86.86865206717106 number episode from 10: 192 avegar over 10 episode: -87.265 avegare return across last 100 episodes: -87.255 state values: tensor(0.6323) 202
193 178 -178.0 -83.28660649851152 number episode from 10: 193 avegar over 10 episode: -87.245 avegare return across last 100 episodes: -87.202 state values: tensor(0.6490) 178
194 207 -207.0 -87.51221877410474 number episode from 10: 194 avegar over 10 episode: -87.246 avegare return across last 100 episodes: -87.21 state values: tensor(0.6323) 207
195 210 -210.0 -87.88311836429506 number episode from 10: 195 avegar over 10 episode: -87.249 avegare return across last 100 episodes: -87.211 state values: tensor(0.6276) 210
196 208 -208.0 -87.6370965863637 number episode from 10: 196 avegar over 10 episode: -87.251 avegare return across last 100 episodes: -87.208 state values: tensor(0.6303) 208
197 201 -201.0 -86.73601218906167 number episode from 10: 197 avegar over 10 episode: -87.249 avegare return across last 100 episodes: -87.194 state values: tensor(0.6347) 201
198 210 -210.0 -87.88311836429506 number episode from 10: 198 avegar over 10 episode: -87.252 avegare return across last 100 episodes: -87.194 state values: tensor(0.6307) 210
199 212 -212.0 -88.12424430884558 number episode from 10: 199 avegar over 10 episode: -87.256 avegare return across last 100 episodes: -87.236 state values: tensor(0.6294) 212
200 219 -219.0 -88.93101964006571 number episode from 10: 200 avegar over 10 episode: -87.264 avegare return across last 100 episodes: -87.261 state values: tensor(0.6206) 219
load offline data!!!!!
mem_cntr: 50000 ; mem_size: 50000
nn.learn_nn_feature_fqi FQI:  998
nn.learn_nn_feature_fqi FQI:  1998
nn.learn_nn_feature_fqi FQI:  2998
nn.learn_nn_feature_fqi FQI:  3998
nn.learn_nn_feature_fqi FQI:  4998
nn.learn_nn_feature_fqi FQI:  5998
nn.learn_nn_feature_fqi FQI:  6998
nn.learn_nn_feature_fqi FQI:  7998
nn.learn_nn_feature_fqi FQI:  8998
nn.learn_nn_feature_fqi FQI:  9998
nn.learn_nn_feature_fqi FQI:  10998
nn.learn_nn_feature_fqi FQI:  11998
nn.learn_nn_feature_fqi FQI:  12998
nn.learn_nn_feature_fqi FQI:  13998
nn.learn_nn_feature_fqi FQI:  14998
nn.learn_nn_feature_fqi FQI:  15998
nn.learn_nn_feature_fqi FQI:  16998
nn.learn_nn_feature_fqi FQI:  17998
nn.learn_nn_feature_fqi FQI:  18998
nn.learn_nn_feature_fqi FQI:  19998
nn.learn_nn_feature_fqi FQI:  20998
nn.learn_nn_feature_fqi FQI:  21998
nn.learn_nn_feature_fqi FQI:  22998
nn.learn_nn_feature_fqi FQI:  23998
nn.learn_nn_feature_fqi FQI:  24998
nn.learn_nn_feature_fqi FQI:  25998
nn.learn_nn_feature_fqi FQI:  26998
nn.learn_nn_feature_fqi FQI:  27998
nn.learn_nn_feature_fqi FQI:  28998
nn.learn_nn_feature_fqi FQI:  29998
nn.learn_nn_feature_fqi FQI:  30998
nn.learn_nn_feature_fqi FQI:  31998
nn.learn_nn_feature_fqi FQI:  32998
nn.learn_nn_feature_fqi FQI:  33998
nn.learn_nn_feature_fqi FQI:  34998
nn.learn_nn_feature_fqi FQI:  35998
nn.learn_nn_feature_fqi FQI:  36998
nn.learn_nn_feature_fqi FQI:  37998
nn.learn_nn_feature_fqi FQI:  38998
nn.learn_nn_feature_fqi FQI:  39998
nn.learn_nn_feature_fqi FQI:  40998
nn.learn_nn_feature_fqi FQI:  41998
nn.learn_nn_feature_fqi FQI:  42998
nn.learn_nn_feature_fqi FQI:  43998
nn.learn_nn_feature_fqi FQI:  44998
nn.learn_nn_feature_fqi FQI:  45998
nn.learn_nn_feature_fqi FQI:  46998
nn.learn_nn_feature_fqi FQI:  47998
nn.learn_nn_feature_fqi FQI:  48998
nn.learn_nn_feature_fqi FQI:  49998
nn.learn_nn_feature_fqi FQI:  50998
nn.learn_nn_feature_fqi FQI:  51998
nn.learn_nn_feature_fqi FQI:  52998
nn.learn_nn_feature_fqi FQI:  53998
nn.learn_nn_feature_fqi FQI:  54998
nn.learn_nn_feature_fqi FQI:  55998
nn.learn_nn_feature_fqi FQI:  56998
nn.learn_nn_feature_fqi FQI:  57998
nn.learn_nn_feature_fqi FQI:  58998
nn.learn_nn_feature_fqi FQI:  59998
nn.learn_nn_feature_fqi FQI:  60998
nn.learn_nn_feature_fqi FQI:  61998
nn.learn_nn_feature_fqi FQI:  62998
nn.learn_nn_feature_fqi FQI:  63998
nn.learn_nn_feature_fqi FQI:  64998
nn.learn_nn_feature_fqi FQI:  65998
nn.learn_nn_feature_fqi FQI:  66998
nn.learn_nn_feature_fqi FQI:  67998
nn.learn_nn_feature_fqi FQI:  68998
nn.learn_nn_feature_fqi FQI:  69998
nn.learn_nn_feature_fqi FQI:  70998
nn.learn_nn_feature_fqi FQI:  71998
nn.learn_nn_feature_fqi FQI:  72998
nn.learn_nn_feature_fqi FQI:  73998
nn.learn_nn_feature_fqi FQI:  74998
nn.learn_nn_feature_fqi FQI:  75998
nn.learn_nn_feature_fqi FQI:  76998
nn.learn_nn_feature_fqi FQI:  77998
nn.learn_nn_feature_fqi FQI:  78998
nn.learn_nn_feature_fqi FQI:  79998
nn.learn_nn_feature_fqi FQI:  80998
nn.learn_nn_feature_fqi FQI:  81998
nn.learn_nn_feature_fqi FQI:  82998
nn.learn_nn_feature_fqi FQI:  83998
nn.learn_nn_feature_fqi FQI:  84998
nn.learn_nn_feature_fqi FQI:  85998
nn.learn_nn_feature_fqi FQI:  86998
nn.learn_nn_feature_fqi FQI:  87998
nn.learn_nn_feature_fqi FQI:  88998
nn.learn_nn_feature_fqi FQI:  89998
nn.learn_nn_feature_fqi FQI:  90998
nn.learn_nn_feature_fqi FQI:  91998
nn.learn_nn_feature_fqi FQI:  92998
nn.learn_nn_feature_fqi FQI:  93998
nn.learn_nn_feature_fqi FQI:  94998
nn.learn_nn_feature_fqi FQI:  95998
nn.learn_nn_feature_fqi FQI:  96998
nn.learn_nn_feature_fqi FQI:  97998
nn.learn_nn_feature_fqi FQI:  98998
nn.learn_nn_feature_fqi FQI:  99998
nn.learn_nn_feature_fqi FQI:  100998
nn.learn_nn_feature_fqi FQI:  101998
nn.learn_nn_feature_fqi FQI:  102998
nn.learn_nn_feature_fqi FQI:  103998
nn.learn_nn_feature_fqi FQI:  104998
nn.learn_nn_feature_fqi FQI:  105998
nn.learn_nn_feature_fqi FQI:  106998
nn.learn_nn_feature_fqi FQI:  107998
nn.learn_nn_feature_fqi FQI:  108998
nn.learn_nn_feature_fqi FQI:  109998
nn.learn_nn_feature_fqi FQI:  110998
nn.learn_nn_feature_fqi FQI:  111998
nn.learn_nn_feature_fqi FQI:  112998
nn.learn_nn_feature_fqi FQI:  113998
nn.learn_nn_feature_fqi FQI:  114998
nn.learn_nn_feature_fqi FQI:  115998
nn.learn_nn_feature_fqi FQI:  116998
nn.learn_nn_feature_fqi FQI:  117998
nn.learn_nn_feature_fqi FQI:  118998
nn.learn_nn_feature_fqi FQI:  119998
nn.learn_nn_feature_fqi FQI:  120998
nn.learn_nn_feature_fqi FQI:  121998
nn.learn_nn_feature_fqi FQI:  122998
nn.learn_nn_feature_fqi FQI:  123998
nn.learn_nn_feature_fqi FQI:  124998
nn.learn_nn_feature_fqi FQI:  125998
nn.learn_nn_feature_fqi FQI:  126998
nn.learn_nn_feature_fqi FQI:  127998
nn.learn_nn_feature_fqi FQI:  128998
nn.learn_nn_feature_fqi FQI:  129998
nn.learn_nn_feature_fqi FQI:  130998
nn.learn_nn_feature_fqi FQI:  131998
nn.learn_nn_feature_fqi FQI:  132998
nn.learn_nn_feature_fqi FQI:  133998
nn.learn_nn_feature_fqi FQI:  134998
nn.learn_nn_feature_fqi FQI:  135998
nn.learn_nn_feature_fqi FQI:  136998
nn.learn_nn_feature_fqi FQI:  137998
nn.learn_nn_feature_fqi FQI:  138998
nn.learn_nn_feature_fqi FQI:  139998
nn.learn_nn_feature_fqi FQI:  140998
nn.learn_nn_feature_fqi FQI:  141998
nn.learn_nn_feature_fqi FQI:  142998
nn.learn_nn_feature_fqi FQI:  143998
nn.learn_nn_feature_fqi FQI:  144998
nn.learn_nn_feature_fqi FQI:  145998
nn.learn_nn_feature_fqi FQI:  146998
nn.learn_nn_feature_fqi FQI:  147998
nn.learn_nn_feature_fqi FQI:  148998
nn.learn_nn_feature_fqi FQI:  149998
nn.learn_nn_feature_fqi FQI:  150998
nn.learn_nn_feature_fqi FQI:  151998
nn.learn_nn_feature_fqi FQI:  152998
nn.learn_nn_feature_fqi FQI:  153998
nn.learn_nn_feature_fqi FQI:  154998
nn.learn_nn_feature_fqi FQI:  155998
0 1001 -1000.0 -98.99572604650622 number episode from 10: 0 avegar over 10 episode: -98.996 avegare return across last 100 episodes: -98.996 state values: tensor(0.5530) 1000
1 1000 -1000.0 -99.99568287525881 number episode from 10: 1 avegar over 10 episode: -99.496 avegare return across last 100 episodes: -99.496 state values: tensor(0.5642) 1000
2 1000 -1000.0 -99.99568287525881 number episode from 10: 2 avegar over 10 episode: -99.662 avegare return across last 100 episodes: -99.662 state values: tensor(0.5523) 1000
3 1000 -1000.0 -99.99568287525881 number episode from 10: 3 avegar over 10 episode: -99.746 avegare return across last 100 episodes: -99.746 state values: tensor(0.5556) 1000
4 1000 -1000.0 -99.99568287525881 number episode from 10: 4 avegar over 10 episode: -99.796 avegare return across last 100 episodes: -99.796 state values: tensor(0.5691) 1000
5 1000 -1000.0 -99.99568287525881 number episode from 10: 5 avegar over 10 episode: -99.829 avegare return across last 100 episodes: -99.829 state values: tensor(0.5574) 1000
6 1000 -1000.0 -99.99568287525881 number episode from 10: 6 avegar over 10 episode: -99.853 avegare return across last 100 episodes: -99.853 state values: tensor(0.5626) 1000
7 1000 -1000.0 -99.99568287525881 number episode from 10: 7 avegar over 10 episode: -99.871 avegare return across last 100 episodes: -99.871 state values: tensor(0.5670) 1000
8 1000 -1000.0 -99.99568287525881 number episode from 10: 8 avegar over 10 episode: -99.885 avegare return across last 100 episodes: -99.885 state values: tensor(0.5638) 1000
9 1000 -1000.0 -99.99568287525881 number episode from 10: 9 avegar over 10 episode: -99.896 avegare return across last 100 episodes: -99.896 state values: tensor(0.5512) 1000
10 1000 -1000.0 -99.99568287525881 number episode from 10: 10 avegar over 10 episode: -99.905 avegare return across last 100 episodes: -99.905 state values: tensor(0.5603) 1000
11 1000 -1000.0 -99.99568287525881 number episode from 10: 11 avegar over 10 episode: -99.912 avegare return across last 100 episodes: -99.912 state values: tensor(0.5509) 1000
12 1000 -1000.0 -99.99568287525881 number episode from 10: 12 avegar over 10 episode: -99.919 avegare return across last 100 episodes: -99.919 state values: tensor(0.5576) 1000
13 1000 -1000.0 -99.99568287525881 number episode from 10: 13 avegar over 10 episode: -99.924 avegare return across last 100 episodes: -99.924 state values: tensor(0.5659) 1000
14 1000 -1000.0 -99.99568287525881 number episode from 10: 14 avegar over 10 episode: -99.929 avegare return across last 100 episodes: -99.929 state values: tensor(0.5603) 1000
15 1000 -1000.0 -99.99568287525881 number episode from 10: 15 avegar over 10 episode: -99.933 avegare return across last 100 episodes: -99.933 state values: tensor(0.5695) 1000
16 1000 -1000.0 -99.99568287525881 number episode from 10: 16 avegar over 10 episode: -99.937 avegare return across last 100 episodes: -99.937 state values: tensor(0.5518) 1000
17 1000 -1000.0 -99.99568287525881 number episode from 10: 17 avegar over 10 episode: -99.94 avegare return across last 100 episodes: -99.94 state values: tensor(0.5517) 1000
18 1000 -1000.0 -99.99568287525881 number episode from 10: 18 avegar over 10 episode: -99.943 avegare return across last 100 episodes: -99.943 state values: tensor(0.5554) 1000
19 1000 -1000.0 -99.99568287525881 number episode from 10: 19 avegar over 10 episode: -99.946 avegare return across last 100 episodes: -99.946 state values: tensor(0.5571) 1000
20 1000 -1000.0 -99.99568287525881 number episode from 10: 20 avegar over 10 episode: -99.948 avegare return across last 100 episodes: -99.948 state values: tensor(0.5529) 1000
21 1000 -1000.0 -99.99568287525881 number episode from 10: 21 avegar over 10 episode: -99.95 avegare return across last 100 episodes: -99.95 state values: tensor(0.5501) 1000
22 1000 -1000.0 -99.99568287525881 number episode from 10: 22 avegar over 10 episode: -99.952 avegare return across last 100 episodes: -99.952 state values: tensor(0.5538) 1000
23 1000 -1000.0 -99.99568287525881 number episode from 10: 23 avegar over 10 episode: -99.954 avegare return across last 100 episodes: -99.954 state values: tensor(0.5682) 1000
24 1000 -1000.0 -99.99568287525881 number episode from 10: 24 avegar over 10 episode: -99.956 avegare return across last 100 episodes: -99.956 state values: tensor(0.5562) 1000
25 1000 -1000.0 -99.99568287525881 number episode from 10: 25 avegar over 10 episode: -99.957 avegare return across last 100 episodes: -99.957 state values: tensor(0.5556) 1000
26 1000 -1000.0 -99.99568287525881 number episode from 10: 26 avegar over 10 episode: -99.959 avegare return across last 100 episodes: -99.959 state values: tensor(0.5660) 1000
27 1000 -1000.0 -99.99568287525881 number episode from 10: 27 avegar over 10 episode: -99.96 avegare return across last 100 episodes: -99.96 state values: tensor(0.5619) 1000
28 1000 -1000.0 -99.99568287525881 number episode from 10: 28 avegar over 10 episode: -99.961 avegare return across last 100 episodes: -99.961 state values: tensor(0.5577) 1000
29 1000 -1000.0 -99.99568287525881 number episode from 10: 29 avegar over 10 episode: -99.962 avegare return across last 100 episodes: -99.962 state values: tensor(0.5534) 1000
30 1000 -1000.0 -99.99568287525881 number episode from 10: 30 avegar over 10 episode: -99.963 avegare return across last 100 episodes: -99.963 state values: tensor(0.5510) 1000
31 1000 -1000.0 -99.99568287525881 number episode from 10: 31 avegar over 10 episode: -99.964 avegare return across last 100 episodes: -99.964 state values: tensor(0.5567) 1000
32 1000 -1000.0 -99.99568287525881 number episode from 10: 32 avegar over 10 episode: -99.965 avegare return across last 100 episodes: -99.965 state values: tensor(0.5536) 1000
33 1000 -1000.0 -99.99568287525881 number episode from 10: 33 avegar over 10 episode: -99.966 avegare return across last 100 episodes: -99.966 state values: tensor(0.5557) 1000
34 1000 -1000.0 -99.99568287525881 number episode from 10: 34 avegar over 10 episode: -99.967 avegare return across last 100 episodes: -99.967 state values: tensor(0.5584) 1000
35 1000 -1000.0 -99.99568287525881 number episode from 10: 35 avegar over 10 episode: -99.968 avegare return across last 100 episodes: -99.968 state values: tensor(0.5623) 1000
36 1000 -1000.0 -99.99568287525881 number episode from 10: 36 avegar over 10 episode: -99.969 avegare return across last 100 episodes: -99.969 state values: tensor(0.5521) 1000
37 1000 -1000.0 -99.99568287525881 number episode from 10: 37 avegar over 10 episode: -99.969 avegare return across last 100 episodes: -99.969 state values: tensor(0.5508) 1000
38 1000 -1000.0 -99.99568287525881 number episode from 10: 38 avegar over 10 episode: -99.97 avegare return across last 100 episodes: -99.97 state values: tensor(0.5560) 1000
39 1000 -1000.0 -99.99568287525881 number episode from 10: 39 avegar over 10 episode: -99.971 avegare return across last 100 episodes: -99.971 state values: tensor(0.5566) 1000
40 1000 -1000.0 -99.99568287525881 number episode from 10: 40 avegar over 10 episode: -99.971 avegare return across last 100 episodes: -99.971 state values: tensor(0.5516) 1000
41 1000 -1000.0 -99.99568287525881 number episode from 10: 41 avegar over 10 episode: -99.972 avegare return across last 100 episodes: -99.972 state values: tensor(0.5535) 1000
42 1000 -1000.0 -99.99568287525881 number episode from 10: 42 avegar over 10 episode: -99.972 avegare return across last 100 episodes: -99.972 state values: tensor(0.5628) 1000
43 1000 -1000.0 -99.99568287525881 number episode from 10: 43 avegar over 10 episode: -99.973 avegare return across last 100 episodes: -99.973 state values: tensor(0.5512) 1000
44 1000 -1000.0 -99.99568287525881 number episode from 10: 44 avegar over 10 episode: -99.973 avegare return across last 100 episodes: -99.973 state values: tensor(0.5582) 1000
45 1000 -1000.0 -99.99568287525881 number episode from 10: 45 avegar over 10 episode: -99.974 avegare return across last 100 episodes: -99.974 state values: tensor(0.5505) 1000
46 1000 -1000.0 -99.99568287525881 number episode from 10: 46 avegar over 10 episode: -99.974 avegare return across last 100 episodes: -99.974 state values: tensor(0.5552) 1000
47 1000 -1000.0 -99.99568287525881 number episode from 10: 47 avegar over 10 episode: -99.975 avegare return across last 100 episodes: -99.975 state values: tensor(0.5513) 1000
48 1000 -1000.0 -99.99568287525881 number episode from 10: 48 avegar over 10 episode: -99.975 avegare return across last 100 episodes: -99.975 state values: tensor(0.5577) 1000
49 1000 -1000.0 -99.99568287525881 number episode from 10: 49 avegar over 10 episode: -99.976 avegare return across last 100 episodes: -99.976 state values: tensor(0.5539) 1000
50 1000 -1000.0 -99.99568287525881 number episode from 10: 50 avegar over 10 episode: -99.976 avegare return across last 100 episodes: -99.976 state values: tensor(0.5538) 1000
51 1000 -1000.0 -99.99568287525881 number episode from 10: 51 avegar over 10 episode: -99.976 avegare return across last 100 episodes: -99.976 state values: tensor(0.5629) 1000
52 1000 -1000.0 -99.99568287525881 number episode from 10: 52 avegar over 10 episode: -99.977 avegare return across last 100 episodes: -99.977 state values: tensor(0.5560) 1000
53 1000 -1000.0 -99.99568287525881 number episode from 10: 53 avegar over 10 episode: -99.977 avegare return across last 100 episodes: -99.977 state values: tensor(0.5655) 1000
54 1000 -1000.0 -99.99568287525881 number episode from 10: 54 avegar over 10 episode: -99.978 avegare return across last 100 episodes: -99.978 state values: tensor(0.5592) 1000
55 1000 -1000.0 -99.99568287525881 number episode from 10: 55 avegar over 10 episode: -99.978 avegare return across last 100 episodes: -99.978 state values: tensor(0.5669) 1000
56 1000 -1000.0 -99.99568287525881 number episode from 10: 56 avegar over 10 episode: -99.978 avegare return across last 100 episodes: -99.978 state values: tensor(0.5504) 1000
57 1000 -1000.0 -99.99568287525881 number episode from 10: 57 avegar over 10 episode: -99.978 avegare return across last 100 episodes: -99.978 state values: tensor(0.5539) 1000
58 1000 -1000.0 -99.99568287525881 number episode from 10: 58 avegar over 10 episode: -99.979 avegare return across last 100 episodes: -99.979 state values: tensor(0.5543) 1000
59 1000 -1000.0 -99.99568287525881 number episode from 10: 59 avegar over 10 episode: -99.979 avegare return across last 100 episodes: -99.979 state values: tensor(0.5560) 1000
60 1000 -1000.0 -99.99568287525881 number episode from 10: 60 avegar over 10 episode: -99.979 avegare return across last 100 episodes: -99.979 state values: tensor(0.5582) 1000
61 1000 -1000.0 -99.99568287525881 number episode from 10: 61 avegar over 10 episode: -99.98 avegare return across last 100 episodes: -99.98 state values: tensor(0.5556) 1000
62 1000 -1000.0 -99.99568287525881 number episode from 10: 62 avegar over 10 episode: -99.98 avegare return across last 100 episodes: -99.98 state values: tensor(0.5599) 1000
63 1000 -1000.0 -99.99568287525881 number episode from 10: 63 avegar over 10 episode: -99.98 avegare return across last 100 episodes: -99.98 state values: tensor(0.5501) 1000
64 1000 -1000.0 -99.99568287525881 number episode from 10: 64 avegar over 10 episode: -99.98 avegare return across last 100 episodes: -99.98 state values: tensor(0.5504) 1000
65 1000 -1000.0 -99.99568287525881 number episode from 10: 65 avegar over 10 episode: -99.981 avegare return across last 100 episodes: -99.981 state values: tensor(0.5680) 1000
66 1000 -1000.0 -99.99568287525881 number episode from 10: 66 avegar over 10 episode: -99.981 avegare return across last 100 episodes: -99.981 state values: tensor(0.5518) 1000
67 1000 -1000.0 -99.99568287525881 number episode from 10: 67 avegar over 10 episode: -99.981 avegare return across last 100 episodes: -99.981 state values: tensor(0.5656) 1000
68 1000 -1000.0 -99.99568287525881 number episode from 10: 68 avegar over 10 episode: -99.981 avegare return across last 100 episodes: -99.981 state values: tensor(0.5529) 1000
69 1000 -1000.0 -99.99568287525881 number episode from 10: 69 avegar over 10 episode: -99.981 avegare return across last 100 episodes: -99.981 state values: tensor(0.5538) 1000
70 1000 -1000.0 -99.99568287525881 number episode from 10: 70 avegar over 10 episode: -99.982 avegare return across last 100 episodes: -99.982 state values: tensor(0.5544) 1000
71 1000 -1000.0 -99.99568287525881 number episode from 10: 71 avegar over 10 episode: -99.982 avegare return across last 100 episodes: -99.982 state values: tensor(0.5525) 1000
72 1000 -1000.0 -99.99568287525881 number episode from 10: 72 avegar over 10 episode: -99.982 avegare return across last 100 episodes: -99.982 state values: tensor(0.5599) 1000
73 1000 -1000.0 -99.99568287525881 number episode from 10: 73 avegar over 10 episode: -99.982 avegare return across last 100 episodes: -99.982 state values: tensor(0.5499) 1000
74 1000 -1000.0 -99.99568287525881 number episode from 10: 74 avegar over 10 episode: -99.982 avegare return across last 100 episodes: -99.982 state values: tensor(0.5615) 1000
75 1000 -1000.0 -99.99568287525881 number episode from 10: 75 avegar over 10 episode: -99.983 avegare return across last 100 episodes: -99.983 state values: tensor(0.5553) 1000
76 1000 -1000.0 -99.99568287525881 number episode from 10: 76 avegar over 10 episode: -99.983 avegare return across last 100 episodes: -99.983 state values: tensor(0.5555) 1000
77 1000 -1000.0 -99.99568287525881 number episode from 10: 77 avegar over 10 episode: -99.983 avegare return across last 100 episodes: -99.983 state values: tensor(0.5501) 1000
78 1000 -1000.0 -99.99568287525881 number episode from 10: 78 avegar over 10 episode: -99.983 avegare return across last 100 episodes: -99.983 state values: tensor(0.5571) 1000
79 1000 -1000.0 -99.99568287525881 number episode from 10: 79 avegar over 10 episode: -99.983 avegare return across last 100 episodes: -99.983 state values: tensor(0.5500) 1000
80 1000 -1000.0 -99.99568287525881 number episode from 10: 80 avegar over 10 episode: -99.983 avegare return across last 100 episodes: -99.983 state values: tensor(0.5616) 1000
81 1000 -1000.0 -99.99568287525881 number episode from 10: 81 avegar over 10 episode: -99.983 avegare return across last 100 episodes: -99.983 state values: tensor(0.5626) 1000
82 1000 -1000.0 -99.99568287525881 number episode from 10: 82 avegar over 10 episode: -99.984 avegare return across last 100 episodes: -99.984 state values: tensor(0.5678) 1000
83 1000 -1000.0 -99.99568287525881 number episode from 10: 83 avegar over 10 episode: -99.984 avegare return across last 100 episodes: -99.984 state values: tensor(0.5523) 1000
84 1000 -1000.0 -99.99568287525881 number episode from 10: 84 avegar over 10 episode: -99.984 avegare return across last 100 episodes: -99.984 state values: tensor(0.5521) 1000
85 1000 -1000.0 -99.99568287525881 number episode from 10: 85 avegar over 10 episode: -99.984 avegare return across last 100 episodes: -99.984 state values: tensor(0.5616) 1000
86 1000 -1000.0 -99.99568287525881 number episode from 10: 86 avegar over 10 episode: -99.984 avegare return across last 100 episodes: -99.984 state values: tensor(0.5518) 1000
87 1000 -1000.0 -99.99568287525881 number episode from 10: 87 avegar over 10 episode: -99.984 avegare return across last 100 episodes: -99.984 state values: tensor(0.5517) 1000
88 1000 -1000.0 -99.99568287525881 number episode from 10: 88 avegar over 10 episode: -99.984 avegare return across last 100 episodes: -99.984 state values: tensor(0.5523) 1000
89 1000 -1000.0 -99.99568287525881 number episode from 10: 89 avegar over 10 episode: -99.985 avegare return across last 100 episodes: -99.985 state values: tensor(0.5571) 1000
90 1000 -1000.0 -99.99568287525881 number episode from 10: 90 avegar over 10 episode: -99.985 avegare return across last 100 episodes: -99.985 state values: tensor(0.5613) 1000
91 1000 -1000.0 -99.99568287525881 number episode from 10: 91 avegar over 10 episode: -99.985 avegare return across last 100 episodes: -99.985 state values: tensor(0.5513) 1000
92 1000 -1000.0 -99.99568287525881 number episode from 10: 92 avegar over 10 episode: -99.985 avegare return across last 100 episodes: -99.985 state values: tensor(0.5545) 1000
93 1000 -1000.0 -99.99568287525881 number episode from 10: 93 avegar over 10 episode: -99.985 avegare return across last 100 episodes: -99.985 state values: tensor(0.5563) 1000
94 1000 -1000.0 -99.99568287525881 number episode from 10: 94 avegar over 10 episode: -99.985 avegare return across last 100 episodes: -99.985 state values: tensor(0.5560) 1000
95 1000 -1000.0 -99.99568287525881 number episode from 10: 95 avegar over 10 episode: -99.985 avegare return across last 100 episodes: -99.985 state values: tensor(0.5543) 1000
96 1000 -1000.0 -99.99568287525881 number episode from 10: 96 avegar over 10 episode: -99.985 avegare return across last 100 episodes: -99.985 state values: tensor(0.5642) 1000
97 1000 -1000.0 -99.99568287525881 number episode from 10: 97 avegar over 10 episode: -99.985 avegare return across last 100 episodes: -99.985 state values: tensor(0.5538) 1000
98 1000 -1000.0 -99.99568287525881 number episode from 10: 98 avegar over 10 episode: -99.986 avegare return across last 100 episodes: -99.986 state values: tensor(0.5549) 1000
99 1000 -1000.0 -99.99568287525881 number episode from 10: 99 avegar over 10 episode: -99.986 avegare return across last 100 episodes: -99.986 state values: tensor(0.5518) 1000
100 1000 -1000.0 -99.99568287525881 number episode from 10: 100 avegar over 10 episode: -99.986 avegare return across last 100 episodes: -99.996 state values: tensor(0.5629) 1000
101 1000 -1000.0 -99.99568287525881 number episode from 10: 101 avegar over 10 episode: -99.986 avegare return across last 100 episodes: -99.996 state values: tensor(0.5524) 1000
102 1000 -1000.0 -99.99568287525881 number episode from 10: 102 avegar over 10 episode: -99.986 avegare return across last 100 episodes: -99.996 state values: tensor(0.5514) 1000
103 1000 -1000.0 -99.99568287525881 number episode from 10: 103 avegar over 10 episode: -99.986 avegare return across last 100 episodes: -99.996 state values: tensor(0.5556) 1000
104 1000 -1000.0 -99.99568287525881 number episode from 10: 104 avegar over 10 episode: -99.986 avegare return across last 100 episodes: -99.996 state values: tensor(0.5690) 1000
105 1000 -1000.0 -99.99568287525881 number episode from 10: 105 avegar over 10 episode: -99.986 avegare return across last 100 episodes: -99.996 state values: tensor(0.5684) 1000
106 1000 -1000.0 -99.99568287525881 number episode from 10: 106 avegar over 10 episode: -99.986 avegare return across last 100 episodes: -99.996 state values: tensor(0.5582) 1000
107 1000 -1000.0 -99.99568287525881 number episode from 10: 107 avegar over 10 episode: -99.986 avegare return across last 100 episodes: -99.996 state values: tensor(0.5531) 1000
108 1000 -1000.0 -99.99568287525881 number episode from 10: 108 avegar over 10 episode: -99.987 avegare return across last 100 episodes: -99.996 state values: tensor(0.5518) 1000
109 1000 -1000.0 -99.99568287525881 number episode from 10: 109 avegar over 10 episode: -99.987 avegare return across last 100 episodes: -99.996 state values: tensor(0.5586) 1000
110 1000 -1000.0 -99.99568287525881 number episode from 10: 110 avegar over 10 episode: -99.987 avegare return across last 100 episodes: -99.996 state values: tensor(0.5617) 1000
111 1000 -1000.0 -99.99568287525881 number episode from 10: 111 avegar over 10 episode: -99.987 avegare return across last 100 episodes: -99.996 state values: tensor(0.5514) 1000
112 1000 -1000.0 -99.99568287525881 number episode from 10: 112 avegar over 10 episode: -99.987 avegare return across last 100 episodes: -99.996 state values: tensor(0.5645) 1000
113 1000 -1000.0 -99.99568287525881 number episode from 10: 113 avegar over 10 episode: -99.987 avegare return across last 100 episodes: -99.996 state values: tensor(0.5500) 1000
114 1000 -1000.0 -99.99568287525881 number episode from 10: 114 avegar over 10 episode: -99.987 avegare return across last 100 episodes: -99.996 state values: tensor(0.5502) 1000
115 1000 -1000.0 -99.99568287525881 number episode from 10: 115 avegar over 10 episode: -99.987 avegare return across last 100 episodes: -99.996 state values: tensor(0.5637) 1000
116 1000 -1000.0 -99.99568287525881 number episode from 10: 116 avegar over 10 episode: -99.987 avegare return across last 100 episodes: -99.996 state values: tensor(0.5567) 1000
117 1000 -1000.0 -99.99568287525881 number episode from 10: 117 avegar over 10 episode: -99.987 avegare return across last 100 episodes: -99.996 state values: tensor(0.5600) 1000
118 1000 -1000.0 -99.99568287525881 number episode from 10: 118 avegar over 10 episode: -99.987 avegare return across last 100 episodes: -99.996 state values: tensor(0.5512) 1000
119 1000 -1000.0 -99.99568287525881 number episode from 10: 119 avegar over 10 episode: -99.987 avegare return across last 100 episodes: -99.996 state values: tensor(0.5596) 1000
120 1000 -1000.0 -99.99568287525881 number episode from 10: 120 avegar over 10 episode: -99.987 avegare return across last 100 episodes: -99.996 state values: tensor(0.5581) 1000
121 1000 -1000.0 -99.99568287525881 number episode from 10: 121 avegar over 10 episode: -99.987 avegare return across last 100 episodes: -99.996 state values: tensor(0.5518) 1000
122 1000 -1000.0 -99.99568287525881 number episode from 10: 122 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.5500) 1000
123 1000 -1000.0 -99.99568287525881 number episode from 10: 123 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.5592) 1000
124 1000 -1000.0 -99.99568287525881 number episode from 10: 124 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.5527) 1000
125 1000 -1000.0 -99.99568287525881 number episode from 10: 125 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.5685) 1000
126 1000 -1000.0 -99.99568287525881 number episode from 10: 126 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.5590) 1000
127 1000 -1000.0 -99.99568287525881 number episode from 10: 127 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.5576) 1000
128 1000 -1000.0 -99.99568287525881 number episode from 10: 128 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.5513) 1000
129 1000 -1000.0 -99.99568287525881 number episode from 10: 129 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.5636) 1000
130 1000 -1000.0 -99.99568287525881 number episode from 10: 130 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.5607) 1000
131 1000 -1000.0 -99.99568287525881 number episode from 10: 131 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.5652) 1000
132 1000 -1000.0 -99.99568287525881 number episode from 10: 132 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.5662) 1000
133 1000 -1000.0 -99.99568287525881 number episode from 10: 133 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.5582) 1000
134 1000 -1000.0 -99.99568287525881 number episode from 10: 134 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.5555) 1000
135 1000 -1000.0 -99.99568287525881 number episode from 10: 135 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.5670) 1000
136 1000 -1000.0 -99.99568287525881 number episode from 10: 136 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.5691) 1000
137 1000 -1000.0 -99.99568287525881 number episode from 10: 137 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.5676) 1000
138 1000 -1000.0 -99.99568287525881 number episode from 10: 138 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.5510) 1000
139 1000 -1000.0 -99.99568287525881 number episode from 10: 139 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.5672) 1000
140 1000 -1000.0 -99.99568287525881 number episode from 10: 140 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.5572) 1000
141 1000 -1000.0 -99.99568287525881 number episode from 10: 141 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.5549) 1000
142 1000 -1000.0 -99.99568287525881 number episode from 10: 142 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.5521) 1000
143 1000 -1000.0 -99.99568287525881 number episode from 10: 143 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.5513) 1000
144 1000 -1000.0 -99.99568287525881 number episode from 10: 144 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.5509) 1000
145 1000 -1000.0 -99.99568287525881 number episode from 10: 145 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.5646) 1000
146 1000 -1000.0 -99.99568287525881 number episode from 10: 146 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.5692) 1000
147 1000 -1000.0 -99.99568287525881 number episode from 10: 147 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.5681) 1000
148 1000 -1000.0 -99.99568287525881 number episode from 10: 148 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.5581) 1000
149 1000 -1000.0 -99.99568287525881 number episode from 10: 149 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.5525) 1000
150 1000 -1000.0 -99.99568287525881 number episode from 10: 150 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.5604) 1000
151 1000 -1000.0 -99.99568287525881 number episode from 10: 151 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.5569) 1000
152 1000 -1000.0 -99.99568287525881 number episode from 10: 152 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.5611) 1000
153 1000 -1000.0 -99.99568287525881 number episode from 10: 153 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.5518) 1000
154 1000 -1000.0 -99.99568287525881 number episode from 10: 154 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.5572) 1000
155 1000 -1000.0 -99.99568287525881 number episode from 10: 155 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.5589) 1000
156 1000 -1000.0 -99.99568287525881 number episode from 10: 156 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.5575) 1000
157 1000 -1000.0 -99.99568287525881 number episode from 10: 157 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.5620) 1000
158 1000 -1000.0 -99.99568287525881 number episode from 10: 158 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.5593) 1000
159 1000 -1000.0 -99.99568287525881 number episode from 10: 159 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.5574) 1000
160 1000 -1000.0 -99.99568287525881 number episode from 10: 160 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.5600) 1000
161 1000 -1000.0 -99.99568287525881 number episode from 10: 161 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.5553) 1000
162 1000 -1000.0 -99.99568287525881 number episode from 10: 162 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.5531) 1000
163 1000 -1000.0 -99.99568287525881 number episode from 10: 163 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.5649) 1000
164 1000 -1000.0 -99.99568287525881 number episode from 10: 164 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.5624) 1000
165 1000 -1000.0 -99.99568287525881 number episode from 10: 165 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.5619) 1000
166 1000 -1000.0 -99.99568287525881 number episode from 10: 166 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.5698) 1000
167 1000 -1000.0 -99.99568287525881 number episode from 10: 167 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.5538) 1000
168 1000 -1000.0 -99.99568287525881 number episode from 10: 168 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.5545) 1000
169 1000 -1000.0 -99.99568287525881 number episode from 10: 169 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.5510) 1000
170 1000 -1000.0 -99.99568287525881 number episode from 10: 170 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.5662) 1000
171 1000 -1000.0 -99.99568287525881 number episode from 10: 171 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.5575) 1000
172 1000 -1000.0 -99.99568287525881 number episode from 10: 172 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.5670) 1000
173 1000 -1000.0 -99.99568287525881 number episode from 10: 173 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.5506) 1000
174 1000 -1000.0 -99.99568287525881 number episode from 10: 174 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.5619) 1000
175 1000 -1000.0 -99.99568287525881 number episode from 10: 175 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.5554) 1000
176 1000 -1000.0 -99.99568287525881 number episode from 10: 176 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.5608) 1000
177 1000 -1000.0 -99.99568287525881 number episode from 10: 177 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.5513) 1000
178 1000 -1000.0 -99.99568287525881 number episode from 10: 178 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.5639) 1000
179 1000 -1000.0 -99.99568287525881 number episode from 10: 179 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.5604) 1000
180 1000 -1000.0 -99.99568287525881 number episode from 10: 180 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.5589) 1000
181 1000 -1000.0 -99.99568287525881 number episode from 10: 181 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.5599) 1000
182 1000 -1000.0 -99.99568287525881 number episode from 10: 182 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.5555) 1000
183 1000 -1000.0 -99.99568287525881 number episode from 10: 183 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.5584) 1000
184 1000 -1000.0 -99.99568287525881 number episode from 10: 184 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.5503) 1000
185 1000 -1000.0 -99.99568287525881 number episode from 10: 185 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.5595) 1000
186 1000 -1000.0 -99.99568287525881 number episode from 10: 186 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.5546) 1000
187 1000 -1000.0 -99.99568287525881 number episode from 10: 187 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.5551) 1000
188 1000 -1000.0 -99.99568287525881 number episode from 10: 188 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.5613) 1000
189 1000 -1000.0 -99.99568287525881 number episode from 10: 189 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.5526) 1000
190 1000 -1000.0 -99.99568287525881 number episode from 10: 190 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.5654) 1000
191 1000 -1000.0 -99.99568287525881 number episode from 10: 191 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.5553) 1000
192 1000 -1000.0 -99.99568287525881 number episode from 10: 192 avegar over 10 episode: -99.991 avegare return across last 100 episodes: -99.996 state values: tensor(0.5533) 1000
193 1000 -1000.0 -99.99568287525881 number episode from 10: 193 avegar over 10 episode: -99.991 avegare return across last 100 episodes: -99.996 state values: tensor(0.5503) 1000
194 1000 -1000.0 -99.99568287525881 number episode from 10: 194 avegar over 10 episode: -99.991 avegare return across last 100 episodes: -99.996 state values: tensor(0.5636) 1000
195 1000 -1000.0 -99.99568287525881 number episode from 10: 195 avegar over 10 episode: -99.991 avegare return across last 100 episodes: -99.996 state values: tensor(0.5524) 1000
196 1000 -1000.0 -99.99568287525881 number episode from 10: 196 avegar over 10 episode: -99.991 avegare return across last 100 episodes: -99.996 state values: tensor(0.5572) 1000
197 1000 -1000.0 -99.99568287525881 number episode from 10: 197 avegar over 10 episode: -99.991 avegare return across last 100 episodes: -99.996 state values: tensor(0.5597) 1000
198 1000 -1000.0 -99.99568287525881 number episode from 10: 198 avegar over 10 episode: -99.991 avegare return across last 100 episodes: -99.996 state values: tensor(0.5613) 1000
199 1000 -1000.0 -99.99568287525881 number episode from 10: 199 avegar over 10 episode: -99.991 avegare return across last 100 episodes: -99.996 state values: tensor(0.5581) 1000
200 1000 -1000.0 -99.99568287525881 number episode from 10: 200 avegar over 10 episode: -99.991 avegare return across last 100 episodes: -99.996 state values: tensor(0.5542) 1000
load offline data!!!!!
mem_cntr: 50000 ; mem_size: 50000
nn.learn_nn_feature_fqi FQI:  998
nn.learn_nn_feature_fqi FQI:  1998
nn.learn_nn_feature_fqi FQI:  2998
nn.learn_nn_feature_fqi FQI:  3998
nn.learn_nn_feature_fqi FQI:  4998
nn.learn_nn_feature_fqi FQI:  5998
nn.learn_nn_feature_fqi FQI:  6998
nn.learn_nn_feature_fqi FQI:  7998
nn.learn_nn_feature_fqi FQI:  8998
nn.learn_nn_feature_fqi FQI:  9998
nn.learn_nn_feature_fqi FQI:  10998
nn.learn_nn_feature_fqi FQI:  11998
nn.learn_nn_feature_fqi FQI:  12998
nn.learn_nn_feature_fqi FQI:  13998
nn.learn_nn_feature_fqi FQI:  14998
nn.learn_nn_feature_fqi FQI:  15998
nn.learn_nn_feature_fqi FQI:  16998
nn.learn_nn_feature_fqi FQI:  17998
nn.learn_nn_feature_fqi FQI:  18998
nn.learn_nn_feature_fqi FQI:  19998
nn.learn_nn_feature_fqi FQI:  20998
nn.learn_nn_feature_fqi FQI:  21998
nn.learn_nn_feature_fqi FQI:  22998
nn.learn_nn_feature_fqi FQI:  23998
nn.learn_nn_feature_fqi FQI:  24998
nn.learn_nn_feature_fqi FQI:  25998
nn.learn_nn_feature_fqi FQI:  26998
nn.learn_nn_feature_fqi FQI:  27998
nn.learn_nn_feature_fqi FQI:  28998
nn.learn_nn_feature_fqi FQI:  29998
nn.learn_nn_feature_fqi FQI:  30998
nn.learn_nn_feature_fqi FQI:  31998
nn.learn_nn_feature_fqi FQI:  32998
nn.learn_nn_feature_fqi FQI:  33998
nn.learn_nn_feature_fqi FQI:  34998
nn.learn_nn_feature_fqi FQI:  35998
nn.learn_nn_feature_fqi FQI:  36998
nn.learn_nn_feature_fqi FQI:  37998
nn.learn_nn_feature_fqi FQI:  38998
nn.learn_nn_feature_fqi FQI:  39998
nn.learn_nn_feature_fqi FQI:  40998
nn.learn_nn_feature_fqi FQI:  41998
nn.learn_nn_feature_fqi FQI:  42998
nn.learn_nn_feature_fqi FQI:  43998
nn.learn_nn_feature_fqi FQI:  44998
nn.learn_nn_feature_fqi FQI:  45998
nn.learn_nn_feature_fqi FQI:  46998
nn.learn_nn_feature_fqi FQI:  47998
nn.learn_nn_feature_fqi FQI:  48998
nn.learn_nn_feature_fqi FQI:  49998
nn.learn_nn_feature_fqi FQI:  50998
nn.learn_nn_feature_fqi FQI:  51998
nn.learn_nn_feature_fqi FQI:  52998
nn.learn_nn_feature_fqi FQI:  53998
nn.learn_nn_feature_fqi FQI:  54998
nn.learn_nn_feature_fqi FQI:  55998
nn.learn_nn_feature_fqi FQI:  56998
nn.learn_nn_feature_fqi FQI:  57998
nn.learn_nn_feature_fqi FQI:  58998
nn.learn_nn_feature_fqi FQI:  59998
nn.learn_nn_feature_fqi FQI:  60998
nn.learn_nn_feature_fqi FQI:  61998
nn.learn_nn_feature_fqi FQI:  62998
nn.learn_nn_feature_fqi FQI:  63998
nn.learn_nn_feature_fqi FQI:  64998
nn.learn_nn_feature_fqi FQI:  65998
nn.learn_nn_feature_fqi FQI:  66998
nn.learn_nn_feature_fqi FQI:  67998
nn.learn_nn_feature_fqi FQI:  68998
nn.learn_nn_feature_fqi FQI:  69998
nn.learn_nn_feature_fqi FQI:  70998
nn.learn_nn_feature_fqi FQI:  71998
nn.learn_nn_feature_fqi FQI:  72998
nn.learn_nn_feature_fqi FQI:  73998
nn.learn_nn_feature_fqi FQI:  74998
nn.learn_nn_feature_fqi FQI:  75998
nn.learn_nn_feature_fqi FQI:  76998
nn.learn_nn_feature_fqi FQI:  77998
nn.learn_nn_feature_fqi FQI:  78998
nn.learn_nn_feature_fqi FQI:  79998
nn.learn_nn_feature_fqi FQI:  80998
nn.learn_nn_feature_fqi FQI:  81998
nn.learn_nn_feature_fqi FQI:  82998
nn.learn_nn_feature_fqi FQI:  83998
nn.learn_nn_feature_fqi FQI:  84998
nn.learn_nn_feature_fqi FQI:  85998
nn.learn_nn_feature_fqi FQI:  86998
nn.learn_nn_feature_fqi FQI:  87998
nn.learn_nn_feature_fqi FQI:  88998
nn.learn_nn_feature_fqi FQI:  89998
nn.learn_nn_feature_fqi FQI:  90998
nn.learn_nn_feature_fqi FQI:  91998
nn.learn_nn_feature_fqi FQI:  92998
nn.learn_nn_feature_fqi FQI:  93998
nn.learn_nn_feature_fqi FQI:  94998
nn.learn_nn_feature_fqi FQI:  95998
nn.learn_nn_feature_fqi FQI:  96998
nn.learn_nn_feature_fqi FQI:  97998
nn.learn_nn_feature_fqi FQI:  98998
nn.learn_nn_feature_fqi FQI:  99998
nn.learn_nn_feature_fqi FQI:  100998
nn.learn_nn_feature_fqi FQI:  101998
nn.learn_nn_feature_fqi FQI:  102998
nn.learn_nn_feature_fqi FQI:  103998
nn.learn_nn_feature_fqi FQI:  104998
nn.learn_nn_feature_fqi FQI:  105998
nn.learn_nn_feature_fqi FQI:  106998
nn.learn_nn_feature_fqi FQI:  107998
nn.learn_nn_feature_fqi FQI:  108998
nn.learn_nn_feature_fqi FQI:  109998
nn.learn_nn_feature_fqi FQI:  110998
nn.learn_nn_feature_fqi FQI:  111998
nn.learn_nn_feature_fqi FQI:  112998
nn.learn_nn_feature_fqi FQI:  113998
nn.learn_nn_feature_fqi FQI:  114998
nn.learn_nn_feature_fqi FQI:  115998
nn.learn_nn_feature_fqi FQI:  116998
nn.learn_nn_feature_fqi FQI:  117998
nn.learn_nn_feature_fqi FQI:  118998
nn.learn_nn_feature_fqi FQI:  119998
nn.learn_nn_feature_fqi FQI:  120998
nn.learn_nn_feature_fqi FQI:  121998
nn.learn_nn_feature_fqi FQI:  122998
nn.learn_nn_feature_fqi FQI:  123998
nn.learn_nn_feature_fqi FQI:  124998
nn.learn_nn_feature_fqi FQI:  125998
nn.learn_nn_feature_fqi FQI:  126998
nn.learn_nn_feature_fqi FQI:  127998
nn.learn_nn_feature_fqi FQI:  128998
nn.learn_nn_feature_fqi FQI:  129998
nn.learn_nn_feature_fqi FQI:  130998
nn.learn_nn_feature_fqi FQI:  131998
nn.learn_nn_feature_fqi FQI:  132998
nn.learn_nn_feature_fqi FQI:  133998
nn.learn_nn_feature_fqi FQI:  134998
nn.learn_nn_feature_fqi FQI:  135998
nn.learn_nn_feature_fqi FQI:  136998
nn.learn_nn_feature_fqi FQI:  137998
nn.learn_nn_feature_fqi FQI:  138998
nn.learn_nn_feature_fqi FQI:  139998
nn.learn_nn_feature_fqi FQI:  140998
nn.learn_nn_feature_fqi FQI:  141998
nn.learn_nn_feature_fqi FQI:  142998
nn.learn_nn_feature_fqi FQI:  143998
nn.learn_nn_feature_fqi FQI:  144998
nn.learn_nn_feature_fqi FQI:  145998
nn.learn_nn_feature_fqi FQI:  146998
nn.learn_nn_feature_fqi FQI:  147998
nn.learn_nn_feature_fqi FQI:  148998
nn.learn_nn_feature_fqi FQI:  149998
nn.learn_nn_feature_fqi FQI:  150998
nn.learn_nn_feature_fqi FQI:  151998
nn.learn_nn_feature_fqi FQI:  152998
nn.learn_nn_feature_fqi FQI:  153998
nn.learn_nn_feature_fqi FQI:  154998
nn.learn_nn_feature_fqi FQI:  155998
0 391 -390.0 -97.03500663786126 number episode from 10: 0 avegar over 10 episode: -97.035 avegare return across last 100 episodes: -97.035 state values: tensor(0.5756) 390
1 1000 -1000.0 -99.99568287525881 number episode from 10: 1 avegar over 10 episode: -98.515 avegare return across last 100 episodes: -98.515 state values: tensor(0.4592) 1000
2 325 -325.0 -96.18549451073217 number episode from 10: 2 avegar over 10 episode: -97.739 avegare return across last 100 episodes: -97.739 state values: tensor(0.6264) 325
3 317 -317.0 -95.86613121451465 number episode from 10: 3 avegar over 10 episode: -97.271 avegare return across last 100 episodes: -97.271 state values: tensor(0.5964) 317
4 1000 -1000.0 -99.99568287525881 number episode from 10: 4 avegar over 10 episode: -97.816 avegare return across last 100 episodes: -97.816 state values: tensor(0.4605) 1000
5 355 -355.0 -97.17840886529692 number episode from 10: 5 avegar over 10 episode: -97.709 avegare return across last 100 episodes: -97.709 state values: tensor(0.5925) 355
6 243 -243.0 -91.30334409017519 number episode from 10: 6 avegar over 10 episode: -96.794 avegare return across last 100 episodes: -96.794 state values: tensor(0.6291) 243
7 318 -318.0 -95.9074699023695 number episode from 10: 7 avegar over 10 episode: -96.683 avegare return across last 100 episodes: -96.683 state values: tensor(0.6140) 318
8 355 -355.0 -97.17840886529692 number episode from 10: 8 avegar over 10 episode: -96.738 avegare return across last 100 episodes: -96.738 state values: tensor(0.5977) 355
9 1000 -1000.0 -99.99568287525881 number episode from 10: 9 avegar over 10 episode: -97.064 avegare return across last 100 episodes: -97.064 state values: tensor(0.4600) 1000
10 354 -354.0 -97.14990794474436 number episode from 10: 10 avegar over 10 episode: -97.072 avegare return across last 100 episodes: -97.072 state values: tensor(0.5981) 354
11 969 -969.0 -99.99410473183649 number episode from 10: 11 avegar over 10 episode: -97.315 avegare return across last 100 episodes: -97.315 state values: tensor(0.5069) 969
12 1000 -1000.0 -99.99568287525881 number episode from 10: 12 avegar over 10 episode: -97.522 avegare return across last 100 episodes: -97.522 state values: tensor(0.4596) 1000
13 1000 -1000.0 -99.99568287525881 number episode from 10: 13 avegar over 10 episode: -97.698 avegare return across last 100 episodes: -97.698 state values: tensor(0.4647) 1000
14 321 -321.0 -96.0290221387992 number episode from 10: 14 avegar over 10 episode: -97.587 avegare return across last 100 episodes: -97.587 state values: tensor(0.6172) 321
15 315 -315.0 -95.78219693349114 number episode from 10: 15 avegar over 10 episode: -97.474 avegare return across last 100 episodes: -97.474 state values: tensor(0.5961) 315
16 1000 -1000.0 -99.99568287525881 number episode from 10: 16 avegar over 10 episode: -97.623 avegare return across last 100 episodes: -97.623 state values: tensor(0.4598) 1000
17 1000 -1000.0 -99.99568287525881 number episode from 10: 17 avegar over 10 episode: -97.754 avegare return across last 100 episodes: -97.754 state values: tensor(0.4834) 1000
18 311 -311.0 -95.60918115149273 number episode from 10: 18 avegar over 10 episode: -97.641 avegare return across last 100 episodes: -97.641 state values: tensor(0.5986) 311
19 322 -322.0 -96.06873191741121 number episode from 10: 19 avegar over 10 episode: -97.563 avegare return across last 100 episodes: -97.563 state values: tensor(0.6160) 322
20 311 -311.0 -95.60918115149273 number episode from 10: 20 avegar over 10 episode: -97.47 avegare return across last 100 episodes: -97.47 state values: tensor(0.5930) 311
21 1000 -1000.0 -99.99568287525881 number episode from 10: 21 avegar over 10 episode: -97.585 avegare return across last 100 episodes: -97.585 state values: tensor(0.4608) 1000
22 1000 -1000.0 -99.99568287525881 number episode from 10: 22 avegar over 10 episode: -97.689 avegare return across last 100 episodes: -97.689 state values: tensor(0.4618) 1000
23 1000 -1000.0 -99.99568287525881 number episode from 10: 23 avegar over 10 episode: -97.786 avegare return across last 100 episodes: -97.786 state values: tensor(0.4638) 1000
24 1000 -1000.0 -99.99568287525881 number episode from 10: 24 avegar over 10 episode: -97.874 avegare return across last 100 episodes: -97.874 state values: tensor(0.4627) 1000
25 1000 -1000.0 -99.99568287525881 number episode from 10: 25 avegar over 10 episode: -97.956 avegare return across last 100 episodes: -97.956 state values: tensor(0.4592) 1000
26 241 -241.0 -91.12676674846973 number episode from 10: 26 avegar over 10 episode: -97.703 avegare return across last 100 episodes: -97.703 state values: tensor(0.6155) 241
27 1000 -1000.0 -99.99568287525881 number episode from 10: 27 avegar over 10 episode: -97.785 avegare return across last 100 episodes: -97.785 state values: tensor(0.4602) 1000
28 1000 -1000.0 -99.99568287525881 number episode from 10: 28 avegar over 10 episode: -97.861 avegare return across last 100 episodes: -97.861 state values: tensor(0.4638) 1000
29 1000 -1000.0 -99.99568287525881 number episode from 10: 29 avegar over 10 episode: -97.932 avegare return across last 100 episodes: -97.932 state values: tensor(0.4917) 1000
30 1000 -1000.0 -99.99568287525881 number episode from 10: 30 avegar over 10 episode: -97.999 avegare return across last 100 episodes: -97.999 state values: tensor(0.4607) 1000
31 1000 -1000.0 -99.99568287525881 number episode from 10: 31 avegar over 10 episode: -98.061 avegare return across last 100 episodes: -98.061 state values: tensor(0.4595) 1000
32 239 -239.0 -90.94660417148224 number episode from 10: 32 avegar over 10 episode: -97.845 avegare return across last 100 episodes: -97.845 state values: tensor(0.6147) 239
33 1000 -1000.0 -99.99568287525881 number episode from 10: 33 avegar over 10 episode: -97.909 avegare return across last 100 episodes: -97.909 state values: tensor(0.4594) 1000
34 241 -241.0 -91.12676674846973 number episode from 10: 34 avegar over 10 episode: -97.715 avegare return across last 100 episodes: -97.715 state values: tensor(0.6196) 241
35 1000 -1000.0 -99.99568287525881 number episode from 10: 35 avegar over 10 episode: -97.778 avegare return across last 100 episodes: -97.778 state values: tensor(0.4598) 1000
36 1000 -1000.0 -99.99568287525881 number episode from 10: 36 avegar over 10 episode: -97.838 avegare return across last 100 episodes: -97.838 state values: tensor(0.4595) 1000
37 1000 -1000.0 -99.99568287525881 number episode from 10: 37 avegar over 10 episode: -97.895 avegare return across last 100 episodes: -97.895 state values: tensor(0.4604) 1000
38 1000 -1000.0 -99.99568287525881 number episode from 10: 38 avegar over 10 episode: -97.949 avegare return across last 100 episodes: -97.949 state values: tensor(0.4607) 1000
39 1000 -1000.0 -99.99568287525881 number episode from 10: 39 avegar over 10 episode: -98.0 avegare return across last 100 episodes: -98.0 state values: tensor(0.4690) 1000
40 1000 -1000.0 -99.99568287525881 number episode from 10: 40 avegar over 10 episode: -98.049 avegare return across last 100 episodes: -98.049 state values: tensor(0.4634) 1000
41 1000 -1000.0 -99.99568287525881 number episode from 10: 41 avegar over 10 episode: -98.095 avegare return across last 100 episodes: -98.095 state values: tensor(0.4644) 1000
42 1000 -1000.0 -99.99568287525881 number episode from 10: 42 avegar over 10 episode: -98.139 avegare return across last 100 episodes: -98.139 state values: tensor(0.4632) 1000
43 1000 -1000.0 -99.99568287525881 number episode from 10: 43 avegar over 10 episode: -98.181 avegare return across last 100 episodes: -98.181 state values: tensor(0.4593) 1000
44 1000 -1000.0 -99.99568287525881 number episode from 10: 44 avegar over 10 episode: -98.222 avegare return across last 100 episodes: -98.222 state values: tensor(0.4605) 1000
45 886 -886.0 -99.98642366913742 number episode from 10: 45 avegar over 10 episode: -98.26 avegare return across last 100 episodes: -98.26 state values: tensor(0.5104) 886
46 317 -317.0 -95.86613121451465 number episode from 10: 46 avegar over 10 episode: -98.209 avegare return across last 100 episodes: -98.209 state values: tensor(0.5933) 317
47 1000 -1000.0 -99.99568287525881 number episode from 10: 47 avegar over 10 episode: -98.246 avegare return across last 100 episodes: -98.246 state values: tensor(0.4606) 1000
48 345 -345.0 -96.88008949682511 number episode from 10: 48 avegar over 10 episode: -98.218 avegare return across last 100 episodes: -98.218 state values: tensor(0.5876) 345
49 1000 -1000.0 -99.99568287525881 number episode from 10: 49 avegar over 10 episode: -98.254 avegare return across last 100 episodes: -98.254 state values: tensor(0.4593) 1000
50 1000 -1000.0 -99.99568287525881 number episode from 10: 50 avegar over 10 episode: -98.288 avegare return across last 100 episodes: -98.288 state values: tensor(0.4616) 1000
51 1000 -1000.0 -99.99568287525881 number episode from 10: 51 avegar over 10 episode: -98.321 avegare return across last 100 episodes: -98.321 state values: tensor(0.4596) 1000
52 1000 -1000.0 -99.99568287525881 number episode from 10: 52 avegar over 10 episode: -98.353 avegare return across last 100 episodes: -98.353 state values: tensor(0.4597) 1000
53 241 -241.0 -91.12676674846973 number episode from 10: 53 avegar over 10 episode: -98.219 avegare return across last 100 episodes: -98.219 state values: tensor(0.6171) 241
54 1000 -1000.0 -99.99568287525881 number episode from 10: 54 avegar over 10 episode: -98.251 avegare return across last 100 episodes: -98.251 state values: tensor(0.4629) 1000
55 1000 -1000.0 -99.99568287525881 number episode from 10: 55 avegar over 10 episode: -98.282 avegare return across last 100 episodes: -98.282 state values: tensor(0.4951) 1000
56 355 -355.0 -97.17840886529692 number episode from 10: 56 avegar over 10 episode: -98.263 avegare return across last 100 episodes: -98.263 state values: tensor(0.5872) 355
57 239 -239.0 -90.94660417148224 number episode from 10: 57 avegar over 10 episode: -98.137 avegare return across last 100 episodes: -98.137 state values: tensor(0.6058) 239
58 1000 -1000.0 -99.99568287525881 number episode from 10: 58 avegar over 10 episode: -98.168 avegare return across last 100 episodes: -98.168 state values: tensor(0.4672) 1000
59 319 -319.0 -95.9483952033458 number episode from 10: 59 avegar over 10 episode: -98.131 avegare return across last 100 episodes: -98.131 state values: tensor(0.6114) 319
60 238 -238.0 -90.85515572876993 number episode from 10: 60 avegar over 10 episode: -98.012 avegare return across last 100 episodes: -98.012 state values: tensor(0.6170) 238
61 241 -241.0 -91.12676674846973 number episode from 10: 61 avegar over 10 episode: -97.901 avegare return across last 100 episodes: -97.901 state values: tensor(0.6177) 241
62 1000 -1000.0 -99.99568287525881 number episode from 10: 62 avegar over 10 episode: -97.934 avegare return across last 100 episodes: -97.934 state values: tensor(0.4613) 1000
63 347 -347.0 -96.94217571583829 number episode from 10: 63 avegar over 10 episode: -97.919 avegare return across last 100 episodes: -97.919 state values: tensor(0.5840) 347
64 1000 -1000.0 -99.99568287525881 number episode from 10: 64 avegar over 10 episode: -97.951 avegare return across last 100 episodes: -97.951 state values: tensor(0.4599) 1000
65 318 -318.0 -95.9074699023695 number episode from 10: 65 avegar over 10 episode: -97.92 avegare return across last 100 episodes: -97.92 state values: tensor(0.6127) 318
66 321 -321.0 -96.0290221387992 number episode from 10: 66 avegar over 10 episode: -97.891 avegare return across last 100 episodes: -97.891 state values: tensor(0.6185) 321
67 356 -356.0 -97.20662477664395 number episode from 10: 67 avegar over 10 episode: -97.881 avegare return across last 100 episodes: -97.881 state values: tensor(0.5912) 356
68 1000 -1000.0 -99.99568287525881 number episode from 10: 68 avegar over 10 episode: -97.912 avegare return across last 100 episodes: -97.912 state values: tensor(0.4597) 1000
69 1000 -1000.0 -99.99568287525881 number episode from 10: 69 avegar over 10 episode: -97.942 avegare return across last 100 episodes: -97.942 state values: tensor(0.4627) 1000
70 317 -317.0 -95.86613121451465 number episode from 10: 70 avegar over 10 episode: -97.913 avegare return across last 100 episodes: -97.913 state values: tensor(0.6107) 317
71 1000 -1000.0 -99.99568287525881 number episode from 10: 71 avegar over 10 episode: -97.941 avegare return across last 100 episodes: -97.941 state values: tensor(0.4599) 1000
72 1000 -1000.0 -99.99568287525881 number episode from 10: 72 avegar over 10 episode: -97.97 avegare return across last 100 episodes: -97.97 state values: tensor(0.5032) 1000
73 318 -318.0 -95.9074699023695 number episode from 10: 73 avegar over 10 episode: -97.942 avegare return across last 100 episodes: -97.942 state values: tensor(0.6111) 318
74 1000 -1000.0 -99.99568287525881 number episode from 10: 74 avegar over 10 episode: -97.969 avegare return across last 100 episodes: -97.969 state values: tensor(0.4640) 1000
75 1000 -1000.0 -99.99568287525881 number episode from 10: 75 avegar over 10 episode: -97.996 avegare return across last 100 episodes: -97.996 state values: tensor(0.4615) 1000
76 1000 -1000.0 -99.99568287525881 number episode from 10: 76 avegar over 10 episode: -98.022 avegare return across last 100 episodes: -98.022 state values: tensor(0.4636) 1000
77 1000 -1000.0 -99.99568287525881 number episode from 10: 77 avegar over 10 episode: -98.047 avegare return across last 100 episodes: -98.047 state values: tensor(0.4604) 1000
78 1000 -1000.0 -99.99568287525881 number episode from 10: 78 avegar over 10 episode: -98.072 avegare return across last 100 episodes: -98.072 state values: tensor(0.4600) 1000
79 356 -356.0 -97.20662477664395 number episode from 10: 79 avegar over 10 episode: -98.061 avegare return across last 100 episodes: -98.061 state values: tensor(0.5915) 356
80 319 -319.0 -95.9483952033458 number episode from 10: 80 avegar over 10 episode: -98.035 avegare return across last 100 episodes: -98.035 state values: tensor(0.6315) 319
81 901 -901.0 -99.98832356321624 number episode from 10: 81 avegar over 10 episode: -98.059 avegare return across last 100 episodes: -98.059 state values: tensor(0.5264) 901
82 238 -238.0 -90.85515572876993 number episode from 10: 82 avegar over 10 episode: -97.972 avegare return across last 100 episodes: -97.972 state values: tensor(0.6141) 238
83 239 -239.0 -90.94660417148224 number episode from 10: 83 avegar over 10 episode: -97.888 avegare return across last 100 episodes: -97.888 state values: tensor(0.6178) 239
84 312 -312.0 -95.65308933997781 number episode from 10: 84 avegar over 10 episode: -97.862 avegare return across last 100 episodes: -97.862 state values: tensor(0.6018) 312
85 1000 -1000.0 -99.99568287525881 number episode from 10: 85 avegar over 10 episode: -97.887 avegare return across last 100 episodes: -97.887 state values: tensor(0.5025) 1000
86 1000 -1000.0 -99.99568287525881 number episode from 10: 86 avegar over 10 episode: -97.911 avegare return across last 100 episodes: -97.911 state values: tensor(0.4886) 1000
87 1000 -1000.0 -99.99568287525881 number episode from 10: 87 avegar over 10 episode: -97.935 avegare return across last 100 episodes: -97.935 state values: tensor(0.4609) 1000
88 242 -242.0 -91.21549908098504 number episode from 10: 88 avegar over 10 episode: -97.859 avegare return across last 100 episodes: -97.859 state values: tensor(0.6155) 242
89 754 -754.0 -99.94883927072323 number episode from 10: 89 avegar over 10 episode: -97.882 avegare return across last 100 episodes: -97.882 state values: tensor(0.5206) 754
90 1000 -1000.0 -99.99568287525881 number episode from 10: 90 avegar over 10 episode: -97.906 avegare return across last 100 episodes: -97.906 state values: tensor(0.4596) 1000
91 313 -313.0 -95.69655844657804 number episode from 10: 91 avegar over 10 episode: -97.882 avegare return across last 100 episodes: -97.882 state values: tensor(0.6008) 313
92 314 -314.0 -95.73959286211226 number episode from 10: 92 avegar over 10 episode: -97.859 avegare return across last 100 episodes: -97.859 state values: tensor(0.6150) 314
93 353 -353.0 -97.1211191361054 number episode from 10: 93 avegar over 10 episode: -97.851 avegare return across last 100 episodes: -97.851 state values: tensor(0.5843) 353
94 1000 -1000.0 -99.99568287525881 number episode from 10: 94 avegar over 10 episode: -97.873 avegare return across last 100 episodes: -97.873 state values: tensor(0.4598) 1000
95 568 -568.0 -99.668265582937 number episode from 10: 95 avegar over 10 episode: -97.892 avegare return across last 100 episodes: -97.892 state values: tensor(0.5406) 568
96 245 -245.0 -91.47640754278069 number episode from 10: 96 avegar over 10 episode: -97.826 avegare return across last 100 episodes: -97.826 state values: tensor(0.6213) 245
97 239 -239.0 -90.94660417148224 number episode from 10: 97 avegar over 10 episode: -97.756 avegare return across last 100 episodes: -97.756 state values: tensor(0.6178) 239
98 1000 -1000.0 -99.99568287525881 number episode from 10: 98 avegar over 10 episode: -97.778 avegare return across last 100 episodes: -97.778 state values: tensor(0.4596) 1000
99 1000 -1000.0 -99.99568287525881 number episode from 10: 99 avegar over 10 episode: -97.8 avegare return across last 100 episodes: -97.8 state values: tensor(0.4599) 1000
100 1000 -1000.0 -99.99568287525881 number episode from 10: 100 avegar over 10 episode: -97.822 avegare return across last 100 episodes: -97.83 state values: tensor(0.4614) 1000
101 315 -315.0 -95.78219693349114 number episode from 10: 101 avegar over 10 episode: -97.802 avegare return across last 100 episodes: -97.788 state values: tensor(0.6045) 315
102 1000 -1000.0 -99.99568287525881 number episode from 10: 102 avegar over 10 episode: -97.824 avegare return across last 100 episodes: -97.826 state values: tensor(0.4601) 1000
103 321 -321.0 -96.0290221387992 number episode from 10: 103 avegar over 10 episode: -97.806 avegare return across last 100 episodes: -97.828 state values: tensor(0.6368) 321
104 398 -398.0 -98.16849777828321 number episode from 10: 104 avegar over 10 episode: -97.81 avegare return across last 100 episodes: -97.809 state values: tensor(0.6101) 398
105 1000 -1000.0 -99.99568287525881 number episode from 10: 105 avegar over 10 episode: -97.83 avegare return across last 100 episodes: -97.838 state values: tensor(0.4602) 1000
106 354 -354.0 -97.14990794474436 number episode from 10: 106 avegar over 10 episode: -97.824 avegare return across last 100 episodes: -97.896 state values: tensor(0.5992) 354
107 1000 -1000.0 -99.99568287525881 number episode from 10: 107 avegar over 10 episode: -97.844 avegare return across last 100 episodes: -97.937 state values: tensor(0.4601) 1000
108 324 -324.0 -96.14696415225472 number episode from 10: 108 avegar over 10 episode: -97.829 avegare return across last 100 episodes: -97.927 state values: tensor(0.6256) 324
109 237 -237.0 -90.76278356441406 number episode from 10: 109 avegar over 10 episode: -97.764 avegare return across last 100 episodes: -97.834 state values: tensor(0.6197) 237
110 238 -238.0 -90.85515572876993 number episode from 10: 110 avegar over 10 episode: -97.702 avegare return across last 100 episodes: -97.771 state values: tensor(0.6119) 238
111 245 -245.0 -91.47640754278069 number episode from 10: 111 avegar over 10 episode: -97.646 avegare return across last 100 episodes: -97.686 state values: tensor(0.6101) 245
112 239 -239.0 -90.94660417148224 number episode from 10: 112 avegar over 10 episode: -97.587 avegare return across last 100 episodes: -97.596 state values: tensor(0.6176) 239
113 321 -321.0 -96.0290221387992 number episode from 10: 113 avegar over 10 episode: -97.573 avegare return across last 100 episodes: -97.556 state values: tensor(0.6372) 321
114 239 -239.0 -90.94660417148224 number episode from 10: 114 avegar over 10 episode: -97.516 avegare return across last 100 episodes: -97.505 state values: tensor(0.6181) 239
115 1000 -1000.0 -99.99568287525881 number episode from 10: 115 avegar over 10 episode: -97.537 avegare return across last 100 episodes: -97.547 state values: tensor(0.4594) 1000
116 746 -746.0 -99.94455592149627 number episode from 10: 116 avegar over 10 episode: -97.558 avegare return across last 100 episodes: -97.547 state values: tensor(0.5220) 746
117 1000 -1000.0 -99.99568287525881 number episode from 10: 117 avegar over 10 episode: -97.578 avegare return across last 100 episodes: -97.547 state values: tensor(0.4594) 1000
118 1000 -1000.0 -99.99568287525881 number episode from 10: 118 avegar over 10 episode: -97.599 avegare return across last 100 episodes: -97.591 state values: tensor(0.4604) 1000
119 1000 -1000.0 -99.99568287525881 number episode from 10: 119 avegar over 10 episode: -97.619 avegare return across last 100 episodes: -97.63 state values: tensor(0.4597) 1000
120 350 -350.0 -97.03299615490216 number episode from 10: 120 avegar over 10 episode: -97.614 avegare return across last 100 episodes: -97.644 state values: tensor(0.5864) 350
121 320 -320.0 -95.98891125131233 number episode from 10: 121 avegar over 10 episode: -97.601 avegare return across last 100 episodes: -97.604 state values: tensor(0.6362) 320
122 240 -240.0 -91.03713812976741 number episode from 10: 122 avegar over 10 episode: -97.547 avegare return across last 100 episodes: -97.515 state values: tensor(0.6125) 240
123 1000 -1000.0 -99.99568287525881 number episode from 10: 123 avegar over 10 episode: -97.567 avegare return across last 100 episodes: -97.515 state values: tensor(0.4599) 1000
124 561 -561.0 -99.64408673940306 number episode from 10: 124 avegar over 10 episode: -97.584 avegare return across last 100 episodes: -97.511 state values: tensor(0.5394) 561
125 388 -388.0 -97.97485789211497 number episode from 10: 125 avegar over 10 episode: -97.587 avegare return across last 100 episodes: -97.491 state values: tensor(0.5726) 388
126 1000 -1000.0 -99.99568287525881 number episode from 10: 126 avegar over 10 episode: -97.606 avegare return across last 100 episodes: -97.579 state values: tensor(0.4600) 1000
127 325 -325.0 -96.18549451073217 number episode from 10: 127 avegar over 10 episode: -97.595 avegare return across last 100 episodes: -97.541 state values: tensor(0.6278) 325
128 1000 -1000.0 -99.99568287525881 number episode from 10: 128 avegar over 10 episode: -97.613 avegare return across last 100 episodes: -97.541 state values: tensor(0.4596) 1000
129 354 -354.0 -97.14990794474436 number episode from 10: 129 avegar over 10 episode: -97.61 avegare return across last 100 episodes: -97.513 state values: tensor(0.5992) 354
130 1000 -1000.0 -99.99568287525881 number episode from 10: 130 avegar over 10 episode: -97.628 avegare return across last 100 episodes: -97.513 state values: tensor(0.4597) 1000
131 1000 -1000.0 -99.99568287525881 number episode from 10: 131 avegar over 10 episode: -97.646 avegare return across last 100 episodes: -97.513 state values: tensor(0.4628) 1000
132 1000 -1000.0 -99.99568287525881 number episode from 10: 132 avegar over 10 episode: -97.663 avegare return across last 100 episodes: -97.603 state values: tensor(0.4606) 1000
133 1000 -1000.0 -99.99568287525881 number episode from 10: 133 avegar over 10 episode: -97.681 avegare return across last 100 episodes: -97.603 state values: tensor(0.4597) 1000
134 1000 -1000.0 -99.99568287525881 number episode from 10: 134 avegar over 10 episode: -97.698 avegare return across last 100 episodes: -97.692 state values: tensor(0.4640) 1000
135 459 -459.0 -99.00790257989588 number episode from 10: 135 avegar over 10 episode: -97.708 avegare return across last 100 episodes: -97.682 state values: tensor(0.5543) 459
136 313 -313.0 -95.69655844657804 number episode from 10: 136 avegar over 10 episode: -97.693 avegare return across last 100 episodes: -97.639 state values: tensor(0.5945) 313
137 1000 -1000.0 -99.99568287525881 number episode from 10: 137 avegar over 10 episode: -97.71 avegare return across last 100 episodes: -97.639 state values: tensor(0.4590) 1000
138 319 -319.0 -95.9483952033458 number episode from 10: 138 avegar over 10 episode: -97.697 avegare return across last 100 episodes: -97.599 state values: tensor(0.6087) 319
139 1000 -1000.0 -99.99568287525881 number episode from 10: 139 avegar over 10 episode: -97.713 avegare return across last 100 episodes: -97.599 state values: tensor(0.4613) 1000
140 242 -242.0 -91.21549908098504 number episode from 10: 140 avegar over 10 episode: -97.667 avegare return across last 100 episodes: -97.511 state values: tensor(0.6127) 242
141 1000 -1000.0 -99.99568287525881 number episode from 10: 141 avegar over 10 episode: -97.684 avegare return across last 100 episodes: -97.511 state values: tensor(0.4597) 1000
142 610 -610.0 -99.78249527067084 number episode from 10: 142 avegar over 10 episode: -97.698 avegare return across last 100 episodes: -97.509 state values: tensor(0.5338) 610
143 1000 -1000.0 -99.99568287525881 number episode from 10: 143 avegar over 10 episode: -97.714 avegare return across last 100 episodes: -97.509 state values: tensor(0.4598) 1000
144 1000 -1000.0 -99.99568287525881 number episode from 10: 144 avegar over 10 episode: -97.73 avegare return across last 100 episodes: -97.509 state values: tensor(0.4595) 1000
145 239 -239.0 -90.94660417148224 number episode from 10: 145 avegar over 10 episode: -97.684 avegare return across last 100 episodes: -97.418 state values: tensor(0.6189) 239
146 1000 -1000.0 -99.99568287525881 number episode from 10: 146 avegar over 10 episode: -97.699 avegare return across last 100 episodes: -97.46 state values: tensor(0.4632) 1000
147 239 -239.0 -90.94660417148224 number episode from 10: 147 avegar over 10 episode: -97.654 avegare return across last 100 episodes: -97.369 state values: tensor(0.6173) 239
148 1000 -1000.0 -99.99568287525881 number episode from 10: 148 avegar over 10 episode: -97.669 avegare return across last 100 episodes: -97.4 state values: tensor(0.4618) 1000
149 1000 -1000.0 -99.99568287525881 number episode from 10: 149 avegar over 10 episode: -97.685 avegare return across last 100 episodes: -97.4 state values: tensor(0.4590) 1000
150 1000 -1000.0 -99.99568287525881 number episode from 10: 150 avegar over 10 episode: -97.7 avegare return across last 100 episodes: -97.4 state values: tensor(0.4615) 1000
151 323 -323.0 -96.1080445982371 number episode from 10: 151 avegar over 10 episode: -97.69 avegare return across last 100 episodes: -97.362 state values: tensor(0.6305) 323
152 243 -243.0 -91.30334409017519 number episode from 10: 152 avegar over 10 episode: -97.648 avegare return across last 100 episodes: -97.275 state values: tensor(0.6178) 243
153 1000 -1000.0 -99.99568287525881 number episode from 10: 153 avegar over 10 episode: -97.663 avegare return across last 100 episodes: -97.363 state values: tensor(0.4832) 1000
154 397 -397.0 -98.14999775584162 number episode from 10: 154 avegar over 10 episode: -97.666 avegare return across last 100 episodes: -97.345 state values: tensor(0.6086) 397
155 1000 -1000.0 -99.99568287525881 number episode from 10: 155 avegar over 10 episode: -97.681 avegare return across last 100 episodes: -97.345 state values: tensor(0.4611) 1000
156 313 -313.0 -95.69655844657804 number episode from 10: 156 avegar over 10 episode: -97.669 avegare return across last 100 episodes: -97.33 state values: tensor(0.5996) 313
157 1000 -1000.0 -99.99568287525881 number episode from 10: 157 avegar over 10 episode: -97.683 avegare return across last 100 episodes: -97.421 state values: tensor(0.4670) 1000
158 494 -494.0 -99.30211135661274 number episode from 10: 158 avegar over 10 episode: -97.694 avegare return across last 100 episodes: -97.414 state values: tensor(0.5482) 494
159 1000 -1000.0 -99.99568287525881 number episode from 10: 159 avegar over 10 episode: -97.708 avegare return across last 100 episodes: -97.454 state values: tensor(0.4646) 1000
160 1000 -1000.0 -99.99568287525881 number episode from 10: 160 avegar over 10 episode: -97.722 avegare return across last 100 episodes: -97.545 state values: tensor(0.4621) 1000
161 725 -725.0 -99.93152751599689 number episode from 10: 161 avegar over 10 episode: -97.736 avegare return across last 100 episodes: -97.633 state values: tensor(0.5520) 725
162 239 -239.0 -90.94660417148224 number episode from 10: 162 avegar over 10 episode: -97.694 avegare return across last 100 episodes: -97.543 state values: tensor(0.6185) 239
163 1000 -1000.0 -99.99568287525881 number episode from 10: 163 avegar over 10 episode: -97.708 avegare return across last 100 episodes: -97.574 state values: tensor(0.4619) 1000
164 346 -346.0 -96.91128860185685 number episode from 10: 164 avegar over 10 episode: -97.703 avegare return across last 100 episodes: -97.543 state values: tensor(0.5872) 346
165 238 -238.0 -90.85515572876993 number episode from 10: 165 avegar over 10 episode: -97.662 avegare return across last 100 episodes: -97.492 state values: tensor(0.6141) 238
166 355 -355.0 -97.17840886529692 number episode from 10: 166 avegar over 10 episode: -97.659 avegare return across last 100 episodes: -97.504 state values: tensor(0.5967) 355
167 355 -355.0 -97.17840886529692 number episode from 10: 167 avegar over 10 episode: -97.656 avegare return across last 100 episodes: -97.503 state values: tensor(0.5849) 355
168 1000 -1000.0 -99.99568287525881 number episode from 10: 168 avegar over 10 episode: -97.67 avegare return across last 100 episodes: -97.503 state values: tensor(0.4605) 1000
169 238 -238.0 -90.85515572876993 number episode from 10: 169 avegar over 10 episode: -97.63 avegare return across last 100 episodes: -97.412 state values: tensor(0.6152) 238
170 313 -313.0 -95.69655844657804 number episode from 10: 170 avegar over 10 episode: -97.619 avegare return across last 100 episodes: -97.41 state values: tensor(0.6015) 313
171 1000 -1000.0 -99.99568287525881 number episode from 10: 171 avegar over 10 episode: -97.633 avegare return across last 100 episodes: -97.41 state values: tensor(0.4605) 1000
172 1000 -1000.0 -99.99568287525881 number episode from 10: 172 avegar over 10 episode: -97.646 avegare return across last 100 episodes: -97.41 state values: tensor(0.4602) 1000
173 1000 -1000.0 -99.99568287525881 number episode from 10: 173 avegar over 10 episode: -97.66 avegare return across last 100 episodes: -97.451 state values: tensor(0.4595) 1000
174 1000 -1000.0 -99.99568287525881 number episode from 10: 174 avegar over 10 episode: -97.673 avegare return across last 100 episodes: -97.451 state values: tensor(0.4595) 1000
175 976 -976.0 -99.99450522482817 number episode from 10: 175 avegar over 10 episode: -97.686 avegare return across last 100 episodes: -97.451 state values: tensor(0.5114) 976
176 429 -429.0 -98.65878475150726 number episode from 10: 176 avegar over 10 episode: -97.692 avegare return across last 100 episodes: -97.438 state values: tensor(0.5727) 429
177 429 -429.0 -98.65878475150726 number episode from 10: 177 avegar over 10 episode: -97.697 avegare return across last 100 episodes: -97.424 state values: tensor(0.5680) 429
178 1000 -1000.0 -99.99568287525881 number episode from 10: 178 avegar over 10 episode: -97.71 avegare return across last 100 episodes: -97.424 state values: tensor(0.4607) 1000
179 1000 -1000.0 -99.99568287525881 number episode from 10: 179 avegar over 10 episode: -97.723 avegare return across last 100 episodes: -97.452 state values: tensor(0.4606) 1000
180 533 -533.0 -99.52841637065397 number episode from 10: 180 avegar over 10 episode: -97.733 avegare return across last 100 episodes: -97.488 state values: tensor(0.5447) 533
181 317 -317.0 -95.86613121451465 number episode from 10: 181 avegar over 10 episode: -97.723 avegare return across last 100 episodes: -97.447 state values: tensor(0.6091) 317
182 238 -238.0 -90.85515572876993 number episode from 10: 182 avegar over 10 episode: -97.685 avegare return across last 100 episodes: -97.447 state values: tensor(0.6177) 238
183 355 -355.0 -97.17840886529692 number episode from 10: 183 avegar over 10 episode: -97.682 avegare return across last 100 episodes: -97.509 state values: tensor(0.5976) 355
184 1000 -1000.0 -99.99568287525881 number episode from 10: 184 avegar over 10 episode: -97.695 avegare return across last 100 episodes: -97.553 state values: tensor(0.4626) 1000
185 1000 -1000.0 -99.99568287525881 number episode from 10: 185 avegar over 10 episode: -97.707 avegare return across last 100 episodes: -97.553 state values: tensor(0.4605) 1000
186 1000 -1000.0 -99.99568287525881 number episode from 10: 186 avegar over 10 episode: -97.719 avegare return across last 100 episodes: -97.553 state values: tensor(0.4607) 1000
187 1000 -1000.0 -99.99568287525881 number episode from 10: 187 avegar over 10 episode: -97.731 avegare return across last 100 episodes: -97.553 state values: tensor(0.4620) 1000
188 321 -321.0 -96.0290221387992 number episode from 10: 188 avegar over 10 episode: -97.722 avegare return across last 100 episodes: -97.601 state values: tensor(0.6189) 321
189 1000 -1000.0 -99.99568287525881 number episode from 10: 189 avegar over 10 episode: -97.734 avegare return across last 100 episodes: -97.601 state values: tensor(0.4618) 1000
190 1000 -1000.0 -99.99568287525881 number episode from 10: 190 avegar over 10 episode: -97.746 avegare return across last 100 episodes: -97.601 state values: tensor(0.4595) 1000
191 238 -238.0 -90.85515572876993 number episode from 10: 191 avegar over 10 episode: -97.71 avegare return across last 100 episodes: -97.553 state values: tensor(0.6100) 238
192 1000 -1000.0 -99.99568287525881 number episode from 10: 192 avegar over 10 episode: -97.722 avegare return across last 100 episodes: -97.595 state values: tensor(0.5044) 1000
193 534 -534.0 -99.53313220694743 number episode from 10: 193 avegar over 10 episode: -97.732 avegare return across last 100 episodes: -97.619 state values: tensor(0.5485) 534
194 1000 -1000.0 -99.99568287525881 number episode from 10: 194 avegar over 10 episode: -97.743 avegare return across last 100 episodes: -97.619 state values: tensor(0.4606) 1000
195 1000 -1000.0 -99.99568287525881 number episode from 10: 195 avegar over 10 episode: -97.755 avegare return across last 100 episodes: -97.623 state values: tensor(0.4621) 1000
196 1000 -1000.0 -99.99568287525881 number episode from 10: 196 avegar over 10 episode: -97.766 avegare return across last 100 episodes: -97.708 state values: tensor(0.4611) 1000
197 1000 -1000.0 -99.99568287525881 number episode from 10: 197 avegar over 10 episode: -97.777 avegare return across last 100 episodes: -97.798 state values: tensor(0.4603) 1000
198 1000 -1000.0 -99.99568287525881 number episode from 10: 198 avegar over 10 episode: -97.788 avegare return across last 100 episodes: -97.798 state values: tensor(0.4600) 1000
199 236 -236.0 -90.66947834789299 number episode from 10: 199 avegar over 10 episode: -97.753 avegare return across last 100 episodes: -97.705 state values: tensor(0.6127) 236
200 239 -239.0 -90.94660417148224 number episode from 10: 200 avegar over 10 episode: -97.719 avegare return across last 100 episodes: -97.615 state values: tensor(0.6087) 239
load offline data!!!!!
mem_cntr: 50000 ; mem_size: 50000
nn.learn_nn_feature_fqi FQI:  998
nn.learn_nn_feature_fqi FQI:  1998
nn.learn_nn_feature_fqi FQI:  2998
nn.learn_nn_feature_fqi FQI:  3998
nn.learn_nn_feature_fqi FQI:  4998
nn.learn_nn_feature_fqi FQI:  5998
nn.learn_nn_feature_fqi FQI:  6998
nn.learn_nn_feature_fqi FQI:  7998
nn.learn_nn_feature_fqi FQI:  8998
nn.learn_nn_feature_fqi FQI:  9998
nn.learn_nn_feature_fqi FQI:  10998
nn.learn_nn_feature_fqi FQI:  11998
nn.learn_nn_feature_fqi FQI:  12998
nn.learn_nn_feature_fqi FQI:  13998
nn.learn_nn_feature_fqi FQI:  14998
nn.learn_nn_feature_fqi FQI:  15998
nn.learn_nn_feature_fqi FQI:  16998
nn.learn_nn_feature_fqi FQI:  17998
nn.learn_nn_feature_fqi FQI:  18998
nn.learn_nn_feature_fqi FQI:  19998
nn.learn_nn_feature_fqi FQI:  20998
nn.learn_nn_feature_fqi FQI:  21998
nn.learn_nn_feature_fqi FQI:  22998
nn.learn_nn_feature_fqi FQI:  23998
nn.learn_nn_feature_fqi FQI:  24998
nn.learn_nn_feature_fqi FQI:  25998
nn.learn_nn_feature_fqi FQI:  26998
nn.learn_nn_feature_fqi FQI:  27998
nn.learn_nn_feature_fqi FQI:  28998
nn.learn_nn_feature_fqi FQI:  29998
nn.learn_nn_feature_fqi FQI:  30998
nn.learn_nn_feature_fqi FQI:  31998
nn.learn_nn_feature_fqi FQI:  32998
nn.learn_nn_feature_fqi FQI:  33998
nn.learn_nn_feature_fqi FQI:  34998
nn.learn_nn_feature_fqi FQI:  35998
nn.learn_nn_feature_fqi FQI:  36998
nn.learn_nn_feature_fqi FQI:  37998
nn.learn_nn_feature_fqi FQI:  38998
nn.learn_nn_feature_fqi FQI:  39998
nn.learn_nn_feature_fqi FQI:  40998
nn.learn_nn_feature_fqi FQI:  41998
nn.learn_nn_feature_fqi FQI:  42998
nn.learn_nn_feature_fqi FQI:  43998
nn.learn_nn_feature_fqi FQI:  44998
nn.learn_nn_feature_fqi FQI:  45998
nn.learn_nn_feature_fqi FQI:  46998
nn.learn_nn_feature_fqi FQI:  47998
nn.learn_nn_feature_fqi FQI:  48998
nn.learn_nn_feature_fqi FQI:  49998
nn.learn_nn_feature_fqi FQI:  50998
nn.learn_nn_feature_fqi FQI:  51998
nn.learn_nn_feature_fqi FQI:  52998
nn.learn_nn_feature_fqi FQI:  53998
nn.learn_nn_feature_fqi FQI:  54998
nn.learn_nn_feature_fqi FQI:  55998
nn.learn_nn_feature_fqi FQI:  56998
nn.learn_nn_feature_fqi FQI:  57998
nn.learn_nn_feature_fqi FQI:  58998
nn.learn_nn_feature_fqi FQI:  59998
nn.learn_nn_feature_fqi FQI:  60998
nn.learn_nn_feature_fqi FQI:  61998
nn.learn_nn_feature_fqi FQI:  62998
nn.learn_nn_feature_fqi FQI:  63998
nn.learn_nn_feature_fqi FQI:  64998
nn.learn_nn_feature_fqi FQI:  65998
nn.learn_nn_feature_fqi FQI:  66998
nn.learn_nn_feature_fqi FQI:  67998
nn.learn_nn_feature_fqi FQI:  68998
nn.learn_nn_feature_fqi FQI:  69998
nn.learn_nn_feature_fqi FQI:  70998
nn.learn_nn_feature_fqi FQI:  71998
nn.learn_nn_feature_fqi FQI:  72998
nn.learn_nn_feature_fqi FQI:  73998
nn.learn_nn_feature_fqi FQI:  74998
nn.learn_nn_feature_fqi FQI:  75998
nn.learn_nn_feature_fqi FQI:  76998
nn.learn_nn_feature_fqi FQI:  77998
nn.learn_nn_feature_fqi FQI:  78998
nn.learn_nn_feature_fqi FQI:  79998
nn.learn_nn_feature_fqi FQI:  80998
nn.learn_nn_feature_fqi FQI:  81998
nn.learn_nn_feature_fqi FQI:  82998
nn.learn_nn_feature_fqi FQI:  83998
nn.learn_nn_feature_fqi FQI:  84998
nn.learn_nn_feature_fqi FQI:  85998
nn.learn_nn_feature_fqi FQI:  86998
nn.learn_nn_feature_fqi FQI:  87998
nn.learn_nn_feature_fqi FQI:  88998
nn.learn_nn_feature_fqi FQI:  89998
nn.learn_nn_feature_fqi FQI:  90998
nn.learn_nn_feature_fqi FQI:  91998
nn.learn_nn_feature_fqi FQI:  92998
nn.learn_nn_feature_fqi FQI:  93998
nn.learn_nn_feature_fqi FQI:  94998
nn.learn_nn_feature_fqi FQI:  95998
nn.learn_nn_feature_fqi FQI:  96998
nn.learn_nn_feature_fqi FQI:  97998
nn.learn_nn_feature_fqi FQI:  98998
nn.learn_nn_feature_fqi FQI:  99998
nn.learn_nn_feature_fqi FQI:  100998
nn.learn_nn_feature_fqi FQI:  101998
nn.learn_nn_feature_fqi FQI:  102998
nn.learn_nn_feature_fqi FQI:  103998
nn.learn_nn_feature_fqi FQI:  104998
nn.learn_nn_feature_fqi FQI:  105998
nn.learn_nn_feature_fqi FQI:  106998
nn.learn_nn_feature_fqi FQI:  107998
nn.learn_nn_feature_fqi FQI:  108998
nn.learn_nn_feature_fqi FQI:  109998
nn.learn_nn_feature_fqi FQI:  110998
nn.learn_nn_feature_fqi FQI:  111998
nn.learn_nn_feature_fqi FQI:  112998
nn.learn_nn_feature_fqi FQI:  113998
nn.learn_nn_feature_fqi FQI:  114998
nn.learn_nn_feature_fqi FQI:  115998
nn.learn_nn_feature_fqi FQI:  116998
nn.learn_nn_feature_fqi FQI:  117998
nn.learn_nn_feature_fqi FQI:  118998
nn.learn_nn_feature_fqi FQI:  119998
nn.learn_nn_feature_fqi FQI:  120998
nn.learn_nn_feature_fqi FQI:  121998
nn.learn_nn_feature_fqi FQI:  122998
nn.learn_nn_feature_fqi FQI:  123998
nn.learn_nn_feature_fqi FQI:  124998
nn.learn_nn_feature_fqi FQI:  125998
nn.learn_nn_feature_fqi FQI:  126998
nn.learn_nn_feature_fqi FQI:  127998
nn.learn_nn_feature_fqi FQI:  128998
nn.learn_nn_feature_fqi FQI:  129998
nn.learn_nn_feature_fqi FQI:  130998
nn.learn_nn_feature_fqi FQI:  131998
nn.learn_nn_feature_fqi FQI:  132998
nn.learn_nn_feature_fqi FQI:  133998
nn.learn_nn_feature_fqi FQI:  134998
nn.learn_nn_feature_fqi FQI:  135998
nn.learn_nn_feature_fqi FQI:  136998
nn.learn_nn_feature_fqi FQI:  137998
nn.learn_nn_feature_fqi FQI:  138998
nn.learn_nn_feature_fqi FQI:  139998
nn.learn_nn_feature_fqi FQI:  140998
nn.learn_nn_feature_fqi FQI:  141998
nn.learn_nn_feature_fqi FQI:  142998
nn.learn_nn_feature_fqi FQI:  143998
nn.learn_nn_feature_fqi FQI:  144998
nn.learn_nn_feature_fqi FQI:  145998
nn.learn_nn_feature_fqi FQI:  146998
nn.learn_nn_feature_fqi FQI:  147998
nn.learn_nn_feature_fqi FQI:  148998
nn.learn_nn_feature_fqi FQI:  149998
nn.learn_nn_feature_fqi FQI:  150998
nn.learn_nn_feature_fqi FQI:  151998
nn.learn_nn_feature_fqi FQI:  152998
nn.learn_nn_feature_fqi FQI:  153998
nn.learn_nn_feature_fqi FQI:  154998
nn.learn_nn_feature_fqi FQI:  155998
0 1001 -1000.0 -98.99572604650622 number episode from 10: 0 avegar over 10 episode: -98.996 avegare return across last 100 episodes: -98.996 state values: tensor(0.8124) 1000
1 1000 -1000.0 -99.99568287525881 number episode from 10: 1 avegar over 10 episode: -99.496 avegare return across last 100 episodes: -99.496 state values: tensor(0.6141) 1000
2 1000 -1000.0 -99.99568287525881 number episode from 10: 2 avegar over 10 episode: -99.662 avegare return across last 100 episodes: -99.662 state values: tensor(0.7978) 1000
3 1000 -1000.0 -99.99568287525881 number episode from 10: 3 avegar over 10 episode: -99.746 avegare return across last 100 episodes: -99.746 state values: tensor(0.6148) 1000
4 1000 -1000.0 -99.99568287525881 number episode from 10: 4 avegar over 10 episode: -99.796 avegare return across last 100 episodes: -99.796 state values: tensor(0.6625) 1000
5 1000 -1000.0 -99.99568287525881 number episode from 10: 5 avegar over 10 episode: -99.829 avegare return across last 100 episodes: -99.829 state values: tensor(0.7908) 1000
6 1000 -1000.0 -99.99568287525881 number episode from 10: 6 avegar over 10 episode: -99.853 avegare return across last 100 episodes: -99.853 state values: tensor(0.6141) 1000
7 1000 -1000.0 -99.99568287525881 number episode from 10: 7 avegar over 10 episode: -99.871 avegare return across last 100 episodes: -99.871 state values: tensor(0.6453) 1000
8 1000 -1000.0 -99.99568287525881 number episode from 10: 8 avegar over 10 episode: -99.885 avegare return across last 100 episodes: -99.885 state values: tensor(0.8155) 1000
9 1000 -1000.0 -99.99568287525881 number episode from 10: 9 avegar over 10 episode: -99.896 avegare return across last 100 episodes: -99.896 state values: tensor(0.8110) 1000
10 1000 -1000.0 -99.99568287525881 number episode from 10: 10 avegar over 10 episode: -99.905 avegare return across last 100 episodes: -99.905 state values: tensor(0.6650) 1000
11 1000 -1000.0 -99.99568287525881 number episode from 10: 11 avegar over 10 episode: -99.912 avegare return across last 100 episodes: -99.912 state values: tensor(0.7940) 1000
12 1000 -1000.0 -99.99568287525881 number episode from 10: 12 avegar over 10 episode: -99.919 avegare return across last 100 episodes: -99.919 state values: tensor(0.7964) 1000
13 1000 -1000.0 -99.99568287525881 number episode from 10: 13 avegar over 10 episode: -99.924 avegare return across last 100 episodes: -99.924 state values: tensor(0.6143) 1000
14 1000 -1000.0 -99.99568287525881 number episode from 10: 14 avegar over 10 episode: -99.929 avegare return across last 100 episodes: -99.929 state values: tensor(0.6143) 1000
15 1000 -1000.0 -99.99568287525881 number episode from 10: 15 avegar over 10 episode: -99.933 avegare return across last 100 episodes: -99.933 state values: tensor(0.6147) 1000
16 1000 -1000.0 -99.99568287525881 number episode from 10: 16 avegar over 10 episode: -99.937 avegare return across last 100 episodes: -99.937 state values: tensor(0.7808) 1000
17 1000 -1000.0 -99.99568287525881 number episode from 10: 17 avegar over 10 episode: -99.94 avegare return across last 100 episodes: -99.94 state values: tensor(0.6147) 1000
18 1000 -1000.0 -99.99568287525881 number episode from 10: 18 avegar over 10 episode: -99.943 avegare return across last 100 episodes: -99.943 state values: tensor(0.7902) 1000
19 1000 -1000.0 -99.99568287525881 number episode from 10: 19 avegar over 10 episode: -99.946 avegare return across last 100 episodes: -99.946 state values: tensor(0.6139) 1000
20 1000 -1000.0 -99.99568287525881 number episode from 10: 20 avegar over 10 episode: -99.948 avegare return across last 100 episodes: -99.948 state values: tensor(0.8105) 1000
21 1000 -1000.0 -99.99568287525881 number episode from 10: 21 avegar over 10 episode: -99.95 avegare return across last 100 episodes: -99.95 state values: tensor(0.8104) 1000
22 1000 -1000.0 -99.99568287525881 number episode from 10: 22 avegar over 10 episode: -99.952 avegare return across last 100 episodes: -99.952 state values: tensor(0.8011) 1000
23 1000 -1000.0 -99.99568287525881 number episode from 10: 23 avegar over 10 episode: -99.954 avegare return across last 100 episodes: -99.954 state values: tensor(0.6145) 1000
24 1000 -1000.0 -99.99568287525881 number episode from 10: 24 avegar over 10 episode: -99.956 avegare return across last 100 episodes: -99.956 state values: tensor(0.6137) 1000
25 1000 -1000.0 -99.99568287525881 number episode from 10: 25 avegar over 10 episode: -99.957 avegare return across last 100 episodes: -99.957 state values: tensor(0.7515) 1000
26 1000 -1000.0 -99.99568287525881 number episode from 10: 26 avegar over 10 episode: -99.959 avegare return across last 100 episodes: -99.959 state values: tensor(0.6139) 1000
27 1000 -1000.0 -99.99568287525881 number episode from 10: 27 avegar over 10 episode: -99.96 avegare return across last 100 episodes: -99.96 state values: tensor(0.8178) 1000
28 1000 -1000.0 -99.99568287525881 number episode from 10: 28 avegar over 10 episode: -99.961 avegare return across last 100 episodes: -99.961 state values: tensor(0.6492) 1000
29 1000 -1000.0 -99.99568287525881 number episode from 10: 29 avegar over 10 episode: -99.962 avegare return across last 100 episodes: -99.962 state values: tensor(0.7984) 1000
30 1000 -1000.0 -99.99568287525881 number episode from 10: 30 avegar over 10 episode: -99.963 avegare return across last 100 episodes: -99.963 state values: tensor(0.8113) 1000
31 1000 -1000.0 -99.99568287525881 number episode from 10: 31 avegar over 10 episode: -99.964 avegare return across last 100 episodes: -99.964 state values: tensor(0.8004) 1000
32 1000 -1000.0 -99.99568287525881 number episode from 10: 32 avegar over 10 episode: -99.965 avegare return across last 100 episodes: -99.965 state values: tensor(0.6147) 1000
33 1000 -1000.0 -99.99568287525881 number episode from 10: 33 avegar over 10 episode: -99.966 avegare return across last 100 episodes: -99.966 state values: tensor(0.8070) 1000
34 1000 -1000.0 -99.99568287525881 number episode from 10: 34 avegar over 10 episode: -99.967 avegare return across last 100 episodes: -99.967 state values: tensor(0.6142) 1000
35 1000 -1000.0 -99.99568287525881 number episode from 10: 35 avegar over 10 episode: -99.968 avegare return across last 100 episodes: -99.968 state values: tensor(0.8157) 1000
36 1000 -1000.0 -99.99568287525881 number episode from 10: 36 avegar over 10 episode: -99.969 avegare return across last 100 episodes: -99.969 state values: tensor(0.6149) 1000
37 1000 -1000.0 -99.99568287525881 number episode from 10: 37 avegar over 10 episode: -99.969 avegare return across last 100 episodes: -99.969 state values: tensor(0.6138) 1000
38 1000 -1000.0 -99.99568287525881 number episode from 10: 38 avegar over 10 episode: -99.97 avegare return across last 100 episodes: -99.97 state values: tensor(0.6578) 1000
39 1000 -1000.0 -99.99568287525881 number episode from 10: 39 avegar over 10 episode: -99.971 avegare return across last 100 episodes: -99.971 state values: tensor(0.6142) 1000
40 1000 -1000.0 -99.99568287525881 number episode from 10: 40 avegar over 10 episode: -99.971 avegare return across last 100 episodes: -99.971 state values: tensor(0.8103) 1000
41 1000 -1000.0 -99.99568287525881 number episode from 10: 41 avegar over 10 episode: -99.972 avegare return across last 100 episodes: -99.972 state values: tensor(0.8131) 1000
42 1000 -1000.0 -99.99568287525881 number episode from 10: 42 avegar over 10 episode: -99.972 avegare return across last 100 episodes: -99.972 state values: tensor(0.8130) 1000
43 1000 -1000.0 -99.99568287525881 number episode from 10: 43 avegar over 10 episode: -99.973 avegare return across last 100 episodes: -99.973 state values: tensor(0.6138) 1000
44 1000 -1000.0 -99.99568287525881 number episode from 10: 44 avegar over 10 episode: -99.973 avegare return across last 100 episodes: -99.973 state values: tensor(0.8110) 1000
45 1000 -1000.0 -99.99568287525881 number episode from 10: 45 avegar over 10 episode: -99.974 avegare return across last 100 episodes: -99.974 state values: tensor(0.8062) 1000
46 1000 -1000.0 -99.99568287525881 number episode from 10: 46 avegar over 10 episode: -99.974 avegare return across last 100 episodes: -99.974 state values: tensor(0.6219) 1000
47 1000 -1000.0 -99.99568287525881 number episode from 10: 47 avegar over 10 episode: -99.975 avegare return across last 100 episodes: -99.975 state values: tensor(0.6146) 1000
48 1000 -1000.0 -99.99568287525881 number episode from 10: 48 avegar over 10 episode: -99.975 avegare return across last 100 episodes: -99.975 state values: tensor(0.6146) 1000
49 1000 -1000.0 -99.99568287525881 number episode from 10: 49 avegar over 10 episode: -99.976 avegare return across last 100 episodes: -99.976 state values: tensor(0.8030) 1000
50 1000 -1000.0 -99.99568287525881 number episode from 10: 50 avegar over 10 episode: -99.976 avegare return across last 100 episodes: -99.976 state values: tensor(0.6141) 1000
51 1000 -1000.0 -99.99568287525881 number episode from 10: 51 avegar over 10 episode: -99.976 avegare return across last 100 episodes: -99.976 state values: tensor(0.6145) 1000
52 1000 -1000.0 -99.99568287525881 number episode from 10: 52 avegar over 10 episode: -99.977 avegare return across last 100 episodes: -99.977 state values: tensor(0.7792) 1000
53 1000 -1000.0 -99.99568287525881 number episode from 10: 53 avegar over 10 episode: -99.977 avegare return across last 100 episodes: -99.977 state values: tensor(0.8118) 1000
54 1000 -1000.0 -99.99568287525881 number episode from 10: 54 avegar over 10 episode: -99.978 avegare return across last 100 episodes: -99.978 state values: tensor(0.8110) 1000
55 1000 -1000.0 -99.99568287525881 number episode from 10: 55 avegar over 10 episode: -99.978 avegare return across last 100 episodes: -99.978 state values: tensor(0.8132) 1000
56 1000 -1000.0 -99.99568287525881 number episode from 10: 56 avegar over 10 episode: -99.978 avegare return across last 100 episodes: -99.978 state values: tensor(0.7272) 1000
57 1000 -1000.0 -99.99568287525881 number episode from 10: 57 avegar over 10 episode: -99.978 avegare return across last 100 episodes: -99.978 state values: tensor(0.6145) 1000
58 1000 -1000.0 -99.99568287525881 number episode from 10: 58 avegar over 10 episode: -99.979 avegare return across last 100 episodes: -99.979 state values: tensor(0.8071) 1000
59 1000 -1000.0 -99.99568287525881 number episode from 10: 59 avegar over 10 episode: -99.979 avegare return across last 100 episodes: -99.979 state values: tensor(0.8175) 1000
60 1000 -1000.0 -99.99568287525881 number episode from 10: 60 avegar over 10 episode: -99.979 avegare return across last 100 episodes: -99.979 state values: tensor(0.6141) 1000
61 1000 -1000.0 -99.99568287525881 number episode from 10: 61 avegar over 10 episode: -99.98 avegare return across last 100 episodes: -99.98 state values: tensor(0.6139) 1000
62 1000 -1000.0 -99.99568287525881 number episode from 10: 62 avegar over 10 episode: -99.98 avegare return across last 100 episodes: -99.98 state values: tensor(0.7082) 1000
63 1000 -1000.0 -99.99568287525881 number episode from 10: 63 avegar over 10 episode: -99.98 avegare return across last 100 episodes: -99.98 state values: tensor(0.8050) 1000
64 1000 -1000.0 -99.99568287525881 number episode from 10: 64 avegar over 10 episode: -99.98 avegare return across last 100 episodes: -99.98 state values: tensor(0.6148) 1000
65 1000 -1000.0 -99.99568287525881 number episode from 10: 65 avegar over 10 episode: -99.981 avegare return across last 100 episodes: -99.981 state values: tensor(0.6148) 1000
66 187 -187.0 -84.73202677240926 number episode from 10: 66 avegar over 10 episode: -99.753 avegare return across last 100 episodes: -99.753 state values: tensor(0.7746) 187
67 1000 -1000.0 -99.99568287525881 number episode from 10: 67 avegar over 10 episode: -99.757 avegare return across last 100 episodes: -99.757 state values: tensor(0.6144) 1000
68 1000 -1000.0 -99.99568287525881 number episode from 10: 68 avegar over 10 episode: -99.76 avegare return across last 100 episodes: -99.76 state values: tensor(0.6147) 1000
69 1000 -1000.0 -99.99568287525881 number episode from 10: 69 avegar over 10 episode: -99.763 avegare return across last 100 episodes: -99.763 state values: tensor(0.7279) 1000
70 1000 -1000.0 -99.99568287525881 number episode from 10: 70 avegar over 10 episode: -99.767 avegare return across last 100 episodes: -99.767 state values: tensor(0.8060) 1000
71 1000 -1000.0 -99.99568287525881 number episode from 10: 71 avegar over 10 episode: -99.77 avegare return across last 100 episodes: -99.77 state values: tensor(0.6147) 1000
72 1000 -1000.0 -99.99568287525881 number episode from 10: 72 avegar over 10 episode: -99.773 avegare return across last 100 episodes: -99.773 state values: tensor(0.8023) 1000
73 1000 -1000.0 -99.99568287525881 number episode from 10: 73 avegar over 10 episode: -99.776 avegare return across last 100 episodes: -99.776 state values: tensor(0.6142) 1000
74 1000 -1000.0 -99.99568287525881 number episode from 10: 74 avegar over 10 episode: -99.779 avegare return across last 100 episodes: -99.779 state values: tensor(0.6146) 1000
75 1000 -1000.0 -99.99568287525881 number episode from 10: 75 avegar over 10 episode: -99.782 avegare return across last 100 episodes: -99.782 state values: tensor(0.8166) 1000
76 1000 -1000.0 -99.99568287525881 number episode from 10: 76 avegar over 10 episode: -99.784 avegare return across last 100 episodes: -99.784 state values: tensor(0.6140) 1000
77 1000 -1000.0 -99.99568287525881 number episode from 10: 77 avegar over 10 episode: -99.787 avegare return across last 100 episodes: -99.787 state values: tensor(0.6146) 1000
78 1000 -1000.0 -99.99568287525881 number episode from 10: 78 avegar over 10 episode: -99.79 avegare return across last 100 episodes: -99.79 state values: tensor(0.8120) 1000
79 1000 -1000.0 -99.99568287525881 number episode from 10: 79 avegar over 10 episode: -99.792 avegare return across last 100 episodes: -99.792 state values: tensor(0.6139) 1000
80 1000 -1000.0 -99.99568287525881 number episode from 10: 80 avegar over 10 episode: -99.795 avegare return across last 100 episodes: -99.795 state values: tensor(0.8100) 1000
81 1000 -1000.0 -99.99568287525881 number episode from 10: 81 avegar over 10 episode: -99.797 avegare return across last 100 episodes: -99.797 state values: tensor(0.6380) 1000
82 1000 -1000.0 -99.99568287525881 number episode from 10: 82 avegar over 10 episode: -99.8 avegare return across last 100 episodes: -99.8 state values: tensor(0.7557) 1000
83 1000 -1000.0 -99.99568287525881 number episode from 10: 83 avegar over 10 episode: -99.802 avegare return across last 100 episodes: -99.802 state values: tensor(0.6146) 1000
84 1000 -1000.0 -99.99568287525881 number episode from 10: 84 avegar over 10 episode: -99.804 avegare return across last 100 episodes: -99.804 state values: tensor(0.6148) 1000
85 1000 -1000.0 -99.99568287525881 number episode from 10: 85 avegar over 10 episode: -99.807 avegare return across last 100 episodes: -99.807 state values: tensor(0.6148) 1000
86 1000 -1000.0 -99.99568287525881 number episode from 10: 86 avegar over 10 episode: -99.809 avegare return across last 100 episodes: -99.809 state values: tensor(0.6147) 1000
87 1000 -1000.0 -99.99568287525881 number episode from 10: 87 avegar over 10 episode: -99.811 avegare return across last 100 episodes: -99.811 state values: tensor(0.6191) 1000
88 1000 -1000.0 -99.99568287525881 number episode from 10: 88 avegar over 10 episode: -99.813 avegare return across last 100 episodes: -99.813 state values: tensor(0.8126) 1000
89 1000 -1000.0 -99.99568287525881 number episode from 10: 89 avegar over 10 episode: -99.815 avegare return across last 100 episodes: -99.815 state values: tensor(0.8094) 1000
90 1000 -1000.0 -99.99568287525881 number episode from 10: 90 avegar over 10 episode: -99.817 avegare return across last 100 episodes: -99.817 state values: tensor(0.8136) 1000
91 1000 -1000.0 -99.99568287525881 number episode from 10: 91 avegar over 10 episode: -99.819 avegare return across last 100 episodes: -99.819 state values: tensor(0.8066) 1000
92 1000 -1000.0 -99.99568287525881 number episode from 10: 92 avegar over 10 episode: -99.821 avegare return across last 100 episodes: -99.821 state values: tensor(0.8087) 1000
93 1000 -1000.0 -99.99568287525881 number episode from 10: 93 avegar over 10 episode: -99.823 avegare return across last 100 episodes: -99.823 state values: tensor(0.8084) 1000
94 1000 -1000.0 -99.99568287525881 number episode from 10: 94 avegar over 10 episode: -99.824 avegare return across last 100 episodes: -99.824 state values: tensor(0.8008) 1000
95 1000 -1000.0 -99.99568287525881 number episode from 10: 95 avegar over 10 episode: -99.826 avegare return across last 100 episodes: -99.826 state values: tensor(0.8042) 1000
96 1000 -1000.0 -99.99568287525881 number episode from 10: 96 avegar over 10 episode: -99.828 avegare return across last 100 episodes: -99.828 state values: tensor(0.6144) 1000
97 1000 -1000.0 -99.99568287525881 number episode from 10: 97 avegar over 10 episode: -99.83 avegare return across last 100 episodes: -99.83 state values: tensor(0.7908) 1000
98 1000 -1000.0 -99.99568287525881 number episode from 10: 98 avegar over 10 episode: -99.831 avegare return across last 100 episodes: -99.831 state values: tensor(0.6147) 1000
99 1000 -1000.0 -99.99568287525881 number episode from 10: 99 avegar over 10 episode: -99.833 avegare return across last 100 episodes: -99.833 state values: tensor(0.8161) 1000
100 1000 -1000.0 -99.99568287525881 number episode from 10: 100 avegar over 10 episode: -99.835 avegare return across last 100 episodes: -99.843 state values: tensor(0.6151) 1000
101 1000 -1000.0 -99.99568287525881 number episode from 10: 101 avegar over 10 episode: -99.836 avegare return across last 100 episodes: -99.843 state values: tensor(0.6179) 1000
102 1000 -1000.0 -99.99568287525881 number episode from 10: 102 avegar over 10 episode: -99.838 avegare return across last 100 episodes: -99.843 state values: tensor(0.6142) 1000
103 1000 -1000.0 -99.99568287525881 number episode from 10: 103 avegar over 10 episode: -99.839 avegare return across last 100 episodes: -99.843 state values: tensor(0.6147) 1000
104 1000 -1000.0 -99.99568287525881 number episode from 10: 104 avegar over 10 episode: -99.841 avegare return across last 100 episodes: -99.843 state values: tensor(0.8114) 1000
105 1000 -1000.0 -99.99568287525881 number episode from 10: 105 avegar over 10 episode: -99.842 avegare return across last 100 episodes: -99.843 state values: tensor(0.8121) 1000
106 1000 -1000.0 -99.99568287525881 number episode from 10: 106 avegar over 10 episode: -99.844 avegare return across last 100 episodes: -99.843 state values: tensor(0.6143) 1000
107 1000 -1000.0 -99.99568287525881 number episode from 10: 107 avegar over 10 episode: -99.845 avegare return across last 100 episodes: -99.843 state values: tensor(0.6145) 1000
108 1000 -1000.0 -99.99568287525881 number episode from 10: 108 avegar over 10 episode: -99.846 avegare return across last 100 episodes: -99.843 state values: tensor(0.6145) 1000
109 1000 -1000.0 -99.99568287525881 number episode from 10: 109 avegar over 10 episode: -99.848 avegare return across last 100 episodes: -99.843 state values: tensor(0.8142) 1000
110 1000 -1000.0 -99.99568287525881 number episode from 10: 110 avegar over 10 episode: -99.849 avegare return across last 100 episodes: -99.843 state values: tensor(0.6138) 1000
111 1000 -1000.0 -99.99568287525881 number episode from 10: 111 avegar over 10 episode: -99.85 avegare return across last 100 episodes: -99.843 state values: tensor(0.6144) 1000
112 1000 -1000.0 -99.99568287525881 number episode from 10: 112 avegar over 10 episode: -99.852 avegare return across last 100 episodes: -99.843 state values: tensor(0.8093) 1000
113 1000 -1000.0 -99.99568287525881 number episode from 10: 113 avegar over 10 episode: -99.853 avegare return across last 100 episodes: -99.843 state values: tensor(0.7745) 1000
114 1000 -1000.0 -99.99568287525881 number episode from 10: 114 avegar over 10 episode: -99.854 avegare return across last 100 episodes: -99.843 state values: tensor(0.6146) 1000
115 1000 -1000.0 -99.99568287525881 number episode from 10: 115 avegar over 10 episode: -99.855 avegare return across last 100 episodes: -99.843 state values: tensor(0.6143) 1000
116 1000 -1000.0 -99.99568287525881 number episode from 10: 116 avegar over 10 episode: -99.857 avegare return across last 100 episodes: -99.843 state values: tensor(0.8009) 1000
117 1000 -1000.0 -99.99568287525881 number episode from 10: 117 avegar over 10 episode: -99.858 avegare return across last 100 episodes: -99.843 state values: tensor(0.6138) 1000
118 1000 -1000.0 -99.99568287525881 number episode from 10: 118 avegar over 10 episode: -99.859 avegare return across last 100 episodes: -99.843 state values: tensor(0.8112) 1000
119 1000 -1000.0 -99.99568287525881 number episode from 10: 119 avegar over 10 episode: -99.86 avegare return across last 100 episodes: -99.843 state values: tensor(0.6138) 1000
120 1000 -1000.0 -99.99568287525881 number episode from 10: 120 avegar over 10 episode: -99.861 avegare return across last 100 episodes: -99.843 state values: tensor(0.6147) 1000
121 1000 -1000.0 -99.99568287525881 number episode from 10: 121 avegar over 10 episode: -99.862 avegare return across last 100 episodes: -99.843 state values: tensor(0.8081) 1000
122 1000 -1000.0 -99.99568287525881 number episode from 10: 122 avegar over 10 episode: -99.863 avegare return across last 100 episodes: -99.843 state values: tensor(0.6143) 1000
123 1000 -1000.0 -99.99568287525881 number episode from 10: 123 avegar over 10 episode: -99.865 avegare return across last 100 episodes: -99.843 state values: tensor(0.6142) 1000
124 1000 -1000.0 -99.99568287525881 number episode from 10: 124 avegar over 10 episode: -99.866 avegare return across last 100 episodes: -99.843 state values: tensor(0.8087) 1000
125 1000 -1000.0 -99.99568287525881 number episode from 10: 125 avegar over 10 episode: -99.867 avegare return across last 100 episodes: -99.843 state values: tensor(0.6222) 1000
126 1000 -1000.0 -99.99568287525881 number episode from 10: 126 avegar over 10 episode: -99.868 avegare return across last 100 episodes: -99.843 state values: tensor(0.6148) 1000
127 1000 -1000.0 -99.99568287525881 number episode from 10: 127 avegar over 10 episode: -99.869 avegare return across last 100 episodes: -99.843 state values: tensor(0.6145) 1000
128 1000 -1000.0 -99.99568287525881 number episode from 10: 128 avegar over 10 episode: -99.87 avegare return across last 100 episodes: -99.843 state values: tensor(0.6138) 1000
129 1000 -1000.0 -99.99568287525881 number episode from 10: 129 avegar over 10 episode: -99.871 avegare return across last 100 episodes: -99.843 state values: tensor(0.8107) 1000
130 1000 -1000.0 -99.99568287525881 number episode from 10: 130 avegar over 10 episode: -99.872 avegare return across last 100 episodes: -99.843 state values: tensor(0.6150) 1000
131 1000 -1000.0 -99.99568287525881 number episode from 10: 131 avegar over 10 episode: -99.872 avegare return across last 100 episodes: -99.843 state values: tensor(0.8177) 1000
132 1000 -1000.0 -99.99568287525881 number episode from 10: 132 avegar over 10 episode: -99.873 avegare return across last 100 episodes: -99.843 state values: tensor(0.8072) 1000
133 1000 -1000.0 -99.99568287525881 number episode from 10: 133 avegar over 10 episode: -99.874 avegare return across last 100 episodes: -99.843 state values: tensor(0.8104) 1000
134 1000 -1000.0 -99.99568287525881 number episode from 10: 134 avegar over 10 episode: -99.875 avegare return across last 100 episodes: -99.843 state values: tensor(0.6154) 1000
135 1000 -1000.0 -99.99568287525881 number episode from 10: 135 avegar over 10 episode: -99.876 avegare return across last 100 episodes: -99.843 state values: tensor(0.8080) 1000
136 1000 -1000.0 -99.99568287525881 number episode from 10: 136 avegar over 10 episode: -99.877 avegare return across last 100 episodes: -99.843 state values: tensor(0.6143) 1000
137 1000 -1000.0 -99.99568287525881 number episode from 10: 137 avegar over 10 episode: -99.878 avegare return across last 100 episodes: -99.843 state values: tensor(0.6147) 1000
138 1000 -1000.0 -99.99568287525881 number episode from 10: 138 avegar over 10 episode: -99.879 avegare return across last 100 episodes: -99.843 state values: tensor(0.6658) 1000
139 1000 -1000.0 -99.99568287525881 number episode from 10: 139 avegar over 10 episode: -99.88 avegare return across last 100 episodes: -99.843 state values: tensor(0.8049) 1000
140 1000 -1000.0 -99.99568287525881 number episode from 10: 140 avegar over 10 episode: -99.88 avegare return across last 100 episodes: -99.843 state values: tensor(0.8117) 1000
141 1000 -1000.0 -99.99568287525881 number episode from 10: 141 avegar over 10 episode: -99.881 avegare return across last 100 episodes: -99.843 state values: tensor(0.8050) 1000
142 1000 -1000.0 -99.99568287525881 number episode from 10: 142 avegar over 10 episode: -99.882 avegare return across last 100 episodes: -99.843 state values: tensor(0.8001) 1000
143 1000 -1000.0 -99.99568287525881 number episode from 10: 143 avegar over 10 episode: -99.883 avegare return across last 100 episodes: -99.843 state values: tensor(0.6151) 1000
144 1000 -1000.0 -99.99568287525881 number episode from 10: 144 avegar over 10 episode: -99.884 avegare return across last 100 episodes: -99.843 state values: tensor(0.8127) 1000
145 1000 -1000.0 -99.99568287525881 number episode from 10: 145 avegar over 10 episode: -99.884 avegare return across last 100 episodes: -99.843 state values: tensor(0.8111) 1000
146 1000 -1000.0 -99.99568287525881 number episode from 10: 146 avegar over 10 episode: -99.885 avegare return across last 100 episodes: -99.843 state values: tensor(0.6141) 1000
147 1000 -1000.0 -99.99568287525881 number episode from 10: 147 avegar over 10 episode: -99.886 avegare return across last 100 episodes: -99.843 state values: tensor(0.8106) 1000
148 1000 -1000.0 -99.99568287525881 number episode from 10: 148 avegar over 10 episode: -99.887 avegare return across last 100 episodes: -99.843 state values: tensor(0.8135) 1000
149 1000 -1000.0 -99.99568287525881 number episode from 10: 149 avegar over 10 episode: -99.887 avegare return across last 100 episodes: -99.843 state values: tensor(0.6147) 1000
150 1000 -1000.0 -99.99568287525881 number episode from 10: 150 avegar over 10 episode: -99.888 avegare return across last 100 episodes: -99.843 state values: tensor(0.7663) 1000
151 1000 -1000.0 -99.99568287525881 number episode from 10: 151 avegar over 10 episode: -99.889 avegare return across last 100 episodes: -99.843 state values: tensor(0.8122) 1000
152 1000 -1000.0 -99.99568287525881 number episode from 10: 152 avegar over 10 episode: -99.889 avegare return across last 100 episodes: -99.843 state values: tensor(0.6145) 1000
153 1000 -1000.0 -99.99568287525881 number episode from 10: 153 avegar over 10 episode: -99.89 avegare return across last 100 episodes: -99.843 state values: tensor(0.6551) 1000
154 1000 -1000.0 -99.99568287525881 number episode from 10: 154 avegar over 10 episode: -99.891 avegare return across last 100 episodes: -99.843 state values: tensor(0.6142) 1000
155 1000 -1000.0 -99.99568287525881 number episode from 10: 155 avegar over 10 episode: -99.891 avegare return across last 100 episodes: -99.843 state values: tensor(0.6655) 1000
156 1000 -1000.0 -99.99568287525881 number episode from 10: 156 avegar over 10 episode: -99.892 avegare return across last 100 episodes: -99.843 state values: tensor(0.6197) 1000
157 1000 -1000.0 -99.99568287525881 number episode from 10: 157 avegar over 10 episode: -99.893 avegare return across last 100 episodes: -99.843 state values: tensor(0.6141) 1000
158 1000 -1000.0 -99.99568287525881 number episode from 10: 158 avegar over 10 episode: -99.893 avegare return across last 100 episodes: -99.843 state values: tensor(0.6213) 1000
159 1000 -1000.0 -99.99568287525881 number episode from 10: 159 avegar over 10 episode: -99.894 avegare return across last 100 episodes: -99.843 state values: tensor(0.7032) 1000
160 1000 -1000.0 -99.99568287525881 number episode from 10: 160 avegar over 10 episode: -99.895 avegare return across last 100 episodes: -99.843 state values: tensor(0.6143) 1000
161 1000 -1000.0 -99.99568287525881 number episode from 10: 161 avegar over 10 episode: -99.895 avegare return across last 100 episodes: -99.843 state values: tensor(0.6138) 1000
162 1000 -1000.0 -99.99568287525881 number episode from 10: 162 avegar over 10 episode: -99.896 avegare return across last 100 episodes: -99.843 state values: tensor(0.8094) 1000
163 1000 -1000.0 -99.99568287525881 number episode from 10: 163 avegar over 10 episode: -99.897 avegare return across last 100 episodes: -99.843 state values: tensor(0.6145) 1000
164 1000 -1000.0 -99.99568287525881 number episode from 10: 164 avegar over 10 episode: -99.897 avegare return across last 100 episodes: -99.843 state values: tensor(0.6143) 1000
165 1000 -1000.0 -99.99568287525881 number episode from 10: 165 avegar over 10 episode: -99.898 avegare return across last 100 episodes: -99.843 state values: tensor(0.8115) 1000
166 1000 -1000.0 -99.99568287525881 number episode from 10: 166 avegar over 10 episode: -99.898 avegare return across last 100 episodes: -99.996 state values: tensor(0.6148) 1000
167 1000 -1000.0 -99.99568287525881 number episode from 10: 167 avegar over 10 episode: -99.899 avegare return across last 100 episodes: -99.996 state values: tensor(0.6142) 1000
168 1000 -1000.0 -99.99568287525881 number episode from 10: 168 avegar over 10 episode: -99.899 avegare return across last 100 episodes: -99.996 state values: tensor(0.8094) 1000
169 1000 -1000.0 -99.99568287525881 number episode from 10: 169 avegar over 10 episode: -99.9 avegare return across last 100 episodes: -99.996 state values: tensor(0.8112) 1000
170 1000 -1000.0 -99.99568287525881 number episode from 10: 170 avegar over 10 episode: -99.901 avegare return across last 100 episodes: -99.996 state values: tensor(0.8209) 1000
171 1000 -1000.0 -99.99568287525881 number episode from 10: 171 avegar over 10 episode: -99.901 avegare return across last 100 episodes: -99.996 state values: tensor(0.6144) 1000
172 1000 -1000.0 -99.99568287525881 number episode from 10: 172 avegar over 10 episode: -99.902 avegare return across last 100 episodes: -99.996 state values: tensor(0.7967) 1000
173 1000 -1000.0 -99.99568287525881 number episode from 10: 173 avegar over 10 episode: -99.902 avegare return across last 100 episodes: -99.996 state values: tensor(0.6143) 1000
174 1000 -1000.0 -99.99568287525881 number episode from 10: 174 avegar over 10 episode: -99.903 avegare return across last 100 episodes: -99.996 state values: tensor(0.6147) 1000
175 1000 -1000.0 -99.99568287525881 number episode from 10: 175 avegar over 10 episode: -99.903 avegare return across last 100 episodes: -99.996 state values: tensor(0.8127) 1000
176 1000 -1000.0 -99.99568287525881 number episode from 10: 176 avegar over 10 episode: -99.904 avegare return across last 100 episodes: -99.996 state values: tensor(0.8189) 1000
177 1000 -1000.0 -99.99568287525881 number episode from 10: 177 avegar over 10 episode: -99.904 avegare return across last 100 episodes: -99.996 state values: tensor(0.6147) 1000
178 1000 -1000.0 -99.99568287525881 number episode from 10: 178 avegar over 10 episode: -99.905 avegare return across last 100 episodes: -99.996 state values: tensor(0.6144) 1000
179 1000 -1000.0 -99.99568287525881 number episode from 10: 179 avegar over 10 episode: -99.905 avegare return across last 100 episodes: -99.996 state values: tensor(0.6146) 1000
180 1000 -1000.0 -99.99568287525881 number episode from 10: 180 avegar over 10 episode: -99.906 avegare return across last 100 episodes: -99.996 state values: tensor(0.6147) 1000
181 1000 -1000.0 -99.99568287525881 number episode from 10: 181 avegar over 10 episode: -99.906 avegare return across last 100 episodes: -99.996 state values: tensor(0.8080) 1000
182 1000 -1000.0 -99.99568287525881 number episode from 10: 182 avegar over 10 episode: -99.907 avegare return across last 100 episodes: -99.996 state values: tensor(0.8129) 1000
183 1000 -1000.0 -99.99568287525881 number episode from 10: 183 avegar over 10 episode: -99.907 avegare return across last 100 episodes: -99.996 state values: tensor(0.6151) 1000
184 1000 -1000.0 -99.99568287525881 number episode from 10: 184 avegar over 10 episode: -99.908 avegare return across last 100 episodes: -99.996 state values: tensor(0.6144) 1000
185 1000 -1000.0 -99.99568287525881 number episode from 10: 185 avegar over 10 episode: -99.908 avegare return across last 100 episodes: -99.996 state values: tensor(0.8165) 1000
186 1000 -1000.0 -99.99568287525881 number episode from 10: 186 avegar over 10 episode: -99.909 avegare return across last 100 episodes: -99.996 state values: tensor(0.6146) 1000
187 1000 -1000.0 -99.99568287525881 number episode from 10: 187 avegar over 10 episode: -99.909 avegare return across last 100 episodes: -99.996 state values: tensor(0.6140) 1000
188 1000 -1000.0 -99.99568287525881 number episode from 10: 188 avegar over 10 episode: -99.91 avegare return across last 100 episodes: -99.996 state values: tensor(0.6144) 1000
189 1000 -1000.0 -99.99568287525881 number episode from 10: 189 avegar over 10 episode: -99.91 avegare return across last 100 episodes: -99.996 state values: tensor(0.6148) 1000
190 1000 -1000.0 -99.99568287525881 number episode from 10: 190 avegar over 10 episode: -99.911 avegare return across last 100 episodes: -99.996 state values: tensor(0.8092) 1000
191 1000 -1000.0 -99.99568287525881 number episode from 10: 191 avegar over 10 episode: -99.911 avegare return across last 100 episodes: -99.996 state values: tensor(0.6144) 1000
192 1000 -1000.0 -99.99568287525881 number episode from 10: 192 avegar over 10 episode: -99.911 avegare return across last 100 episodes: -99.996 state values: tensor(0.6144) 1000
193 1000 -1000.0 -99.99568287525881 number episode from 10: 193 avegar over 10 episode: -99.912 avegare return across last 100 episodes: -99.996 state values: tensor(0.6146) 1000
194 1000 -1000.0 -99.99568287525881 number episode from 10: 194 avegar over 10 episode: -99.912 avegare return across last 100 episodes: -99.996 state values: tensor(0.8063) 1000
195 1000 -1000.0 -99.99568287525881 number episode from 10: 195 avegar over 10 episode: -99.913 avegare return across last 100 episodes: -99.996 state values: tensor(0.6975) 1000
196 1000 -1000.0 -99.99568287525881 number episode from 10: 196 avegar over 10 episode: -99.913 avegare return across last 100 episodes: -99.996 state values: tensor(0.6147) 1000
197 1000 -1000.0 -99.99568287525881 number episode from 10: 197 avegar over 10 episode: -99.914 avegare return across last 100 episodes: -99.996 state values: tensor(0.6144) 1000
198 1000 -1000.0 -99.99568287525881 number episode from 10: 198 avegar over 10 episode: -99.914 avegare return across last 100 episodes: -99.996 state values: tensor(0.6146) 1000
199 1000 -1000.0 -99.99568287525881 number episode from 10: 199 avegar over 10 episode: -99.914 avegare return across last 100 episodes: -99.996 state values: tensor(0.6148) 1000
200 1000 -1000.0 -99.99568287525881 number episode from 10: 200 avegar over 10 episode: -99.915 avegare return across last 100 episodes: -99.996 state values: tensor(0.8073) 1000
load offline data!!!!!
mem_cntr: 50000 ; mem_size: 50000
nn.learn_nn_feature_fqi FQI:  998
nn.learn_nn_feature_fqi FQI:  1998
nn.learn_nn_feature_fqi FQI:  2998
nn.learn_nn_feature_fqi FQI:  3998
nn.learn_nn_feature_fqi FQI:  4998
nn.learn_nn_feature_fqi FQI:  5998
nn.learn_nn_feature_fqi FQI:  6998
nn.learn_nn_feature_fqi FQI:  7998
nn.learn_nn_feature_fqi FQI:  8998
nn.learn_nn_feature_fqi FQI:  9998
nn.learn_nn_feature_fqi FQI:  10998
nn.learn_nn_feature_fqi FQI:  11998
nn.learn_nn_feature_fqi FQI:  12998
nn.learn_nn_feature_fqi FQI:  13998
nn.learn_nn_feature_fqi FQI:  14998
nn.learn_nn_feature_fqi FQI:  15998
nn.learn_nn_feature_fqi FQI:  16998
nn.learn_nn_feature_fqi FQI:  17998
nn.learn_nn_feature_fqi FQI:  18998
nn.learn_nn_feature_fqi FQI:  19998
nn.learn_nn_feature_fqi FQI:  20998
nn.learn_nn_feature_fqi FQI:  21998
nn.learn_nn_feature_fqi FQI:  22998
nn.learn_nn_feature_fqi FQI:  23998
nn.learn_nn_feature_fqi FQI:  24998
nn.learn_nn_feature_fqi FQI:  25998
nn.learn_nn_feature_fqi FQI:  26998
nn.learn_nn_feature_fqi FQI:  27998
nn.learn_nn_feature_fqi FQI:  28998
nn.learn_nn_feature_fqi FQI:  29998
nn.learn_nn_feature_fqi FQI:  30998
nn.learn_nn_feature_fqi FQI:  31998
nn.learn_nn_feature_fqi FQI:  32998
nn.learn_nn_feature_fqi FQI:  33998
nn.learn_nn_feature_fqi FQI:  34998
nn.learn_nn_feature_fqi FQI:  35998
nn.learn_nn_feature_fqi FQI:  36998
nn.learn_nn_feature_fqi FQI:  37998
nn.learn_nn_feature_fqi FQI:  38998
nn.learn_nn_feature_fqi FQI:  39998
nn.learn_nn_feature_fqi FQI:  40998
nn.learn_nn_feature_fqi FQI:  41998
nn.learn_nn_feature_fqi FQI:  42998
nn.learn_nn_feature_fqi FQI:  43998
nn.learn_nn_feature_fqi FQI:  44998
nn.learn_nn_feature_fqi FQI:  45998
nn.learn_nn_feature_fqi FQI:  46998
nn.learn_nn_feature_fqi FQI:  47998
nn.learn_nn_feature_fqi FQI:  48998
nn.learn_nn_feature_fqi FQI:  49998
nn.learn_nn_feature_fqi FQI:  50998
nn.learn_nn_feature_fqi FQI:  51998
nn.learn_nn_feature_fqi FQI:  52998
nn.learn_nn_feature_fqi FQI:  53998
nn.learn_nn_feature_fqi FQI:  54998
nn.learn_nn_feature_fqi FQI:  55998
nn.learn_nn_feature_fqi FQI:  56998
nn.learn_nn_feature_fqi FQI:  57998
nn.learn_nn_feature_fqi FQI:  58998
nn.learn_nn_feature_fqi FQI:  59998
nn.learn_nn_feature_fqi FQI:  60998
nn.learn_nn_feature_fqi FQI:  61998
nn.learn_nn_feature_fqi FQI:  62998
nn.learn_nn_feature_fqi FQI:  63998
nn.learn_nn_feature_fqi FQI:  64998
nn.learn_nn_feature_fqi FQI:  65998
nn.learn_nn_feature_fqi FQI:  66998
nn.learn_nn_feature_fqi FQI:  67998
nn.learn_nn_feature_fqi FQI:  68998
nn.learn_nn_feature_fqi FQI:  69998
nn.learn_nn_feature_fqi FQI:  70998
nn.learn_nn_feature_fqi FQI:  71998
nn.learn_nn_feature_fqi FQI:  72998
nn.learn_nn_feature_fqi FQI:  73998
nn.learn_nn_feature_fqi FQI:  74998
nn.learn_nn_feature_fqi FQI:  75998
nn.learn_nn_feature_fqi FQI:  76998
nn.learn_nn_feature_fqi FQI:  77998
nn.learn_nn_feature_fqi FQI:  78998
nn.learn_nn_feature_fqi FQI:  79998
nn.learn_nn_feature_fqi FQI:  80998
nn.learn_nn_feature_fqi FQI:  81998
nn.learn_nn_feature_fqi FQI:  82998
nn.learn_nn_feature_fqi FQI:  83998
nn.learn_nn_feature_fqi FQI:  84998
nn.learn_nn_feature_fqi FQI:  85998
nn.learn_nn_feature_fqi FQI:  86998
nn.learn_nn_feature_fqi FQI:  87998
nn.learn_nn_feature_fqi FQI:  88998
nn.learn_nn_feature_fqi FQI:  89998
nn.learn_nn_feature_fqi FQI:  90998
nn.learn_nn_feature_fqi FQI:  91998
nn.learn_nn_feature_fqi FQI:  92998
nn.learn_nn_feature_fqi FQI:  93998
nn.learn_nn_feature_fqi FQI:  94998
nn.learn_nn_feature_fqi FQI:  95998
nn.learn_nn_feature_fqi FQI:  96998
nn.learn_nn_feature_fqi FQI:  97998
nn.learn_nn_feature_fqi FQI:  98998
nn.learn_nn_feature_fqi FQI:  99998
nn.learn_nn_feature_fqi FQI:  100998
nn.learn_nn_feature_fqi FQI:  101998
nn.learn_nn_feature_fqi FQI:  102998
nn.learn_nn_feature_fqi FQI:  103998
nn.learn_nn_feature_fqi FQI:  104998
nn.learn_nn_feature_fqi FQI:  105998
nn.learn_nn_feature_fqi FQI:  106998
nn.learn_nn_feature_fqi FQI:  107998
nn.learn_nn_feature_fqi FQI:  108998
nn.learn_nn_feature_fqi FQI:  109998
nn.learn_nn_feature_fqi FQI:  110998
nn.learn_nn_feature_fqi FQI:  111998
nn.learn_nn_feature_fqi FQI:  112998
nn.learn_nn_feature_fqi FQI:  113998
nn.learn_nn_feature_fqi FQI:  114998
nn.learn_nn_feature_fqi FQI:  115998
nn.learn_nn_feature_fqi FQI:  116998
nn.learn_nn_feature_fqi FQI:  117998
nn.learn_nn_feature_fqi FQI:  118998
nn.learn_nn_feature_fqi FQI:  119998
nn.learn_nn_feature_fqi FQI:  120998
nn.learn_nn_feature_fqi FQI:  121998
nn.learn_nn_feature_fqi FQI:  122998
nn.learn_nn_feature_fqi FQI:  123998
nn.learn_nn_feature_fqi FQI:  124998
nn.learn_nn_feature_fqi FQI:  125998
nn.learn_nn_feature_fqi FQI:  126998
nn.learn_nn_feature_fqi FQI:  127998
nn.learn_nn_feature_fqi FQI:  128998
nn.learn_nn_feature_fqi FQI:  129998
nn.learn_nn_feature_fqi FQI:  130998
nn.learn_nn_feature_fqi FQI:  131998
nn.learn_nn_feature_fqi FQI:  132998
nn.learn_nn_feature_fqi FQI:  133998
nn.learn_nn_feature_fqi FQI:  134998
nn.learn_nn_feature_fqi FQI:  135998
nn.learn_nn_feature_fqi FQI:  136998
nn.learn_nn_feature_fqi FQI:  137998
nn.learn_nn_feature_fqi FQI:  138998
nn.learn_nn_feature_fqi FQI:  139998
nn.learn_nn_feature_fqi FQI:  140998
nn.learn_nn_feature_fqi FQI:  141998
nn.learn_nn_feature_fqi FQI:  142998
nn.learn_nn_feature_fqi FQI:  143998
nn.learn_nn_feature_fqi FQI:  144998
nn.learn_nn_feature_fqi FQI:  145998
nn.learn_nn_feature_fqi FQI:  146998
nn.learn_nn_feature_fqi FQI:  147998
nn.learn_nn_feature_fqi FQI:  148998
nn.learn_nn_feature_fqi FQI:  149998
nn.learn_nn_feature_fqi FQI:  150998
nn.learn_nn_feature_fqi FQI:  151998
nn.learn_nn_feature_fqi FQI:  152998
nn.learn_nn_feature_fqi FQI:  153998
nn.learn_nn_feature_fqi FQI:  154998
nn.learn_nn_feature_fqi FQI:  155998
0 1001 -1000.0 -98.99572604650622 number episode from 10: 0 avegar over 10 episode: -98.996 avegare return across last 100 episodes: -98.996 state values: tensor(0.6981) 1000
1 1000 -1000.0 -99.99568287525881 number episode from 10: 1 avegar over 10 episode: -99.496 avegare return across last 100 episodes: -99.496 state values: tensor(0.6992) 1000
2 1000 -1000.0 -99.99568287525881 number episode from 10: 2 avegar over 10 episode: -99.662 avegare return across last 100 episodes: -99.662 state values: tensor(0.6987) 1000
3 1000 -1000.0 -99.99568287525881 number episode from 10: 3 avegar over 10 episode: -99.746 avegare return across last 100 episodes: -99.746 state values: tensor(0.6964) 1000
4 1000 -1000.0 -99.99568287525881 number episode from 10: 4 avegar over 10 episode: -99.796 avegare return across last 100 episodes: -99.796 state values: tensor(0.7008) 1000
5 1000 -1000.0 -99.99568287525881 number episode from 10: 5 avegar over 10 episode: -99.829 avegare return across last 100 episodes: -99.829 state values: tensor(0.6964) 1000
6 1000 -1000.0 -99.99568287525881 number episode from 10: 6 avegar over 10 episode: -99.853 avegare return across last 100 episodes: -99.853 state values: tensor(0.6983) 1000
7 1000 -1000.0 -99.99568287525881 number episode from 10: 7 avegar over 10 episode: -99.871 avegare return across last 100 episodes: -99.871 state values: tensor(0.6987) 1000
8 1000 -1000.0 -99.99568287525881 number episode from 10: 8 avegar over 10 episode: -99.885 avegare return across last 100 episodes: -99.885 state values: tensor(0.6990) 1000
9 1000 -1000.0 -99.99568287525881 number episode from 10: 9 avegar over 10 episode: -99.896 avegare return across last 100 episodes: -99.896 state values: tensor(0.7006) 1000
10 1000 -1000.0 -99.99568287525881 number episode from 10: 10 avegar over 10 episode: -99.905 avegare return across last 100 episodes: -99.905 state values: tensor(0.6971) 1000
11 1000 -1000.0 -99.99568287525881 number episode from 10: 11 avegar over 10 episode: -99.912 avegare return across last 100 episodes: -99.912 state values: tensor(0.6986) 1000
12 1000 -1000.0 -99.99568287525881 number episode from 10: 12 avegar over 10 episode: -99.919 avegare return across last 100 episodes: -99.919 state values: tensor(0.7012) 1000
13 1000 -1000.0 -99.99568287525881 number episode from 10: 13 avegar over 10 episode: -99.924 avegare return across last 100 episodes: -99.924 state values: tensor(0.6979) 1000
14 1000 -1000.0 -99.99568287525881 number episode from 10: 14 avegar over 10 episode: -99.929 avegare return across last 100 episodes: -99.929 state values: tensor(0.6979) 1000
15 1000 -1000.0 -99.99568287525881 number episode from 10: 15 avegar over 10 episode: -99.933 avegare return across last 100 episodes: -99.933 state values: tensor(0.6993) 1000
16 1000 -1000.0 -99.99568287525881 number episode from 10: 16 avegar over 10 episode: -99.937 avegare return across last 100 episodes: -99.937 state values: tensor(0.6965) 1000
17 1000 -1000.0 -99.99568287525881 number episode from 10: 17 avegar over 10 episode: -99.94 avegare return across last 100 episodes: -99.94 state values: tensor(0.6986) 1000
18 1000 -1000.0 -99.99568287525881 number episode from 10: 18 avegar over 10 episode: -99.943 avegare return across last 100 episodes: -99.943 state values: tensor(0.6208) 1000
19 1000 -1000.0 -99.99568287525881 number episode from 10: 19 avegar over 10 episode: -99.946 avegare return across last 100 episodes: -99.946 state values: tensor(0.6980) 1000
20 1000 -1000.0 -99.99568287525881 number episode from 10: 20 avegar over 10 episode: -99.948 avegare return across last 100 episodes: -99.948 state values: tensor(0.6988) 1000
21 1000 -1000.0 -99.99568287525881 number episode from 10: 21 avegar over 10 episode: -99.95 avegare return across last 100 episodes: -99.95 state values: tensor(0.6969) 1000
22 1000 -1000.0 -99.99568287525881 number episode from 10: 22 avegar over 10 episode: -99.952 avegare return across last 100 episodes: -99.952 state values: tensor(0.6977) 1000
23 1000 -1000.0 -99.99568287525881 number episode from 10: 23 avegar over 10 episode: -99.954 avegare return across last 100 episodes: -99.954 state values: tensor(0.6977) 1000
24 1000 -1000.0 -99.99568287525881 number episode from 10: 24 avegar over 10 episode: -99.956 avegare return across last 100 episodes: -99.956 state values: tensor(0.6980) 1000
25 1000 -1000.0 -99.99568287525881 number episode from 10: 25 avegar over 10 episode: -99.957 avegare return across last 100 episodes: -99.957 state values: tensor(0.7006) 1000
26 1000 -1000.0 -99.99568287525881 number episode from 10: 26 avegar over 10 episode: -99.959 avegare return across last 100 episodes: -99.959 state values: tensor(0.6997) 1000
27 1000 -1000.0 -99.99568287525881 number episode from 10: 27 avegar over 10 episode: -99.96 avegare return across last 100 episodes: -99.96 state values: tensor(0.6981) 1000
28 1000 -1000.0 -99.99568287525881 number episode from 10: 28 avegar over 10 episode: -99.961 avegare return across last 100 episodes: -99.961 state values: tensor(0.7018) 1000
29 1000 -1000.0 -99.99568287525881 number episode from 10: 29 avegar over 10 episode: -99.962 avegare return across last 100 episodes: -99.962 state values: tensor(0.6993) 1000
30 1000 -1000.0 -99.99568287525881 number episode from 10: 30 avegar over 10 episode: -99.963 avegare return across last 100 episodes: -99.963 state values: tensor(0.6642) 1000
31 1000 -1000.0 -99.99568287525881 number episode from 10: 31 avegar over 10 episode: -99.964 avegare return across last 100 episodes: -99.964 state values: tensor(0.6990) 1000
32 1000 -1000.0 -99.99568287525881 number episode from 10: 32 avegar over 10 episode: -99.965 avegare return across last 100 episodes: -99.965 state values: tensor(0.6038) 1000
33 1000 -1000.0 -99.99568287525881 number episode from 10: 33 avegar over 10 episode: -99.966 avegare return across last 100 episodes: -99.966 state values: tensor(0.6978) 1000
34 1000 -1000.0 -99.99568287525881 number episode from 10: 34 avegar over 10 episode: -99.967 avegare return across last 100 episodes: -99.967 state values: tensor(0.7017) 1000
35 1000 -1000.0 -99.99568287525881 number episode from 10: 35 avegar over 10 episode: -99.968 avegare return across last 100 episodes: -99.968 state values: tensor(0.7000) 1000
36 1000 -1000.0 -99.99568287525881 number episode from 10: 36 avegar over 10 episode: -99.969 avegare return across last 100 episodes: -99.969 state values: tensor(0.6991) 1000
37 1000 -1000.0 -99.99568287525881 number episode from 10: 37 avegar over 10 episode: -99.969 avegare return across last 100 episodes: -99.969 state values: tensor(0.7010) 1000
38 1000 -1000.0 -99.99568287525881 number episode from 10: 38 avegar over 10 episode: -99.97 avegare return across last 100 episodes: -99.97 state values: tensor(0.6989) 1000
39 1000 -1000.0 -99.99568287525881 number episode from 10: 39 avegar over 10 episode: -99.971 avegare return across last 100 episodes: -99.971 state values: tensor(0.6987) 1000
40 1000 -1000.0 -99.99568287525881 number episode from 10: 40 avegar over 10 episode: -99.971 avegare return across last 100 episodes: -99.971 state values: tensor(0.6986) 1000
41 1000 -1000.0 -99.99568287525881 number episode from 10: 41 avegar over 10 episode: -99.972 avegare return across last 100 episodes: -99.972 state values: tensor(0.7006) 1000
42 1000 -1000.0 -99.99568287525881 number episode from 10: 42 avegar over 10 episode: -99.972 avegare return across last 100 episodes: -99.972 state values: tensor(0.6957) 1000
43 1000 -1000.0 -99.99568287525881 number episode from 10: 43 avegar over 10 episode: -99.973 avegare return across last 100 episodes: -99.973 state values: tensor(0.6990) 1000
44 1000 -1000.0 -99.99568287525881 number episode from 10: 44 avegar over 10 episode: -99.973 avegare return across last 100 episodes: -99.973 state values: tensor(0.6804) 1000
45 1000 -1000.0 -99.99568287525881 number episode from 10: 45 avegar over 10 episode: -99.974 avegare return across last 100 episodes: -99.974 state values: tensor(0.6784) 1000
46 1000 -1000.0 -99.99568287525881 number episode from 10: 46 avegar over 10 episode: -99.974 avegare return across last 100 episodes: -99.974 state values: tensor(0.6988) 1000
47 1000 -1000.0 -99.99568287525881 number episode from 10: 47 avegar over 10 episode: -99.975 avegare return across last 100 episodes: -99.975 state values: tensor(0.6988) 1000
48 1000 -1000.0 -99.99568287525881 number episode from 10: 48 avegar over 10 episode: -99.975 avegare return across last 100 episodes: -99.975 state values: tensor(0.6970) 1000
49 1000 -1000.0 -99.99568287525881 number episode from 10: 49 avegar over 10 episode: -99.976 avegare return across last 100 episodes: -99.976 state values: tensor(0.6963) 1000
50 1000 -1000.0 -99.99568287525881 number episode from 10: 50 avegar over 10 episode: -99.976 avegare return across last 100 episodes: -99.976 state values: tensor(0.6992) 1000
51 1000 -1000.0 -99.99568287525881 number episode from 10: 51 avegar over 10 episode: -99.976 avegare return across last 100 episodes: -99.976 state values: tensor(0.6998) 1000
52 1000 -1000.0 -99.99568287525881 number episode from 10: 52 avegar over 10 episode: -99.977 avegare return across last 100 episodes: -99.977 state values: tensor(0.7018) 1000
53 1000 -1000.0 -99.99568287525881 number episode from 10: 53 avegar over 10 episode: -99.977 avegare return across last 100 episodes: -99.977 state values: tensor(0.6968) 1000
54 1000 -1000.0 -99.99568287525881 number episode from 10: 54 avegar over 10 episode: -99.978 avegare return across last 100 episodes: -99.978 state values: tensor(0.6971) 1000
55 1000 -1000.0 -99.99568287525881 number episode from 10: 55 avegar over 10 episode: -99.978 avegare return across last 100 episodes: -99.978 state values: tensor(0.6996) 1000
56 1000 -1000.0 -99.99568287525881 number episode from 10: 56 avegar over 10 episode: -99.978 avegare return across last 100 episodes: -99.978 state values: tensor(0.6973) 1000
57 1000 -1000.0 -99.99568287525881 number episode from 10: 57 avegar over 10 episode: -99.978 avegare return across last 100 episodes: -99.978 state values: tensor(0.7012) 1000
58 1000 -1000.0 -99.99568287525881 number episode from 10: 58 avegar over 10 episode: -99.979 avegare return across last 100 episodes: -99.979 state values: tensor(0.6992) 1000
59 1000 -1000.0 -99.99568287525881 number episode from 10: 59 avegar over 10 episode: -99.979 avegare return across last 100 episodes: -99.979 state values: tensor(0.6962) 1000
60 1000 -1000.0 -99.99568287525881 number episode from 10: 60 avegar over 10 episode: -99.979 avegare return across last 100 episodes: -99.979 state values: tensor(0.6963) 1000
61 1000 -1000.0 -99.99568287525881 number episode from 10: 61 avegar over 10 episode: -99.98 avegare return across last 100 episodes: -99.98 state values: tensor(0.6961) 1000
62 1000 -1000.0 -99.99568287525881 number episode from 10: 62 avegar over 10 episode: -99.98 avegare return across last 100 episodes: -99.98 state values: tensor(0.6982) 1000
63 1000 -1000.0 -99.99568287525881 number episode from 10: 63 avegar over 10 episode: -99.98 avegare return across last 100 episodes: -99.98 state values: tensor(0.6630) 1000
64 1000 -1000.0 -99.99568287525881 number episode from 10: 64 avegar over 10 episode: -99.98 avegare return across last 100 episodes: -99.98 state values: tensor(0.7008) 1000
65 1000 -1000.0 -99.99568287525881 number episode from 10: 65 avegar over 10 episode: -99.981 avegare return across last 100 episodes: -99.981 state values: tensor(0.6987) 1000
66 1000 -1000.0 -99.99568287525881 number episode from 10: 66 avegar over 10 episode: -99.981 avegare return across last 100 episodes: -99.981 state values: tensor(0.6992) 1000
67 1000 -1000.0 -99.99568287525881 number episode from 10: 67 avegar over 10 episode: -99.981 avegare return across last 100 episodes: -99.981 state values: tensor(0.6970) 1000
68 1000 -1000.0 -99.99568287525881 number episode from 10: 68 avegar over 10 episode: -99.981 avegare return across last 100 episodes: -99.981 state values: tensor(0.6979) 1000
69 1000 -1000.0 -99.99568287525881 number episode from 10: 69 avegar over 10 episode: -99.981 avegare return across last 100 episodes: -99.981 state values: tensor(0.6983) 1000
70 1000 -1000.0 -99.99568287525881 number episode from 10: 70 avegar over 10 episode: -99.982 avegare return across last 100 episodes: -99.982 state values: tensor(0.6949) 1000
71 1000 -1000.0 -99.99568287525881 number episode from 10: 71 avegar over 10 episode: -99.982 avegare return across last 100 episodes: -99.982 state values: tensor(0.7004) 1000
72 1000 -1000.0 -99.99568287525881 number episode from 10: 72 avegar over 10 episode: -99.982 avegare return across last 100 episodes: -99.982 state values: tensor(0.6995) 1000
73 1000 -1000.0 -99.99568287525881 number episode from 10: 73 avegar over 10 episode: -99.982 avegare return across last 100 episodes: -99.982 state values: tensor(0.6998) 1000
74 1000 -1000.0 -99.99568287525881 number episode from 10: 74 avegar over 10 episode: -99.982 avegare return across last 100 episodes: -99.982 state values: tensor(0.6992) 1000
75 1000 -1000.0 -99.99568287525881 number episode from 10: 75 avegar over 10 episode: -99.983 avegare return across last 100 episodes: -99.983 state values: tensor(0.6986) 1000
76 1000 -1000.0 -99.99568287525881 number episode from 10: 76 avegar over 10 episode: -99.983 avegare return across last 100 episodes: -99.983 state values: tensor(0.7012) 1000
77 1000 -1000.0 -99.99568287525881 number episode from 10: 77 avegar over 10 episode: -99.983 avegare return across last 100 episodes: -99.983 state values: tensor(0.7005) 1000
78 1000 -1000.0 -99.99568287525881 number episode from 10: 78 avegar over 10 episode: -99.983 avegare return across last 100 episodes: -99.983 state values: tensor(0.6996) 1000
79 1000 -1000.0 -99.99568287525881 number episode from 10: 79 avegar over 10 episode: -99.983 avegare return across last 100 episodes: -99.983 state values: tensor(0.6984) 1000
80 1000 -1000.0 -99.99568287525881 number episode from 10: 80 avegar over 10 episode: -99.983 avegare return across last 100 episodes: -99.983 state values: tensor(0.6987) 1000
81 1000 -1000.0 -99.99568287525881 number episode from 10: 81 avegar over 10 episode: -99.983 avegare return across last 100 episodes: -99.983 state values: tensor(0.6984) 1000
82 1000 -1000.0 -99.99568287525881 number episode from 10: 82 avegar over 10 episode: -99.984 avegare return across last 100 episodes: -99.984 state values: tensor(0.6990) 1000
83 1000 -1000.0 -99.99568287525881 number episode from 10: 83 avegar over 10 episode: -99.984 avegare return across last 100 episodes: -99.984 state values: tensor(0.6990) 1000
84 1000 -1000.0 -99.99568287525881 number episode from 10: 84 avegar over 10 episode: -99.984 avegare return across last 100 episodes: -99.984 state values: tensor(0.6978) 1000
85 1000 -1000.0 -99.99568287525881 number episode from 10: 85 avegar over 10 episode: -99.984 avegare return across last 100 episodes: -99.984 state values: tensor(0.6898) 1000
86 1000 -1000.0 -99.99568287525881 number episode from 10: 86 avegar over 10 episode: -99.984 avegare return across last 100 episodes: -99.984 state values: tensor(0.6953) 1000
87 1000 -1000.0 -99.99568287525881 number episode from 10: 87 avegar over 10 episode: -99.984 avegare return across last 100 episodes: -99.984 state values: tensor(0.6998) 1000
88 1000 -1000.0 -99.99568287525881 number episode from 10: 88 avegar over 10 episode: -99.984 avegare return across last 100 episodes: -99.984 state values: tensor(0.6971) 1000
89 1000 -1000.0 -99.99568287525881 number episode from 10: 89 avegar over 10 episode: -99.985 avegare return across last 100 episodes: -99.985 state values: tensor(0.6994) 1000
90 1000 -1000.0 -99.99568287525881 number episode from 10: 90 avegar over 10 episode: -99.985 avegare return across last 100 episodes: -99.985 state values: tensor(0.6996) 1000
91 1000 -1000.0 -99.99568287525881 number episode from 10: 91 avegar over 10 episode: -99.985 avegare return across last 100 episodes: -99.985 state values: tensor(0.6962) 1000
92 1000 -1000.0 -99.99568287525881 number episode from 10: 92 avegar over 10 episode: -99.985 avegare return across last 100 episodes: -99.985 state values: tensor(0.7003) 1000
93 1000 -1000.0 -99.99568287525881 number episode from 10: 93 avegar over 10 episode: -99.985 avegare return across last 100 episodes: -99.985 state values: tensor(0.6527) 1000
94 1000 -1000.0 -99.99568287525881 number episode from 10: 94 avegar over 10 episode: -99.985 avegare return across last 100 episodes: -99.985 state values: tensor(0.6992) 1000
95 1000 -1000.0 -99.99568287525881 number episode from 10: 95 avegar over 10 episode: -99.985 avegare return across last 100 episodes: -99.985 state values: tensor(0.6971) 1000
96 1000 -1000.0 -99.99568287525881 number episode from 10: 96 avegar over 10 episode: -99.985 avegare return across last 100 episodes: -99.985 state values: tensor(0.6177) 1000
97 1000 -1000.0 -99.99568287525881 number episode from 10: 97 avegar over 10 episode: -99.985 avegare return across last 100 episodes: -99.985 state values: tensor(0.6995) 1000
98 1000 -1000.0 -99.99568287525881 number episode from 10: 98 avegar over 10 episode: -99.986 avegare return across last 100 episodes: -99.986 state values: tensor(0.7011) 1000
99 1000 -1000.0 -99.99568287525881 number episode from 10: 99 avegar over 10 episode: -99.986 avegare return across last 100 episodes: -99.986 state values: tensor(0.7005) 1000
100 1000 -1000.0 -99.99568287525881 number episode from 10: 100 avegar over 10 episode: -99.986 avegare return across last 100 episodes: -99.996 state values: tensor(0.6990) 1000
101 1000 -1000.0 -99.99568287525881 number episode from 10: 101 avegar over 10 episode: -99.986 avegare return across last 100 episodes: -99.996 state values: tensor(0.6991) 1000
102 1000 -1000.0 -99.99568287525881 number episode from 10: 102 avegar over 10 episode: -99.986 avegare return across last 100 episodes: -99.996 state values: tensor(0.6954) 1000
103 1000 -1000.0 -99.99568287525881 number episode from 10: 103 avegar over 10 episode: -99.986 avegare return across last 100 episodes: -99.996 state values: tensor(0.6975) 1000
104 1000 -1000.0 -99.99568287525881 number episode from 10: 104 avegar over 10 episode: -99.986 avegare return across last 100 episodes: -99.996 state values: tensor(0.6978) 1000
105 1000 -1000.0 -99.99568287525881 number episode from 10: 105 avegar over 10 episode: -99.986 avegare return across last 100 episodes: -99.996 state values: tensor(0.6899) 1000
106 1000 -1000.0 -99.99568287525881 number episode from 10: 106 avegar over 10 episode: -99.986 avegare return across last 100 episodes: -99.996 state values: tensor(0.6990) 1000
107 1000 -1000.0 -99.99568287525881 number episode from 10: 107 avegar over 10 episode: -99.986 avegare return across last 100 episodes: -99.996 state values: tensor(0.6991) 1000
108 1000 -1000.0 -99.99568287525881 number episode from 10: 108 avegar over 10 episode: -99.987 avegare return across last 100 episodes: -99.996 state values: tensor(0.6680) 1000
109 1000 -1000.0 -99.99568287525881 number episode from 10: 109 avegar over 10 episode: -99.987 avegare return across last 100 episodes: -99.996 state values: tensor(0.6984) 1000
110 1000 -1000.0 -99.99568287525881 number episode from 10: 110 avegar over 10 episode: -99.987 avegare return across last 100 episodes: -99.996 state values: tensor(0.7012) 1000
111 1000 -1000.0 -99.99568287525881 number episode from 10: 111 avegar over 10 episode: -99.987 avegare return across last 100 episodes: -99.996 state values: tensor(0.6976) 1000
112 1000 -1000.0 -99.99568287525881 number episode from 10: 112 avegar over 10 episode: -99.987 avegare return across last 100 episodes: -99.996 state values: tensor(0.7000) 1000
113 1000 -1000.0 -99.99568287525881 number episode from 10: 113 avegar over 10 episode: -99.987 avegare return across last 100 episodes: -99.996 state values: tensor(0.6626) 1000
114 1000 -1000.0 -99.99568287525881 number episode from 10: 114 avegar over 10 episode: -99.987 avegare return across last 100 episodes: -99.996 state values: tensor(0.6996) 1000
115 1000 -1000.0 -99.99568287525881 number episode from 10: 115 avegar over 10 episode: -99.987 avegare return across last 100 episodes: -99.996 state values: tensor(0.7006) 1000
116 1000 -1000.0 -99.99568287525881 number episode from 10: 116 avegar over 10 episode: -99.987 avegare return across last 100 episodes: -99.996 state values: tensor(0.6973) 1000
117 1000 -1000.0 -99.99568287525881 number episode from 10: 117 avegar over 10 episode: -99.987 avegare return across last 100 episodes: -99.996 state values: tensor(0.6976) 1000
118 1000 -1000.0 -99.99568287525881 number episode from 10: 118 avegar over 10 episode: -99.987 avegare return across last 100 episodes: -99.996 state values: tensor(0.6997) 1000
119 1000 -1000.0 -99.99568287525881 number episode from 10: 119 avegar over 10 episode: -99.987 avegare return across last 100 episodes: -99.996 state values: tensor(0.6957) 1000
120 1000 -1000.0 -99.99568287525881 number episode from 10: 120 avegar over 10 episode: -99.987 avegare return across last 100 episodes: -99.996 state values: tensor(0.5999) 1000
121 1000 -1000.0 -99.99568287525881 number episode from 10: 121 avegar over 10 episode: -99.987 avegare return across last 100 episodes: -99.996 state values: tensor(0.6967) 1000
122 1000 -1000.0 -99.99568287525881 number episode from 10: 122 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.6996) 1000
123 1000 -1000.0 -99.99568287525881 number episode from 10: 123 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.6979) 1000
124 1000 -1000.0 -99.99568287525881 number episode from 10: 124 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.6988) 1000
125 1000 -1000.0 -99.99568287525881 number episode from 10: 125 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.7014) 1000
126 1000 -1000.0 -99.99568287525881 number episode from 10: 126 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.6999) 1000
127 1000 -1000.0 -99.99568287525881 number episode from 10: 127 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.6956) 1000
128 1000 -1000.0 -99.99568287525881 number episode from 10: 128 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.7005) 1000
129 1000 -1000.0 -99.99568287525881 number episode from 10: 129 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.6977) 1000
130 1000 -1000.0 -99.99568287525881 number episode from 10: 130 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.6993) 1000
131 1000 -1000.0 -99.99568287525881 number episode from 10: 131 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.6982) 1000
132 1000 -1000.0 -99.99568287525881 number episode from 10: 132 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.6994) 1000
133 1000 -1000.0 -99.99568287525881 number episode from 10: 133 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.7004) 1000
134 1000 -1000.0 -99.99568287525881 number episode from 10: 134 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.6965) 1000
135 1000 -1000.0 -99.99568287525881 number episode from 10: 135 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.6972) 1000
136 1000 -1000.0 -99.99568287525881 number episode from 10: 136 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.6977) 1000
137 1000 -1000.0 -99.99568287525881 number episode from 10: 137 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.6748) 1000
138 1000 -1000.0 -99.99568287525881 number episode from 10: 138 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.6989) 1000
139 1000 -1000.0 -99.99568287525881 number episode from 10: 139 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.6988) 1000
140 1000 -1000.0 -99.99568287525881 number episode from 10: 140 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.7007) 1000
141 1000 -1000.0 -99.99568287525881 number episode from 10: 141 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.6978) 1000
142 1000 -1000.0 -99.99568287525881 number episode from 10: 142 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.6985) 1000
143 1000 -1000.0 -99.99568287525881 number episode from 10: 143 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.7012) 1000
144 1000 -1000.0 -99.99568287525881 number episode from 10: 144 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.6984) 1000
145 1000 -1000.0 -99.99568287525881 number episode from 10: 145 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.6955) 1000
146 1000 -1000.0 -99.99568287525881 number episode from 10: 146 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.7004) 1000
147 1000 -1000.0 -99.99568287525881 number episode from 10: 147 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.6997) 1000
148 1000 -1000.0 -99.99568287525881 number episode from 10: 148 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.6977) 1000
149 1000 -1000.0 -99.99568287525881 number episode from 10: 149 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.6282) 1000
150 1000 -1000.0 -99.99568287525881 number episode from 10: 150 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.6966) 1000
151 1000 -1000.0 -99.99568287525881 number episode from 10: 151 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.7010) 1000
152 1000 -1000.0 -99.99568287525881 number episode from 10: 152 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.6976) 1000
153 1000 -1000.0 -99.99568287525881 number episode from 10: 153 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.6999) 1000
154 1000 -1000.0 -99.99568287525881 number episode from 10: 154 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.7014) 1000
155 1000 -1000.0 -99.99568287525881 number episode from 10: 155 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.6954) 1000
156 1000 -1000.0 -99.99568287525881 number episode from 10: 156 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.6981) 1000
157 1000 -1000.0 -99.99568287525881 number episode from 10: 157 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.5951) 1000
158 1000 -1000.0 -99.99568287525881 number episode from 10: 158 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.7005) 1000
159 1000 -1000.0 -99.99568287525881 number episode from 10: 159 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.6995) 1000
160 1000 -1000.0 -99.99568287525881 number episode from 10: 160 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.7001) 1000
161 1000 -1000.0 -99.99568287525881 number episode from 10: 161 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.6973) 1000
162 1000 -1000.0 -99.99568287525881 number episode from 10: 162 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.6975) 1000
163 1000 -1000.0 -99.99568287525881 number episode from 10: 163 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.6399) 1000
164 1000 -1000.0 -99.99568287525881 number episode from 10: 164 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.6999) 1000
165 1000 -1000.0 -99.99568287525881 number episode from 10: 165 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.6701) 1000
166 1000 -1000.0 -99.99568287525881 number episode from 10: 166 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.6991) 1000
167 1000 -1000.0 -99.99568287525881 number episode from 10: 167 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.6042) 1000
168 1000 -1000.0 -99.99568287525881 number episode from 10: 168 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.6972) 1000
169 1000 -1000.0 -99.99568287525881 number episode from 10: 169 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.6800) 1000
170 1000 -1000.0 -99.99568287525881 number episode from 10: 170 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.6961) 1000
171 1000 -1000.0 -99.99568287525881 number episode from 10: 171 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.6975) 1000
172 1000 -1000.0 -99.99568287525881 number episode from 10: 172 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.6993) 1000
173 1000 -1000.0 -99.99568287525881 number episode from 10: 173 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.6988) 1000
174 1000 -1000.0 -99.99568287525881 number episode from 10: 174 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.7020) 1000
175 1000 -1000.0 -99.99568287525881 number episode from 10: 175 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.6966) 1000
176 1000 -1000.0 -99.99568287525881 number episode from 10: 176 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.6999) 1000
177 1000 -1000.0 -99.99568287525881 number episode from 10: 177 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.6966) 1000
178 1000 -1000.0 -99.99568287525881 number episode from 10: 178 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.6998) 1000
179 1000 -1000.0 -99.99568287525881 number episode from 10: 179 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.7005) 1000
180 1000 -1000.0 -99.99568287525881 number episode from 10: 180 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.6989) 1000
181 1000 -1000.0 -99.99568287525881 number episode from 10: 181 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.6996) 1000
182 1000 -1000.0 -99.99568287525881 number episode from 10: 182 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.6724) 1000
183 1000 -1000.0 -99.99568287525881 number episode from 10: 183 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.6962) 1000
184 1000 -1000.0 -99.99568287525881 number episode from 10: 184 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.6906) 1000
185 1000 -1000.0 -99.99568287525881 number episode from 10: 185 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.6992) 1000
186 1000 -1000.0 -99.99568287525881 number episode from 10: 186 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.6994) 1000
187 1000 -1000.0 -99.99568287525881 number episode from 10: 187 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.6970) 1000
188 1000 -1000.0 -99.99568287525881 number episode from 10: 188 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.6965) 1000
189 1000 -1000.0 -99.99568287525881 number episode from 10: 189 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.6969) 1000
190 1000 -1000.0 -99.99568287525881 number episode from 10: 190 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.7000) 1000
191 1000 -1000.0 -99.99568287525881 number episode from 10: 191 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.6953) 1000
192 1000 -1000.0 -99.99568287525881 number episode from 10: 192 avegar over 10 episode: -99.991 avegare return across last 100 episodes: -99.996 state values: tensor(0.6989) 1000
193 1000 -1000.0 -99.99568287525881 number episode from 10: 193 avegar over 10 episode: -99.991 avegare return across last 100 episodes: -99.996 state values: tensor(0.7006) 1000
194 1000 -1000.0 -99.99568287525881 number episode from 10: 194 avegar over 10 episode: -99.991 avegare return across last 100 episodes: -99.996 state values: tensor(0.6983) 1000
195 1000 -1000.0 -99.99568287525881 number episode from 10: 195 avegar over 10 episode: -99.991 avegare return across last 100 episodes: -99.996 state values: tensor(0.6981) 1000
196 1000 -1000.0 -99.99568287525881 number episode from 10: 196 avegar over 10 episode: -99.991 avegare return across last 100 episodes: -99.996 state values: tensor(0.6971) 1000
197 1000 -1000.0 -99.99568287525881 number episode from 10: 197 avegar over 10 episode: -99.991 avegare return across last 100 episodes: -99.996 state values: tensor(0.6965) 1000
198 1000 -1000.0 -99.99568287525881 number episode from 10: 198 avegar over 10 episode: -99.991 avegare return across last 100 episodes: -99.996 state values: tensor(0.7009) 1000
199 1000 -1000.0 -99.99568287525881 number episode from 10: 199 avegar over 10 episode: -99.991 avegare return across last 100 episodes: -99.996 state values: tensor(0.7009) 1000
200 1000 -1000.0 -99.99568287525881 number episode from 10: 200 avegar over 10 episode: -99.991 avegare return across last 100 episodes: -99.996 state values: tensor(0.6989) 1000
load offline data!!!!!
mem_cntr: 50000 ; mem_size: 50000
nn.learn_nn_feature_fqi FQI:  998
nn.learn_nn_feature_fqi FQI:  1998
nn.learn_nn_feature_fqi FQI:  2998
nn.learn_nn_feature_fqi FQI:  3998
nn.learn_nn_feature_fqi FQI:  4998
nn.learn_nn_feature_fqi FQI:  5998
nn.learn_nn_feature_fqi FQI:  6998
nn.learn_nn_feature_fqi FQI:  7998
nn.learn_nn_feature_fqi FQI:  8998
nn.learn_nn_feature_fqi FQI:  9998
nn.learn_nn_feature_fqi FQI:  10998
nn.learn_nn_feature_fqi FQI:  11998
nn.learn_nn_feature_fqi FQI:  12998
nn.learn_nn_feature_fqi FQI:  13998
nn.learn_nn_feature_fqi FQI:  14998
nn.learn_nn_feature_fqi FQI:  15998
nn.learn_nn_feature_fqi FQI:  16998
nn.learn_nn_feature_fqi FQI:  17998
nn.learn_nn_feature_fqi FQI:  18998
nn.learn_nn_feature_fqi FQI:  19998
nn.learn_nn_feature_fqi FQI:  20998
nn.learn_nn_feature_fqi FQI:  21998
nn.learn_nn_feature_fqi FQI:  22998
nn.learn_nn_feature_fqi FQI:  23998
nn.learn_nn_feature_fqi FQI:  24998
nn.learn_nn_feature_fqi FQI:  25998
nn.learn_nn_feature_fqi FQI:  26998
nn.learn_nn_feature_fqi FQI:  27998
nn.learn_nn_feature_fqi FQI:  28998
nn.learn_nn_feature_fqi FQI:  29998
nn.learn_nn_feature_fqi FQI:  30998
nn.learn_nn_feature_fqi FQI:  31998
nn.learn_nn_feature_fqi FQI:  32998
nn.learn_nn_feature_fqi FQI:  33998
nn.learn_nn_feature_fqi FQI:  34998
nn.learn_nn_feature_fqi FQI:  35998
nn.learn_nn_feature_fqi FQI:  36998
nn.learn_nn_feature_fqi FQI:  37998
nn.learn_nn_feature_fqi FQI:  38998
nn.learn_nn_feature_fqi FQI:  39998
nn.learn_nn_feature_fqi FQI:  40998
nn.learn_nn_feature_fqi FQI:  41998
nn.learn_nn_feature_fqi FQI:  42998
nn.learn_nn_feature_fqi FQI:  43998
nn.learn_nn_feature_fqi FQI:  44998
nn.learn_nn_feature_fqi FQI:  45998
nn.learn_nn_feature_fqi FQI:  46998
nn.learn_nn_feature_fqi FQI:  47998
nn.learn_nn_feature_fqi FQI:  48998
nn.learn_nn_feature_fqi FQI:  49998
nn.learn_nn_feature_fqi FQI:  50998
nn.learn_nn_feature_fqi FQI:  51998
nn.learn_nn_feature_fqi FQI:  52998
nn.learn_nn_feature_fqi FQI:  53998
nn.learn_nn_feature_fqi FQI:  54998
nn.learn_nn_feature_fqi FQI:  55998
nn.learn_nn_feature_fqi FQI:  56998
nn.learn_nn_feature_fqi FQI:  57998
nn.learn_nn_feature_fqi FQI:  58998
nn.learn_nn_feature_fqi FQI:  59998
nn.learn_nn_feature_fqi FQI:  60998
nn.learn_nn_feature_fqi FQI:  61998
nn.learn_nn_feature_fqi FQI:  62998
nn.learn_nn_feature_fqi FQI:  63998
nn.learn_nn_feature_fqi FQI:  64998
nn.learn_nn_feature_fqi FQI:  65998
nn.learn_nn_feature_fqi FQI:  66998
nn.learn_nn_feature_fqi FQI:  67998
nn.learn_nn_feature_fqi FQI:  68998
nn.learn_nn_feature_fqi FQI:  69998
nn.learn_nn_feature_fqi FQI:  70998
nn.learn_nn_feature_fqi FQI:  71998
nn.learn_nn_feature_fqi FQI:  72998
nn.learn_nn_feature_fqi FQI:  73998
nn.learn_nn_feature_fqi FQI:  74998
nn.learn_nn_feature_fqi FQI:  75998
nn.learn_nn_feature_fqi FQI:  76998
nn.learn_nn_feature_fqi FQI:  77998
nn.learn_nn_feature_fqi FQI:  78998
nn.learn_nn_feature_fqi FQI:  79998
nn.learn_nn_feature_fqi FQI:  80998
nn.learn_nn_feature_fqi FQI:  81998
nn.learn_nn_feature_fqi FQI:  82998
nn.learn_nn_feature_fqi FQI:  83998
nn.learn_nn_feature_fqi FQI:  84998
nn.learn_nn_feature_fqi FQI:  85998
nn.learn_nn_feature_fqi FQI:  86998
nn.learn_nn_feature_fqi FQI:  87998
nn.learn_nn_feature_fqi FQI:  88998
nn.learn_nn_feature_fqi FQI:  89998
nn.learn_nn_feature_fqi FQI:  90998
nn.learn_nn_feature_fqi FQI:  91998
nn.learn_nn_feature_fqi FQI:  92998
nn.learn_nn_feature_fqi FQI:  93998
nn.learn_nn_feature_fqi FQI:  94998
nn.learn_nn_feature_fqi FQI:  95998
nn.learn_nn_feature_fqi FQI:  96998
nn.learn_nn_feature_fqi FQI:  97998
nn.learn_nn_feature_fqi FQI:  98998
nn.learn_nn_feature_fqi FQI:  99998
nn.learn_nn_feature_fqi FQI:  100998
nn.learn_nn_feature_fqi FQI:  101998
nn.learn_nn_feature_fqi FQI:  102998
nn.learn_nn_feature_fqi FQI:  103998
nn.learn_nn_feature_fqi FQI:  104998
nn.learn_nn_feature_fqi FQI:  105998
nn.learn_nn_feature_fqi FQI:  106998
nn.learn_nn_feature_fqi FQI:  107998
nn.learn_nn_feature_fqi FQI:  108998
nn.learn_nn_feature_fqi FQI:  109998
nn.learn_nn_feature_fqi FQI:  110998
nn.learn_nn_feature_fqi FQI:  111998
nn.learn_nn_feature_fqi FQI:  112998
nn.learn_nn_feature_fqi FQI:  113998
nn.learn_nn_feature_fqi FQI:  114998
nn.learn_nn_feature_fqi FQI:  115998
nn.learn_nn_feature_fqi FQI:  116998
nn.learn_nn_feature_fqi FQI:  117998
nn.learn_nn_feature_fqi FQI:  118998
nn.learn_nn_feature_fqi FQI:  119998
nn.learn_nn_feature_fqi FQI:  120998
nn.learn_nn_feature_fqi FQI:  121998
nn.learn_nn_feature_fqi FQI:  122998
nn.learn_nn_feature_fqi FQI:  123998
nn.learn_nn_feature_fqi FQI:  124998
nn.learn_nn_feature_fqi FQI:  125998
nn.learn_nn_feature_fqi FQI:  126998
nn.learn_nn_feature_fqi FQI:  127998
nn.learn_nn_feature_fqi FQI:  128998
nn.learn_nn_feature_fqi FQI:  129998
nn.learn_nn_feature_fqi FQI:  130998
nn.learn_nn_feature_fqi FQI:  131998
nn.learn_nn_feature_fqi FQI:  132998
nn.learn_nn_feature_fqi FQI:  133998
nn.learn_nn_feature_fqi FQI:  134998
nn.learn_nn_feature_fqi FQI:  135998
nn.learn_nn_feature_fqi FQI:  136998
nn.learn_nn_feature_fqi FQI:  137998
nn.learn_nn_feature_fqi FQI:  138998
nn.learn_nn_feature_fqi FQI:  139998
nn.learn_nn_feature_fqi FQI:  140998
nn.learn_nn_feature_fqi FQI:  141998
nn.learn_nn_feature_fqi FQI:  142998
nn.learn_nn_feature_fqi FQI:  143998
nn.learn_nn_feature_fqi FQI:  144998
nn.learn_nn_feature_fqi FQI:  145998
nn.learn_nn_feature_fqi FQI:  146998
nn.learn_nn_feature_fqi FQI:  147998
nn.learn_nn_feature_fqi FQI:  148998
nn.learn_nn_feature_fqi FQI:  149998
nn.learn_nn_feature_fqi FQI:  150998
nn.learn_nn_feature_fqi FQI:  151998
nn.learn_nn_feature_fqi FQI:  152998
nn.learn_nn_feature_fqi FQI:  153998
nn.learn_nn_feature_fqi FQI:  154998
nn.learn_nn_feature_fqi FQI:  155998
0 1001 -1000.0 -98.99572604650622 number episode from 10: 0 avegar over 10 episode: -98.996 avegare return across last 100 episodes: -98.996 state values: tensor(0.5262) 1000
1 1000 -1000.0 -99.99568287525881 number episode from 10: 1 avegar over 10 episode: -99.496 avegare return across last 100 episodes: -99.496 state values: tensor(0.5263) 1000
2 376 -376.0 -97.71527902550486 number episode from 10: 2 avegar over 10 episode: -98.902 avegare return across last 100 episodes: -98.902 state values: tensor(0.5596) 376
3 1000 -1000.0 -99.99568287525881 number episode from 10: 3 avegar over 10 episode: -99.176 avegare return across last 100 episodes: -99.176 state values: tensor(0.5275) 1000
4 376 -376.0 -97.71527902550486 number episode from 10: 4 avegar over 10 episode: -98.884 avegare return across last 100 episodes: -98.884 state values: tensor(0.5613) 376
5 1000 -1000.0 -99.99568287525881 number episode from 10: 5 avegar over 10 episode: -99.069 avegare return across last 100 episodes: -99.069 state values: tensor(0.5282) 1000
6 1000 -1000.0 -99.99568287525881 number episode from 10: 6 avegar over 10 episode: -99.201 avegare return across last 100 episodes: -99.201 state values: tensor(0.5268) 1000
7 1000 -1000.0 -99.99568287525881 number episode from 10: 7 avegar over 10 episode: -99.301 avegare return across last 100 episodes: -99.301 state values: tensor(0.5269) 1000
8 606 -606.0 -99.77357314931054 number episode from 10: 8 avegar over 10 episode: -99.353 avegare return across last 100 episodes: -99.353 state values: tensor(0.5641) 606
9 1000 -1000.0 -99.99568287525881 number episode from 10: 9 avegar over 10 episode: -99.417 avegare return across last 100 episodes: -99.417 state values: tensor(0.5256) 1000
10 1000 -1000.0 -99.99568287525881 number episode from 10: 10 avegar over 10 episode: -99.47 avegare return across last 100 episodes: -99.47 state values: tensor(0.5263) 1000
11 1000 -1000.0 -99.99568287525881 number episode from 10: 11 avegar over 10 episode: -99.514 avegare return across last 100 episodes: -99.514 state values: tensor(0.5265) 1000
12 1000 -1000.0 -99.99568287525881 number episode from 10: 12 avegar over 10 episode: -99.551 avegare return across last 100 episodes: -99.551 state values: tensor(0.5265) 1000
13 1000 -1000.0 -99.99568287525881 number episode from 10: 13 avegar over 10 episode: -99.583 avegare return across last 100 episodes: -99.583 state values: tensor(0.5258) 1000
14 246 -246.0 -91.56164346735288 number episode from 10: 14 avegar over 10 episode: -99.048 avegare return across last 100 episodes: -99.048 state values: tensor(0.5846) 246
15 1000 -1000.0 -99.99568287525881 number episode from 10: 15 avegar over 10 episode: -99.107 avegare return across last 100 episodes: -99.107 state values: tensor(0.5265) 1000
16 1000 -1000.0 -99.99568287525881 number episode from 10: 16 avegar over 10 episode: -99.159 avegare return across last 100 episodes: -99.159 state values: tensor(0.5266) 1000
17 1000 -1000.0 -99.99568287525881 number episode from 10: 17 avegar over 10 episode: -99.206 avegare return across last 100 episodes: -99.206 state values: tensor(0.5281) 1000
18 1000 -1000.0 -99.99568287525881 number episode from 10: 18 avegar over 10 episode: -99.247 avegare return across last 100 episodes: -99.247 state values: tensor(0.5260) 1000
19 1000 -1000.0 -99.99568287525881 number episode from 10: 19 avegar over 10 episode: -99.285 avegare return across last 100 episodes: -99.285 state values: tensor(0.5264) 1000
20 1000 -1000.0 -99.99568287525881 number episode from 10: 20 avegar over 10 episode: -99.319 avegare return across last 100 episodes: -99.319 state values: tensor(0.5256) 1000
21 1000 -1000.0 -99.99568287525881 number episode from 10: 21 avegar over 10 episode: -99.349 avegare return across last 100 episodes: -99.349 state values: tensor(0.5280) 1000
22 1000 -1000.0 -99.99568287525881 number episode from 10: 22 avegar over 10 episode: -99.378 avegare return across last 100 episodes: -99.378 state values: tensor(0.5266) 1000
23 1000 -1000.0 -99.99568287525881 number episode from 10: 23 avegar over 10 episode: -99.403 avegare return across last 100 episodes: -99.403 state values: tensor(0.5272) 1000
24 1000 -1000.0 -99.99568287525881 number episode from 10: 24 avegar over 10 episode: -99.427 avegare return across last 100 episodes: -99.427 state values: tensor(0.5262) 1000
25 1000 -1000.0 -99.99568287525881 number episode from 10: 25 avegar over 10 episode: -99.449 avegare return across last 100 episodes: -99.449 state values: tensor(0.5270) 1000
26 386 -386.0 -97.93373930426993 number episode from 10: 26 avegar over 10 episode: -99.393 avegare return across last 100 episodes: -99.393 state values: tensor(0.5836) 386
27 469 -469.0 -99.10276487659536 number episode from 10: 27 avegar over 10 episode: -99.382 avegare return across last 100 episodes: -99.382 state values: tensor(0.5812) 469
28 1000 -1000.0 -99.99568287525881 number episode from 10: 28 avegar over 10 episode: -99.404 avegare return across last 100 episodes: -99.404 state values: tensor(0.5277) 1000
29 1000 -1000.0 -99.99568287525881 number episode from 10: 29 avegar over 10 episode: -99.423 avegare return across last 100 episodes: -99.423 state values: tensor(0.5273) 1000
30 1000 -1000.0 -99.99568287525881 number episode from 10: 30 avegar over 10 episode: -99.442 avegare return across last 100 episodes: -99.442 state values: tensor(0.5263) 1000
31 1000 -1000.0 -99.99568287525881 number episode from 10: 31 avegar over 10 episode: -99.459 avegare return across last 100 episodes: -99.459 state values: tensor(0.5285) 1000
32 1000 -1000.0 -99.99568287525881 number episode from 10: 32 avegar over 10 episode: -99.475 avegare return across last 100 episodes: -99.475 state values: tensor(0.5276) 1000
33 316 -316.0 -95.82437496415622 number episode from 10: 33 avegar over 10 episode: -99.368 avegare return across last 100 episodes: -99.368 state values: tensor(0.5961) 316
34 1000 -1000.0 -99.99568287525881 number episode from 10: 34 avegar over 10 episode: -99.386 avegare return across last 100 episodes: -99.386 state values: tensor(0.5260) 1000
35 447 -447.0 -98.88073741806613 number episode from 10: 35 avegar over 10 episode: -99.372 avegare return across last 100 episodes: -99.372 state values: tensor(0.5562) 447
36 1000 -1000.0 -99.99568287525881 number episode from 10: 36 avegar over 10 episode: -99.389 avegare return across last 100 episodes: -99.389 state values: tensor(0.5265) 1000
37 1000 -1000.0 -99.99568287525881 number episode from 10: 37 avegar over 10 episode: -99.405 avegare return across last 100 episodes: -99.405 state values: tensor(0.5273) 1000
38 447 -447.0 -98.88073741806613 number episode from 10: 38 avegar over 10 episode: -99.391 avegare return across last 100 episodes: -99.391 state values: tensor(0.5546) 447
39 606 -606.0 -99.77357314931054 number episode from 10: 39 avegar over 10 episode: -99.401 avegare return across last 100 episodes: -99.401 state values: tensor(0.5651) 606
40 460 -460.0 -99.01782355409692 number episode from 10: 40 avegar over 10 episode: -99.391 avegare return across last 100 episodes: -99.391 state values: tensor(0.5759) 460
41 1000 -1000.0 -99.99568287525881 number episode from 10: 41 avegar over 10 episode: -99.406 avegare return across last 100 episodes: -99.406 state values: tensor(0.5281) 1000
42 1000 -1000.0 -99.99568287525881 number episode from 10: 42 avegar over 10 episode: -99.42 avegare return across last 100 episodes: -99.42 state values: tensor(0.5287) 1000
43 1000 -1000.0 -99.99568287525881 number episode from 10: 43 avegar over 10 episode: -99.433 avegare return across last 100 episodes: -99.433 state values: tensor(0.5260) 1000
44 1000 -1000.0 -99.99568287525881 number episode from 10: 44 avegar over 10 episode: -99.445 avegare return across last 100 episodes: -99.445 state values: tensor(0.5266) 1000
45 397 -397.0 -98.14999775584162 number episode from 10: 45 avegar over 10 episode: -99.417 avegare return across last 100 episodes: -99.417 state values: tensor(0.5924) 397
46 394 -394.0 -98.09336890571012 number episode from 10: 46 avegar over 10 episode: -99.389 avegare return across last 100 episodes: -99.389 state values: tensor(0.5665) 394
47 1000 -1000.0 -99.99568287525881 number episode from 10: 47 avegar over 10 episode: -99.401 avegare return across last 100 episodes: -99.401 state values: tensor(0.5276) 1000
48 1000 -1000.0 -99.99568287525881 number episode from 10: 48 avegar over 10 episode: -99.414 avegare return across last 100 episodes: -99.414 state values: tensor(0.5259) 1000
49 1000 -1000.0 -99.99568287525881 number episode from 10: 49 avegar over 10 episode: -99.425 avegare return across last 100 episodes: -99.425 state values: tensor(0.5261) 1000
50 391 -391.0 -98.03500663786126 number episode from 10: 50 avegar over 10 episode: -99.398 avegare return across last 100 episodes: -99.398 state values: tensor(0.5863) 391
51 1000 -1000.0 -99.99568287525881 number episode from 10: 51 avegar over 10 episode: -99.409 avegare return across last 100 episodes: -99.409 state values: tensor(0.5266) 1000
52 1000 -1000.0 -99.99568287525881 number episode from 10: 52 avegar over 10 episode: -99.421 avegare return across last 100 episodes: -99.421 state values: tensor(0.5265) 1000
53 1000 -1000.0 -99.99568287525881 number episode from 10: 53 avegar over 10 episode: -99.431 avegare return across last 100 episodes: -99.431 state values: tensor(0.5277) 1000
54 1000 -1000.0 -99.99568287525881 number episode from 10: 54 avegar over 10 episode: -99.441 avegare return across last 100 episodes: -99.441 state values: tensor(0.5263) 1000
55 316 -316.0 -95.82437496415622 number episode from 10: 55 avegar over 10 episode: -99.377 avegare return across last 100 episodes: -99.377 state values: tensor(0.5967) 316
56 1000 -1000.0 -99.99568287525881 number episode from 10: 56 avegar over 10 episode: -99.388 avegare return across last 100 episodes: -99.388 state values: tensor(0.5281) 1000
57 1000 -1000.0 -99.99568287525881 number episode from 10: 57 avegar over 10 episode: -99.398 avegare return across last 100 episodes: -99.398 state values: tensor(0.5260) 1000
58 1000 -1000.0 -99.99568287525881 number episode from 10: 58 avegar over 10 episode: -99.408 avegare return across last 100 episodes: -99.408 state values: tensor(0.5265) 1000
59 1000 -1000.0 -99.99568287525881 number episode from 10: 59 avegar over 10 episode: -99.418 avegare return across last 100 episodes: -99.418 state values: tensor(0.5270) 1000
60 249 -249.0 -91.81227109472904 number episode from 10: 60 avegar over 10 episode: -99.293 avegare return across last 100 episodes: -99.293 state values: tensor(0.5868) 249
61 378 -378.0 -97.76074497289731 number episode from 10: 61 avegar over 10 episode: -99.269 avegare return across last 100 episodes: -99.269 state values: tensor(0.5628) 378
62 521 -521.0 -99.46796967728812 number episode from 10: 62 avegar over 10 episode: -99.272 avegare return across last 100 episodes: -99.272 state values: tensor(0.5533) 521
63 1000 -1000.0 -99.99568287525881 number episode from 10: 63 avegar over 10 episode: -99.283 avegare return across last 100 episodes: -99.283 state values: tensor(0.5267) 1000
64 1000 -1000.0 -99.99568287525881 number episode from 10: 64 avegar over 10 episode: -99.294 avegare return across last 100 episodes: -99.294 state values: tensor(0.5270) 1000
65 1000 -1000.0 -99.99568287525881 number episode from 10: 65 avegar over 10 episode: -99.305 avegare return across last 100 episodes: -99.305 state values: tensor(0.5261) 1000
66 1000 -1000.0 -99.99568287525881 number episode from 10: 66 avegar over 10 episode: -99.315 avegare return across last 100 episodes: -99.315 state values: tensor(0.5260) 1000
67 1000 -1000.0 -99.99568287525881 number episode from 10: 67 avegar over 10 episode: -99.325 avegare return across last 100 episodes: -99.325 state values: tensor(0.5262) 1000
68 1000 -1000.0 -99.99568287525881 number episode from 10: 68 avegar over 10 episode: -99.335 avegare return across last 100 episodes: -99.335 state values: tensor(0.5264) 1000
69 388 -388.0 -97.97485789211497 number episode from 10: 69 avegar over 10 episode: -99.315 avegare return across last 100 episodes: -99.315 state values: tensor(0.5831) 388
70 1000 -1000.0 -99.99568287525881 number episode from 10: 70 avegar over 10 episode: -99.325 avegare return across last 100 episodes: -99.325 state values: tensor(0.5260) 1000
71 322 -322.0 -96.06873191741121 number episode from 10: 71 avegar over 10 episode: -99.28 avegare return across last 100 episodes: -99.28 state values: tensor(0.6022) 322
72 315 -315.0 -95.78219693349114 number episode from 10: 72 avegar over 10 episode: -99.232 avegare return across last 100 episodes: -99.232 state values: tensor(0.5733) 315
73 1000 -1000.0 -99.99568287525881 number episode from 10: 73 avegar over 10 episode: -99.242 avegare return across last 100 episodes: -99.242 state values: tensor(0.5281) 1000
74 1000 -1000.0 -99.99568287525881 number episode from 10: 74 avegar over 10 episode: -99.252 avegare return across last 100 episodes: -99.252 state values: tensor(0.5262) 1000
75 1000 -1000.0 -99.99568287525881 number episode from 10: 75 avegar over 10 episode: -99.262 avegare return across last 100 episodes: -99.262 state values: tensor(0.5276) 1000
76 1000 -1000.0 -99.99568287525881 number episode from 10: 76 avegar over 10 episode: -99.272 avegare return across last 100 episodes: -99.272 state values: tensor(0.5261) 1000
77 1000 -1000.0 -99.99568287525881 number episode from 10: 77 avegar over 10 episode: -99.281 avegare return across last 100 episodes: -99.281 state values: tensor(0.5272) 1000
78 314 -314.0 -95.73959286211226 number episode from 10: 78 avegar over 10 episode: -99.236 avegare return across last 100 episodes: -99.236 state values: tensor(0.5726) 314
79 1000 -1000.0 -99.99568287525881 number episode from 10: 79 avegar over 10 episode: -99.245 avegare return across last 100 episodes: -99.245 state values: tensor(0.5258) 1000
80 318 -318.0 -95.9074699023695 number episode from 10: 80 avegar over 10 episode: -99.204 avegare return across last 100 episodes: -99.204 state values: tensor(0.5754) 318
81 1000 -1000.0 -99.99568287525881 number episode from 10: 81 avegar over 10 episode: -99.214 avegare return across last 100 episodes: -99.214 state values: tensor(0.5278) 1000
82 1000 -1000.0 -99.99568287525881 number episode from 10: 82 avegar over 10 episode: -99.223 avegare return across last 100 episodes: -99.223 state values: tensor(0.5263) 1000
83 1000 -1000.0 -99.99568287525881 number episode from 10: 83 avegar over 10 episode: -99.233 avegare return across last 100 episodes: -99.233 state values: tensor(0.5277) 1000
84 1000 -1000.0 -99.99568287525881 number episode from 10: 84 avegar over 10 episode: -99.242 avegare return across last 100 episodes: -99.242 state values: tensor(0.5264) 1000
85 1000 -1000.0 -99.99568287525881 number episode from 10: 85 avegar over 10 episode: -99.25 avegare return across last 100 episodes: -99.25 state values: tensor(0.5285) 1000
86 1000 -1000.0 -99.99568287525881 number episode from 10: 86 avegar over 10 episode: -99.259 avegare return across last 100 episodes: -99.259 state values: tensor(0.5264) 1000
87 1000 -1000.0 -99.99568287525881 number episode from 10: 87 avegar over 10 episode: -99.267 avegare return across last 100 episodes: -99.267 state values: tensor(0.5268) 1000
88 1000 -1000.0 -99.99568287525881 number episode from 10: 88 avegar over 10 episode: -99.275 avegare return across last 100 episodes: -99.275 state values: tensor(0.5280) 1000
89 315 -315.0 -95.78219693349114 number episode from 10: 89 avegar over 10 episode: -99.237 avegare return across last 100 episodes: -99.237 state values: tensor(0.5968) 315
90 240 -240.0 -91.03713812976741 number episode from 10: 90 avegar over 10 episode: -99.146 avegare return across last 100 episodes: -99.146 state values: tensor(0.5831) 240
91 459 -459.0 -99.00790257989588 number episode from 10: 91 avegar over 10 episode: -99.145 avegare return across last 100 episodes: -99.145 state values: tensor(0.5748) 459
92 306 -306.0 -95.38289717230063 number episode from 10: 92 avegar over 10 episode: -99.105 avegare return across last 100 episodes: -99.105 state values: tensor(0.5683) 306
93 1000 -1000.0 -99.99568287525881 number episode from 10: 93 avegar over 10 episode: -99.114 avegare return across last 100 episodes: -99.114 state values: tensor(0.5260) 1000
94 1000 -1000.0 -99.99568287525881 number episode from 10: 94 avegar over 10 episode: -99.123 avegare return across last 100 episodes: -99.123 state values: tensor(0.5280) 1000
95 1000 -1000.0 -99.99568287525881 number episode from 10: 95 avegar over 10 episode: -99.132 avegare return across last 100 episodes: -99.132 state values: tensor(0.5260) 1000
96 1000 -1000.0 -99.99568287525881 number episode from 10: 96 avegar over 10 episode: -99.141 avegare return across last 100 episodes: -99.141 state values: tensor(0.5262) 1000
97 1000 -1000.0 -99.99568287525881 number episode from 10: 97 avegar over 10 episode: -99.15 avegare return across last 100 episodes: -99.15 state values: tensor(0.5258) 1000
98 1000 -1000.0 -99.99568287525881 number episode from 10: 98 avegar over 10 episode: -99.159 avegare return across last 100 episodes: -99.159 state values: tensor(0.5266) 1000
99 1000 -1000.0 -99.99568287525881 number episode from 10: 99 avegar over 10 episode: -99.167 avegare return across last 100 episodes: -99.167 state values: tensor(0.5273) 1000
100 1000 -1000.0 -99.99568287525881 number episode from 10: 100 avegar over 10 episode: -99.175 avegare return across last 100 episodes: -99.177 state values: tensor(0.5258) 1000
101 1000 -1000.0 -99.99568287525881 number episode from 10: 101 avegar over 10 episode: -99.183 avegare return across last 100 episodes: -99.177 state values: tensor(0.5262) 1000
102 1000 -1000.0 -99.99568287525881 number episode from 10: 102 avegar over 10 episode: -99.191 avegare return across last 100 episodes: -99.2 state values: tensor(0.5279) 1000
103 1000 -1000.0 -99.99568287525881 number episode from 10: 103 avegar over 10 episode: -99.199 avegare return across last 100 episodes: -99.2 state values: tensor(0.5264) 1000
104 379 -379.0 -97.78313752316834 number episode from 10: 104 avegar over 10 episode: -99.185 avegare return across last 100 episodes: -99.2 state values: tensor(0.5633) 379
105 1000 -1000.0 -99.99568287525881 number episode from 10: 105 avegar over 10 episode: -99.193 avegare return across last 100 episodes: -99.2 state values: tensor(0.5259) 1000
106 1000 -1000.0 -99.99568287525881 number episode from 10: 106 avegar over 10 episode: -99.2 avegare return across last 100 episodes: -99.2 state values: tensor(0.5264) 1000
107 1000 -1000.0 -99.99568287525881 number episode from 10: 107 avegar over 10 episode: -99.208 avegare return across last 100 episodes: -99.2 state values: tensor(0.5277) 1000
108 305 -305.0 -95.33625977000064 number episode from 10: 108 avegar over 10 episode: -99.172 avegare return across last 100 episodes: -99.156 state values: tensor(0.5667) 305
109 1000 -1000.0 -99.99568287525881 number episode from 10: 109 avegar over 10 episode: -99.18 avegare return across last 100 episodes: -99.156 state values: tensor(0.5274) 1000
110 1000 -1000.0 -99.99568287525881 number episode from 10: 110 avegar over 10 episode: -99.187 avegare return across last 100 episodes: -99.156 state values: tensor(0.5267) 1000
111 1000 -1000.0 -99.99568287525881 number episode from 10: 111 avegar over 10 episode: -99.194 avegare return across last 100 episodes: -99.156 state values: tensor(0.5262) 1000
112 303 -303.0 -95.24156695235246 number episode from 10: 112 avegar over 10 episode: -99.159 avegare return across last 100 episodes: -99.108 state values: tensor(0.5672) 303
113 1000 -1000.0 -99.99568287525881 number episode from 10: 113 avegar over 10 episode: -99.167 avegare return across last 100 episodes: -99.108 state values: tensor(0.5280) 1000
114 1000 -1000.0 -99.99568287525881 number episode from 10: 114 avegar over 10 episode: -99.174 avegare return across last 100 episodes: -99.193 state values: tensor(0.5261) 1000
115 1000 -1000.0 -99.99568287525881 number episode from 10: 115 avegar over 10 episode: -99.181 avegare return across last 100 episodes: -99.193 state values: tensor(0.5258) 1000
116 305 -305.0 -95.33625977000064 number episode from 10: 116 avegar over 10 episode: -99.148 avegare return across last 100 episodes: -99.146 state values: tensor(0.5657) 305
117 1000 -1000.0 -99.99568287525881 number episode from 10: 117 avegar over 10 episode: -99.155 avegare return across last 100 episodes: -99.146 state values: tensor(0.5283) 1000
118 1000 -1000.0 -99.99568287525881 number episode from 10: 118 avegar over 10 episode: -99.162 avegare return across last 100 episodes: -99.146 state values: tensor(0.5261) 1000
119 1000 -1000.0 -99.99568287525881 number episode from 10: 119 avegar over 10 episode: -99.169 avegare return across last 100 episodes: -99.146 state values: tensor(0.5265) 1000
120 1000 -1000.0 -99.99568287525881 number episode from 10: 120 avegar over 10 episode: -99.176 avegare return across last 100 episodes: -99.146 state values: tensor(0.5280) 1000
121 1000 -1000.0 -99.99568287525881 number episode from 10: 121 avegar over 10 episode: -99.183 avegare return across last 100 episodes: -99.146 state values: tensor(0.5264) 1000
122 1000 -1000.0 -99.99568287525881 number episode from 10: 122 avegar over 10 episode: -99.189 avegare return across last 100 episodes: -99.146 state values: tensor(0.5262) 1000
123 1000 -1000.0 -99.99568287525881 number episode from 10: 123 avegar over 10 episode: -99.196 avegare return across last 100 episodes: -99.146 state values: tensor(0.5272) 1000
124 1000 -1000.0 -99.99568287525881 number episode from 10: 124 avegar over 10 episode: -99.202 avegare return across last 100 episodes: -99.146 state values: tensor(0.5274) 1000
125 1000 -1000.0 -99.99568287525881 number episode from 10: 125 avegar over 10 episode: -99.209 avegare return across last 100 episodes: -99.146 state values: tensor(0.5263) 1000
126 316 -316.0 -95.82437496415622 number episode from 10: 126 avegar over 10 episode: -99.182 avegare return across last 100 episodes: -99.125 state values: tensor(0.5980) 316
127 305 -305.0 -95.33625977000064 number episode from 10: 127 avegar over 10 episode: -99.152 avegare return across last 100 episodes: -99.087 state values: tensor(0.5659) 305
128 1000 -1000.0 -99.99568287525881 number episode from 10: 128 avegar over 10 episode: -99.159 avegare return across last 100 episodes: -99.087 state values: tensor(0.5277) 1000
129 1000 -1000.0 -99.99568287525881 number episode from 10: 129 avegar over 10 episode: -99.165 avegare return across last 100 episodes: -99.087 state values: tensor(0.5272) 1000
130 1000 -1000.0 -99.99568287525881 number episode from 10: 130 avegar over 10 episode: -99.171 avegare return across last 100 episodes: -99.087 state values: tensor(0.5262) 1000
131 1000 -1000.0 -99.99568287525881 number episode from 10: 131 avegar over 10 episode: -99.178 avegare return across last 100 episodes: -99.087 state values: tensor(0.5264) 1000
132 520 -520.0 -99.46259563362437 number episode from 10: 132 avegar over 10 episode: -99.18 avegare return across last 100 episodes: -99.082 state values: tensor(0.5528) 520
133 1000 -1000.0 -99.99568287525881 number episode from 10: 133 avegar over 10 episode: -99.186 avegare return across last 100 episodes: -99.124 state values: tensor(0.5267) 1000
134 466 -466.0 -99.07530037297303 number episode from 10: 134 avegar over 10 episode: -99.185 avegare return across last 100 episodes: -99.115 state values: tensor(0.5803) 466
135 1000 -1000.0 -99.99568287525881 number episode from 10: 135 avegar over 10 episode: -99.191 avegare return across last 100 episodes: -99.126 state values: tensor(0.5269) 1000
136 1000 -1000.0 -99.99568287525881 number episode from 10: 136 avegar over 10 episode: -99.197 avegare return across last 100 episodes: -99.126 state values: tensor(0.5265) 1000
137 1000 -1000.0 -99.99568287525881 number episode from 10: 137 avegar over 10 episode: -99.203 avegare return across last 100 episodes: -99.126 state values: tensor(0.5276) 1000
138 1000 -1000.0 -99.99568287525881 number episode from 10: 138 avegar over 10 episode: -99.208 avegare return across last 100 episodes: -99.137 state values: tensor(0.5263) 1000
139 1000 -1000.0 -99.99568287525881 number episode from 10: 139 avegar over 10 episode: -99.214 avegare return across last 100 episodes: -99.139 state values: tensor(0.5262) 1000
140 1000 -1000.0 -99.99568287525881 number episode from 10: 140 avegar over 10 episode: -99.219 avegare return across last 100 episodes: -99.149 state values: tensor(0.5253) 1000
141 1000 -1000.0 -99.99568287525881 number episode from 10: 141 avegar over 10 episode: -99.225 avegare return across last 100 episodes: -99.149 state values: tensor(0.5271) 1000
142 1000 -1000.0 -99.99568287525881 number episode from 10: 142 avegar over 10 episode: -99.23 avegare return across last 100 episodes: -99.149 state values: tensor(0.5253) 1000
143 1000 -1000.0 -99.99568287525881 number episode from 10: 143 avegar over 10 episode: -99.236 avegare return across last 100 episodes: -99.149 state values: tensor(0.5268) 1000
144 1000 -1000.0 -99.99568287525881 number episode from 10: 144 avegar over 10 episode: -99.241 avegare return across last 100 episodes: -99.149 state values: tensor(0.5259) 1000
145 376 -376.0 -97.71527902550486 number episode from 10: 145 avegar over 10 episode: -99.23 avegare return across last 100 episodes: -99.145 state values: tensor(0.5613) 376
146 1000 -1000.0 -99.99568287525881 number episode from 10: 146 avegar over 10 episode: -99.236 avegare return across last 100 episodes: -99.164 state values: tensor(0.5263) 1000
147 1000 -1000.0 -99.99568287525881 number episode from 10: 147 avegar over 10 episode: -99.241 avegare return across last 100 episodes: -99.164 state values: tensor(0.5278) 1000
148 1000 -1000.0 -99.99568287525881 number episode from 10: 148 avegar over 10 episode: -99.246 avegare return across last 100 episodes: -99.164 state values: tensor(0.5264) 1000
149 1000 -1000.0 -99.99568287525881 number episode from 10: 149 avegar over 10 episode: -99.251 avegare return across last 100 episodes: -99.164 state values: tensor(0.5268) 1000
150 1000 -1000.0 -99.99568287525881 number episode from 10: 150 avegar over 10 episode: -99.256 avegare return across last 100 episodes: -99.183 state values: tensor(0.5263) 1000
151 1000 -1000.0 -99.99568287525881 number episode from 10: 151 avegar over 10 episode: -99.261 avegare return across last 100 episodes: -99.183 state values: tensor(0.5273) 1000
152 1000 -1000.0 -99.99568287525881 number episode from 10: 152 avegar over 10 episode: -99.265 avegare return across last 100 episodes: -99.183 state values: tensor(0.5268) 1000
153 1000 -1000.0 -99.99568287525881 number episode from 10: 153 avegar over 10 episode: -99.27 avegare return across last 100 episodes: -99.183 state values: tensor(0.5262) 1000
154 1000 -1000.0 -99.99568287525881 number episode from 10: 154 avegar over 10 episode: -99.275 avegare return across last 100 episodes: -99.183 state values: tensor(0.5261) 1000
155 449 -449.0 -98.90301074344661 number episode from 10: 155 avegar over 10 episode: -99.272 avegare return across last 100 episodes: -99.214 state values: tensor(0.5576) 449
156 387 -387.0 -97.95440191122724 number episode from 10: 156 avegar over 10 episode: -99.264 avegare return across last 100 episodes: -99.194 state values: tensor(0.5840) 387
157 1000 -1000.0 -99.99568287525881 number episode from 10: 157 avegar over 10 episode: -99.269 avegare return across last 100 episodes: -99.194 state values: tensor(0.5276) 1000
158 321 -321.0 -96.0290221387992 number episode from 10: 158 avegar over 10 episode: -99.248 avegare return across last 100 episodes: -99.154 state values: tensor(0.6015) 321
159 1000 -1000.0 -99.99568287525881 number episode from 10: 159 avegar over 10 episode: -99.253 avegare return across last 100 episodes: -99.154 state values: tensor(0.5285) 1000
160 532 -532.0 -99.52365289965047 number episode from 10: 160 avegar over 10 episode: -99.255 avegare return across last 100 episodes: -99.231 state values: tensor(0.5703) 532
161 1000 -1000.0 -99.99568287525881 number episode from 10: 161 avegar over 10 episode: -99.259 avegare return across last 100 episodes: -99.253 state values: tensor(0.5275) 1000
162 1000 -1000.0 -99.99568287525881 number episode from 10: 162 avegar over 10 episode: -99.264 avegare return across last 100 episodes: -99.259 state values: tensor(0.5263) 1000
163 1000 -1000.0 -99.99568287525881 number episode from 10: 163 avegar over 10 episode: -99.268 avegare return across last 100 episodes: -99.259 state values: tensor(0.5267) 1000
164 1000 -1000.0 -99.99568287525881 number episode from 10: 164 avegar over 10 episode: -99.273 avegare return across last 100 episodes: -99.259 state values: tensor(0.5262) 1000
165 1000 -1000.0 -99.99568287525881 number episode from 10: 165 avegar over 10 episode: -99.277 avegare return across last 100 episodes: -99.259 state values: tensor(0.5276) 1000
166 1000 -1000.0 -99.99568287525881 number episode from 10: 166 avegar over 10 episode: -99.281 avegare return across last 100 episodes: -99.259 state values: tensor(0.5260) 1000
167 1000 -1000.0 -99.99568287525881 number episode from 10: 167 avegar over 10 episode: -99.286 avegare return across last 100 episodes: -99.259 state values: tensor(0.5268) 1000
168 1000 -1000.0 -99.99568287525881 number episode from 10: 168 avegar over 10 episode: -99.29 avegare return across last 100 episodes: -99.259 state values: tensor(0.5268) 1000
169 1000 -1000.0 -99.99568287525881 number episode from 10: 169 avegar over 10 episode: -99.294 avegare return across last 100 episodes: -99.279 state values: tensor(0.5264) 1000
170 395 -395.0 -98.11243521665303 number episode from 10: 170 avegar over 10 episode: -99.287 avegare return across last 100 episodes: -99.26 state values: tensor(0.5916) 395
171 1000 -1000.0 -99.99568287525881 number episode from 10: 171 avegar over 10 episode: -99.291 avegare return across last 100 episodes: -99.299 state values: tensor(0.5265) 1000
172 1000 -1000.0 -99.99568287525881 number episode from 10: 172 avegar over 10 episode: -99.295 avegare return across last 100 episodes: -99.341 state values: tensor(0.5264) 1000
173 1000 -1000.0 -99.99568287525881 number episode from 10: 173 avegar over 10 episode: -99.299 avegare return across last 100 episodes: -99.341 state values: tensor(0.5271) 1000
174 1000 -1000.0 -99.99568287525881 number episode from 10: 174 avegar over 10 episode: -99.303 avegare return across last 100 episodes: -99.341 state values: tensor(0.5259) 1000
175 315 -315.0 -95.78219693349114 number episode from 10: 175 avegar over 10 episode: -99.283 avegare return across last 100 episodes: -99.299 state values: tensor(0.5975) 315
176 1000 -1000.0 -99.99568287525881 number episode from 10: 176 avegar over 10 episode: -99.287 avegare return across last 100 episodes: -99.299 state values: tensor(0.5266) 1000
177 377 -377.0 -97.73812623524981 number episode from 10: 177 avegar over 10 episode: -99.279 avegare return across last 100 episodes: -99.277 state values: tensor(0.5610) 377
178 1000 -1000.0 -99.99568287525881 number episode from 10: 178 avegar over 10 episode: -99.283 avegare return across last 100 episodes: -99.319 state values: tensor(0.5265) 1000
179 1000 -1000.0 -99.99568287525881 number episode from 10: 179 avegar over 10 episode: -99.286 avegare return across last 100 episodes: -99.319 state values: tensor(0.5277) 1000
180 1000 -1000.0 -99.99568287525881 number episode from 10: 180 avegar over 10 episode: -99.29 avegare return across last 100 episodes: -99.36 state values: tensor(0.5267) 1000
181 380 -380.0 -97.80530614793665 number episode from 10: 181 avegar over 10 episode: -99.282 avegare return across last 100 episodes: -99.338 state values: tensor(0.5639) 380
182 1000 -1000.0 -99.99568287525881 number episode from 10: 182 avegar over 10 episode: -99.286 avegare return across last 100 episodes: -99.338 state values: tensor(0.5268) 1000
183 317 -317.0 -95.86613121451465 number episode from 10: 183 avegar over 10 episode: -99.268 avegare return across last 100 episodes: -99.297 state values: tensor(0.5952) 317
184 1000 -1000.0 -99.99568287525881 number episode from 10: 184 avegar over 10 episode: -99.271 avegare return across last 100 episodes: -99.297 state values: tensor(0.5267) 1000
185 1000 -1000.0 -99.99568287525881 number episode from 10: 185 avegar over 10 episode: -99.275 avegare return across last 100 episodes: -99.297 state values: tensor(0.5266) 1000
186 1000 -1000.0 -99.99568287525881 number episode from 10: 186 avegar over 10 episode: -99.279 avegare return across last 100 episodes: -99.297 state values: tensor(0.5268) 1000
187 1000 -1000.0 -99.99568287525881 number episode from 10: 187 avegar over 10 episode: -99.283 avegare return across last 100 episodes: -99.297 state values: tensor(0.5281) 1000
188 318 -318.0 -95.9074699023695 number episode from 10: 188 avegar over 10 episode: -99.265 avegare return across last 100 episodes: -99.256 state values: tensor(0.5961) 318
189 1000 -1000.0 -99.99568287525881 number episode from 10: 189 avegar over 10 episode: -99.269 avegare return across last 100 episodes: -99.298 state values: tensor(0.5262) 1000
190 1000 -1000.0 -99.99568287525881 number episode from 10: 190 avegar over 10 episode: -99.273 avegare return across last 100 episodes: -99.388 state values: tensor(0.5267) 1000
191 1000 -1000.0 -99.99568287525881 number episode from 10: 191 avegar over 10 episode: -99.277 avegare return across last 100 episodes: -99.398 state values: tensor(0.5268) 1000
192 314 -314.0 -95.73959286211226 number episode from 10: 192 avegar over 10 episode: -99.258 avegare return across last 100 episodes: -99.401 state values: tensor(0.5719) 314
193 1000 -1000.0 -99.99568287525881 number episode from 10: 193 avegar over 10 episode: -99.262 avegare return across last 100 episodes: -99.401 state values: tensor(0.5274) 1000
194 1000 -1000.0 -99.99568287525881 number episode from 10: 194 avegar over 10 episode: -99.266 avegare return across last 100 episodes: -99.401 state values: tensor(0.5271) 1000
195 1000 -1000.0 -99.99568287525881 number episode from 10: 195 avegar over 10 episode: -99.27 avegare return across last 100 episodes: -99.401 state values: tensor(0.5267) 1000
196 1000 -1000.0 -99.99568287525881 number episode from 10: 196 avegar over 10 episode: -99.273 avegare return across last 100 episodes: -99.401 state values: tensor(0.5259) 1000
197 1000 -1000.0 -99.99568287525881 number episode from 10: 197 avegar over 10 episode: -99.277 avegare return across last 100 episodes: -99.401 state values: tensor(0.5260) 1000
198 1000 -1000.0 -99.99568287525881 number episode from 10: 198 avegar over 10 episode: -99.281 avegare return across last 100 episodes: -99.401 state values: tensor(0.5266) 1000
199 377 -377.0 -97.73812623524981 number episode from 10: 199 avegar over 10 episode: -99.273 avegare return across last 100 episodes: -99.379 state values: tensor(0.5620) 377
200 1000 -1000.0 -99.99568287525881 number episode from 10: 200 avegar over 10 episode: -99.276 avegare return across last 100 episodes: -99.379 state values: tensor(0.5266) 1000
load offline data!!!!!
mem_cntr: 50000 ; mem_size: 50000
nn.learn_nn_feature_fqi FQI:  998
nn.learn_nn_feature_fqi FQI:  1998
nn.learn_nn_feature_fqi FQI:  2998
nn.learn_nn_feature_fqi FQI:  3998
nn.learn_nn_feature_fqi FQI:  4998
nn.learn_nn_feature_fqi FQI:  5998
nn.learn_nn_feature_fqi FQI:  6998
nn.learn_nn_feature_fqi FQI:  7998
nn.learn_nn_feature_fqi FQI:  8998
nn.learn_nn_feature_fqi FQI:  9998
nn.learn_nn_feature_fqi FQI:  10998
nn.learn_nn_feature_fqi FQI:  11998
nn.learn_nn_feature_fqi FQI:  12998
nn.learn_nn_feature_fqi FQI:  13998
nn.learn_nn_feature_fqi FQI:  14998
nn.learn_nn_feature_fqi FQI:  15998
nn.learn_nn_feature_fqi FQI:  16998
nn.learn_nn_feature_fqi FQI:  17998
nn.learn_nn_feature_fqi FQI:  18998
nn.learn_nn_feature_fqi FQI:  19998
nn.learn_nn_feature_fqi FQI:  20998
nn.learn_nn_feature_fqi FQI:  21998
nn.learn_nn_feature_fqi FQI:  22998
nn.learn_nn_feature_fqi FQI:  23998
nn.learn_nn_feature_fqi FQI:  24998
nn.learn_nn_feature_fqi FQI:  25998
nn.learn_nn_feature_fqi FQI:  26998
nn.learn_nn_feature_fqi FQI:  27998
nn.learn_nn_feature_fqi FQI:  28998
nn.learn_nn_feature_fqi FQI:  29998
nn.learn_nn_feature_fqi FQI:  30998
nn.learn_nn_feature_fqi FQI:  31998
nn.learn_nn_feature_fqi FQI:  32998
nn.learn_nn_feature_fqi FQI:  33998
nn.learn_nn_feature_fqi FQI:  34998
nn.learn_nn_feature_fqi FQI:  35998
nn.learn_nn_feature_fqi FQI:  36998
nn.learn_nn_feature_fqi FQI:  37998
nn.learn_nn_feature_fqi FQI:  38998
nn.learn_nn_feature_fqi FQI:  39998
nn.learn_nn_feature_fqi FQI:  40998
nn.learn_nn_feature_fqi FQI:  41998
nn.learn_nn_feature_fqi FQI:  42998
nn.learn_nn_feature_fqi FQI:  43998
nn.learn_nn_feature_fqi FQI:  44998
nn.learn_nn_feature_fqi FQI:  45998
nn.learn_nn_feature_fqi FQI:  46998
nn.learn_nn_feature_fqi FQI:  47998
nn.learn_nn_feature_fqi FQI:  48998
nn.learn_nn_feature_fqi FQI:  49998
nn.learn_nn_feature_fqi FQI:  50998
nn.learn_nn_feature_fqi FQI:  51998
nn.learn_nn_feature_fqi FQI:  52998
nn.learn_nn_feature_fqi FQI:  53998
nn.learn_nn_feature_fqi FQI:  54998
nn.learn_nn_feature_fqi FQI:  55998
nn.learn_nn_feature_fqi FQI:  56998
nn.learn_nn_feature_fqi FQI:  57998
nn.learn_nn_feature_fqi FQI:  58998
nn.learn_nn_feature_fqi FQI:  59998
nn.learn_nn_feature_fqi FQI:  60998
nn.learn_nn_feature_fqi FQI:  61998
nn.learn_nn_feature_fqi FQI:  62998
nn.learn_nn_feature_fqi FQI:  63998
nn.learn_nn_feature_fqi FQI:  64998
nn.learn_nn_feature_fqi FQI:  65998
nn.learn_nn_feature_fqi FQI:  66998
nn.learn_nn_feature_fqi FQI:  67998
nn.learn_nn_feature_fqi FQI:  68998
nn.learn_nn_feature_fqi FQI:  69998
nn.learn_nn_feature_fqi FQI:  70998
nn.learn_nn_feature_fqi FQI:  71998
nn.learn_nn_feature_fqi FQI:  72998
nn.learn_nn_feature_fqi FQI:  73998
nn.learn_nn_feature_fqi FQI:  74998
nn.learn_nn_feature_fqi FQI:  75998
nn.learn_nn_feature_fqi FQI:  76998
nn.learn_nn_feature_fqi FQI:  77998
nn.learn_nn_feature_fqi FQI:  78998
nn.learn_nn_feature_fqi FQI:  79998
nn.learn_nn_feature_fqi FQI:  80998
nn.learn_nn_feature_fqi FQI:  81998
nn.learn_nn_feature_fqi FQI:  82998
nn.learn_nn_feature_fqi FQI:  83998
nn.learn_nn_feature_fqi FQI:  84998
nn.learn_nn_feature_fqi FQI:  85998
nn.learn_nn_feature_fqi FQI:  86998
nn.learn_nn_feature_fqi FQI:  87998
nn.learn_nn_feature_fqi FQI:  88998
nn.learn_nn_feature_fqi FQI:  89998
nn.learn_nn_feature_fqi FQI:  90998
nn.learn_nn_feature_fqi FQI:  91998
nn.learn_nn_feature_fqi FQI:  92998
nn.learn_nn_feature_fqi FQI:  93998
nn.learn_nn_feature_fqi FQI:  94998
nn.learn_nn_feature_fqi FQI:  95998
nn.learn_nn_feature_fqi FQI:  96998
nn.learn_nn_feature_fqi FQI:  97998
nn.learn_nn_feature_fqi FQI:  98998
nn.learn_nn_feature_fqi FQI:  99998
nn.learn_nn_feature_fqi FQI:  100998
nn.learn_nn_feature_fqi FQI:  101998
nn.learn_nn_feature_fqi FQI:  102998
nn.learn_nn_feature_fqi FQI:  103998
nn.learn_nn_feature_fqi FQI:  104998
nn.learn_nn_feature_fqi FQI:  105998
nn.learn_nn_feature_fqi FQI:  106998
nn.learn_nn_feature_fqi FQI:  107998
nn.learn_nn_feature_fqi FQI:  108998
nn.learn_nn_feature_fqi FQI:  109998
nn.learn_nn_feature_fqi FQI:  110998
nn.learn_nn_feature_fqi FQI:  111998
nn.learn_nn_feature_fqi FQI:  112998
nn.learn_nn_feature_fqi FQI:  113998
nn.learn_nn_feature_fqi FQI:  114998
nn.learn_nn_feature_fqi FQI:  115998
nn.learn_nn_feature_fqi FQI:  116998
nn.learn_nn_feature_fqi FQI:  117998
nn.learn_nn_feature_fqi FQI:  118998
nn.learn_nn_feature_fqi FQI:  119998
nn.learn_nn_feature_fqi FQI:  120998
nn.learn_nn_feature_fqi FQI:  121998
nn.learn_nn_feature_fqi FQI:  122998
nn.learn_nn_feature_fqi FQI:  123998
nn.learn_nn_feature_fqi FQI:  124998
nn.learn_nn_feature_fqi FQI:  125998
nn.learn_nn_feature_fqi FQI:  126998
nn.learn_nn_feature_fqi FQI:  127998
nn.learn_nn_feature_fqi FQI:  128998
nn.learn_nn_feature_fqi FQI:  129998
nn.learn_nn_feature_fqi FQI:  130998
nn.learn_nn_feature_fqi FQI:  131998
nn.learn_nn_feature_fqi FQI:  132998
nn.learn_nn_feature_fqi FQI:  133998
nn.learn_nn_feature_fqi FQI:  134998
nn.learn_nn_feature_fqi FQI:  135998
nn.learn_nn_feature_fqi FQI:  136998
nn.learn_nn_feature_fqi FQI:  137998
nn.learn_nn_feature_fqi FQI:  138998
nn.learn_nn_feature_fqi FQI:  139998
nn.learn_nn_feature_fqi FQI:  140998
nn.learn_nn_feature_fqi FQI:  141998
nn.learn_nn_feature_fqi FQI:  142998
nn.learn_nn_feature_fqi FQI:  143998
nn.learn_nn_feature_fqi FQI:  144998
nn.learn_nn_feature_fqi FQI:  145998
nn.learn_nn_feature_fqi FQI:  146998
nn.learn_nn_feature_fqi FQI:  147998
nn.learn_nn_feature_fqi FQI:  148998
nn.learn_nn_feature_fqi FQI:  149998
nn.learn_nn_feature_fqi FQI:  150998
nn.learn_nn_feature_fqi FQI:  151998
nn.learn_nn_feature_fqi FQI:  152998
nn.learn_nn_feature_fqi FQI:  153998
nn.learn_nn_feature_fqi FQI:  154998
nn.learn_nn_feature_fqi FQI:  155998
0 1001 -1000.0 -98.99572604650622 number episode from 10: 0 avegar over 10 episode: -98.996 avegare return across last 100 episodes: -98.996 state values: tensor(0.6053) 1000
1 1000 -1000.0 -99.99568287525881 number episode from 10: 1 avegar over 10 episode: -99.496 avegare return across last 100 episodes: -99.496 state values: tensor(0.6049) 1000
2 1000 -1000.0 -99.99568287525881 number episode from 10: 2 avegar over 10 episode: -99.662 avegare return across last 100 episodes: -99.662 state values: tensor(0.6044) 1000
3 1000 -1000.0 -99.99568287525881 number episode from 10: 3 avegar over 10 episode: -99.746 avegare return across last 100 episodes: -99.746 state values: tensor(0.6046) 1000
4 1000 -1000.0 -99.99568287525881 number episode from 10: 4 avegar over 10 episode: -99.796 avegare return across last 100 episodes: -99.796 state values: tensor(0.6063) 1000
5 1000 -1000.0 -99.99568287525881 number episode from 10: 5 avegar over 10 episode: -99.829 avegare return across last 100 episodes: -99.829 state values: tensor(0.6057) 1000
6 1000 -1000.0 -99.99568287525881 number episode from 10: 6 avegar over 10 episode: -99.853 avegare return across last 100 episodes: -99.853 state values: tensor(0.6047) 1000
7 1000 -1000.0 -99.99568287525881 number episode from 10: 7 avegar over 10 episode: -99.871 avegare return across last 100 episodes: -99.871 state values: tensor(0.6045) 1000
8 1000 -1000.0 -99.99568287525881 number episode from 10: 8 avegar over 10 episode: -99.885 avegare return across last 100 episodes: -99.885 state values: tensor(0.6044) 1000
9 1000 -1000.0 -99.99568287525881 number episode from 10: 9 avegar over 10 episode: -99.896 avegare return across last 100 episodes: -99.896 state values: tensor(0.6058) 1000
10 1000 -1000.0 -99.99568287525881 number episode from 10: 10 avegar over 10 episode: -99.905 avegare return across last 100 episodes: -99.905 state values: tensor(0.6060) 1000
11 1000 -1000.0 -99.99568287525881 number episode from 10: 11 avegar over 10 episode: -99.912 avegare return across last 100 episodes: -99.912 state values: tensor(0.6043) 1000
12 1000 -1000.0 -99.99568287525881 number episode from 10: 12 avegar over 10 episode: -99.919 avegare return across last 100 episodes: -99.919 state values: tensor(0.6057) 1000
13 1000 -1000.0 -99.99568287525881 number episode from 10: 13 avegar over 10 episode: -99.924 avegare return across last 100 episodes: -99.924 state values: tensor(0.6058) 1000
14 1000 -1000.0 -99.99568287525881 number episode from 10: 14 avegar over 10 episode: -99.929 avegare return across last 100 episodes: -99.929 state values: tensor(0.6044) 1000
15 1000 -1000.0 -99.99568287525881 number episode from 10: 15 avegar over 10 episode: -99.933 avegare return across last 100 episodes: -99.933 state values: tensor(0.6045) 1000
16 1000 -1000.0 -99.99568287525881 number episode from 10: 16 avegar over 10 episode: -99.937 avegare return across last 100 episodes: -99.937 state values: tensor(0.6058) 1000
17 1000 -1000.0 -99.99568287525881 number episode from 10: 17 avegar over 10 episode: -99.94 avegare return across last 100 episodes: -99.94 state values: tensor(0.6044) 1000
18 1000 -1000.0 -99.99568287525881 number episode from 10: 18 avegar over 10 episode: -99.943 avegare return across last 100 episodes: -99.943 state values: tensor(0.6057) 1000
19 1000 -1000.0 -99.99568287525881 number episode from 10: 19 avegar over 10 episode: -99.946 avegare return across last 100 episodes: -99.946 state values: tensor(0.6062) 1000
20 1000 -1000.0 -99.99568287525881 number episode from 10: 20 avegar over 10 episode: -99.948 avegare return across last 100 episodes: -99.948 state values: tensor(0.6043) 1000
21 1000 -1000.0 -99.99568287525881 number episode from 10: 21 avegar over 10 episode: -99.95 avegare return across last 100 episodes: -99.95 state values: tensor(0.6046) 1000
22 1000 -1000.0 -99.99568287525881 number episode from 10: 22 avegar over 10 episode: -99.952 avegare return across last 100 episodes: -99.952 state values: tensor(0.6057) 1000
23 1000 -1000.0 -99.99568287525881 number episode from 10: 23 avegar over 10 episode: -99.954 avegare return across last 100 episodes: -99.954 state values: tensor(0.6058) 1000
24 1000 -1000.0 -99.99568287525881 number episode from 10: 24 avegar over 10 episode: -99.956 avegare return across last 100 episodes: -99.956 state values: tensor(0.6043) 1000
25 1000 -1000.0 -99.99568287525881 number episode from 10: 25 avegar over 10 episode: -99.957 avegare return across last 100 episodes: -99.957 state values: tensor(0.6050) 1000
26 1000 -1000.0 -99.99568287525881 number episode from 10: 26 avegar over 10 episode: -99.959 avegare return across last 100 episodes: -99.959 state values: tensor(0.6058) 1000
27 1000 -1000.0 -99.99568287525881 number episode from 10: 27 avegar over 10 episode: -99.96 avegare return across last 100 episodes: -99.96 state values: tensor(0.6046) 1000
28 1000 -1000.0 -99.99568287525881 number episode from 10: 28 avegar over 10 episode: -99.961 avegare return across last 100 episodes: -99.961 state values: tensor(0.6058) 1000
29 1000 -1000.0 -99.99568287525881 number episode from 10: 29 avegar over 10 episode: -99.962 avegare return across last 100 episodes: -99.962 state values: tensor(0.6047) 1000
30 1000 -1000.0 -99.99568287525881 number episode from 10: 30 avegar over 10 episode: -99.963 avegare return across last 100 episodes: -99.963 state values: tensor(0.6057) 1000
31 1000 -1000.0 -99.99568287525881 number episode from 10: 31 avegar over 10 episode: -99.964 avegare return across last 100 episodes: -99.964 state values: tensor(0.6044) 1000
32 1000 -1000.0 -99.99568287525881 number episode from 10: 32 avegar over 10 episode: -99.965 avegare return across last 100 episodes: -99.965 state values: tensor(0.6045) 1000
33 1000 -1000.0 -99.99568287525881 number episode from 10: 33 avegar over 10 episode: -99.966 avegare return across last 100 episodes: -99.966 state values: tensor(0.6060) 1000
34 1000 -1000.0 -99.99568287525881 number episode from 10: 34 avegar over 10 episode: -99.967 avegare return across last 100 episodes: -99.967 state values: tensor(0.6045) 1000
35 1000 -1000.0 -99.99568287525881 number episode from 10: 35 avegar over 10 episode: -99.968 avegare return across last 100 episodes: -99.968 state values: tensor(0.6052) 1000
36 1000 -1000.0 -99.99568287525881 number episode from 10: 36 avegar over 10 episode: -99.969 avegare return across last 100 episodes: -99.969 state values: tensor(0.6044) 1000
37 1000 -1000.0 -99.99568287525881 number episode from 10: 37 avegar over 10 episode: -99.969 avegare return across last 100 episodes: -99.969 state values: tensor(0.6062) 1000
38 1000 -1000.0 -99.99568287525881 number episode from 10: 38 avegar over 10 episode: -99.97 avegare return across last 100 episodes: -99.97 state values: tensor(0.6043) 1000
39 1000 -1000.0 -99.99568287525881 number episode from 10: 39 avegar over 10 episode: -99.971 avegare return across last 100 episodes: -99.971 state values: tensor(0.6044) 1000
40 1000 -1000.0 -99.99568287525881 number episode from 10: 40 avegar over 10 episode: -99.971 avegare return across last 100 episodes: -99.971 state values: tensor(0.6057) 1000
41 1000 -1000.0 -99.99568287525881 number episode from 10: 41 avegar over 10 episode: -99.972 avegare return across last 100 episodes: -99.972 state values: tensor(0.6052) 1000
42 1000 -1000.0 -99.99568287525881 number episode from 10: 42 avegar over 10 episode: -99.972 avegare return across last 100 episodes: -99.972 state values: tensor(0.6059) 1000
43 1000 -1000.0 -99.99568287525881 number episode from 10: 43 avegar over 10 episode: -99.973 avegare return across last 100 episodes: -99.973 state values: tensor(0.6049) 1000
44 1000 -1000.0 -99.99568287525881 number episode from 10: 44 avegar over 10 episode: -99.973 avegare return across last 100 episodes: -99.973 state values: tensor(0.6063) 1000
45 1000 -1000.0 -99.99568287525881 number episode from 10: 45 avegar over 10 episode: -99.974 avegare return across last 100 episodes: -99.974 state values: tensor(0.6044) 1000
46 1000 -1000.0 -99.99568287525881 number episode from 10: 46 avegar over 10 episode: -99.974 avegare return across last 100 episodes: -99.974 state values: tensor(0.6046) 1000
47 1000 -1000.0 -99.99568287525881 number episode from 10: 47 avegar over 10 episode: -99.975 avegare return across last 100 episodes: -99.975 state values: tensor(0.6058) 1000
48 1000 -1000.0 -99.99568287525881 number episode from 10: 48 avegar over 10 episode: -99.975 avegare return across last 100 episodes: -99.975 state values: tensor(0.6046) 1000
49 1000 -1000.0 -99.99568287525881 number episode from 10: 49 avegar over 10 episode: -99.976 avegare return across last 100 episodes: -99.976 state values: tensor(0.6059) 1000
50 1000 -1000.0 -99.99568287525881 number episode from 10: 50 avegar over 10 episode: -99.976 avegare return across last 100 episodes: -99.976 state values: tensor(0.6045) 1000
51 1000 -1000.0 -99.99568287525881 number episode from 10: 51 avegar over 10 episode: -99.976 avegare return across last 100 episodes: -99.976 state values: tensor(0.6052) 1000
52 1000 -1000.0 -99.99568287525881 number episode from 10: 52 avegar over 10 episode: -99.977 avegare return across last 100 episodes: -99.977 state values: tensor(0.6057) 1000
53 1000 -1000.0 -99.99568287525881 number episode from 10: 53 avegar over 10 episode: -99.977 avegare return across last 100 episodes: -99.977 state values: tensor(0.6056) 1000
54 1000 -1000.0 -99.99568287525881 number episode from 10: 54 avegar over 10 episode: -99.978 avegare return across last 100 episodes: -99.978 state values: tensor(0.6048) 1000
55 1000 -1000.0 -99.99568287525881 number episode from 10: 55 avegar over 10 episode: -99.978 avegare return across last 100 episodes: -99.978 state values: tensor(0.6054) 1000
56 1000 -1000.0 -99.99568287525881 number episode from 10: 56 avegar over 10 episode: -99.978 avegare return across last 100 episodes: -99.978 state values: tensor(0.6051) 1000
57 1000 -1000.0 -99.99568287525881 number episode from 10: 57 avegar over 10 episode: -99.978 avegare return across last 100 episodes: -99.978 state values: tensor(0.6060) 1000
58 1000 -1000.0 -99.99568287525881 number episode from 10: 58 avegar over 10 episode: -99.979 avegare return across last 100 episodes: -99.979 state values: tensor(0.6050) 1000
59 1000 -1000.0 -99.99568287525881 number episode from 10: 59 avegar over 10 episode: -99.979 avegare return across last 100 episodes: -99.979 state values: tensor(0.6046) 1000
60 1000 -1000.0 -99.99568287525881 number episode from 10: 60 avegar over 10 episode: -99.979 avegare return across last 100 episodes: -99.979 state values: tensor(0.6058) 1000
61 1000 -1000.0 -99.99568287525881 number episode from 10: 61 avegar over 10 episode: -99.98 avegare return across last 100 episodes: -99.98 state values: tensor(0.6049) 1000
62 1000 -1000.0 -99.99568287525881 number episode from 10: 62 avegar over 10 episode: -99.98 avegare return across last 100 episodes: -99.98 state values: tensor(0.6057) 1000
63 1000 -1000.0 -99.99568287525881 number episode from 10: 63 avegar over 10 episode: -99.98 avegare return across last 100 episodes: -99.98 state values: tensor(0.6062) 1000
64 1000 -1000.0 -99.99568287525881 number episode from 10: 64 avegar over 10 episode: -99.98 avegare return across last 100 episodes: -99.98 state values: tensor(0.6058) 1000
65 1000 -1000.0 -99.99568287525881 number episode from 10: 65 avegar over 10 episode: -99.981 avegare return across last 100 episodes: -99.981 state values: tensor(0.6060) 1000
66 1000 -1000.0 -99.99568287525881 number episode from 10: 66 avegar over 10 episode: -99.981 avegare return across last 100 episodes: -99.981 state values: tensor(0.6059) 1000
67 1000 -1000.0 -99.99568287525881 number episode from 10: 67 avegar over 10 episode: -99.981 avegare return across last 100 episodes: -99.981 state values: tensor(0.6048) 1000
68 1000 -1000.0 -99.99568287525881 number episode from 10: 68 avegar over 10 episode: -99.981 avegare return across last 100 episodes: -99.981 state values: tensor(0.6057) 1000
69 1000 -1000.0 -99.99568287525881 number episode from 10: 69 avegar over 10 episode: -99.981 avegare return across last 100 episodes: -99.981 state values: tensor(0.6052) 1000
70 1000 -1000.0 -99.99568287525881 number episode from 10: 70 avegar over 10 episode: -99.982 avegare return across last 100 episodes: -99.982 state values: tensor(0.6056) 1000
71 1000 -1000.0 -99.99568287525881 number episode from 10: 71 avegar over 10 episode: -99.982 avegare return across last 100 episodes: -99.982 state values: tensor(0.6043) 1000
72 1000 -1000.0 -99.99568287525881 number episode from 10: 72 avegar over 10 episode: -99.982 avegare return across last 100 episodes: -99.982 state values: tensor(0.6059) 1000
73 1000 -1000.0 -99.99568287525881 number episode from 10: 73 avegar over 10 episode: -99.982 avegare return across last 100 episodes: -99.982 state values: tensor(0.6056) 1000
74 1000 -1000.0 -99.99568287525881 number episode from 10: 74 avegar over 10 episode: -99.982 avegare return across last 100 episodes: -99.982 state values: tensor(0.6059) 1000
75 1000 -1000.0 -99.99568287525881 number episode from 10: 75 avegar over 10 episode: -99.983 avegare return across last 100 episodes: -99.983 state values: tensor(0.6058) 1000
76 1000 -1000.0 -99.99568287525881 number episode from 10: 76 avegar over 10 episode: -99.983 avegare return across last 100 episodes: -99.983 state values: tensor(0.6056) 1000
77 1000 -1000.0 -99.99568287525881 number episode from 10: 77 avegar over 10 episode: -99.983 avegare return across last 100 episodes: -99.983 state values: tensor(0.6043) 1000
78 1000 -1000.0 -99.99568287525881 number episode from 10: 78 avegar over 10 episode: -99.983 avegare return across last 100 episodes: -99.983 state values: tensor(0.6045) 1000
79 1000 -1000.0 -99.99568287525881 number episode from 10: 79 avegar over 10 episode: -99.983 avegare return across last 100 episodes: -99.983 state values: tensor(0.6045) 1000
80 1000 -1000.0 -99.99568287525881 number episode from 10: 80 avegar over 10 episode: -99.983 avegare return across last 100 episodes: -99.983 state values: tensor(0.6057) 1000
81 1000 -1000.0 -99.99568287525881 number episode from 10: 81 avegar over 10 episode: -99.983 avegare return across last 100 episodes: -99.983 state values: tensor(0.6046) 1000
82 1000 -1000.0 -99.99568287525881 number episode from 10: 82 avegar over 10 episode: -99.984 avegare return across last 100 episodes: -99.984 state values: tensor(0.6047) 1000
83 1000 -1000.0 -99.99568287525881 number episode from 10: 83 avegar over 10 episode: -99.984 avegare return across last 100 episodes: -99.984 state values: tensor(0.6048) 1000
84 1000 -1000.0 -99.99568287525881 number episode from 10: 84 avegar over 10 episode: -99.984 avegare return across last 100 episodes: -99.984 state values: tensor(0.6058) 1000
85 1000 -1000.0 -99.99568287525881 number episode from 10: 85 avegar over 10 episode: -99.984 avegare return across last 100 episodes: -99.984 state values: tensor(0.6052) 1000
86 1000 -1000.0 -99.99568287525881 number episode from 10: 86 avegar over 10 episode: -99.984 avegare return across last 100 episodes: -99.984 state values: tensor(0.6043) 1000
87 1000 -1000.0 -99.99568287525881 number episode from 10: 87 avegar over 10 episode: -99.984 avegare return across last 100 episodes: -99.984 state values: tensor(0.6058) 1000
88 1000 -1000.0 -99.99568287525881 number episode from 10: 88 avegar over 10 episode: -99.984 avegare return across last 100 episodes: -99.984 state values: tensor(0.6050) 1000
89 1000 -1000.0 -99.99568287525881 number episode from 10: 89 avegar over 10 episode: -99.985 avegare return across last 100 episodes: -99.985 state values: tensor(0.6049) 1000
90 1000 -1000.0 -99.99568287525881 number episode from 10: 90 avegar over 10 episode: -99.985 avegare return across last 100 episodes: -99.985 state values: tensor(0.6062) 1000
91 1000 -1000.0 -99.99568287525881 number episode from 10: 91 avegar over 10 episode: -99.985 avegare return across last 100 episodes: -99.985 state values: tensor(0.6058) 1000
92 1000 -1000.0 -99.99568287525881 number episode from 10: 92 avegar over 10 episode: -99.985 avegare return across last 100 episodes: -99.985 state values: tensor(0.6054) 1000
93 1000 -1000.0 -99.99568287525881 number episode from 10: 93 avegar over 10 episode: -99.985 avegare return across last 100 episodes: -99.985 state values: tensor(0.6063) 1000
94 1000 -1000.0 -99.99568287525881 number episode from 10: 94 avegar over 10 episode: -99.985 avegare return across last 100 episodes: -99.985 state values: tensor(0.6059) 1000
95 1000 -1000.0 -99.99568287525881 number episode from 10: 95 avegar over 10 episode: -99.985 avegare return across last 100 episodes: -99.985 state values: tensor(0.6058) 1000
96 1000 -1000.0 -99.99568287525881 number episode from 10: 96 avegar over 10 episode: -99.985 avegare return across last 100 episodes: -99.985 state values: tensor(0.6045) 1000
97 1000 -1000.0 -99.99568287525881 number episode from 10: 97 avegar over 10 episode: -99.985 avegare return across last 100 episodes: -99.985 state values: tensor(0.6050) 1000
98 1000 -1000.0 -99.99568287525881 number episode from 10: 98 avegar over 10 episode: -99.986 avegare return across last 100 episodes: -99.986 state values: tensor(0.6058) 1000
99 1000 -1000.0 -99.99568287525881 number episode from 10: 99 avegar over 10 episode: -99.986 avegare return across last 100 episodes: -99.986 state values: tensor(0.6048) 1000
100 1000 -1000.0 -99.99568287525881 number episode from 10: 100 avegar over 10 episode: -99.986 avegare return across last 100 episodes: -99.996 state values: tensor(0.6045) 1000
101 1000 -1000.0 -99.99568287525881 number episode from 10: 101 avegar over 10 episode: -99.986 avegare return across last 100 episodes: -99.996 state values: tensor(0.6057) 1000
102 1000 -1000.0 -99.99568287525881 number episode from 10: 102 avegar over 10 episode: -99.986 avegare return across last 100 episodes: -99.996 state values: tensor(0.6055) 1000
103 1000 -1000.0 -99.99568287525881 number episode from 10: 103 avegar over 10 episode: -99.986 avegare return across last 100 episodes: -99.996 state values: tensor(0.6058) 1000
104 1000 -1000.0 -99.99568287525881 number episode from 10: 104 avegar over 10 episode: -99.986 avegare return across last 100 episodes: -99.996 state values: tensor(0.6053) 1000
105 1000 -1000.0 -99.99568287525881 number episode from 10: 105 avegar over 10 episode: -99.986 avegare return across last 100 episodes: -99.996 state values: tensor(0.6047) 1000
106 1000 -1000.0 -99.99568287525881 number episode from 10: 106 avegar over 10 episode: -99.986 avegare return across last 100 episodes: -99.996 state values: tensor(0.6045) 1000
107 1000 -1000.0 -99.99568287525881 number episode from 10: 107 avegar over 10 episode: -99.986 avegare return across last 100 episodes: -99.996 state values: tensor(0.6047) 1000
108 1000 -1000.0 -99.99568287525881 number episode from 10: 108 avegar over 10 episode: -99.987 avegare return across last 100 episodes: -99.996 state values: tensor(0.6057) 1000
109 1000 -1000.0 -99.99568287525881 number episode from 10: 109 avegar over 10 episode: -99.987 avegare return across last 100 episodes: -99.996 state values: tensor(0.6044) 1000
110 1000 -1000.0 -99.99568287525881 number episode from 10: 110 avegar over 10 episode: -99.987 avegare return across last 100 episodes: -99.996 state values: tensor(0.6043) 1000
111 1000 -1000.0 -99.99568287525881 number episode from 10: 111 avegar over 10 episode: -99.987 avegare return across last 100 episodes: -99.996 state values: tensor(0.6059) 1000
112 1000 -1000.0 -99.99568287525881 number episode from 10: 112 avegar over 10 episode: -99.987 avegare return across last 100 episodes: -99.996 state values: tensor(0.6053) 1000
113 1000 -1000.0 -99.99568287525881 number episode from 10: 113 avegar over 10 episode: -99.987 avegare return across last 100 episodes: -99.996 state values: tensor(0.6047) 1000
114 1000 -1000.0 -99.99568287525881 number episode from 10: 114 avegar over 10 episode: -99.987 avegare return across last 100 episodes: -99.996 state values: tensor(0.6053) 1000
115 1000 -1000.0 -99.99568287525881 number episode from 10: 115 avegar over 10 episode: -99.987 avegare return across last 100 episodes: -99.996 state values: tensor(0.6060) 1000
116 1000 -1000.0 -99.99568287525881 number episode from 10: 116 avegar over 10 episode: -99.987 avegare return across last 100 episodes: -99.996 state values: tensor(0.6058) 1000
117 1000 -1000.0 -99.99568287525881 number episode from 10: 117 avegar over 10 episode: -99.987 avegare return across last 100 episodes: -99.996 state values: tensor(0.6060) 1000
118 1000 -1000.0 -99.99568287525881 number episode from 10: 118 avegar over 10 episode: -99.987 avegare return across last 100 episodes: -99.996 state values: tensor(0.6059) 1000
119 1000 -1000.0 -99.99568287525881 number episode from 10: 119 avegar over 10 episode: -99.987 avegare return across last 100 episodes: -99.996 state values: tensor(0.6059) 1000
120 1000 -1000.0 -99.99568287525881 number episode from 10: 120 avegar over 10 episode: -99.987 avegare return across last 100 episodes: -99.996 state values: tensor(0.6044) 1000
121 1000 -1000.0 -99.99568287525881 number episode from 10: 121 avegar over 10 episode: -99.987 avegare return across last 100 episodes: -99.996 state values: tensor(0.6045) 1000
122 1000 -1000.0 -99.99568287525881 number episode from 10: 122 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.6045) 1000
123 1000 -1000.0 -99.99568287525881 number episode from 10: 123 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.6054) 1000
124 1000 -1000.0 -99.99568287525881 number episode from 10: 124 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.6043) 1000
125 1000 -1000.0 -99.99568287525881 number episode from 10: 125 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.6060) 1000
126 1000 -1000.0 -99.99568287525881 number episode from 10: 126 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.6044) 1000
127 1000 -1000.0 -99.99568287525881 number episode from 10: 127 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.6051) 1000
128 1000 -1000.0 -99.99568287525881 number episode from 10: 128 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.6057) 1000
129 1000 -1000.0 -99.99568287525881 number episode from 10: 129 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.6058) 1000
130 1000 -1000.0 -99.99568287525881 number episode from 10: 130 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.6050) 1000
131 1000 -1000.0 -99.99568287525881 number episode from 10: 131 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.6056) 1000
132 1000 -1000.0 -99.99568287525881 number episode from 10: 132 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.6063) 1000
133 1000 -1000.0 -99.99568287525881 number episode from 10: 133 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.6060) 1000
134 1000 -1000.0 -99.99568287525881 number episode from 10: 134 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.6051) 1000
135 1000 -1000.0 -99.99568287525881 number episode from 10: 135 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.6060) 1000
136 1000 -1000.0 -99.99568287525881 number episode from 10: 136 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.6052) 1000
137 1000 -1000.0 -99.99568287525881 number episode from 10: 137 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.6058) 1000
138 1000 -1000.0 -99.99568287525881 number episode from 10: 138 avegar over 10 episode: -99.988 avegare return across last 100 episodes: -99.996 state values: tensor(0.6058) 1000
139 1000 -1000.0 -99.99568287525881 number episode from 10: 139 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.6045) 1000
140 1000 -1000.0 -99.99568287525881 number episode from 10: 140 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.6044) 1000
141 1000 -1000.0 -99.99568287525881 number episode from 10: 141 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.6057) 1000
142 1000 -1000.0 -99.99568287525881 number episode from 10: 142 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.6051) 1000
143 1000 -1000.0 -99.99568287525881 number episode from 10: 143 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.6050) 1000
144 1000 -1000.0 -99.99568287525881 number episode from 10: 144 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.6046) 1000
145 1000 -1000.0 -99.99568287525881 number episode from 10: 145 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.6058) 1000
146 1000 -1000.0 -99.99568287525881 number episode from 10: 146 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.6044) 1000
147 1000 -1000.0 -99.99568287525881 number episode from 10: 147 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.6046) 1000
148 1000 -1000.0 -99.99568287525881 number episode from 10: 148 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.6058) 1000
149 1000 -1000.0 -99.99568287525881 number episode from 10: 149 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.6045) 1000
150 1000 -1000.0 -99.99568287525881 number episode from 10: 150 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.6043) 1000
151 1000 -1000.0 -99.99568287525881 number episode from 10: 151 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.6044) 1000
152 1000 -1000.0 -99.99568287525881 number episode from 10: 152 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.6046) 1000
153 1000 -1000.0 -99.99568287525881 number episode from 10: 153 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.6057) 1000
154 1000 -1000.0 -99.99568287525881 number episode from 10: 154 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.6045) 1000
155 1000 -1000.0 -99.99568287525881 number episode from 10: 155 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.6059) 1000
156 1000 -1000.0 -99.99568287525881 number episode from 10: 156 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.6062) 1000
157 1000 -1000.0 -99.99568287525881 number episode from 10: 157 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.6044) 1000
158 1000 -1000.0 -99.99568287525881 number episode from 10: 158 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.6057) 1000
159 1000 -1000.0 -99.99568287525881 number episode from 10: 159 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.6058) 1000
160 1000 -1000.0 -99.99568287525881 number episode from 10: 160 avegar over 10 episode: -99.989 avegare return across last 100 episodes: -99.996 state values: tensor(0.6045) 1000
161 1000 -1000.0 -99.99568287525881 number episode from 10: 161 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.6049) 1000
162 1000 -1000.0 -99.99568287525881 number episode from 10: 162 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.6056) 1000
163 1000 -1000.0 -99.99568287525881 number episode from 10: 163 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.6046) 1000
164 1000 -1000.0 -99.99568287525881 number episode from 10: 164 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.6052) 1000
165 1000 -1000.0 -99.99568287525881 number episode from 10: 165 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.6046) 1000
166 1000 -1000.0 -99.99568287525881 number episode from 10: 166 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.6048) 1000
167 1000 -1000.0 -99.99568287525881 number episode from 10: 167 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.6057) 1000
168 1000 -1000.0 -99.99568287525881 number episode from 10: 168 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.6058) 1000
169 1000 -1000.0 -99.99568287525881 number episode from 10: 169 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.6046) 1000
170 1000 -1000.0 -99.99568287525881 number episode from 10: 170 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.6050) 1000
171 1000 -1000.0 -99.99568287525881 number episode from 10: 171 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.6058) 1000
172 1000 -1000.0 -99.99568287525881 number episode from 10: 172 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.6045) 1000
173 1000 -1000.0 -99.99568287525881 number episode from 10: 173 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.6058) 1000
174 1000 -1000.0 -99.99568287525881 number episode from 10: 174 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.6059) 1000
175 1000 -1000.0 -99.99568287525881 number episode from 10: 175 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.6048) 1000
176 1000 -1000.0 -99.99568287525881 number episode from 10: 176 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.6046) 1000
177 1000 -1000.0 -99.99568287525881 number episode from 10: 177 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.6063) 1000
178 1000 -1000.0 -99.99568287525881 number episode from 10: 178 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.6044) 1000
179 1000 -1000.0 -99.99568287525881 number episode from 10: 179 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.6064) 1000
180 1000 -1000.0 -99.99568287525881 number episode from 10: 180 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.6044) 1000
181 1000 -1000.0 -99.99568287525881 number episode from 10: 181 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.6044) 1000
182 1000 -1000.0 -99.99568287525881 number episode from 10: 182 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.6045) 1000
183 1000 -1000.0 -99.99568287525881 number episode from 10: 183 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.6057) 1000
184 1000 -1000.0 -99.99568287525881 number episode from 10: 184 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.6053) 1000
185 1000 -1000.0 -99.99568287525881 number episode from 10: 185 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.6051) 1000
186 1000 -1000.0 -99.99568287525881 number episode from 10: 186 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.6043) 1000
187 1000 -1000.0 -99.99568287525881 number episode from 10: 187 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.6044) 1000
188 1000 -1000.0 -99.99568287525881 number episode from 10: 188 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.6050) 1000
189 1000 -1000.0 -99.99568287525881 number episode from 10: 189 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.6058) 1000
190 1000 -1000.0 -99.99568287525881 number episode from 10: 190 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.6047) 1000
191 1000 -1000.0 -99.99568287525881 number episode from 10: 191 avegar over 10 episode: -99.99 avegare return across last 100 episodes: -99.996 state values: tensor(0.6057) 1000
192 1000 -1000.0 -99.99568287525881 number episode from 10: 192 avegar over 10 episode: -99.991 avegare return across last 100 episodes: -99.996 state values: tensor(0.6048) 1000
193 1000 -1000.0 -99.99568287525881 number episode from 10: 193 avegar over 10 episode: -99.991 avegare return across last 100 episodes: -99.996 state values: tensor(0.6057) 1000
194 1000 -1000.0 -99.99568287525881 number episode from 10: 194 avegar over 10 episode: -99.991 avegare return across last 100 episodes: -99.996 state values: tensor(0.6058) 1000
195 1000 -1000.0 -99.99568287525881 number episode from 10: 195 avegar over 10 episode: -99.991 avegare return across last 100 episodes: -99.996 state values: tensor(0.6044) 1000
196 1000 -1000.0 -99.99568287525881 number episode from 10: 196 avegar over 10 episode: -99.991 avegare return across last 100 episodes: -99.996 state values: tensor(0.6062) 1000
197 1000 -1000.0 -99.99568287525881 number episode from 10: 197 avegar over 10 episode: -99.991 avegare return across last 100 episodes: -99.996 state values: tensor(0.6046) 1000
198 1000 -1000.0 -99.99568287525881 number episode from 10: 198 avegar over 10 episode: -99.991 avegare return across last 100 episodes: -99.996 state values: tensor(0.6043) 1000
199 1000 -1000.0 -99.99568287525881 number episode from 10: 199 avegar over 10 episode: -99.991 avegare return across last 100 episodes: -99.996 state values: tensor(0.6046) 1000
200 1000 -1000.0 -99.99568287525881 number episode from 10: 200 avegar over 10 episode: -99.991 avegare return across last 100 episodes: -99.996 state values: tensor(0.6044) 1000
load offline data!!!!!
mem_cntr: 50000 ; mem_size: 50000
nn.learn_nn_feature_fqi FQI:  998
nn.learn_nn_feature_fqi FQI:  1998
nn.learn_nn_feature_fqi FQI:  2998
nn.learn_nn_feature_fqi FQI:  3998
nn.learn_nn_feature_fqi FQI:  4998
nn.learn_nn_feature_fqi FQI:  5998
nn.learn_nn_feature_fqi FQI:  6998
nn.learn_nn_feature_fqi FQI:  7998
nn.learn_nn_feature_fqi FQI:  8998
nn.learn_nn_feature_fqi FQI:  9998
nn.learn_nn_feature_fqi FQI:  10998
nn.learn_nn_feature_fqi FQI:  11998
nn.learn_nn_feature_fqi FQI:  12998
nn.learn_nn_feature_fqi FQI:  13998
nn.learn_nn_feature_fqi FQI:  14998
nn.learn_nn_feature_fqi FQI:  15998
nn.learn_nn_feature_fqi FQI:  16998
nn.learn_nn_feature_fqi FQI:  17998
nn.learn_nn_feature_fqi FQI:  18998
nn.learn_nn_feature_fqi FQI:  19998
nn.learn_nn_feature_fqi FQI:  20998
nn.learn_nn_feature_fqi FQI:  21998
nn.learn_nn_feature_fqi FQI:  22998
nn.learn_nn_feature_fqi FQI:  23998
nn.learn_nn_feature_fqi FQI:  24998
nn.learn_nn_feature_fqi FQI:  25998
nn.learn_nn_feature_fqi FQI:  26998
nn.learn_nn_feature_fqi FQI:  27998
nn.learn_nn_feature_fqi FQI:  28998
nn.learn_nn_feature_fqi FQI:  29998
nn.learn_nn_feature_fqi FQI:  30998
nn.learn_nn_feature_fqi FQI:  31998
nn.learn_nn_feature_fqi FQI:  32998
nn.learn_nn_feature_fqi FQI:  33998
nn.learn_nn_feature_fqi FQI:  34998
nn.learn_nn_feature_fqi FQI:  35998
nn.learn_nn_feature_fqi FQI:  36998
nn.learn_nn_feature_fqi FQI:  37998
nn.learn_nn_feature_fqi FQI:  38998
nn.learn_nn_feature_fqi FQI:  39998
nn.learn_nn_feature_fqi FQI:  40998
nn.learn_nn_feature_fqi FQI:  41998
nn.learn_nn_feature_fqi FQI:  42998
nn.learn_nn_feature_fqi FQI:  43998
nn.learn_nn_feature_fqi FQI:  44998
nn.learn_nn_feature_fqi FQI:  45998
nn.learn_nn_feature_fqi FQI:  46998
nn.learn_nn_feature_fqi FQI:  47998
nn.learn_nn_feature_fqi FQI:  48998
nn.learn_nn_feature_fqi FQI:  49998
nn.learn_nn_feature_fqi FQI:  50998
nn.learn_nn_feature_fqi FQI:  51998
nn.learn_nn_feature_fqi FQI:  52998
nn.learn_nn_feature_fqi FQI:  53998
nn.learn_nn_feature_fqi FQI:  54998
nn.learn_nn_feature_fqi FQI:  55998
nn.learn_nn_feature_fqi FQI:  56998
nn.learn_nn_feature_fqi FQI:  57998
nn.learn_nn_feature_fqi FQI:  58998
nn.learn_nn_feature_fqi FQI:  59998
nn.learn_nn_feature_fqi FQI:  60998
nn.learn_nn_feature_fqi FQI:  61998
nn.learn_nn_feature_fqi FQI:  62998
nn.learn_nn_feature_fqi FQI:  63998
nn.learn_nn_feature_fqi FQI:  64998
nn.learn_nn_feature_fqi FQI:  65998
nn.learn_nn_feature_fqi FQI:  66998
nn.learn_nn_feature_fqi FQI:  67998
nn.learn_nn_feature_fqi FQI:  68998
nn.learn_nn_feature_fqi FQI:  69998
nn.learn_nn_feature_fqi FQI:  70998
nn.learn_nn_feature_fqi FQI:  71998
nn.learn_nn_feature_fqi FQI:  72998
nn.learn_nn_feature_fqi FQI:  73998
nn.learn_nn_feature_fqi FQI:  74998
nn.learn_nn_feature_fqi FQI:  75998
nn.learn_nn_feature_fqi FQI:  76998
nn.learn_nn_feature_fqi FQI:  77998
nn.learn_nn_feature_fqi FQI:  78998
nn.learn_nn_feature_fqi FQI:  79998
nn.learn_nn_feature_fqi FQI:  80998
nn.learn_nn_feature_fqi FQI:  81998
nn.learn_nn_feature_fqi FQI:  82998
nn.learn_nn_feature_fqi FQI:  83998
nn.learn_nn_feature_fqi FQI:  84998
nn.learn_nn_feature_fqi FQI:  85998
nn.learn_nn_feature_fqi FQI:  86998
nn.learn_nn_feature_fqi FQI:  87998
nn.learn_nn_feature_fqi FQI:  88998
nn.learn_nn_feature_fqi FQI:  89998
nn.learn_nn_feature_fqi FQI:  90998
nn.learn_nn_feature_fqi FQI:  91998
nn.learn_nn_feature_fqi FQI:  92998
nn.learn_nn_feature_fqi FQI:  93998
nn.learn_nn_feature_fqi FQI:  94998
nn.learn_nn_feature_fqi FQI:  95998
nn.learn_nn_feature_fqi FQI:  96998
nn.learn_nn_feature_fqi FQI:  97998
nn.learn_nn_feature_fqi FQI:  98998
nn.learn_nn_feature_fqi FQI:  99998
nn.learn_nn_feature_fqi FQI:  100998
nn.learn_nn_feature_fqi FQI:  101998
nn.learn_nn_feature_fqi FQI:  102998
nn.learn_nn_feature_fqi FQI:  103998
nn.learn_nn_feature_fqi FQI:  104998
nn.learn_nn_feature_fqi FQI:  105998
nn.learn_nn_feature_fqi FQI:  106998
nn.learn_nn_feature_fqi FQI:  107998
nn.learn_nn_feature_fqi FQI:  108998
nn.learn_nn_feature_fqi FQI:  109998
nn.learn_nn_feature_fqi FQI:  110998
nn.learn_nn_feature_fqi FQI:  111998
nn.learn_nn_feature_fqi FQI:  112998
nn.learn_nn_feature_fqi FQI:  113998
nn.learn_nn_feature_fqi FQI:  114998
nn.learn_nn_feature_fqi FQI:  115998
nn.learn_nn_feature_fqi FQI:  116998
nn.learn_nn_feature_fqi FQI:  117998
nn.learn_nn_feature_fqi FQI:  118998
nn.learn_nn_feature_fqi FQI:  119998
nn.learn_nn_feature_fqi FQI:  120998
nn.learn_nn_feature_fqi FQI:  121998
nn.learn_nn_feature_fqi FQI:  122998
nn.learn_nn_feature_fqi FQI:  123998
nn.learn_nn_feature_fqi FQI:  124998
nn.learn_nn_feature_fqi FQI:  125998
nn.learn_nn_feature_fqi FQI:  126998
nn.learn_nn_feature_fqi FQI:  127998
nn.learn_nn_feature_fqi FQI:  128998
nn.learn_nn_feature_fqi FQI:  129998
nn.learn_nn_feature_fqi FQI:  130998
nn.learn_nn_feature_fqi FQI:  131998
nn.learn_nn_feature_fqi FQI:  132998
nn.learn_nn_feature_fqi FQI:  133998
nn.learn_nn_feature_fqi FQI:  134998
nn.learn_nn_feature_fqi FQI:  135998
nn.learn_nn_feature_fqi FQI:  136998
nn.learn_nn_feature_fqi FQI:  137998
nn.learn_nn_feature_fqi FQI:  138998
nn.learn_nn_feature_fqi FQI:  139998
nn.learn_nn_feature_fqi FQI:  140998
nn.learn_nn_feature_fqi FQI:  141998
nn.learn_nn_feature_fqi FQI:  142998
nn.learn_nn_feature_fqi FQI:  143998
nn.learn_nn_feature_fqi FQI:  144998
nn.learn_nn_feature_fqi FQI:  145998
nn.learn_nn_feature_fqi FQI:  146998
nn.learn_nn_feature_fqi FQI:  147998
nn.learn_nn_feature_fqi FQI:  148998
nn.learn_nn_feature_fqi FQI:  149998
nn.learn_nn_feature_fqi FQI:  150998
nn.learn_nn_feature_fqi FQI:  151998
nn.learn_nn_feature_fqi FQI:  152998
nn.learn_nn_feature_fqi FQI:  153998
nn.learn_nn_feature_fqi FQI:  154998
nn.learn_nn_feature_fqi FQI:  155998
0 1001 -1000.0 -98.99572604650622 number episode from 10: 0 avegar over 10 episode: -98.996 avegare return across last 100 episodes: -98.996 state values: tensor(0.6029) 1000
1 1000 -1000.0 -99.99568287525881 number episode from 10: 1 avegar over 10 episode: -99.496 avegare return across last 100 episodes: -99.496 state values: tensor(0.6025) 1000
2 1000 -1000.0 -99.99568287525881 number episode from 10: 2 avegar over 10 episode: -99.662 avegare return across last 100 episodes: -99.662 state values: tensor(0.6071) 1000
3 1000 -1000.0 -99.99568287525881 number episode from 10: 3 avegar over 10 episode: -99.746 avegare return across last 100 episodes: -99.746 state values: tensor(0.6063) 1000
4 1000 -1000.0 -99.99568287525881 number episode from 10: 4 avegar over 10 episode: -99.796 avegare return across last 100 episodes: -99.796 state values: tensor(0.6011) 1000
5 935 -935.0 -99.99170327016022 number episode from 10: 5 avegar over 10 episode: -99.828 avegare return across last 100 episodes: -99.828 state values: tensor(0.6537) 935
6 1000 -1000.0 -99.99568287525881 number episode from 10: 6 avegar over 10 episode: -99.852 avegare return across last 100 episodes: -99.852 state values: tensor(0.6008) 1000
7 1000 -1000.0 -99.99568287525881 number episode from 10: 7 avegar over 10 episode: -99.87 avegare return across last 100 episodes: -99.87 state values: tensor(0.6012) 1000
8 1000 -1000.0 -99.99568287525881 number episode from 10: 8 avegar over 10 episode: -99.884 avegare return across last 100 episodes: -99.884 state values: tensor(0.6031) 1000
9 1000 -1000.0 -99.99568287525881 number episode from 10: 9 avegar over 10 episode: -99.895 avegare return across last 100 episodes: -99.895 state values: tensor(0.6080) 1000
10 1000 -1000.0 -99.99568287525881 number episode from 10: 10 avegar over 10 episode: -99.904 avegare return across last 100 episodes: -99.904 state values: tensor(0.6015) 1000
11 1000 -1000.0 -99.99568287525881 number episode from 10: 11 avegar over 10 episode: -99.912 avegare return across last 100 episodes: -99.912 state values: tensor(0.7760) 1000
12 1000 -1000.0 -99.99568287525881 number episode from 10: 12 avegar over 10 episode: -99.918 avegare return across last 100 episodes: -99.918 state values: tensor(0.6361) 1000
13 1000 -1000.0 -99.99568287525881 number episode from 10: 13 avegar over 10 episode: -99.924 avegare return across last 100 episodes: -99.924 state values: tensor(0.6068) 1000
14 688 -688.0 -99.90068522040785 number episode from 10: 14 avegar over 10 episode: -99.922 avegare return across last 100 episodes: -99.922 state values: tensor(0.7671) 688
15 1000 -1000.0 -99.99568287525881 number episode from 10: 15 avegar over 10 episode: -99.927 avegare return across last 100 episodes: -99.927 state values: tensor(0.6028) 1000
16 1000 -1000.0 -99.99568287525881 number episode from 10: 16 avegar over 10 episode: -99.931 avegare return across last 100 episodes: -99.931 state values: tensor(0.6451) 1000
17 1000 -1000.0 -99.99568287525881 number episode from 10: 17 avegar over 10 episode: -99.935 avegare return across last 100 episodes: -99.935 state values: tensor(0.6019) 1000
18 1000 -1000.0 -99.99568287525881 number episode from 10: 18 avegar over 10 episode: -99.938 avegare return across last 100 episodes: -99.938 state values: tensor(0.6032) 1000
19 1000 -1000.0 -99.99568287525881 number episode from 10: 19 avegar over 10 episode: -99.941 avegare return across last 100 episodes: -99.941 state values: tensor(0.6072) 1000
20 1000 -1000.0 -99.99568287525881 number episode from 10: 20 avegar over 10 episode: -99.943 avegare return across last 100 episodes: -99.943 state values: tensor(0.7869) 1000
21 1000 -1000.0 -99.99568287525881 number episode from 10: 21 avegar over 10 episode: -99.946 avegare return across last 100 episodes: -99.946 state values: tensor(0.8315) 1000
22 1000 -1000.0 -99.99568287525881 number episode from 10: 22 avegar over 10 episode: -99.948 avegare return across last 100 episodes: -99.948 state values: tensor(0.6019) 1000
23 1000 -1000.0 -99.99568287525881 number episode from 10: 23 avegar over 10 episode: -99.95 avegare return across last 100 episodes: -99.95 state values: tensor(0.6251) 1000
24 1000 -1000.0 -99.99568287525881 number episode from 10: 24 avegar over 10 episode: -99.952 avegare return across last 100 episodes: -99.952 state values: tensor(0.6042) 1000
25 1000 -1000.0 -99.99568287525881 number episode from 10: 25 avegar over 10 episode: -99.953 avegare return across last 100 episodes: -99.953 state values: tensor(0.6057) 1000
26 1000 -1000.0 -99.99568287525881 number episode from 10: 26 avegar over 10 episode: -99.955 avegare return across last 100 episodes: -99.955 state values: tensor(0.6030) 1000
27 313 -313.0 -95.69655844657804 number episode from 10: 27 avegar over 10 episode: -99.803 avegare return across last 100 episodes: -99.803 state values: tensor(0.7911) 313
28 1000 -1000.0 -99.99568287525881 number episode from 10: 28 avegar over 10 episode: -99.81 avegare return across last 100 episodes: -99.81 state values: tensor(0.6050) 1000
29 622 -622.0 -99.80720709839589 number episode from 10: 29 avegar over 10 episode: -99.809 avegare return across last 100 episodes: -99.809 state values: tensor(0.6463) 622
30 1000 -1000.0 -99.99568287525881 number episode from 10: 30 avegar over 10 episode: -99.815 avegare return across last 100 episodes: -99.815 state values: tensor(0.6041) 1000
31 1000 -1000.0 -99.99568287525881 number episode from 10: 31 avegar over 10 episode: -99.821 avegare return across last 100 episodes: -99.821 state values: tensor(0.6077) 1000
32 1000 -1000.0 -99.99568287525881 number episode from 10: 32 avegar over 10 episode: -99.826 avegare return across last 100 episodes: -99.826 state values: tensor(0.7260) 1000
33 1000 -1000.0 -99.99568287525881 number episode from 10: 33 avegar over 10 episode: -99.831 avegare return across last 100 episodes: -99.831 state values: tensor(0.6046) 1000
34 1000 -1000.0 -99.99568287525881 number episode from 10: 34 avegar over 10 episode: -99.836 avegare return across last 100 episodes: -99.836 state values: tensor(0.6039) 1000
35 1000 -1000.0 -99.99568287525881 number episode from 10: 35 avegar over 10 episode: -99.841 avegare return across last 100 episodes: -99.841 state values: tensor(0.6024) 1000
36 1000 -1000.0 -99.99568287525881 number episode from 10: 36 avegar over 10 episode: -99.845 avegare return across last 100 episodes: -99.845 state values: tensor(0.6031) 1000
37 539 -539.0 -99.55601337418824 number episode from 10: 37 avegar over 10 episode: -99.837 avegare return across last 100 episodes: -99.837 state values: tensor(0.8101) 539
38 1000 -1000.0 -99.99568287525881 number episode from 10: 38 avegar over 10 episode: -99.841 avegare return across last 100 episodes: -99.841 state values: tensor(0.6028) 1000
39 1000 -1000.0 -99.99568287525881 number episode from 10: 39 avegar over 10 episode: -99.845 avegare return across last 100 episodes: -99.845 state values: tensor(0.6016) 1000
40 1000 -1000.0 -99.99568287525881 number episode from 10: 40 avegar over 10 episode: -99.849 avegare return across last 100 episodes: -99.849 state values: tensor(0.6020) 1000
41 1000 -1000.0 -99.99568287525881 number episode from 10: 41 avegar over 10 episode: -99.852 avegare return across last 100 episodes: -99.852 state values: tensor(0.6052) 1000
42 1000 -1000.0 -99.99568287525881 number episode from 10: 42 avegar over 10 episode: -99.856 avegare return across last 100 episodes: -99.856 state values: tensor(0.6036) 1000
43 1000 -1000.0 -99.99568287525881 number episode from 10: 43 avegar over 10 episode: -99.859 avegare return across last 100 episodes: -99.859 state values: tensor(0.6066) 1000
44 1000 -1000.0 -99.99568287525881 number episode from 10: 44 avegar over 10 episode: -99.862 avegare return across last 100 episodes: -99.862 state values: tensor(0.6040) 1000
45 553 -553.0 -99.61428847790062 number episode from 10: 45 avegar over 10 episode: -99.856 avegare return across last 100 episodes: -99.856 state values: tensor(0.8181) 553
46 1000 -1000.0 -99.99568287525881 number episode from 10: 46 avegar over 10 episode: -99.859 avegare return across last 100 episodes: -99.859 state values: tensor(0.8310) 1000
47 1000 -1000.0 -99.99568287525881 number episode from 10: 47 avegar over 10 episode: -99.862 avegare return across last 100 episodes: -99.862 state values: tensor(0.8258) 1000
48 1000 -1000.0 -99.99568287525881 number episode from 10: 48 avegar over 10 episode: -99.865 avegare return across last 100 episodes: -99.865 state values: tensor(0.6060) 1000
49 1000 -1000.0 -99.99568287525881 number episode from 10: 49 avegar over 10 episode: -99.868 avegare return across last 100 episodes: -99.868 state values: tensor(0.6062) 1000
50 1000 -1000.0 -99.99568287525881 number episode from 10: 50 avegar over 10 episode: -99.87 avegare return across last 100 episodes: -99.87 state values: tensor(0.6057) 1000
51 621 -621.0 -99.80525969534939 number episode from 10: 51 avegar over 10 episode: -99.869 avegare return across last 100 episodes: -99.869 state values: tensor(0.7880) 621
52 290 -290.0 -94.57741418959358 number episode from 10: 52 avegar over 10 episode: -99.769 avegare return across last 100 episodes: -99.769 state values: tensor(0.7646) 290
53 1000 -1000.0 -99.99568287525881 number episode from 10: 53 avegar over 10 episode: -99.773 avegare return across last 100 episodes: -99.773 state values: tensor(0.6079) 1000
54 1000 -1000.0 -99.99568287525881 number episode from 10: 54 avegar over 10 episode: -99.777 avegare return across last 100 episodes: -99.777 state values: tensor(0.6027) 1000
55 1000 -1000.0 -99.99568287525881 number episode from 10: 55 avegar over 10 episode: -99.781 avegare return across last 100 episodes: -99.781 state values: tensor(0.6055) 1000
56 1000 -1000.0 -99.99568287525881 number episode from 10: 56 avegar over 10 episode: -99.785 avegare return across last 100 episodes: -99.785 state values: tensor(0.8319) 1000
57 1000 -1000.0 -99.99568287525881 number episode from 10: 57 avegar over 10 episode: -99.789 avegare return across last 100 episodes: -99.789 state values: tensor(0.6065) 1000
58 1000 -1000.0 -99.99568287525881 number episode from 10: 58 avegar over 10 episode: -99.792 avegare return across last 100 episodes: -99.792 state values: tensor(0.6033) 1000
59 1000 -1000.0 -99.99568287525881 number episode from 10: 59 avegar over 10 episode: -99.795 avegare return across last 100 episodes: -99.795 state values: tensor(0.6077) 1000
60 1000 -1000.0 -99.99568287525881 number episode from 10: 60 avegar over 10 episode: -99.799 avegare return across last 100 episodes: -99.799 state values: tensor(0.6064) 1000
61 1000 -1000.0 -99.99568287525881 number episode from 10: 61 avegar over 10 episode: -99.802 avegare return across last 100 episodes: -99.802 state values: tensor(0.6077) 1000
62 1000 -1000.0 -99.99568287525881 number episode from 10: 62 avegar over 10 episode: -99.805 avegare return across last 100 episodes: -99.805 state values: tensor(0.6037) 1000
63 1000 -1000.0 -99.99568287525881 number episode from 10: 63 avegar over 10 episode: -99.808 avegare return across last 100 episodes: -99.808 state values: tensor(0.6019) 1000
64 425 -425.0 -98.60376762496365 number episode from 10: 64 avegar over 10 episode: -99.789 avegare return across last 100 episodes: -99.789 state values: tensor(0.7987) 425
65 1000 -1000.0 -99.99568287525881 number episode from 10: 65 avegar over 10 episode: -99.793 avegare return across last 100 episodes: -99.793 state values: tensor(0.6880) 1000
66 309 -309.0 -95.52002974338612 number episode from 10: 66 avegar over 10 episode: -99.729 avegare return across last 100 episodes: -99.729 state values: tensor(0.7846) 309
67 1000 -1000.0 -99.99568287525881 number episode from 10: 67 avegar over 10 episode: -99.733 avegare return across last 100 episodes: -99.733 state values: tensor(0.6014) 1000
68 192 -192.0 -85.48030937842161 number episode from 10: 68 avegar over 10 episode: -99.526 avegare return across last 100 episodes: -99.526 state values: tensor(0.7423) 192
69 188 -188.0 -84.88470650468516 number episode from 10: 69 avegar over 10 episode: -99.317 avegare return across last 100 episodes: -99.317 state values: tensor(0.7581) 188
70 1000 -1000.0 -99.99568287525881 number episode from 10: 70 avegar over 10 episode: -99.327 avegare return across last 100 episodes: -99.327 state values: tensor(0.6052) 1000
71 1000 -1000.0 -99.99568287525881 number episode from 10: 71 avegar over 10 episode: -99.336 avegare return across last 100 episodes: -99.336 state values: tensor(0.6068) 1000
72 974 -974.0 -99.994393658635 number episode from 10: 72 avegar over 10 episode: -99.345 avegare return across last 100 episodes: -99.345 state values: tensor(0.8094) 974
73 1000 -1000.0 -99.99568287525881 number episode from 10: 73 avegar over 10 episode: -99.354 avegare return across last 100 episodes: -99.354 state values: tensor(0.6072) 1000
74 1000 -1000.0 -99.99568287525881 number episode from 10: 74 avegar over 10 episode: -99.362 avegare return across last 100 episodes: -99.362 state values: tensor(0.6042) 1000
75 1000 -1000.0 -99.99568287525881 number episode from 10: 75 avegar over 10 episode: -99.371 avegare return across last 100 episodes: -99.371 state values: tensor(0.6054) 1000
76 1000 -1000.0 -99.99568287525881 number episode from 10: 76 avegar over 10 episode: -99.379 avegare return across last 100 episodes: -99.379 state values: tensor(0.6024) 1000
77 1000 -1000.0 -99.99568287525881 number episode from 10: 77 avegar over 10 episode: -99.387 avegare return across last 100 episodes: -99.387 state values: tensor(0.6087) 1000
78 1000 -1000.0 -99.99568287525881 number episode from 10: 78 avegar over 10 episode: -99.394 avegare return across last 100 episodes: -99.394 state values: tensor(0.6017) 1000
79 1000 -1000.0 -99.99568287525881 number episode from 10: 79 avegar over 10 episode: -99.402 avegare return across last 100 episodes: -99.402 state values: tensor(0.6091) 1000
80 1000 -1000.0 -99.99568287525881 number episode from 10: 80 avegar over 10 episode: -99.409 avegare return across last 100 episodes: -99.409 state values: tensor(0.6015) 1000
81 423 -423.0 -98.57541845216168 number episode from 10: 81 avegar over 10 episode: -99.399 avegare return across last 100 episodes: -99.399 state values: tensor(0.8045) 423
82 1000 -1000.0 -99.99568287525881 number episode from 10: 82 avegar over 10 episode: -99.406 avegare return across last 100 episodes: -99.406 state values: tensor(0.6014) 1000
83 1000 -1000.0 -99.99568287525881 number episode from 10: 83 avegar over 10 episode: -99.413 avegare return across last 100 episodes: -99.413 state values: tensor(0.6026) 1000
84 1000 -1000.0 -99.99568287525881 number episode from 10: 84 avegar over 10 episode: -99.42 avegare return across last 100 episodes: -99.42 state values: tensor(0.6036) 1000
85 450 -450.0 -98.91398063601214 number episode from 10: 85 avegar over 10 episode: -99.414 avegare return across last 100 episodes: -99.414 state values: tensor(0.6682) 450
86 1000 -1000.0 -99.99568287525881 number episode from 10: 86 avegar over 10 episode: -99.421 avegare return across last 100 episodes: -99.421 state values: tensor(0.6054) 1000
87 317 -317.0 -95.86613121451465 number episode from 10: 87 avegar over 10 episode: -99.38 avegare return across last 100 episodes: -99.38 state values: tensor(0.7908) 317
88 1000 -1000.0 -99.99568287525881 number episode from 10: 88 avegar over 10 episode: -99.387 avegare return across last 100 episodes: -99.387 state values: tensor(0.6042) 1000
89 1000 -1000.0 -99.99568287525881 number episode from 10: 89 avegar over 10 episode: -99.394 avegare return across last 100 episodes: -99.394 state values: tensor(0.6047) 1000
90 1000 -1000.0 -99.99568287525881 number episode from 10: 90 avegar over 10 episode: -99.401 avegare return across last 100 episodes: -99.401 state values: tensor(0.6081) 1000
91 1000 -1000.0 -99.99568287525881 number episode from 10: 91 avegar over 10 episode: -99.407 avegare return across last 100 episodes: -99.407 state values: tensor(0.6020) 1000
92 1000 -1000.0 -99.99568287525881 number episode from 10: 92 avegar over 10 episode: -99.413 avegare return across last 100 episodes: -99.413 state values: tensor(0.6045) 1000
93 1000 -1000.0 -99.99568287525881 number episode from 10: 93 avegar over 10 episode: -99.42 avegare return across last 100 episodes: -99.42 state values: tensor(0.8271) 1000
94 1000 -1000.0 -99.99568287525881 number episode from 10: 94 avegar over 10 episode: -99.426 avegare return across last 100 episodes: -99.426 state values: tensor(0.6011) 1000
95 1000 -1000.0 -99.99568287525881 number episode from 10: 95 avegar over 10 episode: -99.432 avegare return across last 100 episodes: -99.432 state values: tensor(0.6047) 1000
96 1000 -1000.0 -99.99568287525881 number episode from 10: 96 avegar over 10 episode: -99.438 avegare return across last 100 episodes: -99.438 state values: tensor(0.6058) 1000
97 1000 -1000.0 -99.99568287525881 number episode from 10: 97 avegar over 10 episode: -99.443 avegare return across last 100 episodes: -99.443 state values: tensor(0.6023) 1000
98 1000 -1000.0 -99.99568287525881 number episode from 10: 98 avegar over 10 episode: -99.449 avegare return across last 100 episodes: -99.449 state values: tensor(0.8246) 1000
99 1000 -1000.0 -99.99568287525881 number episode from 10: 99 avegar over 10 episode: -99.454 avegare return across last 100 episodes: -99.454 state values: tensor(0.6070) 1000
100 1000 -1000.0 -99.99568287525881 number episode from 10: 100 avegar over 10 episode: -99.46 avegare return across last 100 episodes: -99.464 state values: tensor(0.6160) 1000
101 1000 -1000.0 -99.99568287525881 number episode from 10: 101 avegar over 10 episode: -99.465 avegare return across last 100 episodes: -99.464 state values: tensor(0.6068) 1000
102 628 -628.0 -99.8184893101943 number episode from 10: 102 avegar over 10 episode: -99.468 avegare return across last 100 episodes: -99.462 state values: tensor(0.8028) 628
103 675 -675.0 -99.88682347546192 number episode from 10: 103 avegar over 10 episode: -99.472 avegare return across last 100 episodes: -99.461 state values: tensor(0.8212) 675
104 1000 -1000.0 -99.99568287525881 number episode from 10: 104 avegar over 10 episode: -99.477 avegare return across last 100 episodes: -99.461 state values: tensor(0.6021) 1000
105 1000 -1000.0 -99.99568287525881 number episode from 10: 105 avegar over 10 episode: -99.482 avegare return across last 100 episodes: -99.461 state values: tensor(0.6085) 1000
106 1000 -1000.0 -99.99568287525881 number episode from 10: 106 avegar over 10 episode: -99.487 avegare return across last 100 episodes: -99.461 state values: tensor(0.6037) 1000
107 1000 -1000.0 -99.99568287525881 number episode from 10: 107 avegar over 10 episode: -99.492 avegare return across last 100 episodes: -99.461 state values: tensor(0.6012) 1000
108 661 -661.0 -99.86972423593348 number episode from 10: 108 avegar over 10 episode: -99.495 avegare return across last 100 episodes: -99.46 state values: tensor(0.6835) 661
109 732 -732.0 -99.93617917037557 number episode from 10: 109 avegar over 10 episode: -99.499 avegare return across last 100 episodes: -99.46 state values: tensor(0.7648) 732
110 1000 -1000.0 -99.99568287525881 number episode from 10: 110 avegar over 10 episode: -99.504 avegare return across last 100 episodes: -99.46 state values: tensor(0.6064) 1000
111 1000 -1000.0 -99.99568287525881 number episode from 10: 111 avegar over 10 episode: -99.508 avegare return across last 100 episodes: -99.46 state values: tensor(0.6041) 1000
112 1000 -1000.0 -99.99568287525881 number episode from 10: 112 avegar over 10 episode: -99.512 avegare return across last 100 episodes: -99.46 state values: tensor(0.6010) 1000
113 1000 -1000.0 -99.99568287525881 number episode from 10: 113 avegar over 10 episode: -99.517 avegare return across last 100 episodes: -99.46 state values: tensor(0.6034) 1000
114 1000 -1000.0 -99.99568287525881 number episode from 10: 114 avegar over 10 episode: -99.521 avegare return across last 100 episodes: -99.461 state values: tensor(0.6030) 1000
115 310 -310.0 -95.56482944595226 number episode from 10: 115 avegar over 10 episode: -99.487 avegare return across last 100 episodes: -99.416 state values: tensor(0.7883) 310
116 1000 -1000.0 -99.99568287525881 number episode from 10: 116 avegar over 10 episode: -99.491 avegare return across last 100 episodes: -99.416 state values: tensor(0.6017) 1000
117 1000 -1000.0 -99.99568287525881 number episode from 10: 117 avegar over 10 episode: -99.495 avegare return across last 100 episodes: -99.416 state values: tensor(0.6062) 1000
118 1000 -1000.0 -99.99568287525881 number episode from 10: 118 avegar over 10 episode: -99.5 avegare return across last 100 episodes: -99.416 state values: tensor(0.8154) 1000
119 314 -314.0 -95.73959286211226 number episode from 10: 119 avegar over 10 episode: -99.468 avegare return across last 100 episodes: -99.374 state values: tensor(0.7849) 314
120 1000 -1000.0 -99.99568287525881 number episode from 10: 120 avegar over 10 episode: -99.473 avegare return across last 100 episodes: -99.374 state values: tensor(0.8236) 1000
121 1000 -1000.0 -99.99568287525881 number episode from 10: 121 avegar over 10 episode: -99.477 avegare return across last 100 episodes: -99.374 state values: tensor(0.6056) 1000
122 1000 -1000.0 -99.99568287525881 number episode from 10: 122 avegar over 10 episode: -99.481 avegare return across last 100 episodes: -99.374 state values: tensor(0.6031) 1000
123 1000 -1000.0 -99.99568287525881 number episode from 10: 123 avegar over 10 episode: -99.485 avegare return across last 100 episodes: -99.374 state values: tensor(0.6056) 1000
124 1000 -1000.0 -99.99568287525881 number episode from 10: 124 avegar over 10 episode: -99.489 avegare return across last 100 episodes: -99.374 state values: tensor(0.6048) 1000
125 781 -781.0 -99.96099799077511 number episode from 10: 125 avegar over 10 episode: -99.493 avegare return across last 100 episodes: -99.373 state values: tensor(0.8230) 781
126 1000 -1000.0 -99.99568287525881 number episode from 10: 126 avegar over 10 episode: -99.497 avegare return across last 100 episodes: -99.373 state values: tensor(0.6023) 1000
127 1000 -1000.0 -99.99568287525881 number episode from 10: 127 avegar over 10 episode: -99.501 avegare return across last 100 episodes: -99.416 state values: tensor(0.6082) 1000
128 1000 -1000.0 -99.99568287525881 number episode from 10: 128 avegar over 10 episode: -99.505 avegare return across last 100 episodes: -99.416 state values: tensor(0.6019) 1000
129 1000 -1000.0 -99.99568287525881 number episode from 10: 129 avegar over 10 episode: -99.508 avegare return across last 100 episodes: -99.418 state values: tensor(0.6028) 1000
130 1000 -1000.0 -99.99568287525881 number episode from 10: 130 avegar over 10 episode: -99.512 avegare return across last 100 episodes: -99.418 state values: tensor(0.6021) 1000
131 1000 -1000.0 -99.99568287525881 number episode from 10: 131 avegar over 10 episode: -99.516 avegare return across last 100 episodes: -99.418 state values: tensor(0.6046) 1000
132 1000 -1000.0 -99.99568287525881 number episode from 10: 132 avegar over 10 episode: -99.519 avegare return across last 100 episodes: -99.418 state values: tensor(0.6047) 1000
133 1000 -1000.0 -99.99568287525881 number episode from 10: 133 avegar over 10 episode: -99.523 avegare return across last 100 episodes: -99.418 state values: tensor(0.6048) 1000
134 1000 -1000.0 -99.99568287525881 number episode from 10: 134 avegar over 10 episode: -99.527 avegare return across last 100 episodes: -99.418 state values: tensor(0.6024) 1000
135 1000 -1000.0 -99.99568287525881 number episode from 10: 135 avegar over 10 episode: -99.53 avegare return across last 100 episodes: -99.418 state values: tensor(0.6041) 1000
136 1000 -1000.0 -99.99568287525881 number episode from 10: 136 avegar over 10 episode: -99.533 avegare return across last 100 episodes: -99.418 state values: tensor(0.6072) 1000
137 1000 -1000.0 -99.99568287525881 number episode from 10: 137 avegar over 10 episode: -99.537 avegare return across last 100 episodes: -99.423 state values: tensor(0.6024) 1000
138 1000 -1000.0 -99.99568287525881 number episode from 10: 138 avegar over 10 episode: -99.54 avegare return across last 100 episodes: -99.423 state values: tensor(0.6012) 1000
139 1000 -1000.0 -99.99568287525881 number episode from 10: 139 avegar over 10 episode: -99.543 avegare return across last 100 episodes: -99.423 state values: tensor(0.6023) 1000
140 1000 -1000.0 -99.99568287525881 number episode from 10: 140 avegar over 10 episode: -99.546 avegare return across last 100 episodes: -99.423 state values: tensor(0.6047) 1000
141 1000 -1000.0 -99.99568287525881 number episode from 10: 141 avegar over 10 episode: -99.55 avegare return across last 100 episodes: -99.423 state values: tensor(0.6074) 1000
142 1000 -1000.0 -99.99568287525881 number episode from 10: 142 avegar over 10 episode: -99.553 avegare return across last 100 episodes: -99.423 state values: tensor(0.6025) 1000
143 1000 -1000.0 -99.99568287525881 number episode from 10: 143 avegar over 10 episode: -99.556 avegare return across last 100 episodes: -99.423 state values: tensor(0.6019) 1000
144 1000 -1000.0 -99.99568287525881 number episode from 10: 144 avegar over 10 episode: -99.559 avegare return across last 100 episodes: -99.423 state values: tensor(0.6022) 1000
145 1000 -1000.0 -99.99568287525881 number episode from 10: 145 avegar over 10 episode: -99.562 avegare return across last 100 episodes: -99.426 state values: tensor(0.6035) 1000
146 1000 -1000.0 -99.99568287525881 number episode from 10: 146 avegar over 10 episode: -99.565 avegare return across last 100 episodes: -99.426 state values: tensor(0.8257) 1000
147 1000 -1000.0 -99.99568287525881 number episode from 10: 147 avegar over 10 episode: -99.568 avegare return across last 100 episodes: -99.426 state values: tensor(0.6051) 1000
148 432 -432.0 -98.69862018560275 number episode from 10: 148 avegar over 10 episode: -99.562 avegare return across last 100 episodes: -99.413 state values: tensor(0.8050) 432
149 1000 -1000.0 -99.99568287525881 number episode from 10: 149 avegar over 10 episode: -99.565 avegare return across last 100 episodes: -99.413 state values: tensor(0.6040) 1000
150 1000 -1000.0 -99.99568287525881 number episode from 10: 150 avegar over 10 episode: -99.568 avegare return across last 100 episodes: -99.413 state values: tensor(0.6046) 1000
151 1000 -1000.0 -99.99568287525881 number episode from 10: 151 avegar over 10 episode: -99.57 avegare return across last 100 episodes: -99.415 state values: tensor(0.6082) 1000
152 1000 -1000.0 -99.99568287525881 number episode from 10: 152 avegar over 10 episode: -99.573 avegare return across last 100 episodes: -99.47 state values: tensor(0.6029) 1000
153 1000 -1000.0 -99.99568287525881 number episode from 10: 153 avegar over 10 episode: -99.576 avegare return across last 100 episodes: -99.47 state values: tensor(0.6055) 1000
154 1000 -1000.0 -99.99568287525881 number episode from 10: 154 avegar over 10 episode: -99.579 avegare return across last 100 episodes: -99.47 state values: tensor(0.6016) 1000
155 1000 -1000.0 -99.99568287525881 number episode from 10: 155 avegar over 10 episode: -99.581 avegare return across last 100 episodes: -99.47 state values: tensor(0.7527) 1000
156 1000 -1000.0 -99.99568287525881 number episode from 10: 156 avegar over 10 episode: -99.584 avegare return across last 100 episodes: -99.47 state values: tensor(0.6031) 1000
157 1000 -1000.0 -99.99568287525881 number episode from 10: 157 avegar over 10 episode: -99.587 avegare return across last 100 episodes: -99.47 state values: tensor(0.6062) 1000
158 1000 -1000.0 -99.99568287525881 number episode from 10: 158 avegar over 10 episode: -99.589 avegare return across last 100 episodes: -99.47 state values: tensor(0.6021) 1000
159 1000 -1000.0 -99.99568287525881 number episode from 10: 159 avegar over 10 episode: -99.592 avegare return across last 100 episodes: -99.47 state values: tensor(0.6035) 1000
160 1000 -1000.0 -99.99568287525881 number episode from 10: 160 avegar over 10 episode: -99.594 avegare return across last 100 episodes: -99.47 state values: tensor(0.6683) 1000
161 1000 -1000.0 -99.99568287525881 number episode from 10: 161 avegar over 10 episode: -99.597 avegare return across last 100 episodes: -99.47 state values: tensor(0.6166) 1000
162 1000 -1000.0 -99.99568287525881 number episode from 10: 162 avegar over 10 episode: -99.599 avegare return across last 100 episodes: -99.47 state values: tensor(0.6051) 1000
163 1000 -1000.0 -99.99568287525881 number episode from 10: 163 avegar over 10 episode: -99.602 avegare return across last 100 episodes: -99.47 state values: tensor(0.6050) 1000
164 1000 -1000.0 -99.99568287525881 number episode from 10: 164 avegar over 10 episode: -99.604 avegare return across last 100 episodes: -99.483 state values: tensor(0.6016) 1000
165 634 -634.0 -99.82911128864384 number episode from 10: 165 avegar over 10 episode: -99.605 avegare return across last 100 episodes: -99.482 state values: tensor(0.7316) 634
166 1000 -1000.0 -99.99568287525881 number episode from 10: 166 avegar over 10 episode: -99.608 avegare return across last 100 episodes: -99.527 state values: tensor(0.8143) 1000
167 1000 -1000.0 -99.99568287525881 number episode from 10: 167 avegar over 10 episode: -99.61 avegare return across last 100 episodes: -99.527 state values: tensor(0.6999) 1000
168 1000 -1000.0 -99.99568287525881 number episode from 10: 168 avegar over 10 episode: -99.612 avegare return across last 100 episodes: -99.672 state values: tensor(0.6052) 1000
169 554 -554.0 -99.61814559312161 number episode from 10: 169 avegar over 10 episode: -99.612 avegare return across last 100 episodes: -99.819 state values: tensor(0.8207) 554
170 1000 -1000.0 -99.99568287525881 number episode from 10: 170 avegar over 10 episode: -99.615 avegare return across last 100 episodes: -99.819 state values: tensor(0.6046) 1000
171 1000 -1000.0 -99.99568287525881 number episode from 10: 171 avegar over 10 episode: -99.617 avegare return across last 100 episodes: -99.819 state values: tensor(0.6033) 1000
172 1000 -1000.0 -99.99568287525881 number episode from 10: 172 avegar over 10 episode: -99.619 avegare return across last 100 episodes: -99.819 state values: tensor(0.6027) 1000
173 1000 -1000.0 -99.99568287525881 number episode from 10: 173 avegar over 10 episode: -99.621 avegare return across last 100 episodes: -99.819 state values: tensor(0.6016) 1000
174 1000 -1000.0 -99.99568287525881 number episode from 10: 174 avegar over 10 episode: -99.623 avegare return across last 100 episodes: -99.819 state values: tensor(0.6013) 1000
175 1000 -1000.0 -99.99568287525881 number episode from 10: 175 avegar over 10 episode: -99.625 avegare return across last 100 episodes: -99.819 state values: tensor(0.6017) 1000
176 1000 -1000.0 -99.99568287525881 number episode from 10: 176 avegar over 10 episode: -99.627 avegare return across last 100 episodes: -99.819 state values: tensor(0.6023) 1000
177 1000 -1000.0 -99.99568287525881 number episode from 10: 177 avegar over 10 episode: -99.63 avegare return across last 100 episodes: -99.819 state values: tensor(0.6049) 1000
178 1000 -1000.0 -99.99568287525881 number episode from 10: 178 avegar over 10 episode: -99.632 avegare return across last 100 episodes: -99.819 state values: tensor(0.6073) 1000
179 307 -307.0 -95.42906820057762 number episode from 10: 179 avegar over 10 episode: -99.608 avegare return across last 100 episodes: -99.773 state values: tensor(0.7873) 307
180 721 -721.0 -99.92871875034842 number episode from 10: 180 avegar over 10 episode: -99.61 avegare return across last 100 episodes: -99.773 state values: tensor(0.7249) 721
181 1000 -1000.0 -99.99568287525881 number episode from 10: 181 avegar over 10 episode: -99.612 avegare return across last 100 episodes: -99.787 state values: tensor(0.6057) 1000
182 1000 -1000.0 -99.99568287525881 number episode from 10: 182 avegar over 10 episode: -99.614 avegare return across last 100 episodes: -99.787 state values: tensor(0.6051) 1000
183 308 -308.0 -95.47477751857184 number episode from 10: 183 avegar over 10 episode: -99.592 avegare return across last 100 episodes: -99.742 state values: tensor(0.7956) 308
184 1000 -1000.0 -99.99568287525881 number episode from 10: 184 avegar over 10 episode: -99.594 avegare return across last 100 episodes: -99.742 state values: tensor(0.6020) 1000
185 1000 -1000.0 -99.99568287525881 number episode from 10: 185 avegar over 10 episode: -99.596 avegare return across last 100 episodes: -99.752 state values: tensor(0.6070) 1000
186 186 -186.0 -84.57780482061541 number episode from 10: 186 avegar over 10 episode: -99.516 avegare return across last 100 episodes: -99.598 state values: tensor(0.7527) 186
187 1000 -1000.0 -99.99568287525881 number episode from 10: 187 avegar over 10 episode: -99.518 avegare return across last 100 episodes: -99.64 state values: tensor(0.6072) 1000
188 1000 -1000.0 -99.99568287525881 number episode from 10: 188 avegar over 10 episode: -99.521 avegare return across last 100 episodes: -99.64 state values: tensor(0.6025) 1000
189 1000 -1000.0 -99.99568287525881 number episode from 10: 189 avegar over 10 episode: -99.523 avegare return across last 100 episodes: -99.64 state values: tensor(0.6038) 1000
190 446 -446.0 -98.86943173542033 number episode from 10: 190 avegar over 10 episode: -99.52 avegare return across last 100 episodes: -99.628 state values: tensor(0.7200) 446
191 566 -566.0 -99.66153003054484 number episode from 10: 191 avegar over 10 episode: -99.521 avegare return across last 100 episodes: -99.625 state values: tensor(0.7499) 566
192 1000 -1000.0 -99.99568287525881 number episode from 10: 192 avegar over 10 episode: -99.523 avegare return across last 100 episodes: -99.625 state values: tensor(0.6056) 1000
193 1000 -1000.0 -99.99568287525881 number episode from 10: 193 avegar over 10 episode: -99.526 avegare return across last 100 episodes: -99.625 state values: tensor(0.8279) 1000
194 1000 -1000.0 -99.99568287525881 number episode from 10: 194 avegar over 10 episode: -99.528 avegare return across last 100 episodes: -99.625 state values: tensor(0.6039) 1000
195 1000 -1000.0 -99.99568287525881 number episode from 10: 195 avegar over 10 episode: -99.53 avegare return across last 100 episodes: -99.625 state values: tensor(0.6046) 1000
196 1000 -1000.0 -99.99568287525881 number episode from 10: 196 avegar over 10 episode: -99.533 avegare return across last 100 episodes: -99.625 state values: tensor(0.6031) 1000
197 1000 -1000.0 -99.99568287525881 number episode from 10: 197 avegar over 10 episode: -99.535 avegare return across last 100 episodes: -99.625 state values: tensor(0.6020) 1000
198 1000 -1000.0 -99.99568287525881 number episode from 10: 198 avegar over 10 episode: -99.537 avegare return across last 100 episodes: -99.625 state values: tensor(0.6061) 1000
199 1000 -1000.0 -99.99568287525881 number episode from 10: 199 avegar over 10 episode: -99.54 avegare return across last 100 episodes: -99.625 state values: tensor(0.6014) 1000
200 1000 -1000.0 -99.99568287525881 number episode from 10: 200 avegar over 10 episode: -99.542 avegare return across last 100 episodes: -99.625 state values: tensor(0.6034) 1000
load offline data!!!!!
mem_cntr: 50000 ; mem_size: 50000
nn.learn_nn_feature_fqi FQI:  998
nn.learn_nn_feature_fqi FQI:  1998
nn.learn_nn_feature_fqi FQI:  2998
nn.learn_nn_feature_fqi FQI:  3998
nn.learn_nn_feature_fqi FQI:  4998
nn.learn_nn_feature_fqi FQI:  5998
nn.learn_nn_feature_fqi FQI:  6998
nn.learn_nn_feature_fqi FQI:  7998
nn.learn_nn_feature_fqi FQI:  8998
nn.learn_nn_feature_fqi FQI:  9998
nn.learn_nn_feature_fqi FQI:  10998
nn.learn_nn_feature_fqi FQI:  11998
nn.learn_nn_feature_fqi FQI:  12998
nn.learn_nn_feature_fqi FQI:  13998
nn.learn_nn_feature_fqi FQI:  14998
nn.learn_nn_feature_fqi FQI:  15998
nn.learn_nn_feature_fqi FQI:  16998
nn.learn_nn_feature_fqi FQI:  17998
nn.learn_nn_feature_fqi FQI:  18998
nn.learn_nn_feature_fqi FQI:  19998
nn.learn_nn_feature_fqi FQI:  20998
nn.learn_nn_feature_fqi FQI:  21998
nn.learn_nn_feature_fqi FQI:  22998
nn.learn_nn_feature_fqi FQI:  23998
nn.learn_nn_feature_fqi FQI:  24998
nn.learn_nn_feature_fqi FQI:  25998
nn.learn_nn_feature_fqi FQI:  26998
nn.learn_nn_feature_fqi FQI:  27998
nn.learn_nn_feature_fqi FQI:  28998
nn.learn_nn_feature_fqi FQI:  29998
nn.learn_nn_feature_fqi FQI:  30998
nn.learn_nn_feature_fqi FQI:  31998
nn.learn_nn_feature_fqi FQI:  32998
nn.learn_nn_feature_fqi FQI:  33998
nn.learn_nn_feature_fqi FQI:  34998
nn.learn_nn_feature_fqi FQI:  35998
nn.learn_nn_feature_fqi FQI:  36998
nn.learn_nn_feature_fqi FQI:  37998
nn.learn_nn_feature_fqi FQI:  38998
nn.learn_nn_feature_fqi FQI:  39998
nn.learn_nn_feature_fqi FQI:  40998
nn.learn_nn_feature_fqi FQI:  41998
nn.learn_nn_feature_fqi FQI:  42998
nn.learn_nn_feature_fqi FQI:  43998
nn.learn_nn_feature_fqi FQI:  44998
nn.learn_nn_feature_fqi FQI:  45998
nn.learn_nn_feature_fqi FQI:  46998
nn.learn_nn_feature_fqi FQI:  47998
nn.learn_nn_feature_fqi FQI:  48998
nn.learn_nn_feature_fqi FQI:  49998
nn.learn_nn_feature_fqi FQI:  50998
nn.learn_nn_feature_fqi FQI:  51998
nn.learn_nn_feature_fqi FQI:  52998
nn.learn_nn_feature_fqi FQI:  53998
nn.learn_nn_feature_fqi FQI:  54998
nn.learn_nn_feature_fqi FQI:  55998
nn.learn_nn_feature_fqi FQI:  56998
nn.learn_nn_feature_fqi FQI:  57998
nn.learn_nn_feature_fqi FQI:  58998
nn.learn_nn_feature_fqi FQI:  59998
nn.learn_nn_feature_fqi FQI:  60998
nn.learn_nn_feature_fqi FQI:  61998
nn.learn_nn_feature_fqi FQI:  62998
nn.learn_nn_feature_fqi FQI:  63998
nn.learn_nn_feature_fqi FQI:  64998
nn.learn_nn_feature_fqi FQI:  65998
nn.learn_nn_feature_fqi FQI:  66998
nn.learn_nn_feature_fqi FQI:  67998
nn.learn_nn_feature_fqi FQI:  68998
nn.learn_nn_feature_fqi FQI:  69998
nn.learn_nn_feature_fqi FQI:  70998
nn.learn_nn_feature_fqi FQI:  71998
nn.learn_nn_feature_fqi FQI:  72998
nn.learn_nn_feature_fqi FQI:  73998
nn.learn_nn_feature_fqi FQI:  74998
nn.learn_nn_feature_fqi FQI:  75998
nn.learn_nn_feature_fqi FQI:  76998
nn.learn_nn_feature_fqi FQI:  77998
nn.learn_nn_feature_fqi FQI:  78998
nn.learn_nn_feature_fqi FQI:  79998
nn.learn_nn_feature_fqi FQI:  80998
nn.learn_nn_feature_fqi FQI:  81998
nn.learn_nn_feature_fqi FQI:  82998
nn.learn_nn_feature_fqi FQI:  83998
nn.learn_nn_feature_fqi FQI:  84998
nn.learn_nn_feature_fqi FQI:  85998
nn.learn_nn_feature_fqi FQI:  86998
nn.learn_nn_feature_fqi FQI:  87998
nn.learn_nn_feature_fqi FQI:  88998
nn.learn_nn_feature_fqi FQI:  89998
nn.learn_nn_feature_fqi FQI:  90998
nn.learn_nn_feature_fqi FQI:  91998
nn.learn_nn_feature_fqi FQI:  92998
nn.learn_nn_feature_fqi FQI:  93998
nn.learn_nn_feature_fqi FQI:  94998
nn.learn_nn_feature_fqi FQI:  95998
nn.learn_nn_feature_fqi FQI:  96998
nn.learn_nn_feature_fqi FQI:  97998
nn.learn_nn_feature_fqi FQI:  98998
nn.learn_nn_feature_fqi FQI:  99998
nn.learn_nn_feature_fqi FQI:  100998
nn.learn_nn_feature_fqi FQI:  101998
nn.learn_nn_feature_fqi FQI:  102998
nn.learn_nn_feature_fqi FQI:  103998
nn.learn_nn_feature_fqi FQI:  104998
nn.learn_nn_feature_fqi FQI:  105998
nn.learn_nn_feature_fqi FQI:  106998
nn.learn_nn_feature_fqi FQI:  107998
nn.learn_nn_feature_fqi FQI:  108998
nn.learn_nn_feature_fqi FQI:  109998
nn.learn_nn_feature_fqi FQI:  110998
nn.learn_nn_feature_fqi FQI:  111998
nn.learn_nn_feature_fqi FQI:  112998
nn.learn_nn_feature_fqi FQI:  113998
nn.learn_nn_feature_fqi FQI:  114998
nn.learn_nn_feature_fqi FQI:  115998
nn.learn_nn_feature_fqi FQI:  116998
nn.learn_nn_feature_fqi FQI:  117998
nn.learn_nn_feature_fqi FQI:  118998
nn.learn_nn_feature_fqi FQI:  119998
nn.learn_nn_feature_fqi FQI:  120998
nn.learn_nn_feature_fqi FQI:  121998
nn.learn_nn_feature_fqi FQI:  122998
nn.learn_nn_feature_fqi FQI:  123998
nn.learn_nn_feature_fqi FQI:  124998
nn.learn_nn_feature_fqi FQI:  125998
nn.learn_nn_feature_fqi FQI:  126998
nn.learn_nn_feature_fqi FQI:  127998
nn.learn_nn_feature_fqi FQI:  128998
nn.learn_nn_feature_fqi FQI:  129998
nn.learn_nn_feature_fqi FQI:  130998
nn.learn_nn_feature_fqi FQI:  131998
nn.learn_nn_feature_fqi FQI:  132998
nn.learn_nn_feature_fqi FQI:  133998
nn.learn_nn_feature_fqi FQI:  134998
nn.learn_nn_feature_fqi FQI:  135998
nn.learn_nn_feature_fqi FQI:  136998
nn.learn_nn_feature_fqi FQI:  137998
nn.learn_nn_feature_fqi FQI:  138998
nn.learn_nn_feature_fqi FQI:  139998
nn.learn_nn_feature_fqi FQI:  140998
nn.learn_nn_feature_fqi FQI:  141998
nn.learn_nn_feature_fqi FQI:  142998
nn.learn_nn_feature_fqi FQI:  143998
nn.learn_nn_feature_fqi FQI:  144998
nn.learn_nn_feature_fqi FQI:  145998
nn.learn_nn_feature_fqi FQI:  146998
nn.learn_nn_feature_fqi FQI:  147998
nn.learn_nn_feature_fqi FQI:  148998
nn.learn_nn_feature_fqi FQI:  149998
nn.learn_nn_feature_fqi FQI:  150998
nn.learn_nn_feature_fqi FQI:  151998
nn.learn_nn_feature_fqi FQI:  152998
nn.learn_nn_feature_fqi FQI:  153998
nn.learn_nn_feature_fqi FQI:  154998
nn.learn_nn_feature_fqi FQI:  155998
0 154 -153.0 -77.72742967709803 number episode from 10: 0 avegar over 10 episode: -77.727 avegare return across last 100 episodes: -77.727 state values: tensor(0.5855) 153
1 1000 -1000.0 -99.99568287525881 number episode from 10: 1 avegar over 10 episode: -88.862 avegare return across last 100 episodes: -88.862 state values: tensor(0.4509) 1000
2 151 -151.0 -78.07627306335267 number episode from 10: 2 avegar over 10 episode: -85.266 avegare return across last 100 episodes: -85.266 state values: tensor(0.5872) 151
3 151 -151.0 -78.07627306335267 number episode from 10: 3 avegar over 10 episode: -83.469 avegare return across last 100 episodes: -83.469 state values: tensor(0.5939) 151
4 152 -152.0 -78.29551033271915 number episode from 10: 4 avegar over 10 episode: -82.434 avegare return across last 100 episodes: -82.434 state values: tensor(0.5886) 152
5 152 -152.0 -78.29551033271915 number episode from 10: 5 avegar over 10 episode: -81.744 avegare return across last 100 episodes: -81.744 state values: tensor(0.5853) 152
6 1000 -1000.0 -99.99568287525881 number episode from 10: 6 avegar over 10 episode: -84.352 avegare return across last 100 episodes: -84.352 state values: tensor(0.4506) 1000
7 152 -152.0 -78.29551033271915 number episode from 10: 7 avegar over 10 episode: -83.595 avegare return across last 100 episodes: -83.595 state values: tensor(0.5839) 152
8 161 -161.0 -80.17257434110844 number episode from 10: 8 avegar over 10 episode: -83.214 avegare return across last 100 episodes: -83.214 state values: tensor(0.5812) 161
9 284 -284.0 -94.24036097430579 number episode from 10: 9 avegar over 10 episode: -84.317 avegare return across last 100 episodes: -84.317 state values: tensor(0.5098) 284
10 154 -154.0 -78.72742967709803 number episode from 10: 10 avegar over 10 episode: -83.809 avegare return across last 100 episodes: -83.809 state values: tensor(0.5600) 154
11 1000 -1000.0 -99.99568287525881 number episode from 10: 11 avegar over 10 episode: -85.158 avegare return across last 100 episodes: -85.158 state values: tensor(0.4503) 1000
12 188 -188.0 -84.88470650468516 number episode from 10: 12 avegar over 10 episode: -85.137 avegare return across last 100 episodes: -85.137 state values: tensor(0.5614) 188
13 151 -151.0 -78.07627306335267 number episode from 10: 13 avegar over 10 episode: -84.632 avegare return across last 100 episodes: -84.632 state values: tensor(0.5904) 151
14 439 -439.0 -98.7870289705347 number episode from 10: 14 avegar over 10 episode: -85.576 avegare return across last 100 episodes: -85.576 state values: tensor(0.4947) 439
15 151 -151.0 -78.07627306335267 number episode from 10: 15 avegar over 10 episode: -85.107 avegare return across last 100 episodes: -85.107 state values: tensor(0.5904) 151
16 152 -152.0 -78.29551033271915 number episode from 10: 16 avegar over 10 episode: -84.707 avegare return across last 100 episodes: -84.707 state values: tensor(0.5871) 152
17 151 -151.0 -78.07627306335267 number episode from 10: 17 avegar over 10 episode: -84.338 avegare return across last 100 episodes: -84.338 state values: tensor(0.5914) 151
18 993 -993.0 -99.9953682166697 number episode from 10: 18 avegar over 10 episode: -85.162 avegare return across last 100 episodes: -85.162 state values: tensor(0.4695) 993
19 337 -337.0 -96.61888004123486 number episode from 10: 19 avegar over 10 episode: -85.735 avegare return across last 100 episodes: -85.735 state values: tensor(0.5066) 337
20 155 -155.0 -78.94015538032704 number episode from 10: 20 avegar over 10 episode: -85.412 avegare return across last 100 episodes: -85.412 state values: tensor(0.5715) 155
21 152 -152.0 -78.29551033271915 number episode from 10: 21 avegar over 10 episode: -85.088 avegare return across last 100 episodes: -85.088 state values: tensor(0.5980) 152
22 1000 -1000.0 -99.99568287525881 number episode from 10: 22 avegar over 10 episode: -85.736 avegare return across last 100 episodes: -85.736 state values: tensor(0.4503) 1000
23 152 -152.0 -78.29551033271915 number episode from 10: 23 avegar over 10 episode: -85.426 avegare return across last 100 episodes: -85.426 state values: tensor(0.5887) 152
24 224 -224.0 -89.47350981516395 number episode from 10: 24 avegar over 10 episode: -85.588 avegare return across last 100 episodes: -85.588 state values: tensor(0.5305) 224
25 188 -188.0 -84.88470650468516 number episode from 10: 25 avegar over 10 episode: -85.561 avegare return across last 100 episodes: -85.561 state values: tensor(0.5641) 188
26 1000 -1000.0 -99.99568287525881 number episode from 10: 26 avegar over 10 episode: -86.096 avegare return across last 100 episodes: -86.096 state values: tensor(0.4505) 1000
27 1000 -1000.0 -99.99568287525881 number episode from 10: 27 avegar over 10 episode: -86.592 avegare return across last 100 episodes: -86.592 state values: tensor(0.4506) 1000
28 154 -154.0 -78.72742967709803 number episode from 10: 28 avegar over 10 episode: -86.321 avegare return across last 100 episodes: -86.321 state values: tensor(0.5760) 154
29 1000 -1000.0 -99.99568287525881 number episode from 10: 29 avegar over 10 episode: -86.777 avegare return across last 100 episodes: -86.777 state values: tensor(0.4497) 1000
30 152 -152.0 -78.29551033271915 number episode from 10: 30 avegar over 10 episode: -86.503 avegare return across last 100 episodes: -86.503 state values: tensor(0.5885) 152
31 163 -163.0 -80.56714011172039 number episode from 10: 31 avegar over 10 episode: -86.318 avegare return across last 100 episodes: -86.318 state values: tensor(0.5796) 163
32 987 -987.0 -99.9950803175901 number episode from 10: 32 avegar over 10 episode: -86.732 avegare return across last 100 episodes: -86.732 state values: tensor(0.4692) 987
33 187 -187.0 -84.73202677240926 number episode from 10: 33 avegar over 10 episode: -86.673 avegare return across last 100 episodes: -86.673 state values: tensor(0.5616) 187
34 152 -152.0 -78.29551033271915 number episode from 10: 34 avegar over 10 episode: -86.434 avegare return across last 100 episodes: -86.434 state values: tensor(0.5885) 152
35 157 -157.0 -79.35924628825853 number episode from 10: 35 avegar over 10 episode: -86.237 avegare return across last 100 episodes: -86.237 state values: tensor(0.5822) 157
36 1000 -1000.0 -99.99568287525881 number episode from 10: 36 avegar over 10 episode: -86.609 avegare return across last 100 episodes: -86.609 state values: tensor(0.4502) 1000
37 1000 -1000.0 -99.99568287525881 number episode from 10: 37 avegar over 10 episode: -86.962 avegare return across last 100 episodes: -86.962 state values: tensor(0.4502) 1000
38 189 -189.0 -85.0358594396383 number episode from 10: 38 avegar over 10 episode: -86.912 avegare return across last 100 episodes: -86.912 state values: tensor(0.5607) 189
39 188 -188.0 -84.88470650468516 number episode from 10: 39 avegar over 10 episode: -86.862 avegare return across last 100 episodes: -86.862 state values: tensor(0.5631) 188
40 152 -152.0 -78.29551033271915 number episode from 10: 40 avegar over 10 episode: -86.653 avegare return across last 100 episodes: -86.653 state values: tensor(0.5864) 152
41 517 -517.0 -99.44614560421516 number episode from 10: 41 avegar over 10 episode: -86.957 avegare return across last 100 episodes: -86.957 state values: tensor(0.4938) 517
42 151 -151.0 -78.07627306335267 number episode from 10: 42 avegar over 10 episode: -86.751 avegare return across last 100 episodes: -86.751 state values: tensor(0.5902) 151
43 186 -186.0 -84.57780482061541 number episode from 10: 43 avegar over 10 episode: -86.701 avegare return across last 100 episodes: -86.701 state values: tensor(0.5644) 186
44 152 -152.0 -78.29551033271915 number episode from 10: 44 avegar over 10 episode: -86.514 avegare return across last 100 episodes: -86.514 state values: tensor(0.5855) 152
45 308 -308.0 -95.47477751857184 number episode from 10: 45 avegar over 10 episode: -86.709 avegare return across last 100 episodes: -86.709 state values: tensor(0.5177) 308
46 152 -152.0 -78.29551033271915 number episode from 10: 46 avegar over 10 episode: -86.53 avegare return across last 100 episodes: -86.53 state values: tensor(0.5939) 152
47 154 -154.0 -78.72742967709803 number episode from 10: 47 avegar over 10 episode: -86.368 avegare return across last 100 episodes: -86.368 state values: tensor(0.5608) 154
48 1000 -1000.0 -99.99568287525881 number episode from 10: 48 avegar over 10 episode: -86.646 avegare return across last 100 episodes: -86.646 state values: tensor(0.4506) 1000
49 1000 -1000.0 -99.99568287525881 number episode from 10: 49 avegar over 10 episode: -86.913 avegare return across last 100 episodes: -86.913 state values: tensor(0.4514) 1000
50 191 -191.0 -85.3336458367895 number episode from 10: 50 avegar over 10 episode: -86.882 avegare return across last 100 episodes: -86.882 state values: tensor(0.5565) 191
51 155 -155.0 -78.94015538032704 number episode from 10: 51 avegar over 10 episode: -86.729 avegare return across last 100 episodes: -86.729 state values: tensor(0.5797) 155
52 1000 -1000.0 -99.99568287525881 number episode from 10: 52 avegar over 10 episode: -86.979 avegare return across last 100 episodes: -86.979 state values: tensor(0.4496) 1000
53 1000 -1000.0 -99.99568287525881 number episode from 10: 53 avegar over 10 episode: -87.22 avegare return across last 100 episodes: -87.22 state values: tensor(0.4505) 1000
54 1000 -1000.0 -99.99568287525881 number episode from 10: 54 avegar over 10 episode: -87.453 avegare return across last 100 episodes: -87.453 state values: tensor(0.4501) 1000
55 191 -191.0 -85.3336458367895 number episode from 10: 55 avegar over 10 episode: -87.415 avegare return across last 100 episodes: -87.415 state values: tensor(0.5597) 191
56 830 -830.0 -99.97616519978622 number episode from 10: 56 avegar over 10 episode: -87.635 avegare return across last 100 episodes: -87.635 state values: tensor(0.4705) 830
57 1000 -1000.0 -99.99568287525881 number episode from 10: 57 avegar over 10 episode: -87.848 avegare return across last 100 episodes: -87.848 state values: tensor(0.4500) 1000
58 152 -152.0 -78.29551033271915 number episode from 10: 58 avegar over 10 episode: -87.686 avegare return across last 100 episodes: -87.686 state values: tensor(0.5850) 152
59 152 -152.0 -78.29551033271915 number episode from 10: 59 avegar over 10 episode: -87.53 avegare return across last 100 episodes: -87.53 state values: tensor(0.5860) 152
60 151 -151.0 -78.07627306335267 number episode from 10: 60 avegar over 10 episode: -87.375 avegare return across last 100 episodes: -87.375 state values: tensor(0.5910) 151
61 310 -310.0 -95.56482944595226 number episode from 10: 61 avegar over 10 episode: -87.507 avegare return across last 100 episodes: -87.507 state values: tensor(0.5134) 310
62 533 -533.0 -99.52841637065397 number episode from 10: 62 avegar over 10 episode: -87.698 avegare return across last 100 episodes: -87.698 state values: tensor(0.4913) 533
63 665 -665.0 -99.874857620838 number episode from 10: 63 avegar over 10 episode: -87.888 avegare return across last 100 episodes: -87.888 state values: tensor(0.4792) 665
64 1000 -1000.0 -99.99568287525881 number episode from 10: 64 avegar over 10 episode: -88.074 avegare return across last 100 episodes: -88.074 state values: tensor(0.4503) 1000
65 151 -151.0 -78.07627306335267 number episode from 10: 65 avegar over 10 episode: -87.923 avegare return across last 100 episodes: -87.923 state values: tensor(0.5911) 151
66 154 -154.0 -78.72742967709803 number episode from 10: 66 avegar over 10 episode: -87.786 avegare return across last 100 episodes: -87.786 state values: tensor(0.5786) 154
67 1000 -1000.0 -99.99568287525881 number episode from 10: 67 avegar over 10 episode: -87.965 avegare return across last 100 episodes: -87.965 state values: tensor(0.4507) 1000
68 1000 -1000.0 -99.99568287525881 number episode from 10: 68 avegar over 10 episode: -88.14 avegare return across last 100 episodes: -88.14 state values: tensor(0.4501) 1000
69 153 -153.0 -78.51255522939195 number episode from 10: 69 avegar over 10 episode: -88.002 avegare return across last 100 episodes: -88.002 state values: tensor(0.5981) 153
70 154 -154.0 -78.72742967709803 number episode from 10: 70 avegar over 10 episode: -87.871 avegare return across last 100 episodes: -87.871 state values: tensor(0.5692) 154
71 147 -147.0 -77.17695398646585 number episode from 10: 71 avegar over 10 episode: -87.723 avegare return across last 100 episodes: -87.723 state values: tensor(0.5755) 147
72 151 -151.0 -78.07627306335267 number episode from 10: 72 avegar over 10 episode: -87.591 avegare return across last 100 episodes: -87.591 state values: tensor(0.5906) 151
73 152 -152.0 -78.29551033271915 number episode from 10: 73 avegar over 10 episode: -87.465 avegare return across last 100 episodes: -87.465 state values: tensor(0.5861) 152
74 194 -194.0 -85.76925122179102 number episode from 10: 74 avegar over 10 episode: -87.443 avegare return across last 100 episodes: -87.443 state values: tensor(0.5607) 194
75 189 -189.0 -85.0358594396383 number episode from 10: 75 avegar over 10 episode: -87.411 avegare return across last 100 episodes: -87.411 state values: tensor(0.5450) 189
76 1000 -1000.0 -99.99568287525881 number episode from 10: 76 avegar over 10 episode: -87.574 avegare return across last 100 episodes: -87.574 state values: tensor(0.4496) 1000
77 190 -190.0 -85.18550084524192 number episode from 10: 77 avegar over 10 episode: -87.544 avegare return across last 100 episodes: -87.544 state values: tensor(0.5522) 190
78 190 -190.0 -85.18550084524192 number episode from 10: 78 avegar over 10 episode: -87.514 avegare return across last 100 episodes: -87.514 state values: tensor(0.5496) 190
79 1000 -1000.0 -99.99568287525881 number episode from 10: 79 avegar over 10 episode: -87.67 avegare return across last 100 episodes: -87.67 state values: tensor(0.4540) 1000
80 1000 -1000.0 -99.99568287525881 number episode from 10: 80 avegar over 10 episode: -87.822 avegare return across last 100 episodes: -87.822 state values: tensor(0.4506) 1000
81 151 -151.0 -78.07627306335267 number episode from 10: 81 avegar over 10 episode: -87.703 avegare return across last 100 episodes: -87.703 state values: tensor(0.5871) 151
82 199 -199.0 -86.46669950929667 number episode from 10: 82 avegar over 10 episode: -87.688 avegare return across last 100 episodes: -87.688 state values: tensor(0.5586) 199
83 1000 -1000.0 -99.99568287525881 number episode from 10: 83 avegar over 10 episode: -87.835 avegare return across last 100 episodes: -87.835 state values: tensor(0.4504) 1000
84 189 -189.0 -85.0358594396383 number episode from 10: 84 avegar over 10 episode: -87.802 avegare return across last 100 episodes: -87.802 state values: tensor(0.5550) 189
85 1000 -1000.0 -99.99568287525881 number episode from 10: 85 avegar over 10 episode: -87.944 avegare return across last 100 episodes: -87.944 state values: tensor(0.4499) 1000
86 152 -152.0 -78.29551033271915 number episode from 10: 86 avegar over 10 episode: -87.833 avegare return across last 100 episodes: -87.833 state values: tensor(0.5866) 152
87 200 -200.0 -86.6020325142037 number episode from 10: 87 avegar over 10 episode: -87.819 avegare return across last 100 episodes: -87.819 state values: tensor(0.5574) 200
88 152 -152.0 -78.29551033271915 number episode from 10: 88 avegar over 10 episode: -87.712 avegare return across last 100 episodes: -87.712 state values: tensor(0.5854) 152
89 1000 -1000.0 -99.99568287525881 number episode from 10: 89 avegar over 10 episode: -87.848 avegare return across last 100 episodes: -87.848 state values: tensor(0.4503) 1000
90 151 -151.0 -78.07627306335267 number episode from 10: 90 avegar over 10 episode: -87.741 avegare return across last 100 episodes: -87.741 state values: tensor(0.5938) 151
91 151 -151.0 -78.07627306335267 number episode from 10: 91 avegar over 10 episode: -87.636 avegare return across last 100 episodes: -87.636 state values: tensor(0.5944) 151
92 1000 -1000.0 -99.99568287525881 number episode from 10: 92 avegar over 10 episode: -87.769 avegare return across last 100 episodes: -87.769 state values: tensor(0.4510) 1000
93 154 -154.0 -78.72742967709803 number episode from 10: 93 avegar over 10 episode: -87.673 avegare return across last 100 episodes: -87.673 state values: tensor(0.5742) 154
94 200 -200.0 -86.6020325142037 number episode from 10: 94 avegar over 10 episode: -87.661 avegare return across last 100 episodes: -87.661 state values: tensor(0.5586) 200
95 376 -376.0 -97.71527902550486 number episode from 10: 95 avegar over 10 episode: -87.766 avegare return across last 100 episodes: -87.766 state values: tensor(0.5002) 376
96 1000 -1000.0 -99.99568287525881 number episode from 10: 96 avegar over 10 episode: -87.892 avegare return across last 100 episodes: -87.892 state values: tensor(0.4500) 1000
97 158 -158.0 -79.56565382537595 number episode from 10: 97 avegar over 10 episode: -87.807 avegare return across last 100 episodes: -87.807 state values: tensor(0.5817) 158
98 188 -188.0 -84.88470650468516 number episode from 10: 98 avegar over 10 episode: -87.778 avegare return across last 100 episodes: -87.778 state values: tensor(0.5516) 188
99 1000 -1000.0 -99.99568287525881 number episode from 10: 99 avegar over 10 episode: -87.9 avegare return across last 100 episodes: -87.9 state values: tensor(0.4507) 1000
100 151 -151.0 -78.07627306335267 number episode from 10: 100 avegar over 10 episode: -87.803 avegare return across last 100 episodes: -87.903 state values: tensor(0.5916) 151
101 151 -151.0 -78.07627306335267 number episode from 10: 101 avegar over 10 episode: -87.707 avegare return across last 100 episodes: -87.684 state values: tensor(0.5922) 151
102 191 -191.0 -85.3336458367895 number episode from 10: 102 avegar over 10 episode: -87.684 avegare return across last 100 episodes: -87.757 state values: tensor(0.5515) 191
103 154 -154.0 -78.72742967709803 number episode from 10: 103 avegar over 10 episode: -87.598 avegare return across last 100 episodes: -87.763 state values: tensor(0.5845) 154
104 153 -153.0 -78.51255522939195 number episode from 10: 104 avegar over 10 episode: -87.511 avegare return across last 100 episodes: -87.765 state values: tensor(0.5887) 153
105 191 -191.0 -85.3336458367895 number episode from 10: 105 avegar over 10 episode: -87.491 avegare return across last 100 episodes: -87.836 state values: tensor(0.5508) 191
106 153 -153.0 -78.51255522939195 number episode from 10: 106 avegar over 10 episode: -87.407 avegare return across last 100 episodes: -87.621 state values: tensor(0.5861) 153
107 151 -151.0 -78.07627306335267 number episode from 10: 107 avegar over 10 episode: -87.321 avegare return across last 100 episodes: -87.619 state values: tensor(0.5882) 151
108 159 -159.0 -79.76999728712218 number episode from 10: 108 avegar over 10 episode: -87.251 avegare return across last 100 episodes: -87.615 state values: tensor(0.5821) 159
109 1000 -1000.0 -99.99568287525881 number episode from 10: 109 avegar over 10 episode: -87.367 avegare return across last 100 episodes: -87.672 state values: tensor(0.4518) 1000
110 1000 -1000.0 -99.99568287525881 number episode from 10: 110 avegar over 10 episode: -87.481 avegare return across last 100 episodes: -87.885 state values: tensor(0.4501) 1000
111 1000 -1000.0 -99.99568287525881 number episode from 10: 111 avegar over 10 episode: -87.593 avegare return across last 100 episodes: -87.885 state values: tensor(0.4499) 1000
112 158 -158.0 -79.56565382537595 number episode from 10: 112 avegar over 10 episode: -87.522 avegare return across last 100 episodes: -87.832 state values: tensor(0.5815) 158
113 193 -193.0 -85.6255062846374 number episode from 10: 113 avegar over 10 episode: -87.505 avegare return across last 100 episodes: -87.907 state values: tensor(0.5535) 193
114 1000 -1000.0 -99.99568287525881 number episode from 10: 114 avegar over 10 episode: -87.614 avegare return across last 100 episodes: -87.919 state values: tensor(0.4505) 1000
115 1000 -1000.0 -99.99568287525881 number episode from 10: 115 avegar over 10 episode: -87.72 avegare return across last 100 episodes: -88.138 state values: tensor(0.4508) 1000
116 522 -522.0 -99.47328998051525 number episode from 10: 116 avegar over 10 episode: -87.821 avegare return across last 100 episodes: -88.35 state values: tensor(0.4838) 522
117 193 -193.0 -85.6255062846374 number episode from 10: 117 avegar over 10 episode: -87.802 avegare return across last 100 episodes: -88.426 state values: tensor(0.5618) 193
118 1000 -1000.0 -99.99568287525881 number episode from 10: 118 avegar over 10 episode: -87.905 avegare return across last 100 episodes: -88.426 state values: tensor(0.4505) 1000
119 157 -157.0 -79.35924628825853 number episode from 10: 119 avegar over 10 episode: -87.834 avegare return across last 100 episodes: -88.253 state values: tensor(0.5833) 157
120 296 -296.0 -94.89474310107882 number episode from 10: 120 avegar over 10 episode: -87.892 avegare return across last 100 episodes: -88.413 state values: tensor(0.5087) 296
121 194 -194.0 -85.76925122179102 number episode from 10: 121 avegar over 10 episode: -87.874 avegare return across last 100 episodes: -88.487 state values: tensor(0.5589) 194
122 886 -886.0 -99.98642366913742 number episode from 10: 122 avegar over 10 episode: -87.973 avegare return across last 100 episodes: -88.487 state values: tensor(0.4714) 886
123 1000 -1000.0 -99.99568287525881 number episode from 10: 123 avegar over 10 episode: -88.07 avegare return across last 100 episodes: -88.704 state values: tensor(0.4500) 1000
124 1000 -1000.0 -99.99568287525881 number episode from 10: 124 avegar over 10 episode: -88.165 avegare return across last 100 episodes: -88.81 state values: tensor(0.4506) 1000
125 152 -152.0 -78.29551033271915 number episode from 10: 125 avegar over 10 episode: -88.087 avegare return across last 100 episodes: -88.744 state values: tensor(0.5862) 152
126 152 -152.0 -78.29551033271915 number episode from 10: 126 avegar over 10 episode: -88.01 avegare return across last 100 episodes: -88.527 state values: tensor(0.5881) 152
127 1000 -1000.0 -99.99568287525881 number episode from 10: 127 avegar over 10 episode: -88.104 avegare return across last 100 episodes: -88.527 state values: tensor(0.4501) 1000
128 1000 -1000.0 -99.99568287525881 number episode from 10: 128 avegar over 10 episode: -88.196 avegare return across last 100 episodes: -88.739 state values: tensor(0.4504) 1000
129 188 -188.0 -84.88470650468516 number episode from 10: 129 avegar over 10 episode: -88.17 avegare return across last 100 episodes: -88.588 state values: tensor(0.5643) 188
130 152 -152.0 -78.29551033271915 number episode from 10: 130 avegar over 10 episode: -88.095 avegare return across last 100 episodes: -88.588 state values: tensor(0.5876) 152
131 627 -627.0 -99.81665586888313 number episode from 10: 131 avegar over 10 episode: -88.184 avegare return across last 100 episodes: -88.781 state values: tensor(0.4811) 627
132 189 -189.0 -85.0358594396383 number episode from 10: 132 avegar over 10 episode: -88.16 avegare return across last 100 episodes: -88.631 state values: tensor(0.5608) 189
133 151 -151.0 -78.07627306335267 number episode from 10: 133 avegar over 10 episode: -88.085 avegare return across last 100 episodes: -88.565 state values: tensor(0.5918) 151
134 153 -153.0 -78.51255522939195 number episode from 10: 134 avegar over 10 episode: -88.014 avegare return across last 100 episodes: -88.567 state values: tensor(0.5913) 153
135 190 -190.0 -85.18550084524192 number episode from 10: 135 avegar over 10 episode: -87.993 avegare return across last 100 episodes: -88.625 state values: tensor(0.5403) 190
136 1000 -1000.0 -99.99568287525881 number episode from 10: 136 avegar over 10 episode: -88.081 avegare return across last 100 episodes: -88.625 state values: tensor(0.4504) 1000
137 305 -305.0 -95.33625977000064 number episode from 10: 137 avegar over 10 episode: -88.133 avegare return across last 100 episodes: -88.578 state values: tensor(0.5028) 305
138 153 -153.0 -78.51255522939195 number episode from 10: 138 avegar over 10 episode: -88.064 avegare return across last 100 episodes: -88.513 state values: tensor(0.5982) 153
139 423 -423.0 -98.57541845216168 number episode from 10: 139 avegar over 10 episode: -88.139 avegare return across last 100 episodes: -88.65 state values: tensor(0.4948) 423
140 483 -483.0 -99.22053074347296 number episode from 10: 140 avegar over 10 episode: -88.218 avegare return across last 100 episodes: -88.859 state values: tensor(0.4877) 483
141 186 -186.0 -84.57780482061541 number episode from 10: 141 avegar over 10 episode: -88.192 avegare return across last 100 episodes: -88.711 state values: tensor(0.5662) 186
142 1000 -1000.0 -99.99568287525881 number episode from 10: 142 avegar over 10 episode: -88.275 avegare return across last 100 episodes: -88.93 state values: tensor(0.4497) 1000
143 295 -295.0 -94.84317484957457 number episode from 10: 143 avegar over 10 episode: -88.32 avegare return across last 100 episodes: -89.033 state values: tensor(0.5223) 295
144 154 -154.0 -78.72742967709803 number episode from 10: 144 avegar over 10 episode: -88.254 avegare return across last 100 episodes: -89.037 state values: tensor(0.5972) 154
145 770 -770.0 -99.95643879948237 number episode from 10: 145 avegar over 10 episode: -88.334 avegare return across last 100 episodes: -89.082 state values: tensor(0.4729) 770
146 191 -191.0 -85.3336458367895 number episode from 10: 146 avegar over 10 episode: -88.314 avegare return across last 100 episodes: -89.152 state values: tensor(0.5616) 191
147 1000 -1000.0 -99.99568287525881 number episode from 10: 147 avegar over 10 episode: -88.393 avegare return across last 100 episodes: -89.365 state values: tensor(0.4499) 1000
148 188 -188.0 -84.88470650468516 number episode from 10: 148 avegar over 10 episode: -88.369 avegare return across last 100 episodes: -89.214 state values: tensor(0.5508) 188
149 1000 -1000.0 -99.99568287525881 number episode from 10: 149 avegar over 10 episode: -88.447 avegare return across last 100 episodes: -89.214 state values: tensor(0.4535) 1000
150 152 -152.0 -78.29551033271915 number episode from 10: 150 avegar over 10 episode: -88.379 avegare return across last 100 episodes: -89.143 state values: tensor(0.5885) 152
151 1000 -1000.0 -99.99568287525881 number episode from 10: 151 avegar over 10 episode: -88.456 avegare return across last 100 episodes: -89.354 state values: tensor(0.4500) 1000
152 195 -195.0 -85.91155870957311 number episode from 10: 152 avegar over 10 episode: -88.439 avegare return across last 100 episodes: -89.213 state values: tensor(0.5586) 195
153 197 -197.0 -86.19191869125261 number episode from 10: 153 avegar over 10 episode: -88.425 avegare return across last 100 episodes: -89.075 state values: tensor(0.5576) 197
154 152 -152.0 -78.29551033271915 number episode from 10: 154 avegar over 10 episode: -88.359 avegare return across last 100 episodes: -88.858 state values: tensor(0.5929) 152
155 190 -190.0 -85.18550084524192 number episode from 10: 155 avegar over 10 episode: -88.339 avegare return across last 100 episodes: -88.856 state values: tensor(0.5557) 190
156 189 -189.0 -85.0358594396383 number episode from 10: 156 avegar over 10 episode: -88.318 avegare return across last 100 episodes: -88.707 state values: tensor(0.5565) 189
157 443 -443.0 -98.83482486885005 number episode from 10: 157 avegar over 10 episode: -88.384 avegare return across last 100 episodes: -88.695 state values: tensor(0.4931) 443
158 153 -153.0 -78.51255522939195 number episode from 10: 158 avegar over 10 episode: -88.322 avegare return across last 100 episodes: -88.698 state values: tensor(0.5845) 153
159 153 -153.0 -78.51255522939195 number episode from 10: 159 avegar over 10 episode: -88.261 avegare return across last 100 episodes: -88.7 state values: tensor(0.5905) 153
160 151 -151.0 -78.07627306335267 number episode from 10: 160 avegar over 10 episode: -88.198 avegare return across last 100 episodes: -88.7 state values: tensor(0.5909) 151
161 154 -154.0 -78.72742967709803 number episode from 10: 161 avegar over 10 episode: -88.139 avegare return across last 100 episodes: -88.531 state values: tensor(0.5855) 154
162 775 -775.0 -99.95857373174603 number episode from 10: 162 avegar over 10 episode: -88.212 avegare return across last 100 episodes: -88.536 state values: tensor(0.4755) 775
163 151 -151.0 -78.07627306335267 number episode from 10: 163 avegar over 10 episode: -88.15 avegare return across last 100 episodes: -88.318 state values: tensor(0.5873) 151
164 190 -190.0 -85.18550084524192 number episode from 10: 164 avegar over 10 episode: -88.132 avegare return across last 100 episodes: -88.17 state values: tensor(0.5402) 190
165 153 -153.0 -78.51255522939195 number episode from 10: 165 avegar over 10 episode: -88.074 avegare return across last 100 episodes: -88.174 state values: tensor(0.5842) 153
166 151 -151.0 -78.07627306335267 number episode from 10: 166 avegar over 10 episode: -88.014 avegare return across last 100 episodes: -88.167 state values: tensor(0.5879) 151
167 656 -656.0 -99.86301038157 number episode from 10: 167 avegar over 10 episode: -88.085 avegare return across last 100 episodes: -88.166 state values: tensor(0.4799) 656
168 222 -222.0 -89.25977942573611 number episode from 10: 168 avegar over 10 episode: -88.092 avegare return across last 100 episodes: -88.059 state values: tensor(0.5219) 222
169 192 -192.0 -85.48030937842161 number episode from 10: 169 avegar over 10 episode: -88.076 avegare return across last 100 episodes: -88.128 state values: tensor(0.5494) 192
170 1000 -1000.0 -99.99568287525881 number episode from 10: 170 avegar over 10 episode: -88.146 avegare return across last 100 episodes: -88.341 state values: tensor(0.4500) 1000
171 151 -151.0 -78.07627306335267 number episode from 10: 171 avegar over 10 episode: -88.088 avegare return across last 100 episodes: -88.35 state values: tensor(0.5915) 151
172 539 -539.0 -99.55601337418824 number episode from 10: 172 avegar over 10 episode: -88.154 avegare return across last 100 episodes: -88.565 state values: tensor(0.4838) 539
173 153 -153.0 -78.51255522939195 number episode from 10: 173 avegar over 10 episode: -88.098 avegare return across last 100 episodes: -88.567 state values: tensor(0.5850) 153
174 153 -153.0 -78.51255522939195 number episode from 10: 174 avegar over 10 episode: -88.044 avegare return across last 100 episodes: -88.495 state values: tensor(0.5842) 153
175 158 -158.0 -79.56565382537595 number episode from 10: 175 avegar over 10 episode: -87.996 avegare return across last 100 episodes: -88.44 state values: tensor(0.5816) 158
176 151 -151.0 -78.07627306335267 number episode from 10: 176 avegar over 10 episode: -87.939 avegare return across last 100 episodes: -88.221 state values: tensor(0.5899) 151
177 728 -728.0 -99.93356121724426 number episode from 10: 177 avegar over 10 episode: -88.007 avegare return across last 100 episodes: -88.368 state values: tensor(0.4783) 728
178 154 -154.0 -78.72742967709803 number episode from 10: 178 avegar over 10 episode: -87.955 avegare return across last 100 episodes: -88.304 state values: tensor(0.5712) 154
179 152 -152.0 -78.29551033271915 number episode from 10: 179 avegar over 10 episode: -87.901 avegare return across last 100 episodes: -88.087 state values: tensor(0.5882) 152
180 158 -158.0 -79.56565382537595 number episode from 10: 180 avegar over 10 episode: -87.855 avegare return across last 100 episodes: -87.882 state values: tensor(0.5814) 158
181 151 -151.0 -78.07627306335267 number episode from 10: 181 avegar over 10 episode: -87.802 avegare return across last 100 episodes: -87.882 state values: tensor(0.5915) 151
182 1000 -1000.0 -99.99568287525881 number episode from 10: 182 avegar over 10 episode: -87.868 avegare return across last 100 episodes: -88.018 state values: tensor(0.4502) 1000
183 627 -627.0 -99.81665586888313 number episode from 10: 183 avegar over 10 episode: -87.933 avegare return across last 100 episodes: -88.016 state values: tensor(0.4857) 627
184 933 -933.0 -99.99153481293767 number episode from 10: 184 avegar over 10 episode: -87.998 avegare return across last 100 episodes: -88.165 state values: tensor(0.4689) 933
185 163 -163.0 -80.56714011172039 number episode from 10: 185 avegar over 10 episode: -87.958 avegare return across last 100 episodes: -87.971 state values: tensor(0.5784) 163
186 152 -152.0 -78.29551033271915 number episode from 10: 186 avegar over 10 episode: -87.907 avegare return across last 100 episodes: -87.971 state values: tensor(0.5881) 152
187 188 -188.0 -84.88470650468516 number episode from 10: 187 avegar over 10 episode: -87.891 avegare return across last 100 episodes: -87.954 state values: tensor(0.5616) 188
188 869 -869.0 -99.983894133117 number episode from 10: 188 avegar over 10 episode: -87.955 avegare return across last 100 episodes: -88.171 state values: tensor(0.4701) 869
189 612 -612.0 -99.78682361478448 number episode from 10: 189 avegar over 10 episode: -88.017 avegare return across last 100 episodes: -88.169 state values: tensor(0.4796) 612
190 186 -186.0 -84.57780482061541 number episode from 10: 190 avegar over 10 episode: -87.999 avegare return across last 100 episodes: -88.234 state values: tensor(0.5639) 186
191 186 -186.0 -84.57780482061541 number episode from 10: 191 avegar over 10 episode: -87.981 avegare return across last 100 episodes: -88.299 state values: tensor(0.5644) 186
192 864 -864.0 -99.98306410578672 number episode from 10: 192 avegar over 10 episode: -88.043 avegare return across last 100 episodes: -88.299 state values: tensor(0.4688) 864
193 193 -193.0 -85.6255062846374 number episode from 10: 193 avegar over 10 episode: -88.031 avegare return across last 100 episodes: -88.367 state values: tensor(0.5596) 193
194 1000 -1000.0 -99.99568287525881 number episode from 10: 194 avegar over 10 episode: -88.092 avegare return across last 100 episodes: -88.501 state values: tensor(0.4499) 1000
195 1000 -1000.0 -99.99568287525881 number episode from 10: 195 avegar over 10 episode: -88.153 avegare return across last 100 episodes: -88.524 state values: tensor(0.4506) 1000
196 446 -446.0 -98.86943173542033 number episode from 10: 196 avegar over 10 episode: -88.207 avegare return across last 100 episodes: -88.513 state values: tensor(0.4921) 446
197 152 -152.0 -78.29551033271915 number episode from 10: 197 avegar over 10 episode: -88.157 avegare return across last 100 episodes: -88.5 state values: tensor(0.5675) 152
198 190 -190.0 -85.18550084524192 number episode from 10: 198 avegar over 10 episode: -88.142 avegare return across last 100 episodes: -88.503 state values: tensor(0.5608) 190
199 187 -187.0 -84.73202677240926 number episode from 10: 199 avegar over 10 episode: -88.125 avegare return across last 100 episodes: -88.351 state values: tensor(0.5625) 187
200 152 -152.0 -78.29551033271915 number episode from 10: 200 avegar over 10 episode: -88.076 avegare return across last 100 episodes: -88.353 state values: tensor(0.5888) 152
load offline data!!!!!
mem_cntr: 50000 ; mem_size: 50000
nn.learn_nn_feature_fqi FQI:  998
nn.learn_nn_feature_fqi FQI:  1998
nn.learn_nn_feature_fqi FQI:  2998
nn.learn_nn_feature_fqi FQI:  3998
nn.learn_nn_feature_fqi FQI:  4998
nn.learn_nn_feature_fqi FQI:  5998
nn.learn_nn_feature_fqi FQI:  6998
nn.learn_nn_feature_fqi FQI:  7998
nn.learn_nn_feature_fqi FQI:  8998
nn.learn_nn_feature_fqi FQI:  9998
nn.learn_nn_feature_fqi FQI:  10998
nn.learn_nn_feature_fqi FQI:  11998
nn.learn_nn_feature_fqi FQI:  12998
nn.learn_nn_feature_fqi FQI:  13998
nn.learn_nn_feature_fqi FQI:  14998
nn.learn_nn_feature_fqi FQI:  15998
nn.learn_nn_feature_fqi FQI:  16998
nn.learn_nn_feature_fqi FQI:  17998
nn.learn_nn_feature_fqi FQI:  18998
nn.learn_nn_feature_fqi FQI:  19998
nn.learn_nn_feature_fqi FQI:  20998
nn.learn_nn_feature_fqi FQI:  21998
nn.learn_nn_feature_fqi FQI:  22998
nn.learn_nn_feature_fqi FQI:  23998
nn.learn_nn_feature_fqi FQI:  24998
nn.learn_nn_feature_fqi FQI:  25998
nn.learn_nn_feature_fqi FQI:  26998
nn.learn_nn_feature_fqi FQI:  27998
nn.learn_nn_feature_fqi FQI:  28998
nn.learn_nn_feature_fqi FQI:  29998
nn.learn_nn_feature_fqi FQI:  30998
nn.learn_nn_feature_fqi FQI:  31998
nn.learn_nn_feature_fqi FQI:  32998
nn.learn_nn_feature_fqi FQI:  33998
nn.learn_nn_feature_fqi FQI:  34998
nn.learn_nn_feature_fqi FQI:  35998
nn.learn_nn_feature_fqi FQI:  36998
nn.learn_nn_feature_fqi FQI:  37998
nn.learn_nn_feature_fqi FQI:  38998
nn.learn_nn_feature_fqi FQI:  39998
nn.learn_nn_feature_fqi FQI:  40998
nn.learn_nn_feature_fqi FQI:  41998
nn.learn_nn_feature_fqi FQI:  42998
nn.learn_nn_feature_fqi FQI:  43998
nn.learn_nn_feature_fqi FQI:  44998
nn.learn_nn_feature_fqi FQI:  45998
nn.learn_nn_feature_fqi FQI:  46998
nn.learn_nn_feature_fqi FQI:  47998
nn.learn_nn_feature_fqi FQI:  48998
nn.learn_nn_feature_fqi FQI:  49998
nn.learn_nn_feature_fqi FQI:  50998
nn.learn_nn_feature_fqi FQI:  51998
nn.learn_nn_feature_fqi FQI:  52998
nn.learn_nn_feature_fqi FQI:  53998
nn.learn_nn_feature_fqi FQI:  54998
nn.learn_nn_feature_fqi FQI:  55998
nn.learn_nn_feature_fqi FQI:  56998
nn.learn_nn_feature_fqi FQI:  57998
nn.learn_nn_feature_fqi FQI:  58998
nn.learn_nn_feature_fqi FQI:  59998
nn.learn_nn_feature_fqi FQI:  60998
nn.learn_nn_feature_fqi FQI:  61998
nn.learn_nn_feature_fqi FQI:  62998
nn.learn_nn_feature_fqi FQI:  63998
nn.learn_nn_feature_fqi FQI:  64998
nn.learn_nn_feature_fqi FQI:  65998
nn.learn_nn_feature_fqi FQI:  66998
nn.learn_nn_feature_fqi FQI:  67998
nn.learn_nn_feature_fqi FQI:  68998
nn.learn_nn_feature_fqi FQI:  69998
nn.learn_nn_feature_fqi FQI:  70998
nn.learn_nn_feature_fqi FQI:  71998
nn.learn_nn_feature_fqi FQI:  72998
nn.learn_nn_feature_fqi FQI:  73998
nn.learn_nn_feature_fqi FQI:  74998
nn.learn_nn_feature_fqi FQI:  75998
nn.learn_nn_feature_fqi FQI:  76998
nn.learn_nn_feature_fqi FQI:  77998
nn.learn_nn_feature_fqi FQI:  78998
nn.learn_nn_feature_fqi FQI:  79998
nn.learn_nn_feature_fqi FQI:  80998
nn.learn_nn_feature_fqi FQI:  81998
nn.learn_nn_feature_fqi FQI:  82998
nn.learn_nn_feature_fqi FQI:  83998
nn.learn_nn_feature_fqi FQI:  84998
nn.learn_nn_feature_fqi FQI:  85998
nn.learn_nn_feature_fqi FQI:  86998
nn.learn_nn_feature_fqi FQI:  87998
nn.learn_nn_feature_fqi FQI:  88998
nn.learn_nn_feature_fqi FQI:  89998
nn.learn_nn_feature_fqi FQI:  90998
nn.learn_nn_feature_fqi FQI:  91998
nn.learn_nn_feature_fqi FQI:  92998
nn.learn_nn_feature_fqi FQI:  93998
nn.learn_nn_feature_fqi FQI:  94998
nn.learn_nn_feature_fqi FQI:  95998
nn.learn_nn_feature_fqi FQI:  96998
nn.learn_nn_feature_fqi FQI:  97998
nn.learn_nn_feature_fqi FQI:  98998
nn.learn_nn_feature_fqi FQI:  99998
nn.learn_nn_feature_fqi FQI:  100998
nn.learn_nn_feature_fqi FQI:  101998
nn.learn_nn_feature_fqi FQI:  102998
nn.learn_nn_feature_fqi FQI:  103998
nn.learn_nn_feature_fqi FQI:  104998
nn.learn_nn_feature_fqi FQI:  105998
nn.learn_nn_feature_fqi FQI:  106998
nn.learn_nn_feature_fqi FQI:  107998
nn.learn_nn_feature_fqi FQI:  108998
nn.learn_nn_feature_fqi FQI:  109998
nn.learn_nn_feature_fqi FQI:  110998
nn.learn_nn_feature_fqi FQI:  111998
nn.learn_nn_feature_fqi FQI:  112998
nn.learn_nn_feature_fqi FQI:  113998
nn.learn_nn_feature_fqi FQI:  114998
nn.learn_nn_feature_fqi FQI:  115998
nn.learn_nn_feature_fqi FQI:  116998
nn.learn_nn_feature_fqi FQI:  117998
nn.learn_nn_feature_fqi FQI:  118998
nn.learn_nn_feature_fqi FQI:  119998
nn.learn_nn_feature_fqi FQI:  120998
nn.learn_nn_feature_fqi FQI:  121998
nn.learn_nn_feature_fqi FQI:  122998
nn.learn_nn_feature_fqi FQI:  123998
nn.learn_nn_feature_fqi FQI:  124998
nn.learn_nn_feature_fqi FQI:  125998
nn.learn_nn_feature_fqi FQI:  126998
nn.learn_nn_feature_fqi FQI:  127998
nn.learn_nn_feature_fqi FQI:  128998
nn.learn_nn_feature_fqi FQI:  129998
nn.learn_nn_feature_fqi FQI:  130998
nn.learn_nn_feature_fqi FQI:  131998
nn.learn_nn_feature_fqi FQI:  132998
nn.learn_nn_feature_fqi FQI:  133998
nn.learn_nn_feature_fqi FQI:  134998
nn.learn_nn_feature_fqi FQI:  135998
nn.learn_nn_feature_fqi FQI:  136998
nn.learn_nn_feature_fqi FQI:  137998
nn.learn_nn_feature_fqi FQI:  138998
nn.learn_nn_feature_fqi FQI:  139998
nn.learn_nn_feature_fqi FQI:  140998
nn.learn_nn_feature_fqi FQI:  141998
nn.learn_nn_feature_fqi FQI:  142998
nn.learn_nn_feature_fqi FQI:  143998
nn.learn_nn_feature_fqi FQI:  144998
nn.learn_nn_feature_fqi FQI:  145998
nn.learn_nn_feature_fqi FQI:  146998
nn.learn_nn_feature_fqi FQI:  147998
nn.learn_nn_feature_fqi FQI:  148998
nn.learn_nn_feature_fqi FQI:  149998
nn.learn_nn_feature_fqi FQI:  150998
nn.learn_nn_feature_fqi FQI:  151998
nn.learn_nn_feature_fqi FQI:  152998
nn.learn_nn_feature_fqi FQI:  153998
nn.learn_nn_feature_fqi FQI:  154998
nn.learn_nn_feature_fqi FQI:  155998
0 1001 -1000.0 -98.99572604650622 number episode from 10: 0 avegar over 10 episode: -98.996 avegare return across last 100 episodes: -98.996 state values: tensor(0.7679) 1000
1 1000 -1000.0 -99.99568287525881 number episode from 10: 1 avegar over 10 episode: -99.496 avegare return across last 100 episodes: -99.496 state values: tensor(0.7786) 1000
2 1000 -1000.0 -99.99568287525881 number episode from 10: 2 avegar over 10 episode: -99.662 avegare return across last 100 episodes: -99.662 state values: tensor(0.7735) 1000
3 1000 -1000.0 -99.99568287525881 number episode from 10: 3 avegar over 10 episode: -99.746 avegare return across last 100 episodes: -99.746 state values: tensor(0.7755) 1000
4 1000 -1000.0 -99.99568287525881 number episode from 10: 4 avegar over 10 episode: -99.796 avegare return across last 100 episodes: -99.796 state values: tensor(0.7652) 1000
5 1000 -1000.0 -99.99568287525881 number episode from 10: 5 avegar over 10 episode: -99.829 avegare return across last 100 episodes: -99.829 state values: tensor(0.7692) 1000
6 1000 -1000.0 -99.99568287525881 number episode from 10: 6 avegar over 10 episode: -99.853 avegare return across last 100 episodes: -99.853 state values: tensor(0.7673) 1000
7 1000 -1000.0 -99.99568287525881 number episode from 10: 7 avegar over 10 episode: -99.871 avegare return across last 100 episodes: -99.871 state values: tensor(0.7786) 1000
8 1000 -1000.0 -99.99568287525881 number episode from 10: 8 avegar over 10 episode: -99.885 avegare return across last 100 episodes: -99.885 state values: tensor(0.7749) 1000
9 1000 -1000.0 -99.99568287525881 number episode from 10: 9 avegar over 10 episode: -99.896 avegare return across last 100 episodes: -99.896 state values: tensor(0.7703) 1000
10 1000 -1000.0 -99.99568287525881 number episode from 10: 10 avegar over 10 episode: -99.905 avegare return across last 100 episodes: -99.905 state values: tensor(0.7727) 1000
11 1000 -1000.0 -99.99568287525881 number episode from 10: 11 avegar over 10 episode: -99.912 avegare return across last 100 episodes: -99.912 state values: tensor(0.7785) 1000
12 1000 -1000.0 -99.99568287525881 number episode from 10: 12 avegar over 10 episode: -99.919 avegare return across last 100 episodes: -99.919 state values: tensor(0.7647) 1000
13 1000 -1000.0 -99.99568287525881 number episode from 10: 13 avegar over 10 episode: -99.924 avegare return across last 100 episodes: -99.924 state values: tensor(0.7772) 1000
14 1000 -1000.0 -99.99568287525881 number episode from 10: 14 avegar over 10 episode: -99.929 avegare return across last 100 episodes: -99.929 state values: tensor(0.7649) 1000
15 1000 -1000.0 -99.99568287525881 number episode from 10: 15 avegar over 10 episode: -99.933 avegare return across last 100 episodes: -99.933 state values: tensor(0.7665) 1000
16 1000 -1000.0 -99.99568287525881 number episode from 10: 16 avegar over 10 episode: -99.937 avegare return across last 100 episodes: -99.937 state values: tensor(0.7750) 1000
17 1000 -1000.0 -99.99568287525881 number episode from 10: 17 avegar over 10 episode: -99.94 avegare return across last 100 episodes: -99.94 state values: tensor(0.7671) 1000
18 1000 -1000.0 -99.99568287525881 number episode from 10: 18 avegar over 10 episode: -99.943 avegare return across last 100 episodes: -99.943 state values: tensor(0.7744) 1000
19 1000 -1000.0 -99.99568287525881 number episode from 10: 19 avegar over 10 episode: -99.946 avegare return across last 100 episodes: -99.946 state values: tensor(0.7803) 1000
20 1000 -1000.0 -99.99568287525881 number episode from 10: 20 avegar over 10 episode: -99.948 avegare return across last 100 episodes: -99.948 state values: tensor(0.7678) 1000
21 1000 -1000.0 -99.99568287525881 number episode from 10: 21 avegar over 10 episode: -99.95 avegare return across last 100 episodes: -99.95 state values: tensor(0.7726) 1000
22 1000 -1000.0 -99.99568287525881 number episode from 10: 22 avegar over 10 episode: -99.952 avegare return across last 100 episodes: -99.952 state values: tensor(0.7711) 1000
23 347 -347.0 -96.94217571583829 number episode from 10: 23 avegar over 10 episode: -99.827 avegare return across last 100 episodes: -99.827 state values: tensor(0.7570) 347
24 1000 -1000.0 -99.99568287525881 number episode from 10: 24 avegar over 10 episode: -99.834 avegare return across last 100 episodes: -99.834 state values: tensor(0.7770) 1000
25 1000 -1000.0 -99.99568287525881 number episode from 10: 25 avegar over 10 episode: -99.84 avegare return across last 100 episodes: -99.84 state values: tensor(0.7759) 1000
26 1000 -1000.0 -99.99568287525881 number episode from 10: 26 avegar over 10 episode: -99.846 avegare return across last 100 episodes: -99.846 state values: tensor(0.7724) 1000
27 1000 -1000.0 -99.99568287525881 number episode from 10: 27 avegar over 10 episode: -99.851 avegare return across last 100 episodes: -99.851 state values: tensor(0.7654) 1000
28 1000 -1000.0 -99.99568287525881 number episode from 10: 28 avegar over 10 episode: -99.856 avegare return across last 100 episodes: -99.856 state values: tensor(0.7604) 1000
29 726 -726.0 -99.93221224083692 number episode from 10: 29 avegar over 10 episode: -99.858 avegare return across last 100 episodes: -99.858 state values: tensor(0.7796) 726
30 1000 -1000.0 -99.99568287525881 number episode from 10: 30 avegar over 10 episode: -99.863 avegare return across last 100 episodes: -99.863 state values: tensor(0.7730) 1000
31 1000 -1000.0 -99.99568287525881 number episode from 10: 31 avegar over 10 episode: -99.867 avegare return across last 100 episodes: -99.867 state values: tensor(0.7723) 1000
32 1000 -1000.0 -99.99568287525881 number episode from 10: 32 avegar over 10 episode: -99.871 avegare return across last 100 episodes: -99.871 state values: tensor(0.7679) 1000
33 1000 -1000.0 -99.99568287525881 number episode from 10: 33 avegar over 10 episode: -99.875 avegare return across last 100 episodes: -99.875 state values: tensor(0.7732) 1000
34 1000 -1000.0 -99.99568287525881 number episode from 10: 34 avegar over 10 episode: -99.878 avegare return across last 100 episodes: -99.878 state values: tensor(0.7651) 1000
35 786 -786.0 -99.96290947730104 number episode from 10: 35 avegar over 10 episode: -99.88 avegare return across last 100 episodes: -99.88 state values: tensor(0.7705) 786
36 1000 -1000.0 -99.99568287525881 number episode from 10: 36 avegar over 10 episode: -99.884 avegare return across last 100 episodes: -99.884 state values: tensor(0.7745) 1000
37 1000 -1000.0 -99.99568287525881 number episode from 10: 37 avegar over 10 episode: -99.886 avegare return across last 100 episodes: -99.886 state values: tensor(0.7678) 1000
38 1000 -1000.0 -99.99568287525881 number episode from 10: 38 avegar over 10 episode: -99.889 avegare return across last 100 episodes: -99.889 state values: tensor(0.7688) 1000
39 1000 -1000.0 -99.99568287525881 number episode from 10: 39 avegar over 10 episode: -99.892 avegare return across last 100 episodes: -99.892 state values: tensor(0.7633) 1000
40 1000 -1000.0 -99.99568287525881 number episode from 10: 40 avegar over 10 episode: -99.894 avegare return across last 100 episodes: -99.894 state values: tensor(0.7718) 1000
41 1000 -1000.0 -99.99568287525881 number episode from 10: 41 avegar over 10 episode: -99.897 avegare return across last 100 episodes: -99.897 state values: tensor(0.7728) 1000
42 1000 -1000.0 -99.99568287525881 number episode from 10: 42 avegar over 10 episode: -99.899 avegare return across last 100 episodes: -99.899 state values: tensor(0.7714) 1000
43 1000 -1000.0 -99.99568287525881 number episode from 10: 43 avegar over 10 episode: -99.901 avegare return across last 100 episodes: -99.901 state values: tensor(0.7664) 1000
44 1000 -1000.0 -99.99568287525881 number episode from 10: 44 avegar over 10 episode: -99.903 avegare return across last 100 episodes: -99.903 state values: tensor(0.7689) 1000
45 1000 -1000.0 -99.99568287525881 number episode from 10: 45 avegar over 10 episode: -99.905 avegare return across last 100 episodes: -99.905 state values: tensor(0.7770) 1000
46 1000 -1000.0 -99.99568287525881 number episode from 10: 46 avegar over 10 episode: -99.907 avegare return across last 100 episodes: -99.907 state values: tensor(0.7702) 1000
47 1000 -1000.0 -99.99568287525881 number episode from 10: 47 avegar over 10 episode: -99.909 avegare return across last 100 episodes: -99.909 state values: tensor(0.7697) 1000
48 1000 -1000.0 -99.99568287525881 number episode from 10: 48 avegar over 10 episode: -99.911 avegare return across last 100 episodes: -99.911 state values: tensor(0.7693) 1000
49 1000 -1000.0 -99.99568287525881 number episode from 10: 49 avegar over 10 episode: -99.913 avegare return across last 100 episodes: -99.913 state values: tensor(0.7692) 1000
50 1000 -1000.0 -99.99568287525881 number episode from 10: 50 avegar over 10 episode: -99.914 avegare return across last 100 episodes: -99.914 state values: tensor(0.7673) 1000
51 1000 -1000.0 -99.99568287525881 number episode from 10: 51 avegar over 10 episode: -99.916 avegare return across last 100 episodes: -99.916 state values: tensor(0.7652) 1000
52 1000 -1000.0 -99.99568287525881 number episode from 10: 52 avegar over 10 episode: -99.917 avegare return across last 100 episodes: -99.917 state values: tensor(0.7663) 1000
53 1000 -1000.0 -99.99568287525881 number episode from 10: 53 avegar over 10 episode: -99.919 avegare return across last 100 episodes: -99.919 state values: tensor(0.7671) 1000
54 1000 -1000.0 -99.99568287525881 number episode from 10: 54 avegar over 10 episode: -99.92 avegare return across last 100 episodes: -99.92 state values: tensor(0.7729) 1000
55 1000 -1000.0 -99.99568287525881 number episode from 10: 55 avegar over 10 episode: -99.922 avegare return across last 100 episodes: -99.922 state values: tensor(0.7675) 1000
56 1000 -1000.0 -99.99568287525881 number episode from 10: 56 avegar over 10 episode: -99.923 avegare return across last 100 episodes: -99.923 state values: tensor(0.7701) 1000
57 1000 -1000.0 -99.99568287525881 number episode from 10: 57 avegar over 10 episode: -99.924 avegare return across last 100 episodes: -99.924 state values: tensor(0.7774) 1000
58 1000 -1000.0 -99.99568287525881 number episode from 10: 58 avegar over 10 episode: -99.925 avegare return across last 100 episodes: -99.925 state values: tensor(0.7783) 1000
59 1000 -1000.0 -99.99568287525881 number episode from 10: 59 avegar over 10 episode: -99.927 avegare return across last 100 episodes: -99.927 state values: tensor(0.7719) 1000
60 779 -779.0 -99.96020609200605 number episode from 10: 60 avegar over 10 episode: -99.927 avegare return across last 100 episodes: -99.927 state values: tensor(0.7613) 779
61 1000 -1000.0 -99.99568287525881 number episode from 10: 61 avegar over 10 episode: -99.928 avegare return across last 100 episodes: -99.928 state values: tensor(0.7688) 1000
62 1000 -1000.0 -99.99568287525881 number episode from 10: 62 avegar over 10 episode: -99.929 avegare return across last 100 episodes: -99.929 state values: tensor(0.7681) 1000
63 1000 -1000.0 -99.99568287525881 number episode from 10: 63 avegar over 10 episode: -99.93 avegare return across last 100 episodes: -99.93 state values: tensor(0.7638) 1000
64 523 -523.0 -99.47855708071009 number episode from 10: 64 avegar over 10 episode: -99.923 avegare return across last 100 episodes: -99.923 state values: tensor(0.7569) 523
65 1000 -1000.0 -99.99568287525881 number episode from 10: 65 avegar over 10 episode: -99.924 avegare return across last 100 episodes: -99.924 state values: tensor(0.7635) 1000
66 1000 -1000.0 -99.99568287525881 number episode from 10: 66 avegar over 10 episode: -99.925 avegare return across last 100 episodes: -99.925 state values: tensor(0.7737) 1000
67 710 -710.0 -99.9203862346856 number episode from 10: 67 avegar over 10 episode: -99.925 avegare return across last 100 episodes: -99.925 state values: tensor(0.7719) 710
68 1000 -1000.0 -99.99568287525881 number episode from 10: 68 avegar over 10 episode: -99.926 avegare return across last 100 episodes: -99.926 state values: tensor(0.7734) 1000
69 1000 -1000.0 -99.99568287525881 number episode from 10: 69 avegar over 10 episode: -99.927 avegare return across last 100 episodes: -99.927 state values: tensor(0.7723) 1000
70 1000 -1000.0 -99.99568287525881 number episode from 10: 70 avegar over 10 episode: -99.928 avegare return across last 100 episodes: -99.928 state values: tensor(0.7644) 1000
71 1000 -1000.0 -99.99568287525881 number episode from 10: 71 avegar over 10 episode: -99.929 avegare return across last 100 episodes: -99.929 state values: tensor(0.7724) 1000
72 708 -708.0 -99.91876975276564 number episode from 10: 72 avegar over 10 episode: -99.929 avegare return across last 100 episodes: -99.929 state values: tensor(0.7667) 708
73 1000 -1000.0 -99.99568287525881 number episode from 10: 73 avegar over 10 episode: -99.93 avegare return across last 100 episodes: -99.93 state values: tensor(0.7713) 1000
74 1000 -1000.0 -99.99568287525881 number episode from 10: 74 avegar over 10 episode: -99.931 avegare return across last 100 episodes: -99.931 state values: tensor(0.7712) 1000
75 1000 -1000.0 -99.99568287525881 number episode from 10: 75 avegar over 10 episode: -99.932 avegare return across last 100 episodes: -99.932 state values: tensor(0.7646) 1000
76 1000 -1000.0 -99.99568287525881 number episode from 10: 76 avegar over 10 episode: -99.933 avegare return across last 100 episodes: -99.933 state values: tensor(0.7664) 1000
77 1000 -1000.0 -99.99568287525881 number episode from 10: 77 avegar over 10 episode: -99.933 avegare return across last 100 episodes: -99.933 state values: tensor(0.7601) 1000
78 1000 -1000.0 -99.99568287525881 number episode from 10: 78 avegar over 10 episode: -99.934 avegare return across last 100 episodes: -99.934 state values: tensor(0.7716) 1000
79 1000 -1000.0 -99.99568287525881 number episode from 10: 79 avegar over 10 episode: -99.935 avegare return across last 100 episodes: -99.935 state values: tensor(0.7602) 1000
80 1000 -1000.0 -99.99568287525881 number episode from 10: 80 avegar over 10 episode: -99.936 avegare return across last 100 episodes: -99.936 state values: tensor(0.7650) 1000
81 1000 -1000.0 -99.99568287525881 number episode from 10: 81 avegar over 10 episode: -99.936 avegare return across last 100 episodes: -99.936 state values: tensor(0.7658) 1000
82 1000 -1000.0 -99.99568287525881 number episode from 10: 82 avegar over 10 episode: -99.937 avegare return across last 100 episodes: -99.937 state values: tensor(0.7623) 1000
83 1000 -1000.0 -99.99568287525881 number episode from 10: 83 avegar over 10 episode: -99.938 avegare return across last 100 episodes: -99.938 state values: tensor(0.7694) 1000
84 1000 -1000.0 -99.99568287525881 number episode from 10: 84 avegar over 10 episode: -99.939 avegare return across last 100 episodes: -99.939 state values: tensor(0.7603) 1000
85 1000 -1000.0 -99.99568287525881 number episode from 10: 85 avegar over 10 episode: -99.939 avegare return across last 100 episodes: -99.939 state values: tensor(0.7622) 1000
86 249 -249.0 -91.81227109472904 number episode from 10: 86 avegar over 10 episode: -99.846 avegare return across last 100 episodes: -99.846 state values: tensor(0.7119) 249
87 1000 -1000.0 -99.99568287525881 number episode from 10: 87 avegar over 10 episode: -99.848 avegare return across last 100 episodes: -99.848 state values: tensor(0.7645) 1000
88 1000 -1000.0 -99.99568287525881 number episode from 10: 88 avegar over 10 episode: -99.849 avegare return across last 100 episodes: -99.849 state values: tensor(0.7753) 1000
89 1000 -1000.0 -99.99568287525881 number episode from 10: 89 avegar over 10 episode: -99.851 avegare return across last 100 episodes: -99.851 state values: tensor(0.7673) 1000
90 1000 -1000.0 -99.99568287525881 number episode from 10: 90 avegar over 10 episode: -99.852 avegare return across last 100 episodes: -99.852 state values: tensor(0.7766) 1000
91 1000 -1000.0 -99.99568287525881 number episode from 10: 91 avegar over 10 episode: -99.854 avegare return across last 100 episodes: -99.854 state values: tensor(0.7714) 1000
92 1000 -1000.0 -99.99568287525881 number episode from 10: 92 avegar over 10 episode: -99.855 avegare return across last 100 episodes: -99.855 state values: tensor(0.7647) 1000
93 1000 -1000.0 -99.99568287525881 number episode from 10: 93 avegar over 10 episode: -99.857 avegare return across last 100 episodes: -99.857 state values: tensor(0.7629) 1000
94 1000 -1000.0 -99.99568287525881 number episode from 10: 94 avegar over 10 episode: -99.858 avegare return across last 100 episodes: -99.858 state values: tensor(0.7725) 1000
95 1000 -1000.0 -99.99568287525881 number episode from 10: 95 avegar over 10 episode: -99.86 avegare return across last 100 episodes: -99.86 state values: tensor(0.7721) 1000
96 1000 -1000.0 -99.99568287525881 number episode from 10: 96 avegar over 10 episode: -99.861 avegare return across last 100 episodes: -99.861 state values: tensor(0.7720) 1000
97 1000 -1000.0 -99.99568287525881 number episode from 10: 97 avegar over 10 episode: -99.863 avegare return across last 100 episodes: -99.863 state values: tensor(0.7769) 1000
98 1000 -1000.0 -99.99568287525881 number episode from 10: 98 avegar over 10 episode: -99.864 avegare return across last 100 episodes: -99.864 state values: tensor(0.7693) 1000
99 1000 -1000.0 -99.99568287525881 number episode from 10: 99 avegar over 10 episode: -99.865 avegare return across last 100 episodes: -99.865 state values: tensor(0.7768) 1000
100 1000 -1000.0 -99.99568287525881 number episode from 10: 100 avegar over 10 episode: -99.867 avegare return across last 100 episodes: -99.875 state values: tensor(0.7781) 1000
101 1000 -1000.0 -99.99568287525881 number episode from 10: 101 avegar over 10 episode: -99.868 avegare return across last 100 episodes: -99.875 state values: tensor(0.7656) 1000
102 1000 -1000.0 -99.99568287525881 number episode from 10: 102 avegar over 10 episode: -99.869 avegare return across last 100 episodes: -99.875 state values: tensor(0.7638) 1000
103 1000 -1000.0 -99.99568287525881 number episode from 10: 103 avegar over 10 episode: -99.87 avegare return across last 100 episodes: -99.875 state values: tensor(0.7692) 1000
104 1000 -1000.0 -99.99568287525881 number episode from 10: 104 avegar over 10 episode: -99.872 avegare return across last 100 episodes: -99.875 state values: tensor(0.7723) 1000
105 1000 -1000.0 -99.99568287525881 number episode from 10: 105 avegar over 10 episode: -99.873 avegare return across last 100 episodes: -99.875 state values: tensor(0.7699) 1000
106 1000 -1000.0 -99.99568287525881 number episode from 10: 106 avegar over 10 episode: -99.874 avegare return across last 100 episodes: -99.875 state values: tensor(0.7745) 1000
107 1000 -1000.0 -99.99568287525881 number episode from 10: 107 avegar over 10 episode: -99.875 avegare return across last 100 episodes: -99.875 state values: tensor(0.7690) 1000
108 1000 -1000.0 -99.99568287525881 number episode from 10: 108 avegar over 10 episode: -99.876 avegare return across last 100 episodes: -99.875 state values: tensor(0.7700) 1000
109 1000 -1000.0 -99.99568287525881 number episode from 10: 109 avegar over 10 episode: -99.877 avegare return across last 100 episodes: -99.875 state values: tensor(0.7665) 1000
110 1000 -1000.0 -99.99568287525881 number episode from 10: 110 avegar over 10 episode: -99.878 avegare return across last 100 episodes: -99.875 state values: tensor(0.7643) 1000
111 1000 -1000.0 -99.99568287525881 number episode from 10: 111 avegar over 10 episode: -99.879 avegare return across last 100 episodes: -99.875 state values: tensor(0.7668) 1000
112 1000 -1000.0 -99.99568287525881 number episode from 10: 112 avegar over 10 episode: -99.88 avegare return across last 100 episodes: -99.875 state values: tensor(0.7750) 1000
113 1000 -1000.0 -99.99568287525881 number episode from 10: 113 avegar over 10 episode: -99.881 avegare return across last 100 episodes: -99.875 state values: tensor(0.7565) 1000
114 1000 -1000.0 -99.99568287525881 number episode from 10: 114 avegar over 10 episode: -99.882 avegare return across last 100 episodes: -99.875 state values: tensor(0.7698) 1000
115 1000 -1000.0 -99.99568287525881 number episode from 10: 115 avegar over 10 episode: -99.883 avegare return across last 100 episodes: -99.875 state values: tensor(0.7713) 1000
116 1000 -1000.0 -99.99568287525881 number episode from 10: 116 avegar over 10 episode: -99.884 avegare return across last 100 episodes: -99.875 state values: tensor(0.7664) 1000
117 1000 -1000.0 -99.99568287525881 number episode from 10: 117 avegar over 10 episode: -99.885 avegare return across last 100 episodes: -99.875 state values: tensor(0.7649) 1000
118 1000 -1000.0 -99.99568287525881 number episode from 10: 118 avegar over 10 episode: -99.886 avegare return across last 100 episodes: -99.875 state values: tensor(0.7714) 1000
119 1000 -1000.0 -99.99568287525881 number episode from 10: 119 avegar over 10 episode: -99.887 avegare return across last 100 episodes: -99.875 state values: tensor(0.7713) 1000
120 790 -790.0 -99.96437099188657 number episode from 10: 120 avegar over 10 episode: -99.888 avegare return across last 100 episodes: -99.875 state values: tensor(0.7699) 790
121 1000 -1000.0 -99.99568287525881 number episode from 10: 121 avegar over 10 episode: -99.889 avegare return across last 100 episodes: -99.875 state values: tensor(0.7644) 1000
122 1000 -1000.0 -99.99568287525881 number episode from 10: 122 avegar over 10 episode: -99.889 avegare return across last 100 episodes: -99.875 state values: tensor(0.7690) 1000
123 1000 -1000.0 -99.99568287525881 number episode from 10: 123 avegar over 10 episode: -99.89 avegare return across last 100 episodes: -99.906 state values: tensor(0.7689) 1000
124 1000 -1000.0 -99.99568287525881 number episode from 10: 124 avegar over 10 episode: -99.891 avegare return across last 100 episodes: -99.906 state values: tensor(0.7721) 1000
125 1000 -1000.0 -99.99568287525881 number episode from 10: 125 avegar over 10 episode: -99.892 avegare return across last 100 episodes: -99.906 state values: tensor(0.7690) 1000
126 1000 -1000.0 -99.99568287525881 number episode from 10: 126 avegar over 10 episode: -99.893 avegare return across last 100 episodes: -99.906 state values: tensor(0.7809) 1000
127 1000 -1000.0 -99.99568287525881 number episode from 10: 127 avegar over 10 episode: -99.894 avegare return across last 100 episodes: -99.906 state values: tensor(0.7729) 1000
128 1000 -1000.0 -99.99568287525881 number episode from 10: 128 avegar over 10 episode: -99.894 avegare return across last 100 episodes: -99.906 state values: tensor(0.7662) 1000
129 801 -801.0 -99.96809998607473 number episode from 10: 129 avegar over 10 episode: -99.895 avegare return across last 100 episodes: -99.906 state values: tensor(0.7765) 801
130 1000 -1000.0 -99.99568287525881 number episode from 10: 130 avegar over 10 episode: -99.896 avegare return across last 100 episodes: -99.906 state values: tensor(0.7703) 1000
131 1000 -1000.0 -99.99568287525881 number episode from 10: 131 avegar over 10 episode: -99.896 avegare return across last 100 episodes: -99.906 state values: tensor(0.7665) 1000
132 1000 -1000.0 -99.99568287525881 number episode from 10: 132 avegar over 10 episode: -99.897 avegare return across last 100 episodes: -99.906 state values: tensor(0.7688) 1000
133 1000 -1000.0 -99.99568287525881 number episode from 10: 133 avegar over 10 episode: -99.898 avegare return across last 100 episodes: -99.906 state values: tensor(0.7678) 1000
134 1000 -1000.0 -99.99568287525881 number episode from 10: 134 avegar over 10 episode: -99.899 avegare return across last 100 episodes: -99.906 state values: tensor(0.7794) 1000
135 1000 -1000.0 -99.99568287525881 number episode from 10: 135 avegar over 10 episode: -99.899 avegare return across last 100 episodes: -99.906 state values: tensor(0.7814) 1000
136 1000 -1000.0 -99.99568287525881 number episode from 10: 136 avegar over 10 episode: -99.9 avegare return across last 100 episodes: -99.906 state values: tensor(0.7684) 1000
137 1000 -1000.0 -99.99568287525881 number episode from 10: 137 avegar over 10 episode: -99.901 avegare return across last 100 episodes: -99.906 state values: tensor(0.7706) 1000
138 1000 -1000.0 -99.99568287525881 number episode from 10: 138 avegar over 10 episode: -99.901 avegare return across last 100 episodes: -99.906 state values: tensor(0.7751) 1000
139 1000 -1000.0 -99.99568287525881 number episode from 10: 139 avegar over 10 episode: -99.902 avegare return across last 100 episodes: -99.906 state values: tensor(0.7772) 1000
140 1000 -1000.0 -99.99568287525881 number episode from 10: 140 avegar over 10 episode: -99.903 avegare return across last 100 episodes: -99.906 state values: tensor(0.7573) 1000
141 1000 -1000.0 -99.99568287525881 number episode from 10: 141 avegar over 10 episode: -99.903 avegare return across last 100 episodes: -99.906 state values: tensor(0.7696) 1000
142 1000 -1000.0 -99.99568287525881 number episode from 10: 142 avegar over 10 episode: -99.904 avegare return across last 100 episodes: -99.906 state values: tensor(0.7773) 1000
143 1000 -1000.0 -99.99568287525881 number episode from 10: 143 avegar over 10 episode: -99.905 avegare return across last 100 episodes: -99.906 state values: tensor(0.7765) 1000
144 1000 -1000.0 -99.99568287525881 number episode from 10: 144 avegar over 10 episode: -99.905 avegare return across last 100 episodes: -99.906 state values: tensor(0.7775) 1000
145 1000 -1000.0 -99.99568287525881 number episode from 10: 145 avegar over 10 episode: -99.906 avegare return across last 100 episodes: -99.906 state values: tensor(0.7760) 1000
146 1000 -1000.0 -99.99568287525881 number episode from 10: 146 avegar over 10 episode: -99.907 avegare return across last 100 episodes: -99.906 state values: tensor(0.7760) 1000
147 1000 -1000.0 -99.99568287525881 number episode from 10: 147 avegar over 10 episode: -99.907 avegare return across last 100 episodes: -99.906 state values: tensor(0.7687) 1000
148 1000 -1000.0 -99.99568287525881 number episode from 10: 148 avegar over 10 episode: -99.908 avegare return across last 100 episodes: -99.906 state values: tensor(0.7644) 1000
149 1000 -1000.0 -99.99568287525881 number episode from 10: 149 avegar over 10 episode: -99.908 avegare return across last 100 episodes: -99.906 state values: tensor(0.7649) 1000
150 1000 -1000.0 -99.99568287525881 number episode from 10: 150 avegar over 10 episode: -99.909 avegare return across last 100 episodes: -99.906 state values: tensor(0.7655) 1000
151 1000 -1000.0 -99.99568287525881 number episode from 10: 151 avegar over 10 episode: -99.91 avegare return across last 100 episodes: -99.906 state values: tensor(0.7695) 1000
152 1000 -1000.0 -99.99568287525881 number episode from 10: 152 avegar over 10 episode: -99.91 avegare return across last 100 episodes: -99.906 state values: tensor(0.7753) 1000
153 1000 -1000.0 -99.99568287525881 number episode from 10: 153 avegar over 10 episode: -99.911 avegare return across last 100 episodes: -99.906 state values: tensor(0.7697) 1000
154 1000 -1000.0 -99.99568287525881 number episode from 10: 154 avegar over 10 episode: -99.911 avegare return across last 100 episodes: -99.906 state values: tensor(0.7708) 1000
155 1000 -1000.0 -99.99568287525881 number episode from 10: 155 avegar over 10 episode: -99.912 avegare return across last 100 episodes: -99.906 state values: tensor(0.7753) 1000
156 1000 -1000.0 -99.99568287525881 number episode from 10: 156 avegar over 10 episode: -99.912 avegare return across last 100 episodes: -99.906 state values: tensor(0.7687) 1000
157 1000 -1000.0 -99.99568287525881 number episode from 10: 157 avegar over 10 episode: -99.913 avegare return across last 100 episodes: -99.906 state values: tensor(0.7733) 1000
158 1000 -1000.0 -99.99568287525881 number episode from 10: 158 avegar over 10 episode: -99.913 avegare return across last 100 episodes: -99.906 state values: tensor(0.7793) 1000
159 1000 -1000.0 -99.99568287525881 number episode from 10: 159 avegar over 10 episode: -99.914 avegare return across last 100 episodes: -99.906 state values: tensor(0.7773) 1000
160 1000 -1000.0 -99.99568287525881 number episode from 10: 160 avegar over 10 episode: -99.914 avegare return across last 100 episodes: -99.907 state values: tensor(0.7627) 1000
161 1000 -1000.0 -99.99568287525881 number episode from 10: 161 avegar over 10 episode: -99.915 avegare return across last 100 episodes: -99.907 state values: tensor(0.7719) 1000
162 1000 -1000.0 -99.99568287525881 number episode from 10: 162 avegar over 10 episode: -99.915 avegare return across last 100 episodes: -99.907 state values: tensor(0.7630) 1000
163 1000 -1000.0 -99.99568287525881 number episode from 10: 163 avegar over 10 episode: -99.916 avegare return across last 100 episodes: -99.907 state values: tensor(0.7748) 1000
164 1000 -1000.0 -99.99568287525881 number episode from 10: 164 avegar over 10 episode: -99.916 avegare return across last 100 episodes: -99.912 state values: tensor(0.7687) 1000
165 1000 -1000.0 -99.99568287525881 number episode from 10: 165 avegar over 10 episode: -99.917 avegare return across last 100 episodes: -99.912 state values: tensor(0.7639) 1000
166 1000 -1000.0 -99.99568287525881 number episode from 10: 166 avegar over 10 episode: -99.917 avegare return across last 100 episodes: -99.912 state values: tensor(0.7820) 1000
167 1000 -1000.0 -99.99568287525881 number episode from 10: 167 avegar over 10 episode: -99.918 avegare return across last 100 episodes: -99.912 state values: tensor(0.7765) 1000
168 1000 -1000.0 -99.99568287525881 number episode from 10: 168 avegar over 10 episode: -99.918 avegare return across last 100 episodes: -99.912 state values: tensor(0.7737) 1000
169 1000 -1000.0 -99.99568287525881 number episode from 10: 169 avegar over 10 episode: -99.919 avegare return across last 100 episodes: -99.912 state values: tensor(0.7830) 1000
170 258 -258.0 -92.52036842731464 number episode from 10: 170 avegar over 10 episode: -99.875 avegare return across last 100 episodes: -99.838 state values: tensor(0.7214) 258
171 1000 -1000.0 -99.99568287525881 number episode from 10: 171 avegar over 10 episode: -99.876 avegare return across last 100 episodes: -99.838 state values: tensor(0.7732) 1000
172 1000 -1000.0 -99.99568287525881 number episode from 10: 172 avegar over 10 episode: -99.877 avegare return across last 100 episodes: -99.839 state values: tensor(0.7736) 1000
173 1000 -1000.0 -99.99568287525881 number episode from 10: 173 avegar over 10 episode: -99.877 avegare return across last 100 episodes: -99.839 state values: tensor(0.7764) 1000
174 1000 -1000.0 -99.99568287525881 number episode from 10: 174 avegar over 10 episode: -99.878 avegare return across last 100 episodes: -99.839 state values: tensor(0.7704) 1000
175 1000 -1000.0 -99.99568287525881 number episode from 10: 175 avegar over 10 episode: -99.879 avegare return across last 100 episodes: -99.839 state values: tensor(0.7773) 1000
176 1000 -1000.0 -99.99568287525881 number episode from 10: 176 avegar over 10 episode: -99.879 avegare return across last 100 episodes: -99.839 state values: tensor(0.7723) 1000
177 1000 -1000.0 -99.99568287525881 number episode from 10: 177 avegar over 10 episode: -99.88 avegare return across last 100 episodes: -99.839 state values: tensor(0.7708) 1000
178 1000 -1000.0 -99.99568287525881 number episode from 10: 178 avegar over 10 episode: -99.881 avegare return across last 100 episodes: -99.839 state values: tensor(0.7715) 1000
179 1000 -1000.0 -99.99568287525881 number episode from 10: 179 avegar over 10 episode: -99.881 avegare return across last 100 episodes: -99.839 state values: tensor(0.7764) 1000
180 1000 -1000.0 -99.99568287525881 number episode from 10: 180 avegar over 10 episode: -99.882 avegare return across last 100 episodes: -99.839 state values: tensor(0.7432) 1000
181 1000 -1000.0 -99.99568287525881 number episode from 10: 181 avegar over 10 episode: -99.883 avegare return across last 100 episodes: -99.839 state values: tensor(0.7700) 1000
182 1000 -1000.0 -99.99568287525881 number episode from 10: 182 avegar over 10 episode: -99.883 avegare return across last 100 episodes: -99.839 state values: tensor(0.7681) 1000
183 1000 -1000.0 -99.99568287525881 number episode from 10: 183 avegar over 10 episode: -99.884 avegare return across last 100 episodes: -99.839 state values: tensor(0.7687) 1000
184 1000 -1000.0 -99.99568287525881 number episode from 10: 184 avegar over 10 episode: -99.884 avegare return across last 100 episodes: -99.839 state values: tensor(0.7691) 1000
185 1000 -1000.0 -99.99568287525881 number episode from 10: 185 avegar over 10 episode: -99.885 avegare return across last 100 episodes: -99.839 state values: tensor(0.7674) 1000
186 1000 -1000.0 -99.99568287525881 number episode from 10: 186 avegar over 10 episode: -99.886 avegare return across last 100 episodes: -99.92 state values: tensor(0.7704) 1000
187 1000 -1000.0 -99.99568287525881 number episode from 10: 187 avegar over 10 episode: -99.886 avegare return across last 100 episodes: -99.92 state values: tensor(0.7715) 1000
188 1000 -1000.0 -99.99568287525881 number episode from 10: 188 avegar over 10 episode: -99.887 avegare return across last 100 episodes: -99.92 state values: tensor(0.7683) 1000
189 1000 -1000.0 -99.99568287525881 number episode from 10: 189 avegar over 10 episode: -99.887 avegare return across last 100 episodes: -99.92 state values: tensor(0.7681) 1000
190 1000 -1000.0 -99.99568287525881 number episode from 10: 190 avegar over 10 episode: -99.888 avegare return across last 100 episodes: -99.92 state values: tensor(0.7691) 1000
191 1000 -1000.0 -99.99568287525881 number episode from 10: 191 avegar over 10 episode: -99.889 avegare return across last 100 episodes: -99.92 state values: tensor(0.7698) 1000
192 1000 -1000.0 -99.99568287525881 number episode from 10: 192 avegar over 10 episode: -99.889 avegare return across last 100 episodes: -99.92 state values: tensor(0.7680) 1000
193 1000 -1000.0 -99.99568287525881 number episode from 10: 193 avegar over 10 episode: -99.89 avegare return across last 100 episodes: -99.92 state values: tensor(0.7719) 1000
194 1000 -1000.0 -99.99568287525881 number episode from 10: 194 avegar over 10 episode: -99.89 avegare return across last 100 episodes: -99.92 state values: tensor(0.7774) 1000
195 1000 -1000.0 -99.99568287525881 number episode from 10: 195 avegar over 10 episode: -99.891 avegare return across last 100 episodes: -99.92 state values: tensor(0.7728) 1000
196 1000 -1000.0 -99.99568287525881 number episode from 10: 196 avegar over 10 episode: -99.891 avegare return across last 100 episodes: -99.92 state values: tensor(0.7675) 1000
197 1000 -1000.0 -99.99568287525881 number episode from 10: 197 avegar over 10 episode: -99.892 avegare return across last 100 episodes: -99.92 state values: tensor(0.7730) 1000
198 1000 -1000.0 -99.99568287525881 number episode from 10: 198 avegar over 10 episode: -99.892 avegare return across last 100 episodes: -99.92 state values: tensor(0.7709) 1000
199 1000 -1000.0 -99.99568287525881 number episode from 10: 199 avegar over 10 episode: -99.893 avegare return across last 100 episodes: -99.92 state values: tensor(0.7756) 1000
200 1000 -1000.0 -99.99568287525881 number episode from 10: 200 avegar over 10 episode: -99.893 avegare return across last 100 episodes: -99.92 state values: tensor(0.7577) 1000
